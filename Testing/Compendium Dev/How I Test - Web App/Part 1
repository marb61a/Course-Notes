                    How I Test - Web App
                    Course Notes Part 1


Introduction
How I Test - Web App Case Study - Introduction
  - This course is a case study
  - It is equivalent to about a day of testing
  - This will be a practical course rather than extensive theory
  - This is because with each application we will only ever use subsets of our knowledge
  - The aim of the course is to take specific lessons from 1 app
    - And then see how they could be reused is other tests on other applications

Debrief Intro
  - A short, 'live' intro to the course and the testing approach.
  - In order to work as an actual practical course
    - The instructor is going to think through testing a web app from start to finish.

Choosing the Right Person for the Job
But what I’m really talking about is the notion that I had to choose which application I was going
to test and I did that based on my technical knowledge, my understanding of
the web, my understanding of open source applications, my knowledge. So I’m
choosing the right application for me but in the real world, this translates into
choosing the right person for the job. So I’ve chosen Tracks not because I’ve
used it before, although I have so my familiarity with it before, means I know
that it’s a web app, it’s got a lot of JavaScript, it has an API as a database.
There’s a lot of scope for testing, there’s a lot of richness in there. So Tracks
is an open source To Do management system where you create actions, next
actions, you put them into context i.e, Where are you going to do them?
And you can create projects for them and you can set reminders and it’s a To
Do app based on, and Dave Allen’s Getting Things Done methodology. But
ignoring the domain, it’s a very useful open source app that I think is very easy
to instal because I can download, a virtual machine or Docker and use it that
way. So I’m using Tracks and I have used it before but it’s been so long since
I used it and previously I’ve looked at different parts in the application. So
every time we approach a different app, an application, we will learn something
different. Going macro to this, like most of the time we don’t get to choose what
we test because we’d be working in environments, we’re working in companies,
there’ll be a manager, the manager will choose what we work on. But the thing
is we influence that because we have skills and experience and some of our skills
and experience and domain knowledge will not translate into some applications.
So we will not be suitable people to test that without additional training or
without offering a risk essentially to the project. Because we may not know
what we’re doing. And if I have to test a Hadoop app and I really need to
work on a team that really understands Hadoop because I will be learning that
from scratch. So I’ve done consultancy on Hadoop teams but I was relying on
their massive amounts of technical knowledge, me reading around the subject,
conducting experiments from me, asking them questions when they didn’t know
the answer so we can deep dive into it. Me applying my technical testing domain
knowledge onto their project and mixing it that way. So we have to combine
the right people at the right time to have the right team mix. This can be hard
when you’re in management. Any of you that are in management will know
that this can be hard because someone that you need on a project may not be
available because they’re on another project and you’re trying to juggle things
around and projects get delayed and put people off.
So that means we have to have some slack in our teams, or we as managers
have to have the ability to support people or know that there’ll be supported
on the team. 
  - Sometimes we allocate people to teams because of their soft skills
    - Their personality and how they will fit into that team. 
    - This is a key lesson, we have to choose the right people for the right technology
      - for the right job, otherwise there’s a risk. 
    - Else there is a process that means we have to manage it to make sure that they understand what they were doing. 
    - So that is a tiny, tiny lesson, but it is massive. 
  - What is test management. 
    - Choosing the right person for the job. 
  - What is our career management? 
    - Making sure we have the skills we need for the job. 
    - This is absolutely key to what we do, but at a micro level is choosing a particular application to test.


Choosing an Environment
I chose the environment based on my anticipated needs for testing, and based on my experience. If we can't manage our environments and if it restricts our testing, then that is a risk.
Install and Getting Started
Install Session Debrief
A debrief of my first install session.
Releases and Deployments
A description of my first session and the lessons learned for releases and deployments.
Health Check Session Description
A description of a health check session.
Healthcheck Session Debrief
A debrief of the healthcheck session, recorded very soon after the health check was performed. With demo of the app and additional nuance descriptions of the testing.
Course Slides

What to Test?
 Choosing What To Test - Intro
 An overview of test basis and using it to plan testing holistically.
 Why We Plan
 A slide based overview of why we plan - to know what to do, and what we have discounted. A short planning session can set us up for a long time.
 Session Debrief - Planning Session
 A 'very soon after the testing' debrief session for the planning session. Where I outline the thought processes for the planning session.
 Planning to Test Holistically
 A meta analysis of the planning session with additional thoughts of how this fits into Agile Processes and how to evaluated projects for risks to help target your testing.
 Recon Session
 What is a Recon Session
 An overview of a recon session and why we would perform one.
 Recon Session Debrief
 A debrief session conducted very soon after the testing to describe the results of the recon session. Highlights benefits of capturing evidence as we test. Also showing some examples of the system state constraints and testing performed based on the notes that I took. Explaining how my tooling was limiting my testing.
 Recon Session Meta Analysis
 Slide based overview of the recon session which is a short process to help us adjust our approach to better target the application.
 Debrief Session
 Debrief Session
 A 'live' debrief session looking at the exact notes taken. Recorded immediately after the debrief session.
 Debrief Meta Analysis
 Description of why debriefs are important and lessons learned from my note taking and debriefs.
 Modelling Session
 Modelling And Planning Session Debrief
 An overview of my modelling and planning session recorded immediately after my modelling session. With a discussion of the model representations I used.
 An Overview and Lessons learned from Modelling
 An overview of the modelling process and why it is important, with lessons learned from this session and general modelling experience.
 Planning And Modelling Meta Analysis
 Discussion of my planning approach and how differences in approach and timing impact our planning depth.
 Coverage Session
 Coverage Session Introduction
 An introduction to a coverage session where I am more focussed on coverage scope, than identifying new coverage and ideas through exploration.
 Coverage Session Debrief
 Explanation of the coverage session with a walkthrough of my notes and explanation of the tools used. Explaining the expansion of the coverage model during the session.
 Coverage Sessions Lessons Learned
 A summary of the lessons learned from a coverage system.
 Issues and Tooling
 About Issues
 Examining the defect to think through when it might be found. The identification of the requirements and edge cases that would lead to the identification is an exploratory process.
 What drives tooling?
 People are often more interested in what tooling we use, than what process and thinking we use. But thinking through what drives our tooling choices is important.
 Technical Exploratory Session
 Introduction to a Technical Exploratory Session
 An overview of an Exploratory Session and discussing the nuance of a Technical Exploratory Session
 Technical Exploratory Session Debrief
 Debrief recorded immediately after conducting a technical exploratory session, showing the tools used and why I used them.
 Technical Session Macro Summary and Lessons
 A high level overview of lessons learned from the technical session.
 Conclusions
 Additional Activities
 What did I not do? Automating. Short description of how I would approach that. And additional lessons learned. Admin. Description of typical admin processes and how I would approach them.
 Basic Testing Flow Used
 An explanatory summary of the basic testing flow that I used in this process.
 Summary of Testing, Tooling, Bugs, Exploration and Coverage
 Looking back over all sessions and summarising key lessons learned.
 Final Notes
 Why the course was built the way it was and why I didn't show the live test sessions. With an encouragement for you to test and identify your unique approach to testing.
