                    ISTQB Certified Tester Foundation Level
                    Course Notes Part 51
                    
                    
  - Modeling tools can also check state models or object models. 
  - They are particularly useful in complex system architectures. 
  - Examples of modeling tools include visual modeling, database, state, and object modeling tools.
  - The tools available for test specification are
    - Test design tools
    - Test data preparation tools
  - Test design tools help in generating test inputs. 
  - When an automated oracle or test basis is available
    - Test design tools also help generate test cases with the expected results. 
    - This is why many design tools are integrated with other tools such as test management tools
      - Requirements management tools, static tools, and modeling tools. 
      - The details of a test basis are already available in these other tools.
  - There are different types of test design tools with varied levels of automation. 
  - The levels are dependent upon the characteristics of the design tool 
    - And the way the test basis is recorded in the tool.

Some types of test design tools are

tools where test cases with inputs and expected results are generated using specifications in a formal language
tools that generate tests based on a GUI model of the test basis
tools that generate a partially completed template from the requirement specifications held in narrative form
tests that can verify that the model has been built correctly and derive some test cases
Data preparation tools help you collect data, such as fictitious names and addresses, for creating test cases. They are especially useful when you need to collect an extensive volume of data for testing.

Test data preparation tools can generate the data used in tests. They can also select and transfer live data from an existing database and modify it for use in tests. The data acceptable for use can be in a wide range of database formats and files.

The test data preparation tools are used by developers as well as testers during performance and reliability testing. They may also be used for system or acceptance testing.

Test data preparation tools help in

generating new records with random or guidelines-related data
sorting or rearranging existing records differently
extracting selected data records from files or databases
using a template to construct a large number of similar records for volume tests
modifying data records for data protection so they cannot be connected to real people

Tools for Test Execution, Logging, and Monitoring
Using test execution and logging tools
  - As well as providing support for managing tests, test specifications, and static testing
    - There are other activities such as test execution and logging, and performance and monitoring
    - That can be supported with the use of tools. 
    - To help you perform these activities more efficiently, you have tools that help you execute tests
      - Compare them, and keep them secure. You also have tools to help you monitor a software or system being used
        - And evaluate its performance in real time.

Some types of tools that enable you to execute and log test cases are

test execution tools
test harness/unit test framework tools
test comparators
coverage measurement tools
security tools
Some test execution tools, which are also called capture/playback tools, help you to automatically run test scripts and record their results in a test log.

A test script is a file that is used to test software and compare the actual results to the expected results.

Test execution tools enable you to

store expected results for comparison when the test is run again
execute tests from stored scripts and data files accessed by scripts
compare test elements dynamically and post execution
record test timings and test results
send results to test management tools
A test script is essentially program code, and programming skills are required to write or modify scripts. However, many test execution tools facilitate script generation by capturing and recording a tester's or user's manual actions as lines of script. These scripts can then be automated to run repeatedly on the same software module, or modified by a script programmer to utilize different data inputs or to run on different software modules.

However, it is recommended that you don't reuse a captured test script as a long term testing solution because it is likely to be valid only within the exact condition in which it was captured.

Suppose, you record a test script and find that the data values of the original test are embedded in the script itself. This will prevent you from using the original script for another component effectively. While this script can be modified to make it work in most cases, doing so will cause unanticipated delays.

Or, suppose you play back a recorded test script. You then run the risk of the time from the original test being displayed in the current playback. This will result in confusing a test comparator and causing a comparison test to fail.

Test execution tools are especially useful when you need to repeat a test performed earlier for a similar application. For example, you may be able to use a script that captures standard personal details in a number of different software applications.

Though test execution tools are usually used in many forms of testing, they are best suited for regression testing. Here, old tests are rerun to ensure that changes made to an existing system have not altered the functioning of the system.

When used in the medium and long term, the costs of using test execution tools for regression testing decrease. After a point, the costs of automated regression testing become lower than the costs of manual regression testing.

In the graph, the point where the lines converge and cross is the point when the costs of regression testing using test execution tools equal the costs of manual regression testing. In the long run, test execution tools enable you to perform regression tests with better speed and accuracy. They also enable you to avoid manual errors both during execution and during comparison. You can use the time saved to work on the other test-related activities.

A test harness is a test environment that simulates aspects of the production environment in which a software component will eventually run. The test harness contains small programs such as stubs and drivers that interact with the software being tested. Stubs and drivers are examples of unit test framework tools. They are typically skeletal programs designed specifically to call, provide input to, or accept output from, the software modules being tested.

Test harnesses can be programmed in-house using 'XUnit' tools. For instance, you can create a .NET based test harness using an 'NUnit' tool. You can also obtain free source or commercial versions of test harnesses.

A test harness is best used during component or integration testing when parts of the system may be incomplete. Developers usually use test harnesses to test, identify, and localize defects during development.

Test harnesses and unit test framework tools enable you to

provide input and receive output from the software being tested
store and execute tests within the framework and record the results of each test
provide support for debugging
measure coverage at code level
Test comparators compare what the software produces to what the software is expected to produce and store the results either as part of the test case or as computed through a test oracle. For instance, suppose you are executing a test expecting a particular error to be returned during the test. The test execution tool returns an error, but it is not the one you expected. Then to catch the difference and report it, you will use a test comparator.

Test comparators are usually included with the test execution tools and are particularly helpful for regression testing cases.

Your organization is transferring information from an existing database to a new database. You need to check if the data from tables in the old database was transferred into tables of the new database accurately. If done manually, performing this comparison check would take a very long time. But, using the test comparator, you would be able to automate the comparison in a fraction of the time a manual check would take. You could also run the test comparator dynamically during the transfer to issue an alert if any new data appears to overwrite any existing data instead of being copied into an empty field.

The process of identifying differences between the actual results and the expected results for a component under test is called test comparison. Test comparison can be performed in two ways.

They are

dynamic comparison
In dynamic comparison, you use a test execution tool to perform the comparison in real time, while the test is executing. This type of comparison helps identify if the compared and the actual results do not match each other during a test. If the results do not match, you can correct the defect or execute other tests. You can also monitor error messages through this method.
post-execution comparison
In post-execution comparison, you use stand-alone and internally developed tools to perform the comparison after a test has finished executing.

This type of comparison is useful when comparing a large volume of data.

Many operating systems have file comparison tools for post-execution comparison.
Coverage measurement tools measure the percentage of quantifiable structural elements or 'coverage items' that are covered by a given test suite. Some coverage tools can go further to identify elements that have not been exercised during the test, and even to suggest test inputs that will exercise these elements.

Depending on the programming language and the test techniques in use, coverage measurement can be intrusive or non-intrusive.

Note
Software cannot be considered 100% tested if it achieves 100% statement coverage. This only means that those elements that the coverage measurement tool succeeded in identifying have been exercised during the test.

To test an application using a coverage measurement tool, you

instrument the code
You first instrument the code by identifying the coverage items at the component test level.

You use the tools to first identify the coverage items that have undergone a structural test. For example, at the component testing level, the coverage items can be code statements or decisions. Or, at component integration level, they can be calls made to functions or modules.
test the instrumented code
You then run the instrumented code through a series of manual or automated tests.
identify the coverage items that were exercised
Next you use the coverage tool to count the number of coverage items that have been executed by the test suite. You also use it to identify and report the percentage of the exercised coverage items. If the coverage tool you are using is a sophisticated one, you can even use it to identify the test inputs that can exercise paths that include unexercised items.
remove the instrumented code
Finally, just before the code goes into production, you remove the instrumented code.
Security testing tools are used to test a system's resistance to security threats such as computer viruses, worms, or denial of service attacks.

These tools support the execution of test procedures to confirm that there are no flaws in the security systems. They test to check if security systems are secure enough to resist external attacks on the network, support software, databases, and source code. They are particularly important if the application being tested is to be used in an unsecured environment, such as e-commerce or e-business and corporate applications on the Internet.

Because the skills required to use security tools are very specialized, you should ensure that only specialists operate them.

Security testing tools can be used to

identify virus attacks
identify weak passwords
check if the system has weak points such as open ports or points of attack
check if the operations are secure
check if the system is secured against denial of service attacks and the results of test attacks
simulate different types of external attacks
Question
Match the definitions with their different test execution and logging tools.

Options:

Test execution tools
Test harnesses
Coverage measurement tools
Test comparators
Security tools
Targets:

Capture manual tests
Compare expected results with the actual results
Calculate the percentage of the code structure and the modules and function calls covered
Test system against intrusions such as denial of service attacks
A test execution environment comprising stubs and drivers
Answer
Test execution tools capture manual tests and store them. They use stored test inputs and expected outcomes to execute tests automatically.

Test comparators compare what the software produces to what the software is expected to produce. They store the results either as part of the test case or as computed through a test oracle.

Coverage measurement tools measure the percentage of the code structure covered and the percentage of the modules and function calls covered. They are used to report coverage measurement and assess exit or test completion criteria.

Security tools check if the system is guarded from security intrusions such as denial of service attacks. They also simulate different types of external attacks and check if the system is secure.

Test harnesses comprise small programs such as stubs and drivers to interact with the software being tested.

Correct answer(s):

Target 1 = Option A

Target 2 = Option D

Target 3 = Option C

Target 4 = Option E

Target 5 = Option B

2. Using performance and monitoring tools
During testing you can also use additional tools such as

dynamic analysis tools
performance testing tools
monitoring tools
Dynamic analysis tools are used to analyze defects while the software code is executing. Developers use these tools during component testing and component integration testing to detect defects that are difficult to find during static testing.

For example, time dependencies lend themselves to dynamic testing, as does memory leakage handling, or boot-up processes.

You can also use dynamic analysis tools to check websites for dead links.

Dynamic analysis tools can

identify memory leaks
identify pointer arithmetic
detect time dependencies
report the status of the software during code execution
monitor the allocation, use, or deallocation of memory
Performance testing tools test the performance of a system under different load or usage patterns. Like test execution tools, performance testing tools use test scripts and data-driven testing, where variables that point to data in a data table are used to replace hard-coded inputs in test scripts.

You can also use performance testing tools to perform

load testing
In load testing, you check whether the system can cope with a certain number of transactions, loads, or usage patterns by pushing it beyond its normal and expected usage. You increase the load on the system gradually using a test driver so you can identify the usage pattern or the load that could make the system collapse. The output of the test is written to a log. After completion, you generate reports or graphs from the contents of the log to check the performance level.
volume testing
When you are checking volume, you test whether the system is able to handle a large amount of data. Take the case of a file that has many records in it. During volume testing, you check if the system can open and display all the records in the file.
stress testing
In stress testing, you check whether the system can handle more transactions than it is known to handle. You perform both load and volume testing. When you are checking load, you push the system to go beyond its normal and expected usage. You increase the load on the system gradually so you can identify the usage pattern or the load that can make the system collapse. This will help anticipate load issues after the system is deployed and help prevent them. For instance, when an HR system supports details of only 1,000 employees, entering information about the next employee might make the system collapse.
In performance testing, you verify how a system or a software application behaves under simulated usage conditions. For instance, when testing the performance of a web site, you check if the web site can handle the amount of traffic it is supposed to handle. Performance testing is best done at the system level. Ensuring the system is active, you replicate an end-user environment or user profiles. You send a number of test inputs to the system. The parameters that you set for the inputs may vary depending on the performance testing tool you use.

The tool then measures system characteristics such as response time and mean time between failure and sends you a report. If you find that the performance does not meet standards, you analyze where the problem is and how it can be improved.

Analyzing the output of performance testing tools takes time and skill. Therefore, it is a good idea to use specialists to carry out performance testing activities. This is especially so because the cost of some of these tools is quite high. Implementation and training costs increase the investment further. Using specialists will ensure that these tools are used optimally.

Performance testing tools are used to test an integrated group of systems, such as servers, databases, or an environment. Once functional, they need not be continually monitored.

Performance testing tools can typically

discover performance issues
measure loads, average response times, and timing of specific transactions
identify memory leaks
generate graphs or charts of responses
record problems such as locking, concurrency, excessive disk space, or system resources usage
Monitoring tools monitor the status and the performance of the systems in use. They are likely to be used after deployment. For instance, they may be used to recognize increasing demands on the system or abnormal behavior that requires alerting the administrator. If you use a tool to monitor your e-business websites, it will report any unusual behavior from visitors. If a monitoring tool detects a security attack then visitors can be automatically routed to another site, and site administrators receive an alert. You can prevent adverse consequences for the business such as negative publicity or financial loss.

Monitoring tools cover all aspects of IT infrastructure such as servers, databases, networks, performance, applications, and Internet usage. Because monitoring tools are used to monitor network traffic as well as the number of users on a network, they can help identify problems and alert the concerned people. They can also be used to log real-time information and historical data.

Apart from the testing tools covered, there are some other tools that are not specifically designed for testers or developers, but can still be used to support test activities. Examples of such tools are office productivity tools, database query tools, or communication tools, and backup or restore utilities.

For instance, in the absence of a test management tools, you can use a spreadsheet to store data temporarily.

Question
Match the definitions with their different test execution and logging tools.

Options:

Monitoring tools
Dynamic analysis tools
Performance testing tools
Targets:

Analyze defects while the software code is executing
Check whether a system can stand up to a high volume of usage
Continuously check the status and the performance of the systems in use
Answer
Dynamic analysis tools can analyze defects while the software code is executing. They can also perform other activities such as identifying memory leaks, detecting time dependencies, and monitoring the allocation of memory.

Performance testing tools check whether a system can stand up to a high volume of usage. These tools are also used to perform load and stress testing.

Monitoring tools continuously check the status and the performance of the systems in use. They also help identify problems that arise on a network connecting a large number of people.

Correct answer(s):

Target 1 = Option B

Target 2 = Option C

Target 3 = Option A

Question
Match the required activities to the appropriate tools.

Options:

You are required to perform regression testing on an application that went through a version upgrade recently
After migrating a database to a new platform you want to detect any differences between the two versions
You've been assigned to perform component testing on an incomplete system
You want to test an application's defences against intrusion attacks
Targets:

Test harness
Test execution tools
Test comparators
Security testing tools
Answer
A test harness can help you best during component or integration testing when parts of the system may be incomplete. It can measure coverage at the code level.

You should use test execution tools when you need to repeat a test performed earlier for a similar application.

Test comparators compare the expected results to the actual results and store the results either as part of the test case or as computed through a test oracle.

Security testing tools are used to test functions that detect security threats such as computer viruses, worms, or denial of service attacks.

Correct answer(s):

Target 1 = Option C

Target 2 = Option A

Target 3 = Option B

Target 4 = Option D

Question
Match the definitions with their different test execution and logging tools.

Options:

You are testing a software application on the Internet. You find that the number of service requests directed at the application have increased drastically in the past hour.
You have to perform component testing on a software to check for pointer errors.
You want to detect any components that remain unexercised during a test.
You want to verify the working of a system under a simulated usage environment.
Targets:

Performance testing tools
Monitoring tools
Dynamic analysis tools
Coverage measurement tools
Answer
Performance testing tools are used to test an integrated group of systems, such as servers, databases, or an environment under simulated usage conditions.

You use monitoring tools to recognize any abnormal increase in demand on a system that is deployed online.

You perform dynamic testing typically during component and integration testing to detect memory leaks, pointer errors, and time dependencies.

You use a coverage measurement tool to exercise these unexercised coverage items by identifying test inputs that can perform the exercise.

Correct answer(s):

Target 1 = Option D

Target 2 = Option A

Target 3 = Option B

Target 4 = Option C

3. Summary
Test tools provide tool support for testing activities such as test execution and logging, and performance and monitoring.

Test execution tools, test harnesses, test comparators, coverage measurement tools, and security tools help you in executing and logging test cases. Dynamic analysis tools, performance testing tools, and monitoring tools help you in activities such as analyzing code and monitoring performance.

Back to top

Introducing a Tool into an Organization
Learning Objective
After completing this topic, you should be able to

recognize when it is appropriate to introduce a test tool into an organization
1. Appropriate introduction of a test tool
When an organization or project team decides to buy a tool to complete a task, they should study the advantages and disadvantages of buying the tool.

The factors you should keep in mind before buying the tool are

maturity of the internal test processes used
availability of alternate solutions
constraints faced and requirements specified
availability of tools that meet these requirements
detailed evaluation/proof of concept
cost of the selected tool
Before buying a test tool, you should first identify the strengths and weaknesses of the test organization. You should introduce the tool only if it can support the established test processes. To evaluate whether your organization is ready for tools, you can use the Test Process Improvement (TPI) model or the Capability Maturity Model Integration (CMMI) model. These models are software process improvement assessment models that can assess the maturity of an organization and provide guidelines for improving the test process.

It is a good practice to consider alternative solutions before investing in a tool. Trying out alternative solutions can sometimes be more beneficial for a test process than using a test tool or automating an old test pack.

For example, your organization may require version management of its products. Instead of purchasing a configuration management test tool , you could look at alternative options, such as purchasing a cheaper open source tool, or using internal employees to develop this tool.

After you've ensured that there are no alternative solutions available, you should consider the constraints and requirements of the tool.

The constraints could be financial or technical. The requirements could be about factors such as training needs or tool vendors' specifications. The requirements should be drawn up formally, prioritized and approved by the key stakeholders.

If you don't perform a detailed analysis of the need for the tool and specify the requirements and constraints, you could encounter problems such as delays, unnecessary expenditure, or inadequately equipped tools.

For example, you may require a tool that can be remotely accessed. The tool you adjudged to be the best after a series of demonstrations might not be deployable over the Internet. Purchasing the tool without understanding its constraints and your own requirements would result in owning an inadequately equipped tool.

After specifying the requirements, next you should check if the available tools are capable of overcoming the constraints and satisfying the requirements. If they are, shortlist them for purchase.

After you decide to purchase a tool, you can approach tool vendors, attend tool exhibitions, and search for tools on the Internet.

When discussing with vendors, you should ensure that you provide them with a list of the constraints and the requirements so they are clear about your requirements.

After you decide to buy a tool, it is important that you evaluate both the tool vendor and the tool. This evaluation is called a proof of concept. When you've shortlisted only one tool, you can combine the pilot project, which is the first use trial project of the tool with the proof of concept, which is the detailed evaluation of the tool before purchase.

During evaluation, you should evaluate the tool in the same test environment where the tool will be used. This ensures that you don't need to reconfigure the tool. For example, some static analysis tools don't support all versions of all programming languages, so you should test a static analysis tool in the programming language version you intend to use.

After completing the evaluation, you should again assess the tools against the requirements. If there are any additional features, you can note them as potential future requirements.

After evaluating the tool, you should negotiate the cost of the tool with its vendor. During the negotiation, you should discuss the purchase price, consultancy costs, training and implementation costs, and annual license fees. You should also negotiate the costs regarding a pilot run of the tool and the costs associated with a large scale implementation of the tool.

After negotiating the costs, you should conduct a pilot project to test the tool. A pilot project helps you

gain knowledge
You can gain knowledge through a pilot project when you test the tool and identify what the benefits and shortcomings of the tool are.
assess compatibility
The pilot project helps you assess if the test tool is compatible with the existing processes.
decide on process modifications
During the pilot, you can determine what processes and practices you would need to modify to accommodate the tool.
decide on how to ensure people make optimum use of the tool
The pilot project helps you identify how people can make optimum use of the tool so existing processes can be streamlined.
evaluate the benefits of the tool
During the pilot, you can evaluate if the benefits the tool promises can be achieved at a reasonable price. This will help in deciding whether you want to purchase the tool.
determine other details for using the tool
The pilot project will also help you determine other details for using the tool. For example, you can identify the templates required and guidelines needed to use the tool.
If you're satisfied with the results of the pilot project, you should buy the tool. To implement the purchased tool, you should

adopt an incremental approach
You should adopt an incremental approach by releasing the tool to the rest of the organization in phases. After a pilot, you can release the tool into areas where it is likely to be more useful.
adapt the tool to the existing processes
You should find the right balance for using the existing tools and practices with the new tool. You can do this by adapting the tool to the existing processes, old tools, and testware.
use the test pilot data
You can use the test pilot data to create user guidelines that are to be used by the testing team.
train employees
You should train employees on using the tool. This ensures that they are prepared to use the tool in a live project.
create a database
You should compile a database of issues faced and learned based on the findings of the pilot. This ensures that the team will always have solutions to problems that have been encountered.
                    
