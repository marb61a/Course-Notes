                    ISTQB Certified Tester Foundation Level
                    Course Notes Part 39
                    

Components and kinds of test plans (Cont)
  - A test plan is ideally a master test plan that accommodates all the revisions made to the plan as the test progresses. 
    - This helps you reduce redundant documentation. 
    - You can create the master plan during the early stages of a project
      - Include the planned high-level test activities in it.
  - You can choose acceptance testing to test these product features and ensure that it is completed on time.
  - To identify critical defects and ensure that the software is compatible with the hardware, you perform system testing.
  - You can check whether the software can operate with the modules already developed using integration testing. 
    - Checking the code or any component of the software can be performed using component testing. 
      - The test plans for all the Acceptance, System, Integration, and Component test levels are combined 
        - This will create a master test plan.
  - You can create test plans at various levels and derive these plans from the master test plan. 
  - Acceptance test plan
    - You begin acceptance test planning in the early stages of the product life cycle 
    - This is after the high-level requirements are defined. 
    - Acceptance testing ensures that all requirements are met. 
  - System test plan
    - System testing is comprehensive testing on the performance and reliability of the software. 
  - Integration test plan
    - You ensure that all the components of a system interact and function cohesively through integration testing. 
    - You can start the integration test planning when you are stabilizing the software design. 
    - In integration testing, you must test the critical components first 
      - This is so that errors in these components don't show up at a later stage in development resulting in costly delays.
  - Component test plan
    - You can test individual software components, such as the individual units of source code, through component testing. 
    - You can use component testing to detect errors early in the development cycle. 
    - This makes integration testing easier because all components are tested before they are integrated. 

Factors influencing a test plan
  - Test planning is the most prominent phase in any test project. 
  - A test plan lists all the tasks and key areas in a test along with the estimated test effort. 
  - You can use the test plan when you develop, implement, and maintain software.
  - To test a product efficiently, you must clearly understand the factors that can influence the test planning process     
  - Product
Product knowledge helps you perform efficient testing. Any risks that can cause the software product to fail should be understood at an early stage in development. Failure of software involves heavy cost and labor that could be avoided if diagnosed and resolved before or during development. For example, synchronization issues in the audio software of high-end digital music systems are very expensive and time consuming to rectify.
Approach
Different approaches are required for testing different types of software products. For example, software relating to an online banking system requires a more formalized level of testing than software relating to a basic website. The online banking system carries much higher risks and costs associated with failure relative to the basic website.
Process
Test planning is influenced by factors affecting the testing process such as the availability of testing tools. Using these tools can reduce the manual effort that would be required for executing a test. For example, in safety critical environments, such as the aviation industry, you can use debugging tools to reduce the cost and time required to complete a test.
People
One factor with a significant effect on the testing process is people. This factor can include the skills of the individuals on the test team and their relevant experience with similar software products and testing projects. For example, when testing a highly technical product to be used by clients with a technical background, the test team should be populated with testers that possess similar technical knowledge.


Test Estimation, Test Strategies, Entry and Exit Criteria
Estimating tests using test strategies
You should analyze a software test project in order to obtain an accurate estimate. This will enable you to check if the available resources such as the test environment, funding, and the people are adequate for the project. You can then use the test estimate data to assess risks and ensure timely delivery of a project.

Before delivering a product, you need to also ensure that you successfully complete the test plan and that it meets all the necessary exit criteria with no outstanding critical errors.

Successful completion of a test is based on the approach you adopt for testing. You can decide a testing approach according to the risks, cost and time requirements of a project.

To estimate the overall cost for a project or its duration, you can use two approaches:

metric-based
You can use the metric-based approach when you rely more on the test data for estimation. For example, you can analyze the number of test cases to determine the testing cost. Similarly, you can use other data, such as written and executed test cases, the time required to run and execute them, and the defects found, to calculate the estimate.
expert-based
You can use the expert-based approach when you want to use an expert's experience for test estimation. These experts may be technical, analytical, or business experts. With their guidance, you can determine the test scope and the risks involved.

You can then divide the testing process into several tasks based on the expert's data and calculate the cost, time, and the resources required for each task separately. By summing up the data collected for all the tasks, you can estimate the cost of the whole testing project.
These approaches, when combined, can estimate a test more accurately than when handled separately. For example, based on the expertise of the testing team in your organization, you can breakdown a project into several tasks to estimate the testing effort needed for each task.

Then you identify similar metrics from past projects such as the number of tests run and the number of defects found per day. You then apply these parameters to calculate the test duration and test effort for all key tasks in your project. Finally, you estimate individual tasks and obtain a project level estimate.


Testing is a complex activity, and the testing effort is influenced by a variety of factors. When you create test plans or estimate the test effort, you must concentrate on these factors to complete the test successfully.

The key factors that influence the testing effort are

product
You can use project documentation to obtain information about the software product. Adequate information, such as usability and performance requirements of the software, helps you to plan effective and efficient tests. For example, managing timing constraints for an avionics mission control computer system requires you to have intricate knowledge about the product's requirements.
process
The cost of a test project is directly proportional to the size and life cycle of the test project. If the test process is mature enough to enable effective management of changes, you can reduce test execution cost by avoiding rework costs. You can also reduce test execution costs by automating tests through test tools. This also helps reduce the time required to complete testing.
people
A good test team with relevant experience and skills is more capable of performing efficient testing. The team must be reliable in order to commit to timely delivery of quality projects. The stability and geographical distribution of the team also plays an important role in influencing the test effort. For example, on a team that changes often, the experience and knowledge levels may differ and that can adversely affect testing efficiency.
test results
Test results are also important to the total test
effort. If you deliver high quality software and quickly fix errors, you can prevent delays in test execution and ultimately product delivery. For example, once a defect is documented, if it is addressed promptly it will not likely have to go through multiple iterations of fixes and retesting, making it much easier to meet the initial test estimate.

Choosing an appropriate test approach or strategy plays an important role in the success of a testing project. A test strategy defines the test levels and their corresponding activities within the project. Depending on the project, you can use different testing strategies for each level.

When you implement one of these strategies on a project, you effectively define an approach for the project tests. With this strategy-enabled approach, you understand how to perform a test, identifying the requirements for the tests from beginning to end. The strategy you apply also helps you to identify the risk analysis to be carried out, the design techniques to be applied, and the exit criteria to be applied.

The various software testing strategies include

analytical
You use an analytical strategy when you analyze the requirements of a project and the associated risks involved. You plan, design, and estimate tests based on the parameters derived from this analysis. For example, you analyze the requirements specification of a project and design a test process based on these requirements. You then estimate the cost and effort required to execute the test process.
model-based
In model-based testing strategy, you derive test cases from a model that describes some functional aspects of the product under test. Model-based testing presents an excellent candidate for automation. For example, you can run tests automatically instead of hand-crafting test cases to meet the short release cycles in many markets today.
methodical
For a methodical test strategy, you use a planned, systematic approach through which you gather information from major areas of testing and develop a checklist based on this information. You then design, implement, and execute tests based on this checklist.
standard-compliant
You can adopt a standardized strategy for testing. These standards often depend upon an externally developed approach to testing. For example, you can follow the IEEE 829 standard or similar standards for developing a template testing strategy.
dynamic
By employing a dynamic strategy, you can concentrate on finding the maximum number of defects possible during test execution and resolve them. For example, exploratory testing is a dynamic strategy where you can control the design of the tests when they are performed. You can use the knowledge obtained from this to design more efficient tests. You can apply this form of testing at any stage in the development process.
consultative
You can use a consultative strategy when you need to consult with the developers or users for guidance on the product. These resources are normally from outside the test team. They can guide you on product technologies and other items in the testing process.
regression-averse
Regression occurs when a software upgrade identifies errors that were previously not observed. In the regression-averse strategy, you re-run previous tests and use automated testing tools to run all regression test cases and report failures. For example, you modify program code and run the existing tests to check for any variation in performance of the modified code.
You can choose between test strategies that are preventive or reactive. For example, analytical test strategies identify defects prior to test execution and so they are preventive. Dynamic test strategies locate defects during the test execution process and enable you to solve them reactively.

You may also combine any of these strategies to suit a particular test requirement. For example, a tester wants to explore, write, and execute test scripts simultaneously. You then need to consider risks that may cause test cases to fail so that you can avoid or correct them. In this case, you can blend the analytical, dynamic, and regression-averse strategies to satisfy all conditions.

Blending strategies to enhance the success of a testing effort depends on many important factors. Some of these factors are

risks
Risk-management is an important factor to consider in any project. You need to identify, analyze, track, and communicate risks in software intensive programs as they can affect the potential for success of a project. For example, if you identify that a product will not meet the performance or functionality requirements within the defined schedule, it is a risk that you need to focus on resolving.
skills
To execute the chosen strategy, you must consider the skills that a test team has and the lack of skills as well. When a team lacks skill and time is short, the best strategy to choose is one based on standards rather than creating a new approach.
objectives
To perform successful testing, you must ensure that your test meets all objectives of the testing strategies used. If your objective is to find the maximum errors possible within a stipulated time and effort, then a dynamic strategy is appropriate.
regulations
In addition to meeting objectives, your test should also satisfy any regulations that may exist. You may need to develop a methodical test strategy to ensure that your test also meets all the necessary regulatory requirements.
product
Some software products, such as those used in weapon systems, have stringent requirements. You need to analyze whether the software meets these requirements. Therefore, applying an analytical strategy is appropriate in this case.
business
Business considerations are essential as is business continuity. If you can use an existing system as a model for new development, a model-based strategy is a good candidate.


2. Entry and exit criteria in software testing
Entry criteria are used to establish the conditions and timing for a given test activity to commence.  This may include when to start test design, when to start a new level of testing or when to start test execution. Without such criteria, certain test activities may begin at an inappropriate time, using valuable resources, which in turn wastes time and money on a project.

For example, suppose that the test team started testing code which was ready, but the correct data for the testing execution was not at a ready state.  The test team could waste significant valuable time against the project and may have to go back and re-test once the data is ready.

Usual entry criteria include:

test environment availability
Test environment availability indicates that any system that will be used for testing purposes is accessible to those that are doing the testing.  For example, if the system is maintained remotely, then the testers must be able to remotely connect to the system via Remote Desktop (RDP) or similar remote access protocol.
test tools installed and available in test environment
In addition to ensuring that the test environment is available, the environment must also include the test tools installed and configured according to the specifications outlined in the test plan.  For example, if the software test plan calls for the use of a particular test tool, that tool must be installed and configured explicitly for testing purposes.
code is available for testing
The code must be available to testers in order to perform the required tests according to the test plan.  For example, to perform static testing, testers will commonly use a compile environment to ensure syntax validity.  Without the code, this test would be impossible.
test data available and ready to use
This type of entry criteria ensures that the test data indicted by the test plan has been entered in the required environment and is ready to use for testing.  For example, if the software to be tested interfaces with a relational database, the data required in order to run the tests must already exist in the database (such as user roles for login example).
test design activity is complete
In order to carry out testing effectively with no wasted effort, it is essential that the test conditions (coverage items) for a test item, the detailed approach and associated high level test cases are fully documented and complete.  For example, if the test condition calls for a certain approach in testing, and a different approach was employed instead, all testing performed using the erroneous approach would likely amount to wasted effort.
Even though you may use all the indicated and appropriate strategies, inadequate requirements or resources may force you to stop testing a project. To prevent this, you must ensure that your test meets the conditions of exit criteria for successful completion.

Exit criteria identify any inadequacies and incomplete testing tasks during project execution. For example, an exit criteria condition may require you to check if any severe defects are left outstanding before testing can be formally considered complete.

There are various types of exit criteria. You may classify them as

defects
When testing a project, the exit criteria for defects require you to meet certain conditions, for example, that high priority errors must be rectified and retested. This helps you ensure that no critical outstanding errors are present in a project before releasing it.
coverage
You can improve the quality of a project by maximizing the test coverage. Test coverage covers all the test levels. Exit criteria for test coverage include conditions. For example, they may include a condition that says 85% of requirements coverage is to be achieved in order for a test to be considered complete.
quality
Exit criteria provide an effective method for managing the quality of a project. You can use exit criteria to ensure that you have successfully completed a test and the outcomes are of acceptable quality. For example, the criteria for quality may require you to execute maximum test cases with an item pass rate of not less than 80%.
budget
You can stop testing when the budget for the test is exhausted. Exit criteria determine when to stop according to available funding. Using these criteria, you can also rectify your test plan to complete the test within the specified budget.
risk
Using exit criteria, you can ensure that all potential areas of risk such as technical and management risks are completely tested. Exit criteria determine the product features at risk which allows you to leave the low risk areas untested if necessary.
Different exit criteria relate to different levels of testing. For example, checking whether a project is code complete and there are no missing features or media elements is considered component testing. Testing whether a product runs on all the product's supported hardware and software configurations is considered system testing.

You can check whether the outcomes are of acceptable quality by using acceptance testing. Integration testing requires the software product to be compatible with and installable on all other related systems. If a product is approved and signed off by product marketing, the performance of the product is confirmed and approved by functional testing.



Software Test Progress Monitoring and Control
evaluate test summary reports and select test control actions
1. Interpreting test metrics
During testing, a testing team's objective is to check whether a product meets the specified requirements. To ensure that the team successfully achieves its objectives, you need to monitor all testing activities. For effective monitoring, you collect data related to each testing activity and use it to assess whether the activities are progressing as planned. This data is known as Metrics.

Typically, you collect metrics data during and at the end of each test level. This data helps you easily verify whether the testing activities adhere to the allocated schedule and budget. It also helps you verify the relevance and effectiveness of the test objectives and the testing activities.

Some of the metrics you collect include

percentage of work done
To determine the work percentage, you calculate the number of test cases the testers prepared and the time they took to prepare the test cases. You also calculate the percentage of time and effort the testers spent preparing the test environment. These calculations help you determine whether testers are working to meet their targets and objectives.
performance of test cases
You can also use test cases as metrics to monitor the progress of testing. To do this, you determine if each test case was performed, and you further identify the performed test cases that ran successfully. By monitoring test cases, you can validate the time spent by the testers in preparing the test cases.
defect information
When collecting metrics, you also gather information about defects the testers identify. For example, you determine the defect density, which is the ratio of the number of defects testers identify to the size of the component or the system they are testing.

Other defect-related data you collect include the number of defects that were fixed and the number of times a fixed component or system had to be retested.
extent of testing
The extent to which testers test a component or system is also an important metric. For example, you check whether testers tested each code segment thoroughly or if they verified the potential risks of a component or system alone.

The extent of testing varies with the test level. For example, testers test code segments during component testing and verify system requirements during system testing. By monitoring the extent of testing, you can ensure that each test level progresses as planned.
confidence level of testers
You can also use the confidence level of testers in the quality of the product being tested as a metric. If the testers are too confident about the quality, they may not test the product thoroughly and so may overlook serious defects. On the other hand, if the testers are not confident of the quality, they may put the product through unnecessary tests, which can only prolong the testing process. You should try to ensure that the testers adopt a balanced and bias-free approach to testing.
deliverable dates and testing costs
You collect data related to deliverable dates and testing costs as metrics to determine if each test level can be completed on time and within budget. For example, if you find that a testing activity is overshooting the allocated budget, you can decide whether to stop the activity, modify its scope, or perform it according to the existing plan. You base your decision on the impact the testing activity can have on other testing activities and the overall progress of testing.

You can use various tools to record and display test metrics. For example, you can record the data in a textual format in an Institute of Electrical and Electronics Engineers (IEEE) 829 test log template or in Microsoft Office Excel worksheets. You can also represent the data in a graphical format using bar graphs.

If you only want to maintain a simple record of the tests the testers perform and the defects they identify, you use an Institute of Electrical and Electronics Engineers (IEEE) 829 test log template. This template consists of three standard sections: Test log identifier, Description, and Activity and event entries.

Graphic
In the example, the different sections of the standard IEEE 829 test log template are displayed.

In a test log you create using the template, you first add a unique number to identify the log in the Test log identifier section. Then, in the Description section, you describe the software components being tested and the test environment.

The last item you add to the log is information about testing activities and events. For example, you mention the testing process, the outcome of the testing process, defects identified, and a description and location of the defect report.

If you want a more detailed record of the metrics, you can create test-summary sheets using Excel. For example, you can use a summary sheet that contains an overall representation of the test metrics, such as bug ID and planned and actual dates, actual effort, and the test duration, in various columns.


In the Test ID and the Test Case rows of the summary sheet, you store the ID and the name of each test case, respectively. For example, to enter the data for a functionality test, you assign the ID as 1 and the Test Case name as Functionality.

Under each main test case, you also add the names of its specific sub tests. For example, under Functionality, you can include data for tests conducted on menu items of a software product and its formatting and printing capabilities. You then summarize the data related to each test case and its sub tests against the Summary entry.

In the Run By row of the summary sheet, you specify the initials of the person who conducted the test. Similarly, in the Test Duration row, you record the duration of each test and you use the Plan Effort and Actual Effort rows to keep track of planned and actual testing efforts.

Other useful information on the summary sheet includes

Status and System Config
You store the status of each test case in the Status row and the code assigned to each type of testing environment in the System Config row. For example, you specify a status of Pass if a test case runs successfully. Similarly, you specify a status of Warn for a test case that results in a minor failure, the status of Fail for a test case that fails completely, and the status of Skip for a test case that the testers don't perform.

The code you type in the System Config row is defined in the test plan document.
Bug ID and Bug RPN
In the Bug ID and Bug RPN rows, you record the ID and risk priority number (RPN) of each bug, respectively. You use the defect-tracking database to determine the ID of a bug. You use values 1 through 25 for the RPNs. These values are in descending order of risk level. For example, you assign the RPN value of 1 to the most risky bug.
Comment
In the Comment row, you store specific information related to a test case or sub test. For example, if the testers didn't conduct the Printing capabilities sub test, you type the text "Not conducted" in the Comment row.
You can also track the progress of testing activities and test levels based on the number of defects found and closed. To depict the defect data for a testing activity or test level, a graphical format is most suitable. A graph helps you check the overall status of testing easily and quickly.

By using a graph, you can also show the planned and actual start and end dates for a testing activity or test level. Additionally, you can plot the number of defects the testers are expected to find and the number of defects they actually found. The graph also helps you monitor the difference between the number of defects found and closed on specific days.

The graph in the example indicates that the difference between the number of defects open and closed decreases on a holiday. This is because testing activities often decrease or stop during and immediately before holidays.

Similarly, stringent testing on Fridays results in more defects being identified on that day. So the difference between the number of open and closed defects increases on Fridays. Also, as testers verify fixes and close defects on Mondays and Tuesday, the difference between open and closed defects drastically decreases on those days.

When the gap between the number of defects open and the number of defects closed reduces to an acceptable level, the product is fit to be released.

Note
You shouldn't depend solely on a defect-data graph because defects can easily be closed without being fixed.

An alternative way to represent defects in a graph is by depicting the failure-rate or defect-density. You use this type of graph over a period to track the progress of testing. You declare a product fit for release when the failure rate or defect density falls below a pre-specified value.


A failure-rate or a defect-density graph proves useful if you want to create a highly reliable product. You calculate failure rates of a product or a component in terms of a unit of measurement. For example, you calculate the number of times a product fails per hour. You can also use the number of times the product or component is run as a unit of measurement.

2. Evaluating reports and controlling tests
You need to share the data and metrics you collect while monitoring a test level with other members of your team. To share the data and metrics in a format that is easy to interpret, you prepare a test summary report.

Your team members can then use the summary report to quickly check what events occurred during a testing activity or test level. They can also use the report to quickly learn about existing defects in a software product or component, the risks involved, the confidence level of testers in the product or component being tested, and the feasibility of repeatedly testing a product or component.

You can use the IEEE 829 Standard: Test Summary Report Template to create a test summary report. This template consists of eight sections.

You use the Test summary report identifier section to assign a numeric identifier to a test summary report. This identifier helps configuration managers easily identify and track the report.

In the Summary section, you include a summary of all testing activities that were part of the test level. Your team members can then use this section to quickly gather information about test-design specifications, test cases, test procedures, and test environments. This section also enables you to identify defect details, version numbers and descriptions of the products and components that were tested.

The Variances section refers to the variations between the actual testing strategies, specifications, and procedures and guidelines mentioned in the test plan. A testing manager can use this section to learn how to improve and streamline future testing activities and ensure that the activities don't deviate from the plans.

The other five sections of the template include

Comprehensive assessment
In the Comprehensive assessment section, you specify the extent to which the testers completed the testing activities. In this section, you also explain whether or not the activities conformed to the test-plan guidelines. Additionally, you include a detailed reference to the steps the testers took to ensure successful and efficient testing.

Using this section, you can determine the extent to which a product or component meets the exit criteria at the end of each test level.
Summary of results
The Summary of results section provides a summary of the output and results of the testing process. This section also includes a summary of all types of defects and the defect-resolution process.
Evaluation
Using the Evaluation section, you evaluate each tested component or product against the specified requirements and metrics. For example, during integration testing, you evaluate the interaction between software components and record the expected and unexpected behavior of the components.

In the Evaluation section, you also specify the scenarios under which the tested component or product may fail. This information is based on the stability and reliability the component or product exhibited during testing.
Summary of activities
In the Summary of activities section, you include a summary of the major testing activities and events. You also document the total resources, time, and budget you allocated to testing. For example, you document the total number of testers and computers you employed and the duration for which you assigned them to the testing activities.

A testing manager can use the information in this section to estimate the requirements for future testing activities.
Approvals
You record details about the parties responsible for approving the test summary report in the Approvals section. You also obtain their signatures in this section. The signatures certify that the parties responsible for approval understand and accept the test results.

4. Comprehensive assessment

Each testing activity can be delayed by risks. For example, testers might be unable to complete system testing on time because they don't have the administrative rights to access the product. In such cases, you can avoid or minimize the impact of risks on the testing activities by taking measures to control the tests.

Test-control decisions are based on the test metrics and information in the test summary report. For example, if the test summary report indicates a deviation from planned testing activities and the planned testing schedule, you take control measures to minimize the deviation.

As a testing manager, the test-control activities you need to perform include

analyzing test-monitoring data
You analyze the test-monitoring data and make test-control decisions based on the data. For example, if you find that a higher percentage of test cases fail, you may suggest more stringent guidelines for preparing test cases. Similarly, if you find that the testers are ignoring potential risks during testing, you can ask them to test the product against those risks.
changing test schedule and priority
To accommodate delays, you change the test schedule and the priority of the testing activities. For example, if testers don't receive a crucial component for testing on the scheduled date, you change the priority of the testing activities and allow testers to test components available to them. Similarly, you can reschedule testing activities if the test environment is not made available to testers on the scheduled date.
setting acceptance criteria
You can minimize or eliminate defects in a fixed component or product by setting the acceptance criteria for retesting the component or product. For example, you can allow testers to accept the component or product for retesting only if the developers first thoroughly test it and declare it defect free. This type of testing, which is conducted by developers, is known as confirmation testing.
reviewing risks
You can control tests by periodically reviewing risks. For example, during the course of a testing activity or a test level, the risks to a product may change. Existing risks may be eliminated or become less severe, or you may discover new risks. You can then review these risks and change ratings of the identified risks. This also helps you avoid unnecessary tests and allows you to perform efficient testing in less time.
adjusting scope of testing
If new features are added or changes are made to a product during a late stage of development, you need to adjust the scope of testing accordingly. For example, if a client requests that new features be added to a software application that has already been integrated, you include additional tests to check the new features.
There are also a few test activities that the project manager rather than the tester or testing manager is directly responsible for. To help project managers handle these activities efficiently, you can share your test-control experience with them and make suggestions.

