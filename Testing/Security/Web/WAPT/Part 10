                    Web Application Penetration Testing
                    Course Notes Part 10


Fingerprinting Frameworks and Applications 
  - Once a list of subdomains has been obtained then the appropriate techniques can be applied
    - Essentially we start looking at the webpages running on each of the subdomains that were found
  - Common applications are those pieces of software that are available online for anyone to use 
    - There is an acronym to describe these COTS - Common off the shelf
  - They can be either open source or commercial
    - Access to the source code is what makes them interesting for analysis
  - There may be an opportunity to read both the application logic and the security controls implemented
    - This gives a big advantage over custom in-house applications where the logic needs to be guessed to certain degree
  - All of these freely available applications suffered from some kind of vulnerability in their history
  - Understanding what piece of commonly available software the web server is running will give us the possibility for easy exploitation
    - This can be accomplished by simply looking for a publicly available exploit online
    - Obtaining the  name of the application will not be enough
    - One basic step to fingerprinting the application involves browsing the website and looking at things like URL's, logic and appearance
    - Sometimes it is as easy as looking for the application name in the web page content
    - In other cases, we just need to look at the web page source where the name and version is usually in HTML comment or HTTP headers
  - Sometimes we have to look more in-depth to find what we are looking for
    - We may need to read the web page source code and look for information in the META tags and in HTML comments
  - In our Information gathering process we will not only list all the common applications in use
    - We also list all the third party add-ons in use on that application
    - These could be useful further into the testing engagement

Fingerprinting Custom Applications 
  - When not in front of a commonly available application, you have to go through an initial overview of the application logic
    - This example has an in-house application customised for the organisation being tested
    - The inner logic is unknown to us but can be reverse engineered with a careful analysis of its behavior
  - The first step will be to consider the overall scope
    - What is it for?
    - Does it allow user registration?
    - Does it have an administration panel?
    - Does it take input from the user?
    - What kind of input?
    - Does it accept file uploads?
    - Does it use JavaScript or Ajax or Flash etc
    - These questions can be answered by just visiting the website and taking notes of anything found that is relevant
    - Crawling or Spidering the application can be valuable
  - The first step is  to understand what our application does and how it does it
    - There is another aspect to consider and that is finding common software intertwined with custom code
    - Forums or Blogs are a great example
      - When dealing with a custom application, it is very likely we find open source or commercial applications implementing blogs
      - This applies to small company websites as well as corporate websites
      - Recognising them among the custom code is important and should be noted down in our functional graph
      - At this point, it would be helpful to browse the application with a proxy in the middle of our requests, collecting all the headers and responses
      - One of the best tools for this is Burp Suite
      - 
  - Creating a functional graph
    - The goal of the functional graph is to visually spot important information  at a glance
    - We will use this functional graph as a base for further charting our information and prepare it for the testing part
    - It is recommended to concentrate testing efforts on smaller parts instead of the entire application
    - This divide and conquer approach is the most efficient solution when dealing with complex applications
    - To each pictured smaller part of our application, we will then add notes and comments including
      - Client side logic (where there is usually JavaScript code in use), flash applications, cookies, authorisation required, forms 
    - Attack methodology will vary depending on the data collected in this phase 
      - As such, the more information retrieved from direct inspection, the greater the chance in identifying exploitable vulnerabilities
    - The attack surface is the area of the application on which we will focus all of our security testing efforts
  -

Enumerating Resources 
  -

Relevant Information Through Misconfigurations
  - Sometimes the best way to retrieve relevant information about our web applications is to look for potential mistakes in web server configuration
  - A quick and very common way to gather information, files, source code and misconfigurations is by looking for open directory listings
    - These directories have been configured to show a list of the files and subdirectories in paths that we can access directly
    - 99% of the time, these directories have not been deliberately configured to show their content
      - They are just the result of a misconfiguration
    - Looking for directory listings is a task that anyone with a basic experience in scripting languages like Perl, Python etc can automate in few minutes
  - 

Google Hacking 
  -

Shodan HQ 
  -
