                    Beginning Application Development with TensorFlow and Keras
                    Course Notes


                    Section 1 - INTRODUCTION TO NEURAL NETWORKS AND DEEP LEARNING
1 - Course Overview
A quick overview of what the course will cover and an introduction to the instructor

2 - Setting up your Environment
The course uses a couple of tools
  - Visual Studio code
  - The Python extension for VSCode
    - This can be installed through the extensions
    - There may also be a need to install PyLint
There is also a quick guide to installing VS Code
  - The instructor uses MacOS but VSCode is available 

3 - Lesson Overview
A quick overview of what the section will cover

4 - What are Neural Networks and Deep Learning?
Neural Networks
  - They are also known as Artificial Neural Networks
  - They were first proposed in the 1940s
  - They proposed to create a computer system that works like a Human brain
  - It works like an interconnected network
Deep Learning is largely the contemporary study of Neural Networks
  - Deep Learning Neural Networks are typically far greater in size
  - They have many more nodes and layers
  - Deeo Learning networks algorithms and apps require many resources to achieve success
DL systems have been used in many large scale industry applications
  - Neural Networks proponents have demonstrated great success in many areas
  - GPU's and TPU's are able to perform more simultaneous operations than regular CPU's
    - GPU - Graphics Processor Unit
      - Not required to work with NN but there are benefits
      - They can be very helpful when dealing with large datasets
    - TPU - Tensor Processor Unit
      - This is chipset provided by Google for use in DL
  - AlphaGO develops a series of algorithms and is a good example of deep learning
    - https://deepmind.com/research/alphago/
  - A successful application is Google Translate
    - Its Transformer algorithm is now the main algorithm
  - Another successful application is Image Recognition
    - Facebook and Google are able to id and tag entities with images
    - These models are able to suggest contacts or friends with high accuracy
Neural Networks are so powerful because they can be used to predict any given function with reasonable approximation

5 - Limitations of Deep Learning
Deep Learning has some limitations
  - Representation Learning
    - The data used to train a neural network contains representations (features) which explain the problem to be solved
    - Neural networks are computation graphs in which each step computes higher abstraction representations from input data
    - Data progresses through these layers building continuously higher level representations
    - Each one of the steps represents a progression into a different abstraction layer
    - The process finishes with the highest representation possible which is the one the modelis trying to predict 
  - Function Approximation
    - Neural Networks learn new representations of data 
      - They do so by combining weights and biases with Neurons from different layers
    - They adjust the weights of these connections each time a training cycle takes place
      - This takes place using a mathematical technique called backpropagation
    -

6 - Common Components and Operations of Neural Networks

7 - Configuring a Deep Learning Environment

8 - Installing Python 3
Installing Python 3 will depend on the platform that the student is using
  - http://ubuntuhandbook.org/index.php/2017/07/install-python-3-6-1-in-ubuntu-16-04-lts/
  - Current Python is 3.7 but is easily updated using
    - sudo apt-get upgrade python3
  - The instructor provides a run through of installing on MacOS

9 - Installing TensorFlow, Keras and TensorBoard
Using pip to install the packages on MacOS

10 - Installing Jupyter, Notebooks, Pandas and NumPy
Using pip to install the packages on MacOS

11 - Installation Completion
Using pip to install the packages on MacOS

12 - Training a Neural Network with TensorFlow convolutional layer

13 - Training a Neural Network with TensorFlow fully connected layer

14 - Train a Neural Network with TensorFlow

15 - Testing network performance with unseen data

16 - Summary
Summary of what the chapter covered



                    Section 2 - MODEL ARCHITECTURE
1 - Lesson Overview
A quick overview of what the section will cover

2 - Choosing the Right Model Architecture
There are 2 popular architectures which are used for app starting points, these are
  - They are foundational networks and are considered as starting points for most projects
  - Convolutional Neuro Networks (CNN's)
    - These work with problems having a grid like structure
    - The name convolution comes from the mathematical representation of this process
    - They were originally created to classify images
    - They use closely related data as an element of the training process
    - This is especially true of images where combining pixels together is better than taking each pixel on it's own
    - They work with sets of inputs that keep altering the weights and biases of network layers and nodes
      - There is a limitation of this approach as the architecture ignores the sequencing of these inputs
  - Recurrent Neural Networks (RNN's)
    - These are designed towork with sequential data
    - They are used in speech recognition and translation of languages
There are also 3 other networks which are relevant in the field
  - Long Term Short Memory (LTSM)
    - These are variants of RNN's
    - They address the vanishing gradient problem
      - This is a problem caused by nodes to distant from the current step
    - They contain a memory component called the forget gate
  - General Adversarial Network (GAN)
  - Deep Reinforcement Learning
  - These have had great success solving problems lately but are more difficult to use
  

3 - Data Normalization

4 - Using Keras as a TensorFlow Interface

5 - Designing a Model

6 - Training a Model

7 - Making Predictions

8 - The Keras Paradigm

9 - From Data Preparation to Modeling

10 - Reshaping the Time-Series Data

11 - Reshaping the Time-Series Data

12 - Training a Model

13 - Training a Model

14 - Making Predictions

15 - Overfitting

16 - Summary
Summary of what the chapter covered



                    Section 3 - MODEL EVALUATION AND OPTIMIZATION
1 - Lesson Overview
A quick overview of what the section will cover

2 - Model Evaluation

3 - Using TensorBoard

4 - Implementing Model Evaluation Metrics

5 - Evaluating Bitcoin Model

6 - Model Predictions

7 - Interpreting Predictions

8 - Hyperparameter Optimization

9 - Epochs Implementation

10 - Regularization Strategies Implementation

11 - Summary
Summary of what the chapter covered



                    Section 4 - PRODUCTIZATION
1 - Lesson Overview
A quick overview of what the section will cover

2 - Handling and Dealing with New Data

3 - Re-Training an Old Model

4 - Training a New Model

5 - Deploying a Model as a Web Application

6 - Building and executing a Docker run command

7 - Deployment and using Cryptonic

8 - Summary
Summary of what the chapter covered

