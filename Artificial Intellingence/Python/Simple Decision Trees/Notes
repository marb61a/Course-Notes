                    Simple Decision Trees
                    Notes

Decision Trees
  - A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences
    - This includes chance event outcomes, resource costs and utility
  - It is one way to display an algorithm that only contains conditional control statements
  - Decision Trees can lack accuracy at times however there are variants which will help
  - There are 2 types of Decision Tree
    - Regression Tree for continuous target variables
    - Classification for discrete categorical target variables
  - The first part of the tree is the root node
    - Where there is a decision to be made is called a root node
    - The small tree that follows from a decision is called a sub-tree

Concepts
  - The set of possible values is called the predictor space
  - This predictor space is divided into J distinct and non-overlapping regions
  - For every observation that falls into the region Rj, we make the same prediction
    - This is simply the mean of the response values for the training values in Rj
    - The goal is to minimise RSS
  - This uses a Top-Down Greedy Approach
    - This is known as recursive binary splitting
    - Top-down because it begins at the top of the tree and then successively splits the predictor space
  -
  
