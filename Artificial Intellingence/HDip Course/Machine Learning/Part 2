                    Machine Learning
                    Course Notes Part 2
                    
                    
Cross-Validation
  - This is a resampling procedure that is used to evaluate machine learning models on a limited data sample
  - It has a single parameter called k which refers to the number of groups that a sample has to be split into
  - This procedure is referred to as k-fold cross-validation
  - This is useful for smaller data where it is better to not reserve a portion for validation
  - When estimating generalisation errors there must be data that was not seen during training
  - The data is then split as follows
    - Training set (50%)
    - Validation set (25%)
    - Test set (25%)

Cross Industry Standard Process
  - There are noted on CRISP-DM available at the following url
    - https://github.com/marb61a/Course-Notes/tree/master/Artificial Intellingence/HDip Course/Strategic Thinking
  
Classification and Regression
  - When doing classification the goal is to predict a class label
    - This is a choice from a pre-determined list of possibilities
  - Classification is further separated into binary and multiclass classification
    - Binary Classification which is the special case of distinguishing between exactly two classes
      - This can be though of as the answer to a yes\no question
      - A real world use is deciding what is spam
    - Multiclass Classification which is classification between more than two classes
  - A clear way to distinguish between classification and regression tasks is to ask whether there is some kind of continuity in the output
    - If there is continuity between outcomes then the problem is a regression
    - One example is a person's annual income 49999 and 50001 is a regression problem and there is little tangible difference
    - A classification example is languages eg English and Chinese, there is no midway language

Generalization, Overfitting, and Underfitting
  - In supervised learning the model is built on the training data
    - This should be able to make accurate predictions on new, unseen data that has the same characteristics as the training set used
  - If the model is able to make accurate predictions on unseen data then it is said to be able to generalise from the training to the test set
  - In ML models, our objective is to build a model that is able to generalize as accurately as possible
    - If the training and test sets have enough in common, we expect the model to be accurate on the test set
  - There are times when this can go wrong though
    - One way in which things go wrong are to build models that are too complex
  -
  
