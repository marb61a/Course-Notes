                    Linux CBT XenVM Edition Notes


1 - Welcome Message
A welcome message and a brief introduction to the syllabus

2 - Xen Features
Example uses Ubuntu
Xen can be implemented across all distros with minor changes
Backend of Xen will be non-graphical
Some of the features of XenVM are
  - It is a Tier 1 Hypervisor which means that it is a Bare Metal Hypervisor
    - Bare Metal is as close to the physical hardware as possible
    - It is known as a para-virtualisation environment because it is a quick way to insatntiate 
      Linux instances that are in their own sandboxed secure environments
    - Hypervisor is sometimes referred to as a scheduler
    - VMWare is also a Tier 1 provider
    - The difference is that Xen is installed after the OS is installed where as VMWare ESX is installed prior
      - Appears to run on the existing OS
      - Xen intersperses between hardware and the base OS (This is sometimes known as DOM0)
  - It ports OS to run in para-virtual mode which is largely for Linux guests
    - para-virtual is a quasi full installation/virtualisation
    - It maybe the favoured way to run Linux Guest 
    - OS kernel must support Xen or Xen must have virtualisation features eg Intel VT or AMD SVM
      - As of Ubuntu 11.x default kernel supports Xen
  - DOM0 which is the management domain provides hardware access to DOMU's which are guests
    - All DOMU's communicate via DOM0
  - Xen provides rapid provisioning of GUESTS(DOMU's)
    - For example on-demand systems on customer requests
    - The elasticity this provides is reflected in the plethora of online services available
      - The elasticity also helps wtih dynamic adjustments of resources
  - Xen provides 2 different types of GUESTS
    - para-virtualized(PV)
      - Xen-aware GUESTS which is the default
      - Useful for Xen-aware GUESTS
      - Faster than Hardware Virtual Machine(HVM)
      - This approach does not require Hypervisor BIOS support
      - Does not require internal BIOS and GRUB to boot system
    - Hardware Virtual Machine(HVM)
      - Provides fully virtualised environment
        - This means that it has virtualised BIOS, peripherals, storage etc
      - This feature is useful for all supported guests
      - It is also more compatible across platforms than the PV implementations
        - If you are only running Linux derivatives then PV may be the better choice
      - This also requires motherboard enabled virtualisation Intel VT etc
  - Domains are synonymous with GUESTS or VM's or DOMU's as the terminology calls them
  - It runs on both Intel & AMD 64 & 32 bit systems
  - 32 & 64 bit kernels can host both 32 & 64 bit kernels
  - There are up to 32 CPU's per guest 64 on IA64
  - The Xen kernel runs in Domain 0 while GUEST's run in Domains such as Domain 1, Domain 2 etc
  - 32 Xen requires having PAE and supports up to 16gb RAM
    - https://en.wikipedia.org/wiki/Physical_Address_Extension
  - 64 bit Xen requires Intel or AMD and supports up to 1TB RAM
  - There are management tools available
    - xend which runs in Domain 0 and provides console and management access to VM's 
      - This has the ability to Stop, Start, Resume VM's as needed
    - xm which is the common management client and is used via DOM0
      - This is used to Create, Destroy, Delete VM's etc
  - There are some different options available for the provisioning of VM's
    - Xen Tools
    - Virtual Manager 
    - You can also download prebuilt images
  - Virtual Networking is provided via point to point interfaces
  - There is live migration support which means that there is the ability to migrate while operable, this feature
    is disabled by default so will need to be enabled

3 - Network Bridging
This is an integral part of virtualisation #This provides DOMU's with network access
Bridging is a very common method that is used to give DOMU's network access
  - Other methods frequenly used include tunnelling, NAT & routing
Guests use virutal interfaces to identify interfaces to link back to the host (DOM0)
  - virtual interfaces also called vif
  - The scheme to identify each vif is vifDOMID.num
  - From the DOMU perspective interfaces are as normal eth0, eth1 etc
  - IP configuration is also applied as normal
    - static or dhcp and in /etc/network/interfaces
NAT - Network Address Translation is also an option
  - This is a more cumbersome approach to administer
On some distributions such as CentOS or RedHat you should disable Network Manager
  - Use manual approach to handling network connectivity
Installation of some items are needed - Sample Network topology is used
  - Bridging Tools
    - To check to see if it is already installed
      - aptitude search bridge-utils
    - To install if not already
      - aptitude install bridge-utils
    - To show currently defined bridges
      - brctl show
    - Get to know the exiting environment
      - ifconfig - a      // shows all interfaces
    - Bridging the eth0 via the /etc/network/interafaces config file
      - It is necessary to change IP config from eth0 to bridge interface xenbr0
      - Xen uses the first available bridge interface shown with the brctl show command eg xenbr0
    - Syntax from editing the interfaces file
      - auth eth0                   // Will automatically bring eth0 up
      - iface eth0 inet manual      // Instead of assigning IP addresses via DHCP or statically
      - auto xenbr0                 // Sets the Xen Bridge interface
  -

4 - Xen Installation

5 - HVM Preparation

6 - HVM Installation

7 - XM Management

8 - Virtual Manager GUI

9 - Clone VM-LVM

10 - Xen Tools PVGuest
