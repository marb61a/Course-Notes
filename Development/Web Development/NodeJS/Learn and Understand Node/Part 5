                    Learn and Understand NodeJS
                    Course notes Part 5


9 - Files and fs
Built in fs module deal with the filesystem
readFileSync is used to read a file in
Reading OS files will be in binary format
In fs.js source code readSync method uses a buffer
Syntax 
  var fs = require('fs');
  var greet = readFileSync(__dirname + 'file path', 'utf-8');
  
  // This pattern is called an error first callback, callbacks should have an error as their first parameter
  // The first parameter is an error
  // If no error then null otherwise will contain an object defining the error
  var greet2 = readFile(__dirname + 'file path', function(err, data){
    console.log(data);  
  });
  
  console.log(greet);
Sync indicates a synchronous approach
You may not want to use synchronous approaches due to a large amount of usage for example
The readFile() method takes a callback as it is asynchronous

10 - Streams
A stream is just a sequence of data in chunks
Sometimes the word chunk is used in stream code
stream.js exports constructor
Streams are event emitters
  - They have access to mthods like on() and emit();
There is now a variety of streams now available
  - Readable
  - Writeble
  - Duplex 
  - Transform
  - Passthrough
In Node.js sreams are merely an abstract class
  - An abstract class is a type of constructor that you never work with directly but inherit from
  - We create new custom objects that inherit from the abstract class
  - When we talk about readable or writable it is from a Node perspective
  - We need to use a concrete implementation
  - createReadStream is a method in fs.js, it takes a filepath and options which is actually an object and becomes a name value pair
  - createReadStream creates a ReadStream
  - A ReadStream is a special read only stream

Using a Lorem Ipsum generator to build an example file
  - http://www.lipsum.com
Example Syntax
  var fs = require('fs');
  
  // Highwatermark will allow for adjustment of buffer size
  var readable = fs.createReadStream(__dirname + 'filename', {endcoding: 'utf8', highWatermark: 32 * 1024});
  
  // Writable stream
  var writable = fs.createWriteStream(__dirname + 'new file');
  
  readable.on('data', function(chunk){
    // Buffer by default is 64k
    console.log(chunk);
    // To show the amount of data
    console.log(chunk.length);
    // Write the chunks to the file
    writable.write(write);
  });


11 - Conceptual Aside: Pipes
Pipes are how you connect two streams, the pipe is when you write to one stream what you are reading from another
In Node you pipe from a readbable stream to a writable stream
Pipes can be chained


12 - Pipes
Examining the _stream_readable.js file in the node source code
You dont have to stream to and from files
Node likes working with streams

Example Syntax
  var fs = require('fs');
  
  var readable = fs.createReadStream(__dirname + 'filename');
  
  // Writable stream
  var writable = fs.createWriteStream(__dirname + 'new file');
  
  readable.pipe(writable);

Example Syntax
  // using zlib for using gzip compression
  var fs = require('fs');
  var zlib = require('zlib');

  var readable = fs.createReadStream(__dirname + 'filename');

  // Writable stream
  var writable = fs.createWriteStream(__dirname + 'new file');
  
  var compressed = fs.createWriteStream(__dirname + 'new file.gz');
  
  // Creating a gzip file
  var gzip = zlib.createGzip();

  readable.pipe(writable);
  readable.pipe(gzip).pipe(compressed);
  
Method Chaining is where a method returns an object so that we can keep calling methods
  - If it returns the parent object it is called cascading


13 - Web Server Checklist
A list of things needed by Javascript to manage a server

