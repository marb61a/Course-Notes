How to Do a Content Audit [Updated for 2017]
What is a content audit?
A content audit for the purpose of SEO includes a full inventory of all indexable content on a domain, which is then analyzed using 
performance metrics from a variety of sources to determine which content to keep as-is, which to improve, and which to remove or 
consolidate.

What is the purpose of a content audit?
A content audit can have many purposes and desired outcomes. In terms of SEO, they are often used to determine the following:
 How to escape a content-related search engine ranking filter or penalty
 Content that requires copywriting/editing for improved quality
 Content that needs to be updated and made more current
 Content that should be consolidated due to overlapping topics
 Content that should be removed from the site
 The best way to prioritize the editing or removal of content
 Content gap opportunities
 Which content is ranking for which keywords
 Which content should be ranking for which keywords
 The strongest pages on a domain and how to leverage them
 Undiscovered content marketing opportunities
 Due diligence when buying/selling websites or onboarding new clients
The overall “purpose” of a content audit can be defined as:
The purpose of a content audit for SEO is to improve the perceived trust and quality of a domain, while optimizing crawl budget and the
flow of PageRank (PR) and other ranking signals throughout the site. Often, but not always, a big part of achieving these goals involves the removal of low-quality content from search engine indexes. I’ve been told people hate this word, but I prefer the “pruning” analogy to describe the concept.

How & why “pruning” works
Content audits allow SEOs to make informed decisions on which content to keep indexed “as-is,” which content to improve, and which to 
remove. Optimizing crawl budget and the flow of PR is self-explanatory to most SEOs. But how does a content audit improve the perceived
trust and quality of a domain? By removing low-quality content from the index (pruning) and improving some of the content remaining in 
the index, the likelihood that someone arrives on your site through organic search and has a poor user experience (indicated to Google 
in a variety of ways) is lowered. Thus, the quality of the domain improves. I’ve explained the concept here and here.
Others have since shared some likely theories of their own, including a larger focus on the redistribution of PR.
Case study after case study has shown the concept of “pruning” (removing low-quality content from search engine indexes) to be 
effective, especially on very large websites with hundreds of thousands (or even millions) of indexable URLs. So why do content audits 
work? Lots of reasons. But really... Does it matter?

How to do a content audit
Just like anything in SEO, from technical and on-page changes to site migrations, things can go horribly wrong when content audits 
aren’t conducted properly. The most common example would be removing URLs that have external links because link metrics weren’t 
analyzed as part of the audit. Another common mistake is confusing removal from search engine indexes with removal from the website.

Content audits start with taking an inventory of all content available for indexation by search engines. This content is then analyzed against a variety of metrics and given one of three “Action” determinations. The “Details” of each Action are then expanded upon.

The variety of combinations of options between the “Action” of WHAT to do and the “Details” of HOW (and sometimes why) to do it are as varied as the strategies, sites, and tactics themselves. Below are a few hypothetical examples:


You now have a basic overview of how to perform a content audit. More specific instructions can be found below.

The process can be roughly split into three distinct phases:

Inventory & audit
Analysis & recommendations
Summary & reporting
The inventory & audit phase

Taking an inventory of all content, and related metrics, begins with crawling the site.

One difference between crawling for content audits and technical audits:

Technical SEO audit crawls are concerned with all crawlable content (among other things).

Content audit crawls for the purpose of SEO are concerned with all indexable content.

{Expand for more on crawlable vs. indexable content}

All of this is changing rapidly, though. URLs as the unique identifier in Google’s index are probably going away. Yes, we’ll still have URLs, but not everything requires them. So far, the word “content” and URL has been mostly interchangeable. But some URLs contain an entire application’s worth of content. How to do a content audit in that world is something we’ll have to figure out soon, but only after Google figures out how to organize the web’s information in that same world. From the looks of things, we still have a year or two.

Until then, the process below should handle most situations.

Step 1: Crawl all indexable URLs

A good place to start on most websites is a full Screaming Frog crawl. However, some indexable content might be missed this way. It is not recommended that you rely on a crawler as the source for all indexable URLs.

In addition to the crawler, collect URLs from Google Analytics, Google Webmaster Tools, XML Sitemaps, and, if possible, from an internal database, such as an export of all product and category URLs on an eCommerce website. These can then be crawled in “list mode” separately, then added to your main list of URLs and deduplicated to produce a more comprehensive list of indexable URLs.

Some URLs found via GA, XML sitemaps, and other non-crawl sources may not actually be “indexable.” These should be excluded. One strategy that works here is to combine and deduplicate all of the URL “lists,” and then perform a crawl in list mode. Once crawled, remove all URLs with robots meta or X-Robots noindex tags, as well as any URL returning error codes and those that are blocked by the robots.txt file, etc. At this point, you can safely add these URLs to the file containing indexable URLs from the crawl. Once again, deduplicate the list.

Crawling roadblocks & new technologies

Crawling very large websites

First and foremost, you do not need to crawl every URL on the site. Be concerned with indexable content. This is not a technical SEO audit.

{Expand for more about crawling very large websites}

Crawling dynamic mobile sites

This refers to a specific type of mobile setup in which there are two code-bases –– one for mobile and one for desktop –– but only one URL. Thus, the content of a single URL may vary significantly depending on which type of device is visiting that URL. In such cases, you will essentially be performing two separate content audits. Proceed as usual for the desktop version. Below are instructions for crawling the mobile version.

{Expand for more on crawling dynamic websites}
Crawling and rendering JavaScript

One of the many technical issues SEOs have been increasingly dealing with over the last couple of years is the proliferation of websites built on JavaScript frameworks and libraries like React.js, Ember.js, and Angular.js.

{Expand for more on crawling Javascript websites}
Step 2: Gather additional metrics

Most crawlers will give you the URL and various on-page metrics and data, such as the titles, descriptions, meta tags, and word count. In addition to these, you’ll want to know about internal and external links, traffic, content uniqueness, and much more in order to make fully informed recommendations during the analysis portion of the content audit project.

Your process may vary, but we generally try to pull in everything we need using as few sources as possible. URL Profiler is a great resource for this purpose, as it works well with Screaming Frog and integrates easily with all of the APIs we need.

Once the Screaming Frog scan is complete (only crawling indexable content) export the “Internal All” file, which can then be used as the seed list in URL Profiler (combined with any additional indexable URLs found outside of the crawl via GSC, GA, and elsewhere).


This is what my URL Profiler settings look for a typical content audit for a small- or medium-sized site. Also, under “Accounts” I have connected via API keys to Moz and SEMrush.

Once URL Profiler is finished, you should end up with something like this:


Screaming Frog and URL Profiler: Between these two tools and the APIs they connect with, you may not need anything else at all in order to see the metrics below for every indexable URL on the domain.

The risk of getting analytics data from a third-party tool

We've noticed odd data mismatches and sampled data when using the method above on large, high-traffic websites. Our internal process involves exporting these reports directly from Google Analytics, sometimes incorporating Analytics Canvas to get the full, unsampled data from GA. Then VLookups are used in the spreadsheet to combine the data, with URL being the unique identifier.

Metrics to pull for each URL:

Indexed or not?
If crawlers are set up properly, all URLs should be “indexable.”
A non-indexed URL is often a sign of an uncrawled or low-quality page.
Content uniqueness
Copyscape, Siteliner, and now URL Profiler can provide this data.
Traffic from organic search
Typically 90 days
Keep a consistent timeframe across all metrics.
Revenue and/or conversions
You could view this by “total,” or by segmenting to show only revenue from organic search on a per-page basis.
Publish date
If you can get this into Google Analytics as a custom dimension prior to fetching the GA data, it will help you discover stale content.
Internal links
Content audits provide the perfect opportunity to tighten up your internal linking strategy by ensuring the most important pages have the most internal links.
External links
These can come from Moz, SEMRush, and a variety of other tools, most of which integrate natively or via APIs with URL Profiler.
Landing pages resulting in low time-on-site
Take this one with a grain of salt. If visitors found what they want because the content was good, that’s not a bad metric. A better proxy for this would be scroll depth, but that would probably require setting up a scroll-tracking “event.”
Landing pages resulting in Low Pages-Per-Visit
Just like with Time-On-Site, sometimes visitors find what they’re looking for on a single page. This is often true for high-quality content.
Response code
Typically, only URLs that return a 200 (OK) response code are indexable. You may not require this metric in the final data if that's the case on your domain.
Canonical tag
Typically only URLs with a self-referencing rel=“canonical” tag should be considered “indexable.” You may not require this metric in the final data if that's the case on your domain.
Page speed and mobile-friendliness
Again, URL Profiler comes through with their Google PageSpeed Insights API integration.
Before you begin analyzing the data, be sure to drastically improve your mental health and the performance of your machine by taking the opportunity to get rid of any data you don’t need. Here are a few things you might consider deleting right away (after making a copy of the full data set, of course).

Things you don’t need when analyzing the data

{Expand for more on removing unnecessary data}
Hopefully by now you've made a significant dent in reducing the overall size of the file and time it takes to apply formatting and formula changes to the spreadsheet. It’s time to start diving into the data.

The analysis & recommendations phase

Here's where the fun really begins. In a large organization, it's tempting to have a junior SEO do all of the data-gathering up to this point. I find it useful to perform the crawl myself, as the process can be highly informative.

Step 3: Put it all into a dashboard


Even after removing unnecessary data, performance could still be a major issue, especially if working in Google Sheets. I prefer to do all of this in Excel, and only upload into Google Sheets once it's ready for the client. If Excel is running slow, consider splitting up the URLs by directory or some other factor in order to work with multiple, smaller spreadsheets.

Creating a dashboard can be as easy as adding two columns to the spreadsheet. The first new column, “Action,” should be limited to three options, as shown below. This makes filtering and sorting data much easier. The “Details” column can contain freeform text to provide more detailed instructions for implementation.


Use Data Validation and a drop-down selector to limit Action options.

Step 4: Work the content audit dashboard

All of the data you need should now be right in front of you. This step can’t be turned into a repeatable process for every content audit. From here on the actual step-by-step process becomes much more open to interpretation and your own experience. You may do some of them and not others. You may do them a little differently. That's all fine, as long as you're working toward the goal of determining what to do, if anything, for each piece of content on the website.

A good place to start would be to look for any content-related issues that might cause an algorithmic filter or manual penalty to be applied, thereby dragging down your rankings.

Causes of content-related penalties

These typically fall under three major categories: quality, duplication, and relevancy. Each category can be further broken down into a variety of issues, which are detailed below.

{Expand to learn more about quality, duplication, and relevancy issues}
It helps to sort the data in various ways to see what’s going on. Below are a few different things to look for if you’re having trouble getting started.

{Expand to learn more about what to look for}
Taking the hatchet to bloated websites

For big sites, it's best to use a hatchet-based approach as much as possible, and finish up with a scalpel in the end. Otherwise, you'll spend way too much time on the project, which eats into the ROI.


This is not a process that can be documented step-by-step. For the purpose of illustration, however, below are a few different examples of hatchet approaches and when to consider using them.

{Expand for examples of hatchet approaches}
As you can see from the many examples above, sorting by “Page Type” can be quite handy when applying the same Action and Details to an entire section of the website.


After all of the tool set-up, data gathering, data cleanup, and analysis across dozens of metrics, what matters in the end is the Action to take and the Details that go with it.

URL, Action, and Details: These three columns will be used by someone to implement your recommendations. Be clear and concise in your instructions, and don’t make decisions without reviewing all of the wonderful data-points you’ve collected.

Here is a sample content audit spreadsheet to use as a template, or for ideas. It includes a few extra tabs specific to the way we used to do content audits at Inflow.

WARNING!

As Razvan Gavrilas pointed out in his post on Cognitive SEO from 2015, without doing the research above you risk pruning valuable content from search engine indexes. Be bold, but make highly informed decisions:



Content audits allow SEOs to make informed decisions on which content to keep indexed “as-is,” which content to improve, and which to remove.

The reporting phase

The content audit dashboard is exactly what we need internally: a spreadsheet crammed with data that can be sliced and diced in so many useful ways that we can always go back to it for more insight and ideas. Some clients appreciate that as well, but most are going to find the greater benefit in our final content audit report, which includes a high-level overview of our recommendations.


Counting actions from Column B

It is useful to count the quantity of each Action along with total organic search traffic and/or revenue for each URL. This will help you (and the client) identify important metrics, such as total organic traffic for pages marked to be pruned. It will also make the final report much easier to build.


Step 5: Writing up the report

Your analysis and recommendations should be delivered at the same time as the audit dashboard. It summarizes the findings, recommendations, and next steps from the audit, and should start with an executive summary.

Here is a real example of an executive summary from one of Inflow's content audit strategies:

As a result of our comprehensive content audit, we are recommending the following, which will be covered in more detail below:

Removal of about 624 pages from Google index by deletion or consolidation:

203 Pages were marked for Removal with a 404 error (no redirect needed)
110 Pages were marked for Removal with a 301 redirect to another page
311 Pages were marked for Consolidation of content into other pages
Followed by a redirect to the page into which they were consolidated
Rewriting or improving of 668 pages

605 Product Pages are to be rewritten due to use of manufacturer product descriptions (duplicate content), these being prioritized from first to last within the Content Audit.
63 "Other" pages to be rewritten due to low-quality or duplicate content.
Keeping 226 pages as-is

No rewriting or improvements needed
These changes reflect an immediate need to "improve or remove" content in order to avoid an obvious content-based penalty from Google (e.g. Panda) due to thin, low-quality and duplicate content, especially concerning Representative and Dealers pages with some added risk from Style pages.

The content strategy should end with recommended next steps, including action items for the consultant and the client. Below is a real example from one of our documents.

We recommend the following three projects in order of their urgency and/or potential ROI for the site:

Project 1: Remove or consolidate all pages marked as “Remove”. Detailed instructions for each URL can be found in the "Details" column of the Content Audit Dashboard.

Project 2: Copywriting to improve/rewrite content on Style pages. Ensure unique, robust content and proper keyword targeting.

Project 3: Improve/rewrite all remaining pages marked as “Improve” in the Content Audit Dashboard. Detailed instructions for each URL can be found in the "Details" column

Content audit resources & further reading

Understanding Mobile-First Indexing and the Long-Term Impact on SEO by Cindy Krum
This thought-provoking post begs the question: How will we perform content inventories without URLs? It helps to know Google is dealing with the exact same problem on a much, much larger scale.

Here is a spreadsheet template to help you calculate revenue and traffic changes before and after updating content.

Expanding the Horizons of eCommerce Content Strategy by Dan Kern of Inflow
An epic post about content strategies for eCommerce businesses, which includes several good examples of content on different types of pages targeted toward various stages in the buying cycle.

The Content Inventory is Your Friend by Kristina Halvorson on BrainTraffic
Praise for the life-changing powers of a good content audit inventory.



Mastering Google Search Operators in 67 Easy Steps
This post is a journey in 67 parts, split into five functional stories:
 - Content Research
 - Title Research
 - Plagiarism Check
 - Competitive Research
 - Technical SEO/Audits
When you're done, you'll understand not only what each operator does, but how to use it in real-world situations and mix-and-match it 
with other useful operators.
I. Content Research
Crafting original content in 2017 requires wading into the sea of content that's already been created, and Google remains the most 
complete map of that sea. Advanced search operators are invaluable research tools for content marketers.

1. Find all the content
 - tesla
Let's say you've got a blog post to write about the inventor Nikola Tesla. You hop over to Google and search "tesla, Google has decided 
that Tesla Motors is the dominant intent for this phrase, which doesn't help you very much for your current project.

2. Narrow your search
 - nikola tesla
So, of course you add more keywords and narrow your search. Now you're on the right track. Anyone who's ever run a Google search 
understands this, but there's an important point here that we often overlook. Whenever you string together more than one word in a 
Google search, Google connects them with a logical AND. This is true of both keywords and operators. If you combine operators, Google 
will assume that you meant AND and will try to meet all conditions.

3. Mind special characters
 - tesla ac/dc
Let's say you want to specifically find pages with the phrase "ac/dc", so you try the search above. Google has returned anything 
matching "AC" and "DC" separately. In this case, they've treated the forward slash as the same as a space, which probably isn't what 
you intended.

4. Force exact match with quotes
 - tesla "ac/dc"
By putting quotation marks around a phrase, you can force an exact-match search. This requires Google to match the specific, full
phrase – with all terms and in the order specified This is a lot closer than the previous attempt, but Google is still taking some 
liberties with the forward slash. Be sure to do a sanity check of results any time you use non-alphanumeric characters in a search.

5. Force a logical OR
 - tesla OR edison
If you specifically want a logical OR between keywords or operators, use the "OR" operator. OR must be in all-caps, or, alternatively 
you can use the pipe symbol (|). Note that, in most cases, Google is still going to give priority to results that contain both terms. 
Specifying logical OR is most useful when two terms only co-occur rarely.

6. Group terms with parentheses
 - (tesla OR edison) alternating current
Some operators, including OR, are more useful in complex searches. Here, we're using parentheses to group "tesla OR edison" and then 
are adding "alternating current" as an AND condition. Requiring all three terms might be unnecessarily restrictive. By using both ANDs
and ORs in the same search, we're giving Google a bit more flexibility. Since you probably don't want to memorize the precedence of all 
Google search operators, I highly recommend using parentheses whenever you're in doubt.

7. Exclude specific terms
 - tesla -motors
Maybe you want to know what other uses of "tesla" are out there, beyond Tesla Motors. You could use the (-) operator to tell Google to 
exclude any result with "motors" in it. Browsing these results, you can see quickly that Tesla is also a band and a unit of measurement.
Keyword exclusions are also called "negative keywords" (thus the minus sign).

8. Exclude multiple terms
 - tesla -motors -car -battery
Like positive keywords,you can chain together negative keywords. Each minus sign should only be paired with a single keyword or operator.

9. Exclude exact-match phrases
 - tesla -motors -"rock n roll"
You can exclude full phrases by using the (-) sign followed by the phrase in quotes You can combine individual negative keywords with
negative exact-match phrases as needed.

10. Match broadly with wildcards
 - tesla -motors "rock * roll"
What if you specifically wanted to include more about the rock-n-roll band, but you didn't care whether it was spelled "rock-n-roll,"
"rock and roll," or "rock & roll," etc.? You can use the asterisk (*) operator as a wildcard to replace any single word:
Wildcards behave most predictably within an exact-match phrase, allowing you to find near-matches when you can't pin down your search to
a single phrase. The (*) operator only operates on the word level. There is no single-character wildcard operator.

11. Find terms near each other
 - tesla AROUND(3) edison
Maybe you want to find results where "Tesla" and "Edison" not only appear in the document but are fairly close to each other. 
The AROUND(X) operator tells Google to only return results where the two words are within X words of each other. Phrases like 
"Tesla vs. Thomas Edison" show up as matches, but an article where the two men were mentioned in separate paragraphs wouldn't.

12. Find near exact-match phrases
 - "nikola tesla" AROUND(2) "thomas alva edison"
What if, for some reason, you really needed references to include full names? You can combine AROUND(X) with exact-match phrases 
(in quotes). AROUND(X) only works on the entities immediately preceding and following it, so be careful when combining it with other 
operators or phrases that aren't exact-match. Note that AROUND(0) returns strange results – if you want to return two words only if 
they appear together, use an exact-match phrase instead.

13. Find content on specific sites
- nikola tesla site:pbs.org
The "site:" operator is an advanced command that lets you specify a specific domain you want to search on. We usually think of it as
a technical SEO and audit tool, but it can also help you refine content searches. Let's say you remembered reading an article on PBS 
about Tesla, but lost the URL. Typically, you'll use "site:" with a root domain (i.e. leave subdomains, like "www", off) to match as 
broadly as possible. Advanced operators like "site:" can be combined with each other and with keywords.

14. Find content on specific TLDs
 - nikola tesla site:edu
You don't have to include a full domain with "site:". For example, let's say you wanted to find any content about Nikola Tesla on a 
university website. You could search on all ".edu" domains (also known as a Top-Level Domain, or TLD). The "site:" operator will not
work on a partial domain name. It only accepts full domains, root domains, or TLDs. You can use it on country-specific TLDs (ccTLDs), 
such as "co.uk" or "com.sg".

15. Find content on multiple TLDs
 - nikola tesla (site:gov OR site:edu)
Just as with keywords, you can combine "site:" operators with logical OR to search multiple domains:
Often, it's easier and a bit less confusing to run individual searches, but this example is just to illustrate that you can combine 
advanced operators in complex ways.

16. Dealing with broad matches
 - discount airfare
Google is getting better at matching synonyms, which is usually good thing, but it sometimes means that results are a lot broader than
you might have expected. Here, a search for "discount airfare" is returning keywords like "cheapest flights," "cheap flights," 
"airfare deals," and a variety of other combinations.

17. Use exact-match to block synonyms
 - "discount airfare"
This is another situation where exact-match can help. It doesn't just tell Google to use the full phrase, but it blocks Google from 
returning any kind of broad match, including synonyms. Obviously, the results may still contain synonyms (naturally written content 
often does), but using exact-match ensures that there will be at least one instance of "discount airfare" in each of the results you 
get back.

18. Exact-match on a single word
 - discount "airfare"
This may seem counter-intuitive, but you can apply exact match to just one word. In this case, putting an exact match on "airfare" 
blocks Google from using synonyms just for that word. Here, Google is free to match on synonyms for "discount" (such as "cheapest"),
but every result is forced to include "airfare." Exact-match single words when you want to exclude variations of that word.

19. What to do when exact-match fails
 - "orbi vs eero vs google wifi"
The other day, I was searching for articles that specifically compared Orbi, Eero, and Google Wifi networking hardware. Something odd 
happened when I searched on the exact-match phrase. It's not obvious from the search results themselves, but the first result doesn't 
contain the phrase anywhere in the body of the text. On rare occasion, Google may match a phrase on secondary relevance factors, such 
as inbound link anchor text.

20. Search only in the body text
 - intext:"orbi vs eero vs google wifi"
In these rare cases, you can use the "intext:" operator. This forces Google to find the text in the body of the document. Now, all of 
the top results clearly have an exact match in the content itself. Interestingly, the second result reveals what happened with our last
search. 

21. Find a set of keywords in the text
 - allintext: orbi eero google wifi
What if you want to find a set of words, but they don't need to be in an exact-match phrase? You could use a separate "intext:" 
operator for each word, or you could use "allintext:" which tells Google to apply "intext:" to all of the words following the operator.
All of the results have the target keywords in the body text, in some combination or order. Be very careful about mixing "allintext:" 
(or any "allin...:" operator) with other commands, or you could end up with unexpected results. The "allintext:" operator will 
automatically try to process anything that follows it.

II. Title Research
Here are some search operator combos for title research.

22. Check for a specific phrase
 - "tesla vs edison"
You've settled on using "Tesla vs. Edison" in your title, so let's do a quick check on content with that exact-match phrase:
You've pinned down Google to an exact-match phrase, but that phrase can occur anywhere in the text. How do we look for it in just the 
document title?

23. Check for a phrase in the title
 - intitle:"tesla vs edison"
Use the "intitle:" operator to specify that a keyword or phrase (in quotes) has to occur in the document title:
Be aware that sometimes Google may rewrite a display title in search results, so it's possible to get a result back where the phrase 
doesn't seem to match the title because Google has rewritten it.

24. Check multiple keywords in title
 - intitle:tesla intitle:vs intitle:edison
If you want to check for multiple keywords in a title, but don't want to restrict yourself to exact-match, you can string together
multiple "intitle:" operators with single keywords.

25. Check multiple keywords easily
 - allintitle: tesla vs edison
Like "allintext:", there's an "allintitle:" operator. It will match any of the keywords following it returns roughly the same results
as #24.

26. Check for titles with lists
 - intitle:"top 10 facts" tesla
Maybe you've got your heart set on a listicle, but you want to make sure it hasn't been done to death. You can combine an "intitle:" 
operator with a general keyword search on a topic. Theresults are all pages that talk about Tesla but have "Top 10 Facts" in the title.

27. Find lists and exact-match phrases
 - intitle:"top 10 facts" "nikola tesla"
Oops, we 're pulling in results about Tesla Motors again. Luckily, you can combine "intitle:" with exact-match phrases and other, 
more complex operator combos. This is much closer to what you probably had in mind, but the bad news is that the "Top 10" things does 
seem like it's been overdone.

28. Check for Top X lists
 - intitle:"top 7..9 facts" "nikola tesla"
The range (..) operator lets you search for a specific range of numbers. Maybe you're tired of Top 10, but don't want too short of 
a list. Let's check out what Top 7, 8, and 9 lists are out there.This returned only four results, and they were all videos. So, at 
least you're on the right track, originality-wise. Once you master search operators, you'll eventually reach the mythical end of the 
Internet.

29. Check the title for this post
 - intitle:"search operators" "in * easy steps"
Let's put all of this to the test – how original is my title for this post? I'm not expecting an exact match to a post with 67 steps, 
but what about any post mentioning "Search Operators" in the title that also uses some variation of "in * easy steps" anywhere in the 
result? It looks like I did alright, from an originality standpoint. Of course, there are many ways to mix-and-match operators to find
similar titles. Ultimately, you have to decide how you define "unique."


III. Plagiarism Check
You've finally published that article, but you suspect someone else may have copied it and is taking your traffic. Advanced search
operators can be great for hunting down plagiarism.

30. Find articles with your exact title
 - intitle:"duplicate content in a post-panda world"
Use the "intitle:" operator with your exact-match title to easily spot whether someone has copied your entire article with no 
modifications. 

31. Find title matches, excluding sites
 - intitle:"duplicate content in a post-panda world" -site:moz.com
Use (-) with the "site:" operator to exclude specific sites. In this case, we already know that the original title was posted on
Moz.com. It turns out that two of these sites are just linking to the post in kind of a low-quality but not outright malicious way. 
What you really want to know if someone is copying the text wholesale.

32. Find unique, exact-match text
 - "they were frolicking in our entrails" -site:moz.com
Another alternative is to run exact-match on a long, unique phrase. Luckily, this particular blog post has some pretty unique phrases. 
I'm going to keep the Moz.com exclusion. The first result is a harmless (if slightly odd) Facebook post, but the other two are full, 
copied-and-pasted duplicates of the original post.

33. Find unique text only in the body
 - intext:"they were frolicking in our entrails" -site:moz.com -site:facebook.com
If you want to be completely sure that the unique text is in the body of the document, you can use the "intext:" operator. Here, I've 
added both "intext:" and a Facebook exclusion. Within reason, it's ok to mix-and-match a variety of operators: Practically speaking, 
"intext:" often returns similar results to the exact-match phrase by itself. I typically use "intext:" only when I'm seeing strange 
results or want to make absolutely sure that I'm only looking at document body text.

34. Find a quote you're not sure about
 - i would rather kiss a wookiee
What if you're looking for a long quote, but you can't remember if you're getting that quote quite right? We often equate exact-match
with long searches, but sometimes it's better to let Google go broad.

IV. Competitive Research
In some cases, your research may be very focused on what kind of content the competition is creating. Google search operators can help 
you easily narrow down what your competitors are up to.

35. Start with a basic search
 - tesla announcements
Let's say you want to find out who's publishing Tesla Motors announcements, so you start with the simplest query you can think of.

36. Exclude obvious sites
 - tesla announcements -site:tesla.com
You grab the handy "site:" operator and run a negative (-) on Tesla's own site. These are all pretty familiar competitors if you're in
the news game.

37. Target specific competitors
 - tesla announcements site:nytimes.com
Maybe you want to focus on just one competitor. You can use the "site:" operator for that, too. Obviously, this approach is going to 
work best for large competitors with a high volume of content.

38. Target a specific subdomain
 - tesla announcements site:wheels.blogs.nytimes.com
Remember that you can use "site:" with a full subdomain. Maybe you just want to find out what CNN's "Wheels" auto industry blog is 
posting about. You can, of course, exclude specific subdomains with "-site:" as well.

39. Target a specific author on a site
 - tesla announcements site:nytimes.com "neal e boudette"
Maybe you're interested in just a single author. There's no reliable author search operator for organic results, but in most cases, 
just including the author's name as exact-match text will do the trick. Make sure to pull up an article first to see how the author's
name is presented (middle initial, etc.).

40. Target by keywords, site, and title
 - tesla announcements site:nytimes.com intitle:earnings
If you wanted Tesla announcements in the New York Times that only mention "Earnings" in the title, then you can mix-and-match operators 
as needed. Don't be afraid to get creative. The Google index is a big, big place and there's always more to be found, especially on 
very large sites.

41. Find related competitors
 - related:nytimes.com
What if you wanted to branch out to other publications? By using the "related:" operator with a root domain, Google will show you 
other sites/domains like the one you specify. The "related:" operator is great when it works, but be warned that it only works for 
certain niches and typically for larger sites. It's also one of the rare Google search operators that can't be combined with other 
operators.

42. Find content in a specific path
 - tesla announcements site:fortune.com/2016
If you want to drill down into a site, you can specify URL folders with the "site:" operator. Forbes, for example, is conveniently 
organized with year-based folders, so you can easily see just articles from 2016. Keep in mind that this only works for parts of the URL
directly following the domain name. So, how do you search on text in other parts of the URL?

43. Search broadly for a "folder"
 - tesla announcements inurl:2016
Luckily, Google also has an "inurl:" operator. By searching on a year, for example, you can find that year anywhere it happens to 
appear in the result URL. Keep in mind that the text you specify "inurl:" can appear anywhere in the URL, not just at the folder level.

44. Search by a specific date range
 - tesla announcements daterange:2457663-2457754
What if you really want to narrow down your date range? Google also has a "daterange:" operator which lets you pinpoint publication 
dates to the day, in theory. Unfortunately, in regular organic results, publication dates aren't always accurate, and "daterange:" can, 
in practice, return some pretty strange results. You may have noticed, too, that that's not your typical date format. The "daterange:" 
operator uses the Julian date format.

45. Search by broad date range
 - tesla announcement 2015..2017
If you don't need your date range to be particularly precise, consider using the range (..) operator with a year on either side of it. 
As numbers go, years are generally unique enough to return reasonable results. Please note that this is not specifically a date search, 
but as cheats go, it's not a bad one. Unfortunately, the range operator doesn't always work properly paired with "inurl:" and other
advanced operators.

46. Target just one type of file
 - tesla announcements filetype:pdf
The "filetype:" operator lets you specify an extension, such as PDF files. Let's say you only want Tesla announcements that have been
published as PDFs. Other file extensions to try are "doc" (Word), "xls" (Excel), "ppt" (PowerPoint), and "txt" (text files). You can 
also use "filetype:" to specify certain varieties of web pages, including "html", "php", "asp", etc. Keep in mind that the file 
extension typically has to be listed in the URL, so these searches are not exhaustive.

47. Find sites linking to competitors
 - link:nytimes.com tesla
The "link:" operator lets you do competitive link research. For example, the search above looks for all documents relevant to Tesla that
have links from The New York Times.

48. Find links excluding the source
 - link:nytimes.com -site:nytimes.com tesla
Let's combine "link:" with a negative (-) "site:" operator to remove links from The New York Times. Google has deprecated a lot of the 
functionality of the "link:" operator and the results it returns are just a sample (and, potentially, an unreliable sample). For 
in-depth competitive link research, we strongly recommend third-party tools.

49. Search inside link anchor text
 - inanchor:"tesla announcements"
You can use the "inanchor:" operator to search inside linked text. So, for example, the search above looks for sites being linked to 
from sites using "tesla announcements" in the linked text. In other words, the results represent the targets of those links 
(not the sources). Please note that, like the "link:" operator, the "inanchor:" operator represents only a small sample of the index 
and is no longer actively supported by Google. 

50. Search multiple words in anchor text
 - allinanchor: tesla announcements "model x"
Like the other "allin..." varieties, "allinanchor:" applies to every word after it, looking for all of those words in the anchor text, 
but not as an exact-match. The three link-based operators ("link:", "inanchor:", "allinanchor:") can be useful for your initial 
research, but do not expect them to return a full, accurate representation of all links to your site or your competitors.


V. Technical SEO/Audits
Advanced Google search operators can also be powerful tools for understanding how sites are indexed and for performing technical audits.
Technical SEO is a complex subject, of course, but here are a few examples to get you started:

51. Glimpse into a site's index
 - site:amazon.com
It all starts with the "site:" operator, which, at its most basic level, can help you get a glimpse of how Google indexes a site. Here
are a few results from Google's index of Amazon.com. Please note that the result count here (and for any large-volume search) is at best
an estimate. Given an estimate of 119,000,000 pages, though, we can be assured that the real number is massive.

52. Filter out the "www" subdomain
 - site:amazon.com -inurl:www
To drill deep into a site's index, the combination of "site:" with "inurl:" will quickly become your best friend. For example, maybe you
want to see only pages on Amazon that aren't under the "www" subdomain. You could use "site:" along with a negative match (-) on the
"inurl:" operator. Even in the first few results, you can see a sampling of the other subdomains that Google is indexing. This can give
you a good starting point for where to drill down next.

53. Filter out multiple subdomains
 - site:amazon.com -inurl:www -inurl:logistics -inurl:developer -inurl:kdp
You can extend this concept pretty far, building successively on earlier searches to return narrower and narrower lists of pages. 
I've done this with over a dozen "inurl:" statements and am not aware of any fixed limit on how many operators you can combine in a 
single search. Most sites aren't big enough to require those kinds of extremes.

54. Focus on a single subdomain
- site:developer.amazon.com
Alternatively, you can focus on a single subdomain. For this, I generally prefer to include the subdomain in the "site:" operator
instead of using "inurl:". Otherwise, you could find the text anywhere in the URL. You could extend this concept to dive deeper into any
of the sub-folders returned here ("/ios", "/ja", etc.) and even combine a more specific "site:" operator with additional "inurl:" 
operators.

55. Filter for non-secure pages
 - site:amazon.com -inurl:https
Interestingly, you can use "inurl:" to include or exclude secure (https:) pages. If you're moving a site from "http:" to "https:", this 
trick can help you make sure that new pages are being indexed properly and old pages are gradually disappearing from the index.

56. Search for a URL parameter
 - site:amazon.com inurl:field-keywords
You can also use "inurl:" to target URL parameters on dynamic pages. For example, let's say you want to see what kind of internal search
pages Google is indexing on Amazon. Please note that there's no way to specify a URL parameter – Google may find the text anywhere in 
the URL. On the bright side, many URL parameters tend to have unique names.

57. Search multiple URL attributes
- allinurl: amazon field-keywords nikon
Much like "allintitle:" and "allintext:", there's an "allinurl:" operator. In this example, you're looking for internal search pages on 
Amazon that have the word "Nikon" in the URL. Unfortunately, "allinurl:" suffers from two problems. One, you can't reliably combine it
with "site:", which limits your options. Two, it tends to return strange results. For example, notice that the top results for my US 
search were from Amazon France. In most cases, I recommend using multiple "inurl:" statements instead.

58. Find stray text files
site:amazon.com filetype:txt -inurl:robots.txt
You might be wondering if you left any stray documentation files laying around your site that happened to get picked up by Google. You 
can do this using a combination of "site:" and "filetype:". In this case, you want to exclude "robots.txt" (using "-inurl:") because
Amazon has dozens of Robots files. This combo is a good way to clean up files that have been accidentally left live on a site.

59. Dig deep into duplicate content
 - site:amazon.com "hot wheels 20 car gift pack"
A site like Amazon has massive potential for internal duplicate content. By using the "site:" operator with exact match phrases, you 
can start to pin down near-duplicates.

60. Dig through duplicate titles
 - site:amazon.com intitle:"hot wheels 20 car gift pack"
You can specifically using "site:" plus "intitle:" to find pages on a site that may be exact duplicates. Believe it or not, Google 
still returns over 100 matching pages. Let's keep at it...

61. Find title duplicates with exclusions
 - site:amazon.com intitle:"hot wheels 20 car gift pack" -inurl:review -inurl:reviews
You dig in and notice that many of the results in #60 are review pages, with either "review" or "reviews" in the URL. So, you build on 
the previous search and add two exclusions. Voilà... you're down to just a half-dozen results. You just leveled up in technical SEO.

62. Find similar products with different counts
 - site:amazon.com "hot wheels * car gift pack"
Maybe you're curious about other Hot Wheels gifts packs that represent similar products but not exactly the same one. You could 
replace "20" with the wildcard (*) operator. Unfortunately, wildcards don't play well with the "intitle:" operator, so you'll generally 
be restricted to exact-match phrases outside of advanced operators.

63. Find similar products with exclusions
 - site:amazon.com "hot wheels * car gift pack" -20
Given all of the previous searches, you probably don't need to know about the 20-packs, so you can add an exclusion on the number 20 
(just treat it as a word with negative match).

64. Follow the rabbit hole to Wonderland
 - site:amazon.com "hot wheels * car gift pack" -20 -5
It's time to take the red pill and find out just how deep this rabbit hole goes. You can keep adding exclusions and take out the
5-packs as well. Finally, you're nearing the bottom. This process may seem a bit obsessive, but auditing large sites is a process of 
identifying potential problems and drilling down until you either you pin down the issues or decide they aren't worth worrying about.
Once you master them, advanced search operators shine at drill-downs.

65. Bonus: Show me the money!
site:amazon.com "hot wheels" $19.95
I woke up in a cold sweat at 2am realizing I had forgotten a search operator (sadly, while you may find it funny, this is not a joke). 
I warned earlier that special characters can produce weird results, but one that Google does recognize is the dollar sign ($).
This isn't really a site audit example, but it fits well with our Amazon story. Keep in mind that, while Google will honor the ($) in 
the results, they could appear anywhere in those results. Many Amazon pages list multiple prices. Still, it can be a useful tool to add
to your arsenal.

66. Find results in a price range
- site:amazon.com "hot wheels" $19..$20
You can also combine a ($) search with the range operator (..) and search a range of prices. Let's say you wanted to find any pages 
mentioning "Hot Wheels" and prices in the $19-20 range. While this tactic can definitely be useful for general product research,
e-commerce sites can also use it in an audit to find pages with incorrect or outdated prices.

67. Find other TLDs for your brand
- site:amazon.* -site:amazon.com
This last tip could be either an audit trick or a way to track down the competition, depending on how you use it. Use the wildcard (*)
in the top-level domain (TLD) to find any site with the same name, and then exclude the main site. For a large site, like Amazon, this 
could help you find other legitimate TLDs, including country-specific TLDs (ccTLDs). Alternatively, you could use this trick to find 
competitors who have registered your brand name under other TLDs.
