                    AZ900 Microsoft Azure Cloud Fundamentals 2021
                    Additional Material Course Notes Part 6


Blob Lifecycle Management and the Portal
  - Lifecycle management is important when it comes to cloud stored data.
  - Sometimes it might be required for regulatory compliance that you configure how data is treated over time
    - Such as, it be archived and retained for a period of time, or for cost savings
    - Maybe for infrequently accessed data you want Azure to automatically move it to the cool tier to save on costs
    - Either way we can do this with Blob lifecycle management
    - In the portal we are in the navigation bar for an existing Storage account
    - We can scroll down under the Blob service section where we click Lifecycle Management
  - What we are going to do here is add a lifecycle management rule
    - Click Add rule, this rule is going to determine things like how many days we want to elapse before files stored here
    - Blobs, are moved to some other type of storage
  - For example we are going to call this first Rule name CoolStorage
    - For blobs, we can choose to move blobs to cool storage a certain number of days after they were last modified
    - So maybe after 90 days, so that means they're not being written to, we will move it to CoolStorage, which is designed for infrequently accessed data
    - It really does this at a reduced charge. we can also Move blob to archive storage
  -Now you might be required to archive data and retain it for a period of time
    - This would take care of the archiving portion at least in an automated fashion
    - We can also determine if we want to delete blobs after a period of time
    - So a certain number of days after they were last modified and same with Snapshots that might have been taken
    = We can delete blob snapshots, a certain days after the blob was created.
    - We can go ahead and do that, but this is just the rule
  - The next thing we have to do is specify the filter set
    - In other words, to what in the storage account should this rule apply? 
    - Perhaps it's the whole storage account, or maybe a specific container
    - Or maybe only a certain type of file within this storage account
    - We're going to find out what to do by clicking next down below to add the Filter set, now we can add a prefix here
  - There's nothing here by default, which means that if we don't specify anything
    - We are looking at everything stored in this Azure storage account to determine when it was last modified
    - To determine if it should be moved to cool storage
    - But we could specify containers or folders that we want to use as a prefix
    - Instead of typing that in, we are going to click Browse, and from the drop-down list then choose one of our containers
    - In this case, let's say eastprojects, the entire container, and choose Select, it's been added down here to the list.
    - That's what we want this Filter set applied to, that is the filter set.
  - We are going to then click next down at the bottom for review and add, validation has passed, perfect
    - Click Add, so that we can create this lifecycle rule. And we can now see that we have our CoolStorage lifecycle rule and it's been Enabled


Blob Container Access Levels
  - You create blob containers to organize the blobs that you might store within an Azure storage account
    - Each of those blob containers can have an access level, to determine what access is allowed to the container itself or the blobs within it.
  - To get started here in the portal, we are looking at the navigation bar for an existing Storage account
    - Scroll down and choose Blob service, Containers.
    - This way we'll see what's already here. For example, open up the eastdata folder, we'll see any files that might exist there
  - We going to upload a new file, so click Upload, and we will upload a JPEG logo file
    - after a moment, we can see quite clearly that our logo file exists.
    - If I click on that blob, then we can even see what it looks like
    - When it opens up the properties, we can click Edit which in this case shows us that we've got a fictitious logo for a fictitious organization
  - The next thing we want to do is take a look at access to that item
    - For example, if we go to the Overview for that blob or that file, we have a URL
    - The URL we are going to copy because we're going to paste that into a browser to see what kind of access we have to it
    - We can see that the URL consists of the name of the storage account, followed by the default suffix .blob.core.windows.net
    - Then after that we see the path /eastdata is the blob container and the file, of course, we just uploaded is called logo.jpg.
    - put that into a web browser it basically says can't find it, don't know what you're talking about
  - Find out why that message is showing up
    - To do that, we should go back and look at the folder
    - We will have to go back a couple of levels here, so we can jump in and find out what's going on
    - It's eastdata, we can select that folder, and change the access level
    - Now notice, it's currently Private (no anonymous access)
  - That explains why we currently are unable to view that file or access it using the URL
    - Let's change it to, for example Blob (anonymous read access for blobs only)
    - The third option is to allow the enumeration of the container so to list blobs, such as programmatically
    - Here we are just going to choose Blob (anonymous read access for blobs only), so for individual blobs, and click OK
    - So anonymous access, that means no authentication required.
  - There are times when that may be useful for public information posted on a web application and so forth
    - Go ahead and refresh the previous web browser session we had.
    - This time, instead of saying resource not found, it's actually showing the blob to us
    - That's because we've modified the blob container access level to allow access to individual blobs given that we have the URL for that individual blob


Storage Account Queues
  - Within an Azure storage account, you can create queues, scroll down here in the navigation bar for an existing Storage account.
    - Scroll down until we see Queue service and Queues and click on Queues
  - Now, what is the purpose of this? This is of great interest definitely to software developers
    - Because it allows them to build modular code in a loosely coupled way
    - What that means is that multiple software components instead of requiring each to be online to transmit messages
    - They can instead drop messages into a storage queue where the other component can pick up that message when it's available or when it's up and running
    - We are now able to go ahead and click the Add queue button
  - We are going to call this queue1, notice, if we were to put in let's say Q in the name, it doesn't like it so lowercase letters only
    - Now this queue will be referred to programmatically by developers, click OK
  - At this point, we've got a queue created called queue1, we can see if we scroll over here the Url
    - It's using the storage account name, followed by the default DNS suffix of .queue.core.windows.net
    - Then a reference at the end to the name of the queue
    - Click to open the queue, one of the things we can do here is submit a sample test message.
  - We can click Add message, Hello world, and the default expiration is set for 7 days, leave that and just click OK
    - There's our Hello message being stored in the queue
    - You might do that if you're a developer and then you want to write some code to retrieve the message from it
    - Either way, we can put some sample messages in there
    - We can also define an Access policy, click Access policy on the left, this determines what access is allowed to the queue
    - For example, click Add policy, then the first thing we have to do is specify an Identifier
  - We are going to call this AccessQueue1, then specify the Permissions, for example the ability only to read messages stored in the queue
    - We can specify a start date and time of when that should apply in an expiration date and time of when that should stop
    - That would, of course, be in accordance with the specified time zone information for both the start and explorations
    - Why do this, you would create this access policy as it limited way for software components in this case to read messages in this queue
    - It's good to know it's tied queue1 because we're creating this access policy for queue1
    - Go ahead and click OK and then we are going to Save that policy.
    - What we can also do here, go back to the storage account level, is we can open up the Storage Explorer tool from the navigation bar that's in preview
  - What we can do is generate a shared access signature based on that access policy for the queue, which is kind of a cooler feature
    - We can do it all right in here, for example, take a look at our QUEUES here
    - We can see we've got queue1, and if we right click on it, we can get a shared access signature.
  - Shared Access Signatures traditionally provide limited and in some case timed access where there's an expiration to resources within a storage account
    - As opposed to a storage account access key which gives access to the entire account
    - That's not the case here. It's only really Read access for a specific queue
    - We are going to choose the Access policy from the list here it's AccessQueue1
    - We can see the details for the start and expiration dates and times, and the Permissions which are Read
  - At this time when we created, then we can copy either the URI or the Query string depending on how
    - As developers we are making a connection, to the Shared Access Signature to gain these privileges
