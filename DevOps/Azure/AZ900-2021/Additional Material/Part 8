                    AZ900 Microsoft Azure Cloud Fundamentals 2021
                    Additional Material Course Notes Part 8


Storage Account Replication
  - When you create an Azure storage account, at creation time you can determine whether or not you want a specific type of replication enabled for that account.
  - Replication allows you to increase the data availability for whatever you have stored in the account
    - First of all, we can change this after the fact and we are going to do that in the portal
    - We've got the properties of an existing Storage account displayed and the navigation bar
    - The first thing we'll do is go down to Geo-replication, but when we click there, what we will see is a map with our Primary location
  - Where is the option to add additional locations for replication? Well, there's nothing, not even down at the bottom
    - All we see is that our current primary location is Canada Central
    - Well, that's because we have to enable replication, if it wasn't enabled when the account was created, by going to Configuration over on the left
    - We are going to go ahead and do that so we'll be able to select the type of replication that we're interested in
  - If we take a look, currently it's set to Locally-redundant storage (LRS)
    - What this means is that we've got three copies of data within an Azure location
    - If we've got a problem such as fire in an Azure data center, we might lose all access to those three copies
    - For additional availability, you might select either Geo-redundant storage (GRS), or Read-access geo-redundant storage (RA-GRS).
  - The difference being that with geo-redundant storage if there's a failure in the primary region
    - You've got to initiate a failover to the secondary region where data was copied to in order to be able to access it
    - We are going to choose in this case, Geo-redundant storage (GRS).
    - We going to Save that config change here, we're changing the configuration of an existing Storage account, it says it successfully updated it
  - Go back and let's look at the Geo-replication screen
    - Previously, we had only the blue indicator on the map which according to the legend of what was our Primary location
    - It's automatically determined that geo-replication will be enabled for the green listed item on the map, which is a different location
    - It's another region but it is reasonably close to the primary, which ever is nearest in your case 
    - So now, your region will be replicated to another nearby
    - At this point at the bottom, it says, well you can't even enable failover because replication is happening, you've just enabled this
    - As you might imagine, depending on the amount of data in the account will determine how long it takes for this to complete
    - But at this point, we've increased the availability of the data by replicating it to an alternate or secondary Azure region


Azure Storage Explorer Connectivity
  - Microsoft Azure Storage Explorer is a free GUI tool that lets you connect to various aspects of an Azure storage account
    - Such as, if you want to manage blobs, or queues, or tables, and so on
  - In my browser, I've navigated to the Azure Storage Explorer download page
    - You can search this up quite easily using your favorite search engine
    - We are going to go ahead and download and install Azure Storage Explorer for the Windows platform on my on-premises Windows 10 station
    - You can then start Microsoft Azure Storage Explorer from your Start menu like you would with any app
    - Now, the first thing we need to do here is determine how we are going to make a connection to a storage account in Azure
    -So for example, I can expand Storage Accounts here and I can right-click and choose Connect to Azure storage.
  - We have a number of ways we can do that using my Azure account credentials, or via Azure AD credentials
    - Using a connection string, a shared access signature, a storage account name and a key to it
    - Or we can attach to a local emulator for testing purposes
    - In this case, let's say we want to connect to a storage account using its name and key, then click Next
  - You'll want a Display name for example give it the name of the storage account StorAcct333325
    - We also have to give it an Account name that would be for the storage account and also the Account key
    - We can pop in the actual name of it, storacct333325, however we also need an Account key
  - Here in the portal in oue storage account, we are going to scroll down to Access keys of which there are two
    - It doesn't make a difference which one we copy, so just take the first one and click the copy icon
    - After that then go ahead and paste that in the Account key field
    - That's all we going to change here so click Next and then Connect
  - Now we can see the storage account listed in the navigator and in parentheses the word Key, since that is how we gained access to the account
    - Now we can check out what's in the account, we can drill down into it, expand Blob Containers
    - This shows all of the different blob containers we have and we can click on each one of those and see files, download, upload, content
    - We can also see any Azure File Shares that might have been created, of course, the contents of those file shares.
    - We can see any Queues that might have been defined, and those items are shown here and so on.
  - Really, the Azure Storage Explorer is another way to make a connection to a storage account
    - In our case, with the storage account access key, which gives access to the whole storage account 
    - From which we can then work with the content in the storage account


Storage Account Blob Soft Delete
  - One of the many options you have when you create a storage account in Azure is whether or not you want the blob soft delete option enabled.
  - It's disabled by default. Now you can check this out on an existing Storage account in the portal by going into the navigation bar
    - Scrolling down under Blob service, and choosing Data protection.
  - You will see that the current state is as it was by default Disabled, choose Enabled
    - We've got a retention policy set for a default value of 7 days
    - This means that any data, blob data, that is overwritten or deleted can be recovered for up to 7 days
    - This doesn't apply, if we're talking about a container, essentially a folder that is deleted
    - You can't get those contents back after 7 days, it also doesn't apply if any of the metadata, such as tagging and so on related to blob items is modified
    - Go ahead and click Save to save that change, navigate to our Blob service Containers, and open the example Container called eastprojects
  - In here, I have a file named Project_A.txt, we are going to select that file and choose to Delete it
    - It also asks would you also like to delete any blob snapshots, if there are any
    - We don't have any, so just choose OK and we can now see that our blob is deleted, the file is gone, Project_A.txt
  - Notice within this view here over on the far right I have the option to Show deleted blobs. If I turn that on, we can clearly see Project_A.txt was deleted because the Status says as much.
  - What I can do is click directly on that blob. And when I'm in the properties of it over on the right I can click Undelete. So it says it successfully undeleted it.
  - If we close that current property window or blade, so close that out, we can now see Project_A.txt
    - Instead of having a Status of deleted is now back at being Active
    - And we have the ability then to do this for the retention period, which by default is 7 days.


Storage Account Encryption
  - Encryption of data at rest has become more and more important over time
    - As we keep hearing media reports about compromised customer information for example, due to the fact that data was not stored in an encrypted format
  - Really, in this day and age, that's completely unacceptable as there are so many freely available encryption tools out there
    - In many cases, it's enabled by default, such as with an Azure storage account
    - To explore that a little bit in the portal, we are going to go into Storage accounts and open an existing Azure Storage account
    - What we want to do is scroll down in the navigation bar and click Encryption
    - When we do this, we'll see that it's set currently to Microsoft Managed Keys.
  - Yes, it is server-side encryption. It is enabled but the keys are controlled by Microsoft
    - Depending upon your regulatory compliance requirements, that might not work, you might need to have control of them
    - We do have the option, as we can see here, to enable Customer Managed Keys, down below we can select a Key vault
  - A Key vault is a centralized Azure resource
    - We say centralized only meaning it serves as a central repository to store secrets like PKI certificates, passphrases and of course, keys
    - Other Azure resources or software code that you might develop can refer to this centralized storage location for secrets and call upon things
    - In this case we are going to go and select a key vault
    - Because we want to choose a key from it that will be used to encrypt the storage account and it will be under our control.
    - From the drop-down list, we have a key vault we've created called KV1East1
    - Within it, there is a key called Key1 which is something that we created or generated
    - We can go ahead and choose Select, at this point we've now got the required information to enable Customer Managed Keys here for our storage account
  - After that's filled in, we can go up at the top and choose Save
    - It says it's updating the server-side encryption for the storage account
    - At this point, it's now been enabled, from this point forward, newly added items to the storage account will be encrypted
    - Of course, any existing items will be retroactively encrypted with the background encryption process.
