                    AZ900 Microsoft Azure Cloud Fundamentals 2021
                    Additional Material Course Notes Part 4


Uploading Blobs Using the Portal
  - In this demonstration, I'm going to use the portal to upload some content into an Azure storage account.
  - To get started, we are in the portal and in the Storage accounts view
    - We are going to click on an existing storage account where we are interested in uploading some blob files, binary large objects
    - So scroll down in the navigation bar until we see Blob service and we are going to choose Containers
  - A blob service container is just a folder, the same way you would organize files on a USB drive, for example, by organizing them in folders
    - Well, we do the same thing here with containers, click + Container and start by creating a container called budgets
  - The default Public access level is Private, so no anonymous access
    - Depending on what you might be dumping into this container might require that you enable something different
    - Like anonymous read access for individual blobs or anonymous read access for containers and blobs within them
    - You might do that if you've got some public product brochures or documentation that
    - For example should be made available to anybody on a static host of web site
    - In this case, leave it on Private (no anonymous access) and click Create
    - So we can now see that we have a budgets folder.
  - We can select that folder and click Change access level at any point in time
    - But we are not going to do that, instead we are going to click to open it up to go into it.
  - We are going to go ahead and click the Upload button to upload some content into this blob container
    - Over on the right, we need to select one or more files, which we will do
  - We can specify whether we want to overwrite the files if they're already there
    - Open up Advanced, we can determine if we want to authenticate using the storage Account key versus Azure AD
    - We can determine the Blob type, the default here is set to a Block blob
  - When you're uploading things like Excel spreadsheet files, Block blob would be appropriate
    - But if you're going to be dealing with storing things like virtual hard disk files, page blobs are better
    - Append blobs are useful if you've got files such as logs that keep getting added to
  - We are going to leave it on Block blob, and we are going to go ahead down below 
    - And specify in this case that we wanted to use the Cool Access tier, because it's not going to be accessed frequently
    - We are going to go ahead and click on the Upload button. So we can now see that our content has been uploaded into this container
  - We can also select a specific blob here and then we have options at the top, such as changing tier, so go ahead and do that
    - From the drop-down list we can determine if we want it to be in the Hot, Cool, or Archive tier, but we also can acquire a lease
  - When you acquire a lease on a blob, what you're doing is locking it
    - It's kind of like a resource lock on an entire Azure resource, the difference here being it's a blob within a resource, within a storage account
    - We can also click right on the Name of that uploaded blob and get some details about it
  - We can see the Properties, the URL to it, we can see the modification and creation date and timestamp
    - We can see the size of it and we have the option of downloading it, we can also Delete it, and so on
  - Go back in there for one second, because there's something else that's important
    - When you go into an individual blob, you can also specify a shared access signature just for that specific blob, notice here we have Generate SAS
    - A shared access signature allows you to set an expiration on certain permissions that should apply and in this case, it's for a specific blob.
  - If we were to back out of my budgets container and go back to the Storage account level
    - We can also specify that we want to create a shared access signature at that level
    - So you can do it at the Storage account level, as well as at the individual blob level
    - Shared access signatures of course provide limited access to items within the storage account


Uploading Blobs Using the CLI
  - You can use the Azure CLI to not only create and manage storage accounts, but also to work with the contents within storage accounts
    - Such as uploading blobs, which is going to be the focus of what we're going to do here. 
  - In the Azure portal, we've launched a Cloud Shell, specifically it's Bash shell
    - We're going to learn how to make a reference to a storage account here in the CLI and upload a file
    - First thing we need to do is get a file here that we want to upload
    - If we haven't already, we have the ability of clicking this Upload/Download files button
    - So we are going to choose Upload to get a file here in our Cloud Shell environment.
    - We can go ahead and do a ls, we can see that we have a file here called HR_EmployeeList.xlsx
  - We just minimize this and if we just look at the storage account here in the portal, in the background, that we're going to be using
    - If we were to go all the way down, under Blob service, Containers, we'll see that there are none
  - A container is just essentially a folder that we use to organize blobs that we upload here
    - At the same time, while we're here, why don't we take a look at the Access keys
    - Every storage account in the Azure Cloud gets two keys assigned automatically
  - These are used for programmatic or API access to the storage account's contents
    - You might ask, why two keys, why not just one? Well, the idea is that we might have scripts and programming code that refers to, let's say key1
    - From a security perspective, you should be regenerating keys to change them periodically
    - Although, in practice in my experience that happens rarely, but it's what should happen
  - The idea is that we could regenerate a second key, and at some point flip over our code to reference the second key and then regenerate the first key
    - Because you don't want to just regenerate a key without understanding that it will break any scripts or command-line API calls that refer to that key
    - They will no longer work after you change the key or regenerate it
    - Go into the CLI and let's get to work, they first thing we are going to want to do is create a variable
    - We are going to create a variable, let's say, called ACCOUNT and it will equal the name of our storage account
    - So storacct333325, there we go, if we do echo $ACCOUNT, we can see the value of the variable.
    - So, it's the name of our storage account, which is what we want.
  - Clear the screen and I'm going to do the same kind of thing for a storage account key
    - We can even view the keys from here, for example, az storage account keys list --account-name
    - We can actually use our variable here, $ACCOUNT, which is very handy --resource-group
    - It's in a resource group called Rg1, we can just press Enter to see the output of that and there's the two keys, key1 and key2
    - Let's say we want to use key1, it doesn't matter which one you use.
    - We are going to go ahead and copy that first one and dump that in a variable we are going to call key.
    - KEY equals open quote, let's just paste that in there, close the quote, done.
    - So if we echo $KEY, there's the value. Okay.
  - We have an account variable, we have a key variable
    - What we want to do is create a storage account container, essentially a folder in our storage account, in which files we upload will be stored
    - So, az storage container create --name, we want to create a storage container called eastdata --account-name
    - We can use our $ACCOUNT variable name here, which contains simply a text string that references our storage account name
    - And also we'll specify --account-key, and let's pass our key variable $KEY, then press Enter
  - Looks like it was created. We can even check our work here in the portal
    - If we just go back here and scroll down in the navigation bar for the storage account down under Blob service
    - Containers, we should see eastdata, and there it is
  - Go back into the CLI, to actually upload content we're going to use az storage blob upload. --container-name
    - We just created a container and for the example called it eastdata, this is where we want it to go in
    - The other thing we have to specify is the name we want to use for this file
    - We are going to call it HR_EmployeeList.xlsx, that's what we wanted to be called in the storage account once it uploaded. --file
    - We have to specify the actual file we want to upload, we already have it here in our Cloud Shell storage
    - It's called HR, it's actually called the same thing, EmployeeList.xlsx, it doesn't have to be the same
    - We can use the name to be the same or make it the same as the actual file that we're uploading, but it can be changed.
  - Either way, we've got that part done
    - Now we have to specify --account-name, we've got our handy variable here, $ACCOUNT, and --account-key, you guessed it, we have a $KEY variable
    - It looks like the syntax is correct, az storage blob upload, container name, name file
    - This looks good and to be honest it will tell us if there's a syntax error
  - It looks like it finished, just like that, 100.0000%, to see minimize this and open up eastdata here
    - Sure enough, we're going to see the presence of our HR_EmployeeList.xlsx file.

