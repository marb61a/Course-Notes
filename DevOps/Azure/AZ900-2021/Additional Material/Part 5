                    AZ900 Microsoft Azure Cloud Fundamentals 2021
                    Additional Material Course Notes Part 5


Uploading Blobs Using PowerShell
  - In this example, I'm going to use PowerShell to upload a blob to a storage account container
  - To get started here, the first thing we want to do is figure out which storage account we're going to work with
    - We are already in the portal where we've launched a Cloud Shell running PowerShell
    - We're just going to go back here and take a look at our list of Storage accounts
  - There's one here called storacct333325 that we're going to go into and work with, from the PowerShell perspective
    - Let's just scroll down here in the GUI to Blob service, Containers
    - There's already a container here that we're going to see, and it's called eastdata
  - We want to create an HR container and upload a file
    - So we can see currently there is no HR container, at least not yet, go back into PowerShell
    - To do that, we are going to create a variable here that we are going to call context, ctx
    - This variable is going to essentially point us to the storage account
    - To do that, we are going to put =get-azstorageaccount
    - Because we don't want to keep repeating the name of the storage account, the resource group, -r for resource group it's Rg1
    - And -name and the name of the storage accounts, storacct333325
    - What we're going to do, is we're going to store the result of running that command in the context variable, $ctx
    - And it looks like we have a reference to that storage accounts, returning other properties that we didn't specify must be working.
  - This looks good, clear the screen. What's next? Well the next thing we want to do, is actually get the context property
    - What that means is if we run $ctx and pipe that to get-member to show me object properties and methods
    - Although we are going to say -type property, we only care about properties.
  - One of the properties of our variable here is called Context, and we need this
    - What we are going to do then is the following, we will overwrite the same variable, it doesn't matter
    - We're not going to need it again anyway. So $ctx is going to =$ctx., and the name of the property we just looked at is context
    - Okay, so now let's just take a look at our $ctx variable
  - What's got a reference pointer that points to that storage account, this looks different, this is what we needed
    - We are going to run new-azstoragecontainer, spell this correctly, storagecontainer -name
    - We want to make this call hr, human resources and here is where we're going to use our variable, we are going to use -context
    - And, we have to do say, $ctx so that it knows everything about what we are talking about
    - We don't have to tell it, at least not outside of this variable, the name of the storage account, the resource group and so on
  - It doesn't like it because it really needs to be 3 through to 63 characters long, no problem
    - Up arrow key, we will write out humanresources, when we press enter it should accept it
    - Now we have now got a new storage container called humanresources
  - Go back here and refresh the GUI and there's humanresources
    - We can now populate it with stuff so start by clearing the screen
    - We going to do that by, well first of all, let's see what we have here in the Cloud Shell, dir
  - We've got a file called HR_EmployeeList.xlsx, how about we upload that file? 
    - We'll use set-azstorageblobcontent, quite a long cmdlet name, -file, the local file here is called HR_EmployeeList.xlsx
    - Wejust typed in hr and press tab. It's unique enough, so it found the name in the current directory, and it spelled it out for us 
    - This is very convenient, -container and we want to put this in the humanresources container
    - Use humanresources which is the one we just created a moment ago
    - We are going to specify that the blob, let's say, will be called the same thing as the file, how about HR_EmployeeList.xlsx
    - Sometimes you want to change the name of what it will appear as in the storage account
    - Versus what it actually is in the file system that you have but we are okay with using the same name
    - The last thing that we are going to do, is specify -context and pass it our $ctx variable
  - That's not a large file, so it won't take very long for that to be pushed up into the cloud
    - Minimize this and go take a peek, open up humanresources and after a moment we can see our file has been successfully uploaded


Uploading Blobs Using AzCopy
  - The Microsoft AzCopy command line tool can be used when you need to transfer files into a storage account, or from it or even between storage accounts. 
  - So here in the web browser, we've navigated to Microsoft documentation where they discuss AzCopy
    - Scroll down little bit, they also provide the downloads for AzCopy
    - Go ahead and download the 64-bit Windows AzCopy tool on our on-premises Windows 10 computer
    - We've chosen to extract that to a folder on my machine on drive D and we've changed to that directory 
    - If we a dir command then we can see the azcopy.exe tool.
  - Depending on how you plan on using this, you can add this to your path this subdirectory where you've got the tool
    - So that you can run it no matter which subdirectory you're in, in the command line
    - We are not going to bother with that, we are going to run it right from this current location
  - So if we just run azcopy, for example, -h for help, we should be able to tell if it's good to respond and it looks like it is
    - So we know that it's working and it's giving us some help on how to use the AzCopy command-line tool
  - Before you can actually use this to talk to as your storage accounts, you're going to have to log in, and you can do that with azcopy space login.
  - What that does is it says, go to this URL and enter this code to authenticate
    - We have entered that URL into the web browser, it asks us to enter a code which we've copied from that command-line output, so click Next
  - We are going to login with one of my Azure AD users that I know has the appropriate storage account and blob roles
    - They have the right permissions so that they can manage the account such as creating containers
    - And also have the ability to write blobs or upload blobs to storage account containers
    - We've got that person's email address filled in and we are going to click Next
  - We'll then specify the sign in password for that account and click the Sign in button
    - It then says, we've signed in to the Azure Storage AzCopy app on my device
    - We can close this window and get back to work at the command line using the AzCopy tool
    - Back here at the command line, we can see here that the Login succeeded so we're ready to go, so clear the screen
  - Here in the portal we've navigated to a storage account that will be interacted with using AzCopy and gone to Access control (IAM)
    - And on the right, we are going to click View, Role assignments
    - We want to check out which permissions or indirectly through role assignments that Lucas Brenner or L Brenner has
  - Take a look, and if we scroll down, we can see that L Brenner has the Storage Account Contributor
    - We can manage the storage accounts such as working with containers, but he also has the Storage Blob Data Contributor
    - So he can contribute blobs burning on large objects, such as, uploading files
    - The next thing we just want to do is take a look at the properties of this storage account.
  - We interested really in the primary blob service endpoint, because we're going to use that to make a connection, we have to specify basically the URL
    - Scroll over to the right here, and we could see the Blob service resource ID and below that the Primary Blob Service Endpoint.
    - And really it's just the full DNS name of our storage account, so we are just going to go ahead and copy that.
  - We are going to use the azcopy command followed by make, because we want to make a container 
    - Or in other words, a folder or directory in the storage account before we upload content
    - So this is where we've specified the primary blob service URL that we just copied
    - However, what we want to do is specify after that the name of the container that we want to make
    - In this case, we calling it, eastprojects, let's see what happens by pressing Enter
    - Now if you get an error message, it's probably because you don't have the appropriate permissions to create that.
  - That's why it was important that this user that we authenticated with L Brenner, has the storage account contributor role
    - It looks good successfully created the resource, excellent
    - The next thing we want to do is copy a file there
    - To do that, we are going to run azcopy copy, and then in quotes, specify a local path on our on-prem computer
    - In this case, we've decided I want all of the txt files in the projects folder under samplefiles in drive d
    - So instead of specifying an individual file or blob, we are specifying a bunch of them using a wild card asterisk
    - After which we are then specifying where the target is, where's that going?
  - After that the next parameter is my storage account blob service endpoint URL
    - Of course, with our newly created container eastprojects, that's where we want that stuff to go, so press Enter
    - If this fails and you get some kind of a message about permissions or insufficient permissions
    - It's probably because the account you authenticated with, in our case, it was L Brenner, doesn't have the storage blob data contributor role
    - In this case it looks good, it looks like the number of transfers completed was 3 so that is indicative of the fact that there are 3 files
  - Why don't we check our work, well, we could do it in a number of ways including in the portal
    - Back in the portal, we are still looking at the navigation bar here for the storage account question.
  - We are able to scroll down until we see Blob service, Containers
    - Hopefully, we'll see eastprojects, which we do, and if I open that up, we should see whatever files should be there, in this case, Project A, B, and C.txt
    - We asked for everything that had a txt file extension in that location on-premises to be uploaded here, and we did so using the AzCopy command

