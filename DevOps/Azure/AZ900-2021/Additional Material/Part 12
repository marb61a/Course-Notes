                    AZ900 Microsoft Azure Cloud Fundamentals 2021
                    Additional Material Course Notes Part 12


Azure Firewall Overview
Azure Firewall is a managed service. And what that means in the cloud, of course, is that we don't have to set up the underlying infrastructure to support the solution. It's already taken care of for us by the cloud service provider. So Azure Firewall is a managed service, and it's also a stateful firewall. A stateful firewall means that it understands more than just looking at individual packets. It understands sessions such as if we have an inbound allowance to a web server, then the stateful firewall will know, well, I need to make sure I allow the outbound-related traffic out through that firewall.

So you might say, well, a network security group in Azure or NSG is a managed service and it's also a stateful firewall just like Azure Firewall is. So what is the difference? Well, there is a difference. Azure Firewall applies up to Layer 7 of the OSI model, up to the application layer. So beyond IP addresses and port numbers, which is important and which is supported by network security groups, Azure Firewall takes it further and can look at the payload of the transmission, meaning it can look at URLs that people, for example, are trying to connect to.

And so we can build application rules in that example to address that. Azure Firewall, when it's configured, needs a static or unchanging public IP address. And just like the rules in a network security group, the rules in Azure Firewall control traffic flow, either allowing or denying it. You can also configure threat intelligence in conjunction with Azure Firewall. And what it can do is it can look to see if there are any known malicious IP addresses or DNS domains that are involved with transmissions and it can alert on that and even block it.

There are three types of firewall rules with Azure Firewall that you can configure – network rules, which we'll talk about here; application rules; and Network Address Translation, or NAT, rules. We'll talk about each of those three types. Let's start with network rules. So network rules apply up to Layer 4 of the OSI model. So you can deal with TCP, UDP, ICMP, or any of those protocols. You can make decisions on what's allowed or not based on source and destination IP addresses or destination port number. And you can have an Allow or a Deny action. Those are network rules.

Application rules go higher in the OSI model, up to Layer 7, the application layer. It's for outbound connectivity when users are connecting to Fully Qualified Domain Names, FQDNs, such as www.skillsoft.com. So you can use wildcards if you want when you configure application rules. So you could use asterisks as wildcard symbols and specify parts of domain names, such as *.domain.com. [Video description begins] The following information is displayed on screen: Wildcards are allowed, such as *.domain.com or *. [Video description ends]

You can also specify the protocol that would be used, whether it's HTTPS:443 or something different. And of course, you can either allow or deny that type of connection. [Video description begins] The following information is displayed on screen: Protocol:port, such as HTTPS:443. [Video description ends] For example, you might want to deny access to social media sites like Facebook and Twitter. So you can do that with application rules.

Then we have NAT rules of which there are two types. The first is Source Network Address Translation, or SNAT. This means that traffic leaving your virtual network subnets in Azure assume the public IP address of the Azure Firewall. And that's why it needs to have a public IP address.

But then you've got, kind of, the opposite for traffic coming in. You've got Destination Network Address Translation rules, or DNAT rules. So you can use DNAT to translate public IP address and port numbers to private IP addresses and port numbers.Now what does that mean exactly? We'll talk about that in a moment when we have another screenshot. Now when you deploy Azure Firewall into a VNet, you'll be doing that with a subnet called AzureFirewallSubnet.

But let's examine DNAT just a little bit further. So we're looking at a DNAT type of rule here. So we have a rule that's being added to the NAT collection. The name here is Incoming. It's got a priority value of 100. And so the priority value is used to order the rules. So a rule with a priority of 100 gets checked before a rule with the priority of 101. And if there is a match with the traffic for rule, the priority of 100, that's what applies and rule processing stops. So NAT rules, and that's what we're looking out here, these get applied based on the order of the priority value.

Then network rules would go through the same thing and then application rules. So what we have here is we have a rule called Incoming HTTP. So the protocol is TCP and the destination here is 40.80.251.142. That's the public IP address of the Azure Firewall. It's called Destination because that's the destination endpoint that, for example, users think that they're connecting to. Well, really they're connecting to a DNS name, but that name gets resolved to this public IP.

What will happen then is Azure Firewall will say, okay, someone is connecting to that IP – port 80 in this case. I'm going to forward that inside of Azure to a translated IP address of 10.1.1.1 on port 80. So it's a way that we could publish or make available a web application while hiding its true internal address.

[Video description begins] A screenshot of an application displays. It includes the following fields: Name (given as Incoming) and Priority (given as 100). The screenshot also includes a "Rules" section, which contains a table with the following columns: NAME, PROTOCOL, SOURCE ADDRESSES, DESTINATION ADDRESSES, DESTINATION PORTS, TRANSLATED ADDRESS, and TRANSLATED PORT. A couple of rules appear in the table. These include Incoming HTTP with PROTOCOL listed as TCP, SOURCE ADDRESSES listed as *, DESTINATION ADDRESSES listed as 40.80.251.142, DESTINATION PORTS listed as 80, TRANSLATED ADDRESS listed as 10.1.1.1, and TRANSLATED PORT listed as 80. [Video description ends]


Deploying Azure Firewall
In this demo, I'm going to use the portal to configure Azure Firewall. Now Azure Firewall is its own separate type of Azure resource. And so to get started with it here in the portal, I'm going to click Create a resource. And I'm going to search for Firewall. [Video description begins] Azure Home is open. It includes the sections: Azure services and Recent resources. The "Azure services" section contains the following options: Create a resource, All resources, Virtual networks, etc.. With the presenter clicking the "Create a resource" option, the "New" blade that opens includes a Search box. [Video description ends]

And we see Firewall in the list. So I'm going to click on that. Then I'll choose Create. [Video description begins] The "Firewall" blade that opens includes a "Create" button. [Video description ends] I'm going to deploy this into an existing resource group. [Video description begins] A "Create a firewall" blade opens. It includes a "Subscription" drop-down list that has an associated "Resource group" drop-down list. It also contains an "Instance details" section. The section includes a "Name" field; a "Region" drop-down list, which is set to (Canada) Canada Central; a "Choose a virtual network" heading; a "Virtual network name" field; an "Address space" field; and a "Subnet" heading. The "Choose a virtual network" heading has two options: Create new, which is selected, and Use existing. [Video description ends]

And I'm going to call this AzureFW1, Azure Firewall 1. [Video description begins] After selecting the Rg1 option from the "Resource group" drop-down list, he types AzureFW1 in the "Name" field. [Video description ends] I'll deploy it in the Canada Central region. And I have to specify a virtual network I want this applied to.

I'm going to use an existing one. [Video description begins] When he selects the "Use existing" option that displays against the "Choose a virtual network" heading, a "Virtual" network" drop-down list, a "Firewall public IP address" drop-down list, and a "Forced tunneling (preview)" heading replace the "Virtual network name" field, the "Address space" field, and the "Subnet" heading. [Video description ends]

From the list, I'll choose Vnet1. Now notice, it says this virtual network needs to have a subnet named [Video description begins] He selects the Vnet1 (Rg1) option from the "Virtual network" drop-down list. [Video description ends] AzureFirewallSubnet. We don't have that. So let's go back and let's build a subnet with that name in Vnet1. So to get started with that, I'm going to go ahead and right-click and duplicate our web browser tab up at the top. [Video description begins] Azure Home opens in the new web browser tab. [Video description ends]

So we're going to navigate to Virtual networks. [Video description begins] When he selects the "Virtual networks" option, the corresponding blade that opens includes a table with the following columns: Name, Resource group, location, etc.. Four record links, including Vnet1, appear in the table. [Video description ends]

And I'm going to be opening up Vnet1 where we can then see the subnets within that virtual network. [Video description begins] The Vnet1 blade includes an "Overview" category, which is selected, and a "Settings" section in the resource menu. The "Settings" section includes a "Subnets" category. He clicks the category, and the corresponding blade that opens includes a "Subnet" button and a table with the following columns: Name, Address range, IPv4 available addresses, etc.. Three subnets appear in the table. [Video description ends] We can see we've got Subnet1, Subnet2. We have a GatewaySubnet, but we don't have an Azure Firewall subnet.

So I'm going to click add a Subnet. And I'm going to specify that it's going to be called AzureFirewallSubnet. [Video description begins] An "Add subnet" pane appears. It includes the following fields: Name and Address range (CIDR block) (given as 10.0.3.0/24). He types AzureFirewallSubnet in the "Name" field. [Video description ends] And I'm going to specify that it's 10.0.3.0/24 44-bit subnet mask. And that's it. That's all I need to do. So I'm going to go ahead and click OK. We'll just give it a moment to add that subnet. And we can now see that it exists in the list for Vnet1.

So let's go back to where we were creating the firewall. Let's just back out. We know we're not going to save our settings – they were wrong anyways. I'll click Create. [Video description begins] He returns to the first web browser tab and clicks the "Firewall" link in the breadcrumb navigation to return to the corresponding blade. [Video description ends]

And let's step through this again. So I'll just deploy this into the same resource group and basically do the same stuff I just did previously. The difference is this time we've got the correct subnet. So Rg1. We're going to call it AzureFW1, like I did previously with the firewall. It's going to be in Canada Central. And I'm going to use an existing VNet. Let's choose that from the list. This time we don't have the message about Azure Firewall subnet because we created it.

Next thing you have to do is specify a public IP address. Azure Firewall needs to have a static public IP. Now I don't have one that I can select that's not already in use. So I'm going to go ahead and click Add new to make a new one. And I'm going to call it AzureFW1PubIP. [Video description begins] When he clicks the "Add new" link associated with and which displays below the "Firewall public IP address" drop-down list, an "Add a public IP" dialog box appears. It includes a "Name" field and an "Assignment" heading. The heading has two options: Dynamic and Static. [Video description ends]

And I will choose OK. Notice, the assignment, of course, is going to be static. It needs to be static. Okay, so now we've got the public IP address for the firewall. Perfect. So I'm going to go ahead and click review and create in the bottom left. And after the validation has passed, I will then click Create to actually create the Azure Firewall resource. Before too long, we can see that the deployment is complete.

So I'm going to click Go to resource. Because what we want to do is take note of the private IP address. [Video description begins] The AzureFW1 blade that opens includes an "Overview" category in the resource pane. The category is selected and includes a "Firewall public IP" heading and a "Firewall private IP" heading. [Video description ends]

Now we know it's got a public IP, but we're interested in the private IP address of the firewall, which I'm going to copy. Because we need to make a routing table entry for the subnets where we want to route traffic through the firewall, for example, on the way out to the Internet. So I've just copied the private IP of it. [Video description begins] He clicks the "Copy to clipboard" icon associated with the Firewall private IP address. [Video description ends]

So what I want to do then is go back, let's see, into our virtual network list. [Video description begins] He returns to Azure Home and selects the "Virtual networks" option. [Video description ends] And I'm interested in Vnet1. And in particular, I'm interested in making sure that resources like virtual machines on Subnet1 – so let's go to Subnets – send their traffic out through that firewall. So Subnet1. It means we have to look at the route table entries related to Subnet1. So what is it configured with? Well, it's not configured with any routing table.

Okay, so what I want to do then is get a routing table created so that we can link Subnet1 to it. [Video description begins] When he selects the "Subnet1" record in the table in the Vnet1 | Subnets blade, the corresponding blade opens. It includes a "Route table" drop-down list, which contains only a "None" option. [Video description ends]

So I'm going to go home. I'm going to click Create a resource. And as you might guess, I'm going to create a route table. [Video description begins] He types "route" in the Search box in the "New" blade, and "Route table" is among the results that display. [Video description ends] There it is – Route table. And let's go ahead and click Create. We're going to add a route within the route table. So let's call this RouteTable1. And let's deploy it into a resource group.

As I was saying, we're going to create a route in the route table for 0.0.0.0/0. That's the default route for IPv4. So we want to funnel all traffic in Subnet1 out through the firewall on its way out to the Internet. [Video description begins] A "Create route table" blade that opens includes a "Name" field and a "Resource group" drop-down list. And after typing RouteTable1 in the "Name" field and selecting an Rg1 option from the "Resource group" drop-down list, he clicks the "Create" button. [Video description ends]

So we'll be able to do that once the route table resource is created here. [Video description begins] A pop-up, which appears, includes a "Deployment succeeded" message and a "Go to resource" button. [Video description ends] And it's done. So deployment succeeded. I'll click Go to resource to open up the route table. [Video description begins] The RouteTable1 blade includes an "Overview" category, which is selected, and a "Settings" section in the resource pane. The "Settings" section includes a "Routes" category. [Video description ends]

And naturally, we want to create a route entry. So I'm going to click Routes over on the left. And we're going to click the Add button. And we have to fill out a few details here such as the name – so SendToAzureFirewall. The address prefix here is going to be 0.0.0.0/0. [Video description begins] An "Add route" blade opens. It contains a "Route name" field, an "Address prefix" field, and a "Next hop type" drop-down list, which is set to Virtual network gateway. [Video description ends]

So that's the default route for IPv4. The next hop is going to be a virtual appliance. And this is where I'm going to paste in the private IP address of the Azure Firewall. And I'll click OK. And it's done. [Video description begins] When he selects the "Virtual appliance" option from the "Next hop type" drop-down list, a "Next hop address" field appears below the drop-down list. And when he pastes the Firewall private IP address in the field and clicks the "OK" button, a pop-up appears. It includes the message: Adding route. [Video description ends]

So at this point, we've got Azure Firewall configured. So let's go back and check that out and we'll go home here. There's Azure Firewall 1. [Video description begins] After returning to Azure Home, when he clicks the AzureFW1 resource link that displays in a table in the "Recent resources" section, the corresponding blade that opens includes an "Overview" category, which is selected, and a "Settings" section in the resource menu. The "Settings" section includes a "Rules" category. [Video description ends]

Now we're not going to configure them right now. But notice that what we can do is go into Rules where we can create and manage NAT rules, network rules, and application rules. [Video description begins] The AzureFW1 | Rules blade includes the following tabs: NAT rule collection, Network rule collection, and Application rule collection. [Video description ends]


Azure Firewall Application Rules
There are three types of rules that you can configure within Azure Firewall. [Video description begins] An AzureFW1 blade is open. It includes an "Overview" category and a "Settings" section in the resource menu. The "Settings" section includes a "Rules" category. The "Overview" category, which is selected, includes a "Firewall private IP" heading with an IP address displaying against the same. [Video description ends] So here in the portal, I'm in an Azure Firewall configuration.

I'm going to click Rules over on the left, open up the Rules blade. [Video description begins] The AzureFW1 | Rules blade includes a "Refresh" button and three tabs: NAT rule collection, Network rule collection, and Application rule collection. Currently, the "NAT rule collection" tab is selected. [Video description ends]

The three rule types are NAT rules, whether they are NAT rules to allow outbound traffic while assuming the public IP of the firewall or allowing inbound traffic through a public IP address and port translated to an internal IP address and port; network rules, which is the same type of thing you would find with network security groups – so based on protocols like TCP, source and destination IP addresses, and port numbers; and what we're going to focus on here, an application rule.

And this is what makes Azure Firewall or part of what makes it Layer 7 in terms of the OSI model. Because it has the ability to examine not just the packet headers where you'd find things like IP addresses and port numbers, but it can go into the payload and look at the URLs. So we're going to build an application rule here that blocks access to Facebook. [Video description begins] The presenter selects the "Application rule collection" tab. It includes an "Add application rule collection" link and an empty table with the following columns: Priority, Name, Action, and Rules. [Video description ends]

So to do that, I'm going to click Add application rule collection. And we're going to have to configure this accordingly for the appropriate port number and protocol and DNS domain name. [Video description begins] The "Add application rule collection" pane that appears includes a "Name" field; a "Priority" field; an "Action" drop-down list, which is set to Allow; and a Target FQDNs section. The Target FQDNs section contains a table with the following columns: name, Source type, Source, Protocol:Port, and Target FQDNs. A field each displays in the following columns: name, Source type, Protocol:Port, and Target FQDNs. A drop-down list, which is set to IP addresses displays in the "Source type" column. [Video description ends]

So I'm going to call this BlockSocialMedia. That's the name of the collection. We can have individual rules to block different types. For the Priority value, I'll put in 100. And I want to Deny. And down here under Target FQDNS, this is going to say Block Facebook. That's what this first one will be. [Video description begins] After selecting the "Deny" option from the "Action" drop-down list, he types "Block Facebook" in the field that displays in the "name" column of the table in the Target FQDNs section. [Video description ends]

So doesn't matter where the client request is coming from. So the Source is going to be *, anywhere. But the protocol and port will be https:/443 for Facebook. So I know that's what uses that. [Video description begins] He types an asterisk and https://443 in the "Source" column field and the "Protocol:Port" column field, respectively. [Video description ends]

And the other thing I want to specify here is the Target FQDN, which I'm going to specify as *.facebook.com. So anything in facebook.com. Now I notice my Protocol:Port field is outlined in red. That's my fault. There needs to be no slashes there. And let's just, okay, there we go. [Video description begins] He deletes the two forward slashes in https://443. [Video description ends] Now we have the green check mark. So just a little syntax error. It's all good now.

So let's go ahead and add this application rule. [Video description begins] He clicks the "Add" button in the pane. [Video description ends] After a moment, if you click Refresh, you'll see that you have your new application rule that would be listed here. In our case, we are denying access to, specifically, Facebook. [Video description begins] The BlockSocialMedia rule link with Action listed as "Deny" now appears in the table in the "Application rule collection" tab. [Video description ends]

Now in order for this to work or if you're wondering who will be affected by this, you need to think about routing tables. So the next thing I'll do here in the portal is create a route table in the same region as a VNet, where I've got subnets that I want to use the route table.

[Video description begins] He shifts to Azure Home. It includes the following sections: Azure services and Recent resources. The "Azure services" section contains the following options: Create a resource, Virtual networks, All resources, etc.. The "Recent resources" section has a table with the following columns: Name, Type, and Last Viewed. Several resource links, including AzureFW1, appear in the table. He selects the "Create a resource" option, and a "New" blade opens. It includes a Search box. [Video description ends]

So I'm going to search for route table. And what I want to do is create a route table in, in this case, the Canada Central region. [Video description begins] When he types "route table" in the Search box, the search results contain a single option: Route table. He selects the same, and the corresponding blade opens. It includes a "Create" button. And when he clicks the button, a "Create route table" blade opens. It includes a "Name" field, a "Resource group" drop-down list, and a "Location" drop-down list, which is set to (Canada) Canada East. [Video description ends]

So I'm going to call this RouteTable2. I'll deploy it into an existing resource group. [Video description begins] After typing RouteTable2 in the "Name" field, he selects Rg1 from the "Resource group" drop-down list. [Video description ends] And I want to make sure that I place this in Canada Central. So I'll select that region and I'll click Create.

Now while that's happening, let's go and take a look at our Azure Firewall again. Because in the Overview blade, I need to copy the private IP address of the firewall because I need to make a route to it. [Video description begins] He returns to Azure Home and clicks the AzureFW1 resource link in the table in the "Recent resources" section. And when the corresponding blade opens, he clicks the "Copy to clipboard" icon associated with the Firewall private IP address. [Video description ends]

So in my notification icon here, I'm just going to go to my resource for my newly created route table, RouteTable2, got to go to Routes. And I'm going to add a route. Now we want to make sure that traffic is forced through Azure Firewall, such as outbound traffic from my VNet subnet before it goes out to the Internet.

[Video description begins] He selects the "Notifications" control, and the corresponding menu that opens includes a "Go to resource" button. When he clicks the button, the RouteTable2 blade opens. It includes an "Overview" category, which is selected, and a "Settings" section in the resource menu. The "Settings" section includes a "Routes" category. When he selects the category, the corresponding blade that opens includes an "Add" button. And when he clicks the button, an "Add route" blade opens. It contains a "Route name" field, an "Address prefix" field, and a "Next hop type" drop-down list, which is set to Virtual network gateway. [Video description ends]

So I'm going to call this route AzureFirewall. And I want it to capture all traffic. So the default route is referenced with 0.0.0.0/0. [Video description begins] After typing AzureFirewall in the "Route name" field, he types 0.0.0.0/0 in the "Address prefix" field. [Video description ends] The next hop type will be a virtual appliance. We'll just pop in the private IP address of our Azure Firewall. [Video description begins] When he selects the "Virtual appliance" option from the "Next hop type" drop-down list, a "Next hop address" field appears below the list. He pastes the previously copied Firewall private IP address in the field. [Video description ends]

And I'll click OK. So let's go into our Virtual networks. And I'm interested particularly in one called Vnet1. Because it has a subnet called Subnet1 and I want it to be affected by our route. In other words, I want to force all traffic going to the Internet to be funneled through our firewall first. And that's for a particular subnet.

[Video description begins] He returns to Azure Home and selects the "Virtual networks" option. The corresponding blade includes a table with the following columns: Name, Resource group, Location, etc. Four record links, including Vnet1, appear in the table. He clicks the Vnet1 record link, and the corresponding blade that opens has an "Overview" category, which is selected, and a "Settings" section in the resource menu. The "Settings" section includes a "Subnets" category. [Video description ends]

So I'm going to click Subnets. And it's going to be Subnet1 in my case. And what I'm going to do when I open up the properties of Subnet1 is associate it with the route table that we just created. So that's called RouteTable2. [Video description begins] The Vnet1 | Subnets blade includes a table with the following columns: Name, Address range, IPv4 available addresses, etc.. Four subnets, including Subnet1, appear in the table. And when he clicks the "Subnet1" record, the corresponding blade that opens includes a "Save" button and a "Route table" drop-down list, which is set to None. He selects RouteTable2 from the "Route table" drop-down list. [Video description ends]

And it's done. So now I'll click Save. So now resources on Subnet1 and Vnet1 have their traffic sent to the Azure Firewall for inspection.
Azure Bastion Overview

[Video description begins] Topic title: Azure Bastion Overview. Your host for this session is Dan Lachance. [Video description ends]

Azure Bastion is a solution that allows remote management of Azure virtual machines, whether you're connecting through SSH for Linux VMs or through RDP for Windows VMs. You can consider this a platform as a service or a PaaS type of solution. We say this because it's not infrastructure as a service. You are manually deploying a virtual machine and configuring it. It is using a VM, but the provisioning of it is taken care of for you by this feature.

So the purpose of this is to limit VM visibility. What does that mean? Well, the Bastion host gets associated with an Azure VNet. So you need to have a subnet in that VNet called Azure Bastion subnet with at least a /27 subnet mask prefix. Now what happens then is you have a public IP address associated with the Bastion host. And that's great. You need that kind of connectivity.

Although, when you actually make the Bastion connection for management to Linux or Windows VMs, you do that straight through the portal. And it will have a connection on the private network side, and that means that your VMs only need a private IP address, not a public one. So thus you are not exposing them directly to the Internet.

Pictured in our diagram, we get a sequence of steps visually where on the left, we as the administrator in Azure, would make sure that we are authenticated to the Azure portal. When you're in the portal, you navigate to the virtual machine that you want to remotely manage, whether it's Linux or Windows based. And you pull up the connect blade as you normally would if you wanted to view connection options for SSH or RDP.

And you would select the Bastion option. Now what that will do is then provide you the ability to give credentials to authenticate to that VM. You'd put in credentials, for example, on the Windows side for the target Windows VM. These are not credentials for Bastion. By virtue of you being logged into the portal, you already are authenticated. So you don't put in credentials for Bastion – that's not required. It's for the target endpoint you're trying to manage.

And so according to our diagram, the connection via private IPs would then occur, whether it's to a Linux VM over SSH or to a Windows VM using RDP. The benefit is you don't need each and every VM to be exposed to the Internet via a public IP address. That is not a great suggestion when it comes to security. Instead, they should only be available as in this case through the Bastion host which is really acting as a jump-box.


Deploying Azure Bastion
Instead of exposing each Azure virtual machine to the Internet with a public IP address, for management purposes, you can instead deploy an Azure Bastion host. So a Bastion host, essentially, is the jump-box point through which you connect to, in the end, manage your Azure VMs. And those Azure VMs would only have a private IP address.
And I'm going to name it AzureBastionSubnet, all one word. [Video description begins] An "Add subnet" pane appears. It includes two fields: Name and Address range (CIDR block) (given as 10.0.4.0/24). [Video description ends] And after that, I'm going to make sure that I have at least a /27 subnet mask prefix. So I'm going to leave what it suggests here, 10.0.4.0. I can see the other address ranges used in the background here by the other subnets. So this one is logical. I'm going to go with that and I'm going to click OK.

So it's important you do this first. Otherwise, when you go to create the configuration for Azure Bastion, you're going to get an error message. Because it needs to see that subnet name. Now we can get down to business. [Video description begins] The AzureBastionSubnet subnet now appears in the table in the Vnet1 | Subnets blade. [Video description ends]

Let's go home here. I'm going to create a resource here in the portal. [Video description begins] He clicks the "Home" link in the breadcrumb navigation and shifts to Azure Home. It includes the sections: Azure services and Recent resources. The "Azure services" section contains the following options: Create a resource, Virtual networks, All resources, etc.. He clicks the "Create a resource" option, and a "New" blade opens. The blade includes a Search box. [Video description ends]

I'm just going to search for Bastion and I'll select it. And then I'll click on Create. [Video description begins] The "Bastion" blade includes a "Create" button. When he clicks the button, a "Create a Bastion" blade opens. It includes three steps: Basics, Tags, and Review + create. Currently, Basics is selected. It contains four sections: Project details, Instance details, Configure virtual networks, and Public IP address. The "Project details" section has a "Subscription" drop-down list and an associated "Resource group" drop-down list. The "Instance details" section has a "Name" field and a "Region" drop-down list, which is set to westcentralus. The "Configure virtual networks" section contains a "Virtual network" drop-down list. The "Public IP address" section contains the headings: Public IP address, Public IP address name, and Public IP address SKU. The "Public IP address" heading contains two options: Create new, which is selected, and Use existing. [Video description ends]

So I'm going to deploy this into a resource group called Rg1. [Video description begins] He selects the Rg1 option from the "Resource group" drop-down list. [Video description ends] I'm going to call this Bastion1. I'm going to put this in the region that makes sense for my deployment; in this case, Canada Central just because that's where a lot of my VMs are deployed.

I'm going to tie this to Vnet1. And this is where it checks, as you can see here, for AzureBastionSubnet. Otherwise, it would prompt us with an error message and tell us we had to go back and make them. [Video description begins] When he selects the Vnet1 option from the "Virtual network" drop-down list, a "Subnet" drop-down list, which is set to AzureBastionSubnet (10.0.4.0/27), appears below the "Virtual network" list. [Video description ends]

So I'm going to let it create a new public IP address for this. But I'm going to call it BastionPubIP. And that's it. That's all we're going to do. So I'm going to click review and create, make sure it passes validation, which it does. And I'll click Create. [Video description begins] He points to the message that the application displays. [Video description ends] After a moment, the deployment will be complete. [Video description begins] A blade that opens includes a "Your deployment is complete" message and a "Go to resource" button. [Video description ends]

So let's take a look at it. Let's click the Go to resource button. That will take us into the properties of our new deployment of Azure Bastion. So let's just take a peek. We can see here that it's got a public IP address in the Overview blade. [Video description begins] The Bastion1 blade that opens includes an "Overview" category in the resource menu. The category is selected. [Video description ends] You can see that on the right. That's been assigned. We specified that when we deployed it.

So now to connect to a virtual machine through Bastion, I need to go to the virtual machine here in the portal. I'm going to go to my Virtual machines view. I'm going to click on a Windows virtual machine that's currently up and running. [Video description begins] He returns to Azure Home and selects the "Virtual machines" option. The corresponding blade that opens includes a table with the following columns: Name, Type, Status, etc.. The following item links appear in the table: Ubuntu-1 and WinSrv2019-1. When he clicks the WinSrv2019-1 link, the corresponding blade that opens includes an "Overview" category and a "Settings" section in the resource menu. The "Overview" category is selected. The "Settings" section includes a "Connect" category. [Video description ends]

And I'm going to click on Connect. Now when the Connect blade opens up, you'll see some of the normal connection options such as RDP and SSH. And of course, we want to focus on the BASTION option. [Video description begins] The WinSrv2019-1 | Connect blade has three tabs: RDP, SSH, and BASTION. Currently, RDP is selected. When he selects the BASTION tab, the corresponding view includes the fields: Username and Password. [Video description ends]

When I click on it, it'll retrieve information about the Bastion configuration for this VNet. And at this point, all I have to do is supply a username and password, which I will do. These credentials are for the target virtual machine you're trying to manage, not for Bastion. So let's go ahead and click Connect. Depending on your browser config, it might block the connection. I'm going to choose Always allow. And we can see it's opened up a new web browser tab in which it will present me with my remote desktop connection to that virtual machine, the benefit of which is that that virtual machine doesn't need a public IP address.

We can do the same type of thing for Linux. So if I go back to my virtual machine list, I've got a Linux virtual machine. And we would go through the exact same motions. [Video description begins] After returning to the WinSrv2019-1 | Connect blade, he shifts back to the "Virtual machines" blade and clicks the Ubuntu-1 item link. [Video description ends] We would select that host and go to Connect. So we can see when we click on Connect, we have the option of using a Bastion connection by clicking the button. [Video description begins] The BASTION tab includes a "Use Bastion" button. [Video description ends]


Virtual WAN Configuration
In this demonstration, I'm going to configure an Azure Virtual WAN resource here using the portal. [Video description begins] Azure Home is open. It includes the sections: Azure services and Recent resources. The "Azure services" section contains the following options: Create a resource, All resources, Virtual machines, etc.. The "Recent resources" section contains a table with the following columns: Name, Type,and Last Viewed. Several resource links appear in the table. [Video description ends]

So to get started, I'll click Create a resource. And I'm going to search for Virtual WAN. I'll select that from the list. And then I'll click on Create. [Video description begins] A "New" blade that opens includes a Search box. When the presenter types "virtual wan" in it and selects "Virtual WAN" from the search results, the corresponding blade that opens includes a "Create" button, which he clicks. [Video description ends]

I'll deploy this Virtual WAN resource into an existing resource group. [Video description begins] A "Create WAN" blade that opens contains two steps in the navigation pane: Basics and Review + create. Currently, Basics is selected. It contains two sections: Project details and Virtual WAN details. The "Project details" section contains a "Subscription" drop-down list, which has an associated "Resource group" drop-down list. The "Virtual WAN details" section contains a "Resource group location" drop-down list, a "Name" field, and a "Type" drop-down list. He selects an option from the "Resource group" drop-down list. [Video description ends]

And I'm going to deploy this in, let's see. Let's find Canada Central to deploy it in that region. [Video description begins] He selects a "(Canada) Canada Central" option from the "Resource group location" drop-down list. [Video description ends] And then I'm going to call this VWAN1. Currently, the Type is set to Standard. We can also choose Basic. Basic supports site-to-site VPN connectivity through a hub you configure in the Virtual WAN.

If you need additional connectivity such as for VNets or point-to-site VPNs or ExpressRoute, then you should be using Standard. I'm just going to leave it on Standard here. And I'll click review and create. It passes the validation. [Video description begins] He points to the message that the application displays. [Video description ends]

And so let's get this created by clicking the Create button. And after a moment, the deployment is complete. So I'm going to click Go to resource. What I want to do here is go down under the Connectivity section and click on Hubs. Notice, in our geographical map, it says, Each point represents a hub. But we don't have any hubs declared or defined here yet.

[Video description begins] The VWAN1 blade that opens includes an "Overview" category and a "Connectivity" section in the resource menu. The "Connectivity" section contains the following categories: Hubs, VPN sites, User VPN configurations, ExpressRoute circuits, and Virtual network connections. Currently, the "Overview" category is selected. It includes a world map and an empty table with the following columns: Hub, Hub status, Address Space, etc.. [Video description ends]

So I'm going to go ahead and click on Hubs over on the left. And I'm going to click the New Hub button. So I'm going to deploy this in the Canada Central region. It's going to be called VWANHub1. And then I have to specify the hub private address space. [Video description begins] The VWAN1 | Hubs blade includes a "New Hub" button and an empty table with the following columns: Hub, Hub status, Region, etc.. When he clicks the "New Hub" button, a "Create virtual hub" blade opens. It includes a "Virtual Hub Details" section. The section contains a "Region" drop-down list, which is set to (Canada) Canada Central; a "Name" field; and a "Hub private address space" field. [Video description ends]

You just need to make sure it doesn't overlap with any of your on-premises network ranges or your VNet ranges in Azure. So I'm going to put in 15.0.1.0/24 bits in the subnet mask. And it likes that. So there's a note down here that says creating the hub with the gateway will take up to 30 minutes. Not a problem. I'm going to click review and create. And now that the validation has passed, I'll click the Create button. So now it's being created. [Video description begins] A VirtualHubDeployment | Overview blade that opens includes a "Your deployment is complete" message and a "Go to resource" button [Video description ends]

Now the deployment is complete. Okay, let's click Go to resource. So we're still in our Virtual WAN hub. Looking at the details, it's been deployed. Let's go back and take a look at our Virtual WAN, VWAN1. What I want to do in here is just take note here that in the Overview blade we now have a point on the map. And it's approximately the Canada Central region where it was deployed. It's our VWANHub1. We can see it's now listed down below with its address space.

[Video description begins] He returns to Azure Home and clicks the VWAN1 resource link that now appears in the table in the "Recent resources" section. The VWANHub1 link with Address Space listed as 15.0.1.0/24 and Region listed as Canada Central now appears in the table in the "Overview" category of the corresponding blade. [Video description ends]

So because we selected to create a Standard type of virtual WAN config, then in the navigator bar, under Connectivity, we can create configurations for VPN sites; for user VPN configs, in other words, point-to-site; ExpressRoute circuits; or even VNets. All of these types of items can centrally feed into the VWAN hub that we've defined for Virtual WAN configurations. Now if I were, let's say, to go to VPN sites, I want to configure a site-to-site VPN directly into my Virtual WAN. [Video description begins] The VWAN1 | VPN sites blade includes a "Create site" button. [Video description ends]

When I go to create the site, that's when I get the configuration options available. And there's an important note to be made about doing that. And it is in the sense that when you go down, you have to tie it or connect it to a hub – so a Virtual WAN hub, which we've defined.

[Video description begins] When he clicks the "Create site" button, a "Create VPN site" pane appears. It contains three steps in the navigation pane: Basics, Links, and Review + create. Currently, Basics is selected. It includes the sections: Instance details and Connect to. The "Instance details" section includes a "Region" drop-down list, which is set to (US) West Central US. The "Connect to" section has a "Hubs" drop-down list, which features an associated helper tip. [Video description ends]

But in the drop-down list, it says, No available items. Even if I change the region up here to the region where I know that was deployed, the hub was deployed to Canada Central – we saw that. Well, despite the fact that I might select that and then click in a different field to refresh the screen, when I go down to Hubs, it's still not there.

And the reason is because, and you'll see this by the way, use these little helper tips. If you hover over the helper tip, the information icon next to Hubs says the site can only be connected if you've got a VPN gateway in the hub. If you don't see the hub, go create a VPN gateway in the hub first.

So what that means is that we go into my hub over on the left. There's our hub definition. We saw it was plotted on the map. [Video description begins] He selects the "Hubs" category in the VWAN1 | Hubs blade. The corresponding blade that opens now contains a VWANHub1 link in the table. And when he clicks the link, the corresponding blade that opens has an "Overview" category and a "Connectivity" section in the resource menu. The "Connectivity" section contains the following categories: VPN (Site to site), ExpressRoute, User VPN (Point to site), etc.. Currently, the "Overview" category is selected. [Video description ends]

And then you would go to VPN (Site to site) over here on the left. And what it should do is give us, yes, an instruction to create the VPN gateway. [Video description begins] The VWANHub1 | VPN (Site to site) blade includes a "Create VPN gateway" button. [Video description ends]

So we would go through that configuration. So there's a bit of configuration depending on the type of network item that you want to link into your virtual hub in your Virtual WAN, whether it be point-to-site or, as we're seeing here, site-to-site, an ExpressRoute circuit, or Azure VNets. [Video description begins] He clicks the "Create VPN gateway" button, and the corresponding pane appears. [Video description ends]

So let's just close out of this for a second here. Let's go back into our Virtual WAN device. And let's say that we wanted to link a virtual network, making a virtual network connection into that. [Video description begins] He returns to the VWAN1 blade and selects the "Virtual network connections" category. The corresponding blade that opens includes an "Add connection" button. [Video description ends]

So from here, we could add a connection and go to through the configuration  to link our VNet directly into our VWAN virtual hub. [Video description begins] He clicks the "Add connection" button, and the corresponding pane appears. It includes a "Hubs" drop-down list. He selects the VWANHub1 option from the drop-down list. [Video description ends]                    


High Availability Overview
Business continuity means ensuring that business functions continue to operate correctly in the event of a disruption, or we can either do that or try to minimize the impact of disruptions. This is where disaster recovery planning or DRP comes in. There are a couple of terms that we should be aware of, like the recovery time objective, the RTO, and the recovery point objective, the RPO. The RTO really references the maximum tolerance for downtime.

The idea is that we want to bring systems back online as quickly as possible. Or, in the case of data recovery, we want to recover data as quickly as possible so it can continue to be used. So really, we're talking about the amount of time it takes to even move operations to an alternative site.

Now, in the case of Azure, it might be your secondary alternative site if your primary site, if that's on- premises, let's say, becomes unavailable for some region. The recovery point objective of the RPO is the maximum tolerance for data loss. Like the RTO, it's measured in time. So really it deals with how often backups should be taken. So think about what's important and what's not, such as finance servers versus file servers that contain documentation.

Naturally documentation would be easily replaced, but the data on finance servers might be a little trickier to replace, especially if you haven't taken a recent backup. So if the RPO is two hours, that means you'd have to be configuring backups, in our example for finance servers, to be taken at least once every two hours to be compliant with the RPO. A Disaster Recovery Plan document deals with things such as the recovery objective, such as bringing a failed system online as quickly as possible, and the scope to which it would apply. Does it apply to one system or a collection of systems?

Then you have to have a Disaster Recovery Plan team member list with the responsibilities. People in the team need to know what they are responsible for, what their role is. There should be contact information in case an issue comes up that can't be resolved and it needs to be escalated. Such as even to Azure support, depending on the type of Azure subscription you might have. The Incident Response Plan or the IRP is one of those types of things you need to plan for ahead of time before incidents occur, such as security breaches.

Now, if we don't have an incident response plan in place, with team members that know their roles when incidents occur, then, there could be negative financial impacts, It could result in reputation loss for the organization, it could cause a problem with business partnerships, and so on. So there needs to be an annual review at minimum to keep up with changing threats to make sure that the IRP is relevant and it's effective in reducing the impact of negative incidents when they occur.

Now, another aspect of disaster recovery, and ultimately business continuity, is Azure availability zones, or AZs. This is one or more data centers that are contained within an Azure region. So, for example here we've got two availability zones, on the left, AZ 1, on the right, AZ 2. [Video description begins] The host uses an example with two diagrams. The first diagram contains one building while the other one contains three. [Video description ends] The diagrams imply that AZ 1 in this example has one Azure data center but AZ 2 has three of them.

So what we can do when we deploy some Azure services, not all, is, we can configure them to be spread out across availability zones to increase availability. And you can even replicate data between availability zones. So availability zones provide high availability, it's one or more data centers and there's also this notion of fault domains and update domains. Now, if you were to create virtual machines across availability zones, then the virtual machines would be distributed across fault domains and update domains. Fault domains in Azure refer to the equipment within a rack in an Azure data center.

Now, multiple fault domains means that we have different sets of equipment with different network switches and power sources, and increases availability in case we have a physical hypervisor running our VM that fails due to a network switch problem. Update domains are used for rolling updates, so when Microsoft updates the underlying infrastructure in their data centers, at least one of your virtual machines will always be running, such as when you spread out multiple VMs across availability zones.


VM Scale Sets
Now, a virtual machine scale set is used when you want to enable scaling for a workload. [Video description begins] The host is at the "Basics" tab of the "Create a virtual machine scale set" page where there is a template to be filled in with the Project details. [Video description ends] And so the first thing we'll do here is deploy this into an existing resource group. [Video description begins] The host chooses “Rg1” in the dropdown menu of “Resource Group”. [Video description ends] I have to give a name to the scale set, I'm going to call it "vmssapp1" and I'll use the standard nomenclature that's acceptable in my organization for naming resources.
For "Region" I'm going to put this in Canada, so let's say I'll put this in Canada Central, and I can select from some standard Windows and Linux based virtual machine images. But of course, you can also choose from private images if you've created one, and normally, you would create a private image because you would load your custom app, or commercial off the shelf app software and configuration settings within an image and use that here.
Of course, after the fact you can load software, settings and files into VMs in the scale set that you wish. You can do it after the fact, too. So in this case, I'm going to go ahead and choose "Windows Server 2016 Datacenter", assuming I know my app needs that platform. You can also opt to use spot instances for cost savings. Remember that in Azure, spot instances are essentially extra Azure VM capacity that's available for you at a discount, but it's not guaranteed. So you wouldn't use it for anything mission critical or anything like that, because it could go away. But it's great for things like batch processing.
In this case, I don't want to use a spot instance. I can specify the sizing, the underlying horsepower for each VM. And because I'm using Windows I'll have to specify an administrator name and password. [Video description begins] The Administrator account details are displayed, including fields for the "Username", the "Password" and a third one to "Confirm password". The host fills them in. [Video description ends]
So this is going to be for the admin accounts within each VM, which is given a running Windows Server 2016 Datacenter in my case. I don't have server licenses, so I'm just going to leave that on "No" [Video description begins] There is a Save money section with an offer to "Save up to 49% with a license you already own using Azure Hybrid Benefit" and a hyperlink to “Learn more”. [Video description ends] and I'll click "Next" for our disks. So for each VM in the scale set we can determine if we want additional data disks and that might be required depending on the nature of your workload.
And down below, it has a NIC configuration, a Network Interface Configuration that will be used for VMs, I can click the little pencil to edit it. So we can see in the network interface config, we have a subnet affiliation and also a network security group. Now, we could go into "Advanced" and specify the network security group info, but I'm going to leave it on "Basic". It's probably a better idea to use a network security group in this case because you've got a bunch of VMs that are going to support a workload. Probably better to have the network security group associated with the subnet to control in and outbound traffic flow.
So I'm not going to have any public inbound ports. I'm going to leave that as it is, I'll click "OK", and we could also add multiple NICs here, depending on the VM size that was selected. But in this case, I'll leave it on just the single NIC. Not going to use a load balancer at this point, so I'm going to click "Next" for Scaling, because it is a scale set. [Video description begins] The host is now on the "Scaling" tab. [Video description ends]
So the initial instance count here is going to be set to "2". We could use a manual scaling policy or we could click on "Custom". [Video description begins] When the host chooses the "Custom" option in the Scaling section, more fields appear below it. [Video description ends] So perhaps after the CPU is busy, so let's say beyond 75% overall, or ten minutes, we want to increase by one VM at a time, up to a maximum of, let's say here, I'll reduce it from 10 down to 4. You might have to tweak the settings to accommodate the workload and the peaks and troughs, and requests for that workload.
At this point we can also specify what will trigger scaling in. Scaling out horizontally means adding virtual machine nodes to support a workload. Scaling in is the opposite, it means things are slowing down and you want to remove virtual machine nodes, which saves on costs. So when we get to 25%, we could change that value, we'll start decreasing by one VM.
That being done, below I'm just going to go ahead and click "Next" for Management. [Video description begins] The host is on the "Management" tab, with fields for Azure Security Center, the Upgrade Policy and Monitoring configuration settings. [Video description ends] Here, I can choose the upgrade for each of the virtual machine operating systems, in this case, let's say "Rolling - Upgrades roll out inbatches with optional pause" is and we could specify the details for that. I'm just going to leave that as it is. I can also use a system assigned managed identity, I can have that created if I turn it on here.
Depending on the nature of your workload, if it needs access to certain other Azure resources like key vaults and so on, you can then use a system assigned managed identity instead of building that into your code, if you're using custom code. So I'm going to turn on "Automatic OS upgrades" and the automatic instance termination notification when the instances will be terminated, and I'm going to go ahead and click "Next" for Health.
So here we see it's going to connect over HTTP, specifically connecting to Port 80 on the root of each back end node to check that they are healthy and responsive. So I'm going to go ahead and click "Next". [Video description begins] The host is now on the "Advanced" blade. [Video description ends] [Video description begins] The host is now on the "Tags" blade. [Video description ends] I'm not going to change anything under "Advanced", so I'll click "Next".
I'm not going to change anything for Tags, so I'm going to click "Review + create". [Video description begins] The host is now on the "Review + create" tab. [Video description ends] It's going to run a final validation. It's passed the validation, so let's create the scale set. I'm going to click the "Create" button to make that happen. [Video description begins] The host has been redirected to a page with the indication: "Your deployment is complete". [Video description ends]
Okay, so now the deployment is complete, I'm going to click "Go to resource" and that will take us into the navigation bar, the properties for the newly created virtual machine scale set. One of the things I want to take a look at is the instances blade. If I click on "Instances" over on the left, we can see that we've got two instances as per our config. We set it to start off at "2" and to max out, I think, at "4", given a busy CPU average overall.
So we can see those two instances are shown here as running. So the virtual machine scale set then is ready to go. So if I were to click on the link for one of those instances, we would get important details, such as the private IP address used by a particular instance, so that if we want to manage it and add config files or app files, or anything like that, we can do it.
And if we were to take a look at the Networking blade for that scale set instance, we can see the network interface config it picked up when we deployed our virtual machine scale set and we can also see that it made a basic network security group. We used the basic option. So, it's attached to the network interface. Well, we could change that up if we wanted to, as we mentioned, and instead go with a subnet associated network security group.


Load Balancing Overview
Load balancing an application can not only improve performance because you've got multiple back-end VMs handling the app workload, but it also can increase availability in the event that we have a failed VM, because there are other VMs in the back-end that can pick up the slack. So really, the Azure Load Balancer deals with incoming app traffic, incoming client requests. Essentially it gets it distributed to the least busy back-end VM.
You can define a public load balancer, if it's a public facing app, such as a company website on the Internet, or you could have an internal load balancer, perhaps to low balance a busy internal line of business application used by employees. So, pictured in our diagram we have the user at the top connecting to an app or URL. In this case the URL is www.quick24x7.com. That would then be resolved through DNS to the load balancer's IP address.
In the case of a public facing load balancer, it will resolve to the public IP address of the load balancer. So clients connect to the load balancer thinking they're connecting directly to the app server. But the load balancer in turn, then uses a back-end pool configuration, which essentially might be a virtual machine scale set, which has numerous back-end VMS hosting the web app. Now, the client connection to the load balancer public IP address might happen over Port 443, a secured connection, and then the load balancer might connect to the same or a different port number for the back-end nodes. It doesn't have to be the same port number.
Now, the load balancer rules is where you configure that kind of port mapping. It controls the traffic distribution coming in through the load balancer. You have some additional options beyond the port numbers you can configure, like client session IP affinity. What that means is, depending on the nature of the web app, when a client comes to the load balancer and makes a connection to a back-end VM, the back-end pool, depending on the app, you may want the client to maintain a connection with that specific server for the duration of a session, and so that's where the client affinity would kick in, so you can configure that.
You can also configure inbound NAT rules. Essentially, this is like port forwarding for the purposes of managing the back-end VMs. Whether they're Linux-based, whether they're Windows-based doesn't make a difference. And so, remember that in the case of a public load balancer, it's got a public IP address. That's fine, but what do you connect to if you need to manage the back-end VMs? Well, inbound NAT rules can allow that connectivity.
So you could have the front-end configured port and IP address, and allow connectivity to back-end instances for VM management, and the back-end port number could be the same or different. Normally the back-end port would be 22, for SSH connectivity to Linux, and 3389 for RDP connectivity to Windows. Or you might have a different solution in place to allow remote access to those hosts, such as through Azure Bastion.
The other load balancing solution to keep in mind is the Azure Application Gateway. This is a web app load balancer, specifically, whereas a traditional load balancer certainly can load balance web apps, but it's really only designed to work up to layer 4 of the assigned model, so it can work with IP addresses and port numbers, but that's about it. The Azure Application Gateway can make HTTP routing decisions by actually looking at the URL. So this means then that we can have end-to-end SSL and TLS encryption with the Azure Application Gateway.
Now, what this means is, essentially that the application gateway acts as an SSL or TLS Terminator. So you can have client HTTP connections to the gateway, after which the gateway would talk to the back-end servers without using HTTPS. Then you might say, isn't that a security risk? Well, perhaps, I mean, everything should always be encrypted, but at the same time, by doing this, you are relieving that burden, that computationally expensive burden, from the back-end servers, of dealing with SSL or TLS encryption and decryption.
So, gateway termination can be a useful option. You can also enable auto scaling, so that the number of nodes supporting a workload can be increased or decreased depending on demand. You can enable user session affinity, just like a traditional load balancer, and you can enable up to 100 websites to be associated with a single Azure Application Gateway. And the Azure Application Gateway, if you select the Web Application Firewall tier, or the WAF tier, allows you to have a Web Application Firewall protect the web app.
Now, this is based on OWASP rule sets. OWASP is the Open Web Application Security Project, where the singular goal is to protect web apps from common web app exploits. So that would include exploits like cross-site scripting attacks, injection attacks of varying kinds and directory traversal attacks, to name just a few. So the application gateway then supports URL based routing.
If we look at our example we've got a client connecting to www.quick24x7.com. They're connecting to the load balancer or application gateway in this particular example. Let's say it's a public facing one, so public IP, but then what happens is that our application gateway will be configured with rules that look for certain items in the URL.
So on the bottom left, if an incoming URL request has "/media" in it, then that might be directed to a certain set of back-end servers, maybe optimized, for dealing with streaming media, whereas on the right, in the bottom of our diagram, if the application gateway has a rule that checks for uploads in the URL, that might be directed to a different back-end set of servers that are optimized to handle uploads.


Internal Load Balancers
In this demonstration I'm going to use the portal to deploy an internal load balancer. That means that it would be used internally. It's not going to be public-facing perhaps by employees that need access to a custom line of business application.
So to get started here in the portal I'm going to click [Video description begins] The host has launched the home page of the Microsoft Azure portal and the page url is https://portal.azure.com/#home. [Video description ends] "Create a resource" and I'm going to search for "load", and right away there's "Load Balancer", so I select that and I'm going to click "Create". [Video description begins] The host is at "Basics" tab of the "Create load balancer" page where there is a template to be filled in with the project details. [Video description ends]
Next, I'll deploy this into a resource group [Video description begins] The host chooses “Rg1” in the dropdown menu of “Resource Group”. [Video description ends] and I'm going to give this load balancer a name, I'm going to call it "int", for internal, "lb1". Now, it likes that name. We have the green checkmark over to the right of the name field. I'll specify the Azure region where I want this deployed. So in this particular case, I think what we'll do is put it, let's say, in Canada Central.
Now, I would do that if I know that's where, geographically, most people that will need access to it reside. So if we've got branch offices in that location, people'll need to connect to Azure to get to the internal load balancer, that would make sense. But we have to select "internal" for the type. The default is a public load balancer.
In most cases, you'll just leave it as a basic SKU. Although it does say if you have a need for more than 1,000 instances and better flexibility in that sense, then you might choose a standard SKU. I'm going to leave it on basic in this example. It needs to be tied to a virtual network, so I'll chose a VNet I've got here called "Vnet1" and also a subnet. Now, I can select whichever subnet I wish that's available, so I'm going to choose a subnet called "Subnet2", and for the IP address assignment I'm going to use "Dynamic".
So, dynamic of course means that we have an IP address, an internal private IP address, it's an internal load balancer that could change, whereas we could choose "Static" if we didn't want it to change. When we choose "Static", I'll scroll down a bit, you can then specify the address that you want to use. I'm just going to leave it on "Dynamic" for this case and I'll choose "Next" for Tags. I'm not going to tag this, so I'll choose "Next", "Review + create". It's going to check that my settings are valid and then, after it passed, I'll click "Create".
Okay, so the internal load balancer is deployed, but it's not ready to go. [Video description begins] The host has been redirected to a page with the indication: "Your deployment is complete". [Video description ends] We need to configure it further. So I'm going to click on "Go to resource". One of the first things we're going to do here is configure a backend pool. Now, if I go first of all, actually to the frontend IP configuration, we can see the dynamically assigned private IP that's being used for this. So that's fine, that is there.
Let's go to backend pools. The backend pool identifies the backend virtual machine workers that the load balancer will send client requests to. Now, we don't have a backend pool. Well, we need one so I'm going to click "Add" and you have a couple of different sources you can select from to define the VMs in your backend pool. Let's give this a name. I'm going to call it "BackendPool1", and down below, for the association, I can choose a virtual machine or a virtual machine scale set. [Video description begins] The host picks the "Virtual machine scale set" option in the "Associated to" dropdown menu. [Video description ends]
Now I happen to have already created a virtual machine scale set and it's showing up here in this list, and I can select the IP address from the network interface configuration for that scale set. A virtual machine scale set is a collection of virtual machines using the same operating system image, even if it's custom to support your app, that are scaled. You can configure auto-scaling, for example, if you wish, or you could manually scale it. So I'm going to have my load balancer use that existing virtual machine scale set and then I'll click "Add".
Okay, so now we've got our backend pool added to the load balancer configuration I'm going to go to "Health Probes" because we want the load balancer to know which backend VMs in the scale set are healthy versus those not responding. The ones that aren't responding will not have client requests routed to them. So I'm going to click "Add" to add a Health Probe. [Video description begins] The host is redirected to a new page titled "Add health probe". [Video description ends] I'm going to call it "hp1", for Health Probe 1, and I'm going to have it contact TCP port 80 on each backend instance.
So I have to make sure that that port is available and running on those machines, in other words, have the web server stack up and running. So I'm going to go ahead and click "OK" to add that health probe. And I also need a load balancing rule, so I'm going to go to "Load balancing rules" and click "Add". [Video description begins] The host is redirected to a new page titled "Add load balancing rule". [Video description ends]
I'm going to call this "lbrule1", load balancing rule 1, so I can associate this with the frontend IP and essentially what I'm doing, it's kind of, like forwarding or port mapping on a firewall, where I want the load balancer to listen on port 80 and when clients make a request to that, then the load balancer will send that to port 80 on the backend VMs in the scale set. And we could see the backend pool association listed right here.
So I'm going to go ahead and do that and I could also enable, for example, Client IP or Client IP and protocol persistence to keep clients connected through the load balancer, keep them connected to the same backend VM instance. That might be required depending on how the backend app was created. However, I'm just going to leave that on "None" and I'm going to click "OK".
The last thing I might do is click "Inbound NAT rules", where I might create an inbound NAT rule if I want to allow inbound access to remotely manage the backend instances. However, I'm not going to go ahead and do that here. So at this point, we've got our functional load balancer, let's just go take a look at this, meaning, I want to go to the overview of my internal load balancer, so the overview blade. [Video description begins] The host is redirected to a new tab titled "Overview". [Video description ends]
So just bear in mind that normally what we would do is have a DNS record that maps to the private IP in this case, for our internal load balancer. So when clients connect to that DNS name, the request is being sent here, which in turn is being sent to the least busy backend VM supporting the app.


Public Load Balancers
In this demonstration I'm going to configure a public load balancer using the Azure portal. So I'll start by clicking "Create a resource" and I'm going to search for the word "load", and I'll choose "Load Balancer" and then I'll click "Create". Now, public load balancers, [Video description begins] The host is at "Basics" tab of the "Create load balancer" page, where there is a template to be filled in with the project details. [Video description ends] like the name implies, are publicly accessible.
You would do this for example, if you had a public website you wanted available but you wanted to load balance it to improve performance and availability, since you've got a backend pool of VMs serving the app. So I'm going to deploy this into a resource group. [Video description begins] The host chooses “Rg1” in the dropdown menu of “Resource Group”. [Video description ends] I'm going to call this "publb1", so public load balancer 1, and I'm going to deploy this in a region nearest where I think it might be used for the most part, so I'll choose "Canada Central", or if not, I'll deploy it in a region nearest where it will be administered.
I'm going to leave the type to the default value of "Public". We want a public load balancer here. We can either use an existing public IP address resource we might have previously deployed, or create a new one. I'm going to create a new one in this case. I'm going to call it "publb1_pubIP" to name the resource that will be created here. You could go with a statically assigned public IP address, which means it's unchanging. So depending on what your requirements are we'll determine whether you choose Dynamic or Static.
In this case, I'm going to choose "Static". I'm not going to have IPv6 support because I don't need it in this case, so I'll click "Next". I'm not going to tag this, I'll click "Next". It's going to validate my choices. The validation has passed. I'm going to go ahead and click "Create". But of course, we're then going to have to go in and define a backend pool, a health probe, and also some load balancer rules. We'll do that once this is deployed. [Video description begins] The host has been redirected to a page with the indication: "Your deployment is complete". [Video description ends]
Now that the deployment is complete I'm going to click "Go to resource". That's going to open up our load balancer. We can see if we click on the Frontend IP configuration to pull up that blade, that we already have a public IP address, in our case it's static, so it's unchanging, but I'm going to go to "Backend pools" because you need a backend pool of VMs to handle your application. So I'm going to click the "Add" button. So we're going to call this "BackendPool1". I'm going to select a virtual network. Now, this virtual network selection here, in this case "Vnet1", is important.
Let me demonstrate by selecting a virtual network I don't want. I'm going to choose another one called "Rg1-vnet". What I want to do is associate this load balancer with an existing virtual machine scale set that's already scaling an app. So I'm going to go to the Associated to and I'm going to choose "Virtual machine scale set".
But it says none were found in my region, Canada Central, that matches the above criteria. Well, if I change the virtual network, let's say I choose "Vnet1", then I will see that I've got [Video description begins] The host has changed "Rg1-vnet" to "Vnet1" in the"Virtual Network" dropdown menu. [Video description ends] a virtual machine scale set ready. So it's important to make sure if you're going to rely on another resource like a virtual machine scale set that you know the region it was deployed in, and also, as we see in this case, the virtual network it was deployed into. So I'm going to select that virtual machine scale set and its associated network interface for an IP address and I'll click "OK".
Now, that backend pool is pointing to a virtual machine scale set and that virtual machine scale set, so our backend pool then is being served by virtual machines and the scale set, each of which uses the same OS image, which could be a custom image, of course, that has your app software and its configuration. Next, I'm going to configure a health probe because we want to make sure that client requests are not routed to backend instances that are not healthy, that aren't responding.
So I'm going to click "Add" to add a health probe. This will be called "hp1", for health probe 1, and we're going to have the load balancer periodically, we can see the interval here, talk to port 80 on each backend virtual machine within the scale set, and after two consecutive failures, after two five-second intervals have gone by, it will be determined that VM is unhealthy and so, client requests will not be routed to it. So, I'll click "OK" and we're going to go to "Load balancing rules", and I'm going to click "Add", and I'm going to call this... simply call it "rule1".
Now this load balancing rule is going to be important because the load balancing rule, essentially, will have the frontend IP address and port number. So it's a public IP, Port 80, and we have to map that to what we want it to connect to on each VM in the backend, and in this case, that also happens to be Port 80. It doesn't have to be the same port number. We can also see this rule by default wants to use our health probe.
I'm going to go ahead and click "OK" to create the load balancing rule. And if we wanted to allow inbound remote management for connecting to each backend node, then we could configure inbound NAT rules to do that, but you don't necessarily need an inbound NAT rule if you want to remotely manage each backend instance, at least in this particular case, because if I go, let's say into my virtual machine scale set that we've linked to the load balancer, we can look at the instances that are up and running for that scale set, so I'll pop up the instances blade. There are two of them.
If I click on any one of them I'll see that they each have their own unique private IP address and so, I could remotely manage each backend VM instance simply by connecting directly to the private IP address, but I would have to be on the Vnet. You might set up a jump box such as through Azure Bastion to make that happen. Either way, it's important to be able to remotely manage the backend instances that are load balancing your app.


Application Gateway
The Azure Application Gateway can make decisions for routing or load balancing to backend hosts using things like URLs. It also supports a web application firewall. Those are two things the load balancer does not do. So let's deploy one, an application gateway, here using the Azure portal. [Video description begins] The host has launched the home page of the Microsoft Azure portal and the page url is https://portal.azure.com/#home. [Video description ends]
So I'm going to start by clicking "Create a resource" and I'm going to search for "application gateway", and I'll select it from the list, and as usual, I'll click "Create". [Video description begins] The host is at "Basics" tab of the "Create application gateway" page where there is a template to be filled in with the project details. [Video description ends] So I'll deploy this into an existing resource group [Video description begins] The host chooses “Rg1” in the dropdown menu of “Resource Group”. [Video description ends] and I'm going to call this "appgw1", for App Gateway 1.
I'll deploy it in a region, let's say in this case here, I'll choose Canada Central, and here I have the tiers. Now, this is important if I want a web application firewall. So, if I want that kind of support then, I'd have to choose the WAF or the WAF V2 tier, ideally version 2, say as Standard. I want Standard V2 to have the latest options available. I can determine if I want to enable autoscaling with the app gateway. Yes, I do want to do that. So maybe I'll specify a minimum scaling unit of 1, and a max, let's say of 4, and down below, I can tie this to an existing virtual network.
So I'm going to tie this to Vnet1, let's say, and then, down below that I have to make sure I choose a subnet. So I'm going to choose a subnet and I'll click "Next". [Video description begins] The host chooses "Subnet2" in the "Subnet" dropdown menu. [Video description ends] Now, for the frontend configuration, much like we can have an internal [Video description begins] The host is now on "Frontends" tab. [Video description ends] or a private load balancer, as opposed to a public load balancer.
So too, here do we have the same options: a public or a private IP address for the frontend of the app gateway, or both, might want to do both. I'm going to leave it on... let's see let's do "Public" in this particular case. Notice that when I select "Private" it says if you have an App Gateway with a tier of Standard_v2, it doesn't support only private IP addresses, but if you went to just "Standard", not v2, it would.
However, in this case I'm going to go with "Public" and I can go and choose an existing public IP, but here I've got some public IP resources, they're already associated with other objects. All right, then I guess I'll have to click "New". [Video description begins] The host clicks on "Add new" and a template is appears, titled "Add a public IP". [Video description ends] So, "AppGw1" for App Gateway 1, "PubIP", that's what we're going to call it.
Notice that we are using the Standard SKU and the assignment here is going to be "Static". We don't even have the option of using "Dynamic" in this case. That's fine. Next, we have to define a backend pool. [Video description begins] The host is now on the "Backends" tab. [Video description ends] I'm going to click "Add a backend pool" [Video description begins] The host clicks on "Add a backend pool" and a template to be filled appears. [Video description ends] and I'm going to call this "BackendPool1".
Now what I can do here is specify what the backend VMs are. Are they IP addresses or fully qualified domain names? Do I want to add a bunch of individual virtual machines? Do I already have a virtual machine scale set, or an app service? I'm just going to choose "Virtual machine" in this case. [Video description begins] The host has chosen "Virtual machine" in the "Target type" dropdown menu. [Video description ends] And from the target drop down list, I'll choose the virtual machine.
So, I can keep adding multiple virtual machines that would be configured with the same app. In this case, I just have one but that's okay. So I'm going to go ahead and add that backend pool. I'll click "Next" for Configuration. Now, here we see routing rules. I could click "Add a routing rule".
And this is where we have a distinction between a traditional load balancer and what we're doing here with the application gateway, which is an OSI Layer 7 type of item, because it can look way beyond just packet headers that contain things like IP addresses and port numbers. So I'm going to call this "Rule1". For the listener name, I'll call it "Listener1". And I'll choose our public listing from the frontend IP and HTTP or HTTPS depending on what type of connectivity you want allow. I'll leave it just on HTTP, Port 80.
Now, after I've done that, I also have to specify the backend target. So I'm going to use a backend pool that I've already defined, that's "BackendPool1". I don't have any HTTP settings yet, so I'm going to click "Add new" to add some new ones, and I'll call this "HTTPSettings1" for HTTP. And the backend port here will be port number 80. I'm not going to enable cookie-based affinity or anything like that.
And down below, I'm just going to go ahead and click "Add" to add these HTTP settings. And now that's been filled in back here when we were configuring our routing rule. So, down at the bottom I'm going to click "Add multiple targets to create a path-based rule". [Video description begins] When the host clicks on this hyperlink, a template appears titled "Add a routing rule". [Video description ends]
And this is where I can specify, for example, "/media/*" so anything from media in the URL. Maybe I'll call this "Target1" and I can specify some HTTP settings and the backend target where I want to send that. [Video description begins] The host selects "HTTPSettings1" in the HTTP settings dropdown menu. In the Backend target dropdown menu, the host selects "BackendPool1". [Video description ends] So you could configure multiple backend pools to handle different types of URLs.
So /media might go to BackendPool1 because the VMs in BackendPool1 are optimized to stream media. I'll just go ahead and click "Add" and then I'll click "Add" again. So now we've got our routing rule. Of course, we had our frontend and our backend pool. Let's click "Next" for Tagging. I'm not going to tag this application gateway, so I'll click "Next : Review + create". It's going to check the validation which has passed, and so, I'm going to create the application gateway. I'll click the "Create" button.


Load Balancers and Templates
In Azure, load balancers can be deployed and managed using the portal, using PowerShell, using the CLI, and also using templates. We're going to take a look at how to do that here in the portal, how to create a template deployment for a load balancer. So I'm going to start the portal by clicking "Create a resource".
And like I normally would do when I want to deploy a template in this manner, I'm going to search for the word "template" and I'm going to choose "template deployment", and I'll choose Create. [Video description begins] The host is redirected to a new page called "Custom deployment" with various hyperlinks. [Video description ends] Now I could build my own template in the editor if I wanted to do this from scratch and I knew the syntax that I need to use. Or I could go down, let's say, or GitHub, and I could search it up.
For example, if I type in the word "load", I could start with, let's say, "101-internal-loadbalancer-create". I'm going to use that template since I do want to deploy an internal load balancer. So I'm going to select that. I'm going to go down and choose "Select template". [Video description begins] The host is automatically redirected to a template page called "Create a Load Balancer with Inbound NAT Rule". [Video description ends]
The template that you would use would determine what you need to specify for values, in this case, the resource group where I want it deployed. Then, also the VNET and subnet prefix. So, apparently this template is going to create a new VNET and subnet within that region, which is fine. I'm going to go ahead and click" I agree to the terms and conditions".
Now notice, when you're back up here at the top, you could also have chosen to edit the template. And from here you can make changes. So here's the JSON syntax for this particular template. You can see here, it's going to build our subnet, it's going to build our VNET, and so on. However, I'm going to discard that because I don't want to edit the template.
So we're back here where we left off. I'm going to go and click the Purchase button to use this template to deploy our load balancer. And after a moment we'll see our deployment succeeded. So let's just go to all resources here. We're going to look for load balancers. Now notice the template didn't even give us the chance to specify a name for the load balancer.
So I'm going to select "Load balancer", we can see there's only one, here in our subscription, and it's called "loadBalancer1". So this is the load balancer that was deployed as a result of us having selected that template. [Video description begins] The host clicks on the loadbalancer1 and is now at the overview tab. He then clicks on the backend pool tab to examine the details. [Video description ends]
However, if I go into the backend pool, it did create a back end pool but we don't have any virtual machines or scale sets, or anything associated with it. So it did part of the work. Of course, the template could have been coded to do all of the work, but sometimes you'll want to use a template, an ARM template, to get the majority of the hard work done, the underlying work of just creating the resource and getting it deployed. And then you'll want to go in and tweak details in this case like the Backend pool, Health probes or Load balancing rules.


Load Balancer Troubleshooting
Even though you might have successfully and correctly deployed a load balancer configuration, it doesn't necessarily mean that everything's going to work. There could be other problems such as with the backend virtual machines and their configuration. So for example, here in the portal I got a load balancer called LB1 and in the overview blade, over on the right, I can see it has a public IP address.
Okay, I'm going to copy that and I'm going to see if we can pull up the web page for a web app supported by this. Now, that's assuming that your load balancing a specific web app with the front end. So let's open up a new browser window and see what happens when we connect to that IP. [Video description begins] An error message is displayed on the screen. The page requested cannot be reached. [Video description ends] And this is what we get.
I can't seem to pull up anything from that IP address. If I know that I'm load balancing a web app that has a frontend page it shouldn't be showing up, then this is a problem obviously. So what do we do about this? One of the first things we should do to troubleshoot this is perhaps go back to our load balancer and look at the backend pool. [Video description begins] The host comes back to the Microsoft Azure tab and clicks on the "Backend pool" option under the "Settings" section. [Video description ends] So what is being served up here in the backend?
Well, if I look at the backend pool, it looks like a virtual machine called WinSrv2019-1, the status of which is that it failed. Okay, let's click to examine that a little bit. What's the problem? You can have a health probe that checks the health of the virtual machine. And at one point in time it might have had a problem. So if you have a failure with a backend server, naturally that's going to translate to being a failure or a problem with the low bouncers since it depends on them. Now, you might have multiple backend VMs.
If only one has failed, then it means examining the details, clicking links and finding out what the problem with that specific VM is. So back here in the Load balancer, if I go to the backend pool and click directly on it, if that virtual machine is problematic and I can't solve the problem within it, then I could look at the virtual machine association here. This particular backend pool is linked to virtual machines as opposed to a scale set. And I can click the trash can to remove the reference if I couldn't solve the problem with that VM. [Video description begins] The host is now back to the virtual machines tab. [Video description ends]
Now the other thing to do is to also take a look at the actual virtual machine. So I've got it here listed as running, so I'm going to open it up and I'm going to make a connection directly into it. Now, this virtual machine has its own public IP address. If it only had a private one, then I could use, for example, Azure bastion to make a connection to it. But either way, one way or another we need to be able to troubleshoot low bouncing issues by getting into the backend VMs in some cases.
So I'm going to go ahead and click "Connect" here to make a connection to this Windows VM. And I'm going to download the RDP file. [Video description begins] The host is now in the Server Manager dashboard. [Video description ends] So here, within my backend virtual machine, the Server Manager has started up and if I go to "Add Roles and Features" just to step through what I would normally do to install the web server, I can see the web server component is already there. So we should also take a look at the specifics.
In this case for the web app, I should open up the Internet Information Services Manager tool and make sure that the web app, for example, is listening on port 80, assuming that's the load balancer rule and how it's configured. So if I look at "Sites" here, we've got the Default Website and if we just take a look at that by right clicking and editing the bindings well, it is listening on port 80 so it's not like it's listening on port 81 or some non-standard port. [Video description begins] The host is now back on the Azure Portal, at Home > lb1 | Backend pools. [Video description ends]
Back here, in our load balancer, we should probably go to our load balancing rules just to make sure it looks like the correct port numbers are being referenced. This is another important part of troubleshooting and it is: Frontend Port 80, Backend Port 80, which we just verified, was the configuration. The other thing we should do is check out our network security group for our Windows virtual machine. [Video description begins] The host is now on another browser tab, at Home > Virtual machines > WinSrv2019 - 1 | Networking. [Video description ends]
So, when I look at my virtual machine and go to the Networking blade, I can see "Rules". Well, I think we might have a problem here because we don't seem to have an allowance for Port 80. We have one to allow inbound Remote Desktop Protocol on port 3389, Vnet inbound, low bouncer inbound, and then it denies everything else. Well, that's a problem if you don't have an allowance for port 80 here, just like in the OS within the VN there. You want to make sure that you don't have file rules blocking traffic. Well, that's going to be a problem if it's not setup correctly.
So what we're going to do here is going to our network security group and we're going to add a new inbound security rule to allow port 80 traffic. So I'm going to click the "Add" button. We're just going to fill it in accordingly. So the destination port here is going to be Port 80. [Video description begins] The host clicks on the "NSG-Windows" hyperlink in the networking tab. He is redirected to another page, then goes to the"Inbound security rules" tab, under the settings section, and clicks "Add". [Video description ends]
In this case over TCP for our web app [Video description begins] The host changes the "Protocol" from "Any" to "TCP". [Video description ends] and I'll call this Port 80 for the rule. I'll leave the Priority at 110, that's going to be fine, and I'll click "Add" to add the rule to the list. While that's happening, let's go back to our configuration once again for our load balancer because the other thing to think about in the backend pool is that if we click on it, in this case, we'll see our virtual machine. [Video description begins] The host goes back to the "Backend pool" tab that's open on the browser. He clicks on the backend pool to check the details. [Video description ends]
We want to make sure we still have the correct IP address. So currently, when this backend pool was configured, it referred to the virtual machine with an IP, a private IP, of 10.0.1.5. So we want to make sure, for example, if we go back into our virtual machine, that that indeed is the correct private IP address. And it is in this case 10.0.1.5. [Video description begins] The host is now again on the "Overview" tab of WinSrv2019-1. [Video description ends]
So now that we've corrected the problem, which was simply a network security group rule that we added to allow Port 80 traffic, we can see when we connect to the public IP of the load balancer, it's now making the correct connection to the back end web server.


Azure Site Recovery Overview
In a business environment it's crucial that our supporting IT systems are up and running, and that data is available and kept secured. This is where Azure Site Recovery comes in. It's all about business continuity, and also disaster recovery. With Azure Site Recovery we can enable fail over and fail back. This means we can have replication enabled between primary and secondary sites, or Azure regions.
So you could replicate virtual machines, for example, that might be running a mission critical workload. You can also enable application snapshots. So this would take the state of your web application, including memory, transactions, and also any disk files that are related to that. So Azure Site Recovery could be called Disaster Recovery as a Service, or DRaS. Now it's treated as an alternate recovery site as well.
So, for business continuity, you might have a physical on premises facility, or you might have a data center location, or it might be just a corporate network within your building, and you might want to use the Azure Cloud as the alternate network location for IT services. So your primary location is your on-premises network. If something happens to disrupt that, then you could already have had things like physical servers or on-prem virtual machines replicated into Azure that are ready to take over the workload.
What we're talking about doing here is planning for failure. It's inevitable that there's going to be some kind of a disruption at some time, and we don't want to be caught unprepared. We want to have a plan in place before those things happen. Now, you can work with Azure Site Recovery in a number of different types of servers, such as on-premises physical servers can be replicated into the Azure cloud. Azure Virtual Machines can be replicated to a secondary Azure region. You could have VMware Virtual Machines or Microsoft Hyper-V Virtual Machines that you protect with Azure Site Recovery.
Now, not only is fail oversupported, so we can fail over to a virtual machine running in Azure if we have a disruption on-premises, but also fail back. You can fail back to your primary version of a server, for example, on-premises. There are some exceptions, for example, if you try to fail back from Azure to an on-premises physical server, then you're going to have a problem. But if you have an on-premises virtual machine and you failed over to it in the cloud, you'll be able to fail back to it on-premises.


Site-to-Site Recovery
You can protect mission critical Azure VMs by enabling Site Recovery. Now, Azure Site Recovery really lets you copy or replicate a VM to an alternate region, and for that, you're going to need a recovery services vault. We're going to start here in the portal by opening up an existing recovery services vault, because this is one way that you can initiate the process of enabling Azure Site Recovery for a virtual machine.
So I'll scroll down in the navigation bar [Video description begins] The host clicks on the option "Vault1" on the Azure portal. [Video description ends] over on the left and I'm going to choose "Backup items", and notice, among the many things listed here for Azure virtual machine, we have 0 for the backup item count, so we are not yet backing up any Azure VMs. So having done that, that's fine. We're going to scroll up a little bit, and I'm going to click "Site Recovery" over on the left and I'm going to choose "Prepare Infrastructure".
From here, I can determine exactly what it is I want to protect. [Video description begins] The host is now on a section called " Protection goal", the one on the Prepare Infrastructure page. [Video description ends] Is the Virtual Machine in Azure or is it on-premises? [Video description begins] The host selects "On-premises" from the dropdown menu. [Video description ends] And naturally, if I'm doing a migration, I can choose that otherwise, I could choose "No".
Then I can select what it is I'm migrating, whether it's virtualized with Hyper-V, VMware, or if it's a physical server. However, in this case I want to protect an Azure virtual machine, so I'm going to select "Azure" for "Where are your machines located?". [Video description begins] The host goes back on the dropdown menu and changes the "On-premises" option to "Azure". [Video description ends] And I also want to replicate it to Azure, so I'm going to go ahead and click "OK", and then I'll click "OK" yet again.
Then I would click on "Replicate Application" and continue from here. So I'm going to choose the source environment. I've opened up another browser window where we can view our virtual machines. I've got one called WinSrv2019-App1, it's running, and notice it's in the East US location or region. So back here, configuring replication, my source environment is Azure East US and my resource group is going to be Rg8, resource group 8, notice that is where that virtual machine is deployed.
So that's great, that's my source and environment. I'm going to choose OK. [Video description begins] The host is at the "Enable Protection" tab on the second section called "Virtual machines". [Video description ends] There's the virtual machine WinSrv2019-App1, so I'll put a check mark in the box, I'll click "OK". Then I have to select the target location, so from the drop down list I have a number of options. I'm going to leave the selection here of "(US) West US".
Down below, I can see in that target location, it's going to create a new resource group called Rg8-asr. The asr stands for Azure Site Recovery. It's going to do the same type of thing to build a target VNet. I've got a cache storage account here that will be in the source location that's used basically as staging before replicating, in this case, to West US. And it's going to replicate a managed disk because my virtual machine is using one disk.
And down below, we can see the replication policy. So recovery point retention is for 24 hours and app consistent snapshots are taken once every 4 hours. So that's fine, I'm going to go ahead and click "Create target resources". So it's going to create these in the target region, in my case, West US. I'll click "Enable replication". [Video description begins] The host goes back to "Vault1 Site Recovery" page. A window has appeared that says enabling replication for 1 vm(s). [Video description ends]
And we can see in the notification area in the upper right, it's currently enabling replication for 1 VM. And before too long we can see that it successfully enabled replication for one VM. Now, back here in backup items, we still don't see anything for Azure virtual machine because we haven't enabled backup, we've enabled replication, so this is fine. If I go to "Replicated items" we'll see all servers where replication was enabled. We've got one that failed here, normally due to an unsupported configuration or operating system.
But our Windows server hosting our app is listed as healthy when it comes to replication health. Although notice, still at this point, while replication is enabled, 0% is synchronized. So you can watch over this and click the "Refresh" button to track. Let's just flip over to our other open window here where we have our virtual machine selected and in the navigation bar. I'm going to scroll down under "Operations" because I want to click on "Disaster recovery". This is where we will see the fact that we've got replication enabled.
Now, it's still 0% synchronized, and if we were, for example, to go to "Properties" we can see a lot of the properties, again, 0% synchronized. We can see the active location, the replication policy, and if we take a look at "Compute and Network", for example, compute and network resources, we could see it was unable to retrieve anything, because initial synchronization is still happening, and if we click on "Disks" we could still see that it looks like it's synchronizing the OS disk to the target location, so to the replica disk name.
And if we go back and take a look here we can see that it's 97% synchronized, still looking at the Disks blade, it's almost done. Back here, in the recovery services vault, we're still looking at Replicated items. I've clicked "Refresh" and notice now our replication health is healthy and that status now says "Protected".


VM Failover
In this demonstration, I'm going to use the portal to test virtual machine failover in Azure. Now, I've already enabled replication through Azure site recovery, for an Azure VM. So, essentially replicating from Azure to Azure, replicating a VM to another region. Let's take a look at how to test failover. [Video description begins] The host is at the Virtual machines page of the Azure portal. [Video description ends]
So I'm going to open up an existing virtual machine, where I've enabled replication. Now we can check this out in the navigation bar by going down under "Operations" and by clicking on "Disaster recovery". When I do that, in the "Overview" section, I'll get an indication as to whether or not protection is enabled.
And we can see here, the status is "Protected" and that the "Replication health" for this VM is such that it is "Healthy". However, it says "Last successful Test Failover", "Never performed successfully". Well, as part of a recovery drill in the event of a disruption, such as in the primary region of a virtual machine, we should go through and test failover for mission-critical workloads running in these VMs.
So I'm going to do that. I'm going to click the "Test Failover" button up here at the top. So, for the "Failover direction", it already knows where I'm failing over from, "East US" is the primary location. I've already enabled replication. So there's a copy of it in "West US". That's already set and it's grayed out, I cannot change it, and that's normal. What I can select is the "Recovery Point". So I might have numerous recovery points over time that I would like to use for performing this test failover.
So what I'm doing is failing the VM over to the recovery point that I select here from the list. And if you've got multiple VMs, you might actually have this set up through a recovery plan. You can use failover for multiple VMs at once. But in this case, we don't have a recovery plan, it's just a single VM. I need to choose the virtual network, the "Azure virtual network", where I want this created. You want to make sure that this is not one that's used for mission-critical services and production. And after that, I'll go ahead and click on "OK".
We can see it is now starting the test failover for this VM. So, at this point, if I were to look at my list of virtual machines, I should notice the presence of a new virtual machine. It's named similarly to the original except it has "-test" added at the end. It's running and we can see it's in the target "Resource group" that we selected when we tested failover. Also notice it's in the target region, in this case, "West US". The source region is "East US".
So we could test connectivity to an app running within it or remoting into it for RDP and whatnot, if we wanted to fully complete this test. However, at this point, I am finished with that. So I've tested the failover. [Video description begins] The host closes the Virtual Machines tab and returns to the Overview tab of the source Virtual Machine. [Video description ends]
So, if I go back to my source virtual machine, and if I take a look at the disaster recovery options, we now have the option to "Cleanup test failover". So I want to make sure I do that to delete the newly created virtual machine. [Video description begins] The host clicks on the "Cleanup test failover" tab. [Video description ends] I am just going to put in some notes here. "Testing is complete, delete test failover virtual machines". I'll turn on that checkmark and I'll click "OK".


Azure Backup Service Overview
Data backup provides availability in the event that production data becomes corrupted or deleted in some way, we can restore it from backup. And there are a few considerations when using "Microsoft Azure Backup" services. We can back up "On-premises" data in the form of "Files and folders". Even "Hyper-V and VMware VMs" we're hosting on prem, "SQL server, Exchange server, SharePoint server installations.
We can even back up system state, which would include things like operating system boot files, registry settings on a Windows Machine. If it's a Windows domain controller server, even backing up the database for active directory is part of system state. Then we can also perform a "Bare Metal recovery". When you set up a "Bare Metal recovery", what you're really doing is telling Azure Backup you want to backup the entire operating system, so all the OS files and the data on those volumes. So really, it's everything except for user data.

To work with Azure Backup, you need to install the "Microsoft Azure Recovery Services Agent", or the "MARS" agent, on your server that contains the services you want backed up. And that will allow the communication to the Azure cloud, specifically to the recovery services vault for backup purposes. Azure backup lets you backup Microsoft Azure virtual machines, "Azure SQL Database" and "Azure File Share".

The process for setting up on-premises backup, let's say if we have an on-prem Windows Server we want to back up to the Azure Cloud, would be to first make sure that we have a "Recovery Services Vault" created in Azure. Next, we would "Download and install the MARS agent" on the server, whose services we want backed up. And then we would "Register MARS agent with the recovery services vault". Then after that you can enable the backup for the services on that server where the MARS agent is now installed.


Recovery Services Vault
That's going to let me create a recovery services vault. So I'm going to choose "Create". [Video description begins] The host is at the "Basics" tab of "Create Recovery Services Vault". [Video description ends] Okay, so I need to tie this to a "Resource group". I'll do that, I'm going to call this "Vault1". [Video description begins] From the Resource group dropdown menu, the host selects "Rg1". [Video description ends] It's going to check that that name is valid and it is, and it's going to be in the, let's place that vault in our configuration.

Let's leave it actually in the "Canada Central" region. I'm going to put it there. I'm going to click "Next" for tagging. I'm not going to tag this fault. And after that, we're just going to click "Review + Create" and after which we will click "Create". So we're deploying a recovery services vault. [Video description begins] The host is redirected to the a page with a message that states "Your deployment underway" and after that, it states "Your deployment is complete". [Video description ends]

So now the vault has been deployed. I'm going click "Go to resource" so we can take a look at it. So you can think of a recovery services vault in Azure as being essentially the launching pad for your business continuity solutions. So for example, let's scroll down here and I'm going to click, under "Getting started", "Backup".

This is where we can determine if we want to backup items sourced in "Azure" such as "virtual machines", "SQL Server", "Azure FileShare". Or we might select "On-premises" and choose "Files and folders", or on-premises "Hyper-V" or "VMware Virtual Machines", on-premises "SQL Server", "SharePoint", "Exchange", and so on. [Video description begins] The host goes through the different options to select from the dropdown menus. [Video description ends]

We can also go to our "Site Recovery" option on the left and [Video description begins] On the "Site Recovery" tab, the host clicks on the "Prepare infrastructure" option and is redirected to the corresponding page. Currently, the first section is open, named "Protection goal". [Video description ends] start to prepare our infrastructure.

This is where we might choose, okay, we've got our virtual machines that might exist "On-premises". We want to make them available for high availability in "Azure". It asks, "Are you performing a migration?" Well, we could do that, but I'm going to choose "No". And I can tell it that my source on-premises would be "Hyper-V" or "VMware virtual machines" or they're not virtualized.

You can actually enable failover for an on-premises physical server to an Azure VM Failback isn't supported in that context to the on-prem physical server but failover to the VM in the cloud is. Also, here, we have a number of other options available within the recovery services vaults, such as configuring "Backup policies". [Video description begins] The host closes the "Site Recovery" tab. Back on the Vault1 page, he clicks on "Backup policies" tab on the left, under the Manage section. [Video description ends]

So not only are we talking about high availability, such as for virtual machines, but also the ability to back data up into the Azure Cloud. Which really enables data high availability. So the Recovery Services vault then allows for all of this disaster recovery planning.


Azure Backup Policies
In this demonstration, I'm going to use the portal to create a backup policy within a Recovery Services vault. So I've already got a vault I've created here, it's a recovery services vault, it's called "Vault1". So I'm going to click to open it up. And within its navigation panel on the left, I'm going to scroll down until I get to the "Manage" section where I can see "Backup policies". So I'm going to pull up that blade.

And I see on the right I have two default backup policies here automatically. One is called" HourlyLogBackup" for "SQL Server in Azure VMs". And the other is called "DefaultPolicy", it's for "Azure Virtual Machines". However, I want my own custom policy for "Azure Virtual Machines". So I'm going to click the "Add" button.

You might even have a policy for "Azure Virtual Machines" that applies to only some, where you want to use the default VM policy for others. Either way, in this case, I can select" Azure Virtual Machine", "Azure File Share", "SQL Server in Azure VM," or "SAP HANA in Azure VM". But we're talking about "Azure Virtual Machine" backup policies here, so I'm going to select that. First thing I have to do is give this a name.

So I'm going to call this "ProdVMs", as in Production Virtual Machines. And we can set the backup schedule, whether it be daily, or weekly. I'm going to leave it at daily and I can set the time of the day I want that to fire off. So maybe after hours, at 7:30 PM, and I can select the specific time zone if I so choose, or I can use "UTC". Next thing is, how many days do we want to use retention of instant recovery snapshots? The default here is two days and I'm going to leave that.

As we go further down, we have the retention range of the backups, which is going to be 180 days, that can be changed. I want the retention of a weekly backup point. And we can also specify details related to the "monthly" and "yearly" backup point retention period. So we can specify the details when exactly that is going to be taken, and for how many months or years in the case of the yearly backup point that we want that retained.

If you're using Azure services that set up VMs for you in the background, in other words managed VMs, you can also specify resource group information for those. Specifically to store their recovery points. So I'm going to go ahead and click "Create" to create this policy. And before too long, it's done. So let's just go back to our "Vault1" Backup policies.

We can now see we've got a new policy called "ProdVMs" and it's of type "Azure Virtual Machines". We can click on it to open it up at any point in time to see the details that were configured. And at any time, we could go back and modify and change whichever options are required. So this backup policy, then, can be selected when we start enabling backup for Azure VMs.


Azure VM Backup and the Portal
One way to enable backup for an Azure VM is to use the portal. So to get started here, I'm in the "All resources" view, I'm just going to filter the list for my vault. I've got a recovery services vault called "Vault1", and it's in the "Canada Central" region. And I filter this again looking for a virtual machine called "AppServer1", it's also in the "Canada Central" region. So I want to enable protection of "AppServer1" to my vault, "Vault1", [Video description begins] The host is at the Azure portal and uses the search bar to look up the relevant information. [Video description ends]

I want to set up backup. So I'm going to click on my server, my virtual machine. And what I'm going to do in the navigation bar on the left is scroll down under "Operations" and I'll choose "Backup". Now when we look at it from this perspective, we have the option of configuring backup from here. You can also do it from the vault, but I'm going to continue from this perspective, from the VM's perspective.

We can either create a new recovery services vault but there's no need, we already have one in this region called "Vault1". Within the vault, we can select the appropriate backup policy. I've got a custom backup policy I created previously called "ProdVMs". The backup policy determines things like retention periods for backup and restore points.

So I'm going to go ahead and set "ProdVMs" as the backup policy in this case. And we can see that when I do that, it starts showing me down below some of the details within that policy. So the "Retention range" for "daily backup points", "weekly", "monthly", "yearly". I'm okay with that, so I'm going to go ahead and click "Enable backup". [Video description begins] The host is now back to the "All resources" page of Microsoft Azure. [Video description ends]

After a moment, we can see on our notification area that it succeeded, the backup configuration. So let's take a look at this time from the perspective of the, well, let's start with the server. But then we're going to go into the "Vault1", and see what it looks like on that end of things. So back here in our virtual machine, [Video description begins] The host clicked the Appserver1 and is now redirected to its "Overview" page. [Video description ends] let's go back to where we enabled backup.

So I'm going to pull up the "Backup" blade. This is where we initially came to link it to our vault. So instead now, of course, we have a status screen. So we can see any "Alerts" or "Jobs", and we can see the "Last backup status". So it says, "Initial backup pending" because we just enabled them. We can also see the affiliation of this VM with the "Recovery services vault" and the "Backup policy" that's currently in use and any restore points that are available.

Notice we also have the option to perform an on demand "Backup now". So I'm going to go ahead and click on that. We can specify the retention period for this backup, I'll accept the default value, and I'll click "OK". I don't have to do that because we have it scheduled. But, however, we can perform on demand backups whenever we feel the need. So I can click the "View all Jobs" link to get to the jobs page, where we can see the configuration of backup for various servers, including "AppServer1". And we can see that currently a backup is in progress.

So what's happening is a snapshot of the VM is being taken and the backup is stemming from that. So therefore, production workloads are unaffected when it comes to performing these backups, to protect your data in your Azure VMs.


Azure VM Backup and the CLI
In this demo, I'm going to use the CLI to enable backup of an Azure VM. Before I do that here in the portal, let's go to the VM in question called "AppServer2". We can see its state is that it's currently "Running". So I'm going to click on "AppServer2". The reason is because first of all, I want to check to see that it's not already associated with the recovery services vault because it can only be associated with one vault at a time.

So I'm going to scroll down under "Operations". I'm going to click "Backup". And what we should see is it prompting us to associate it with the vault. And that's great. It's not associated with the vault, but we don't want to do it here in the portal. While we're in here though, I'm going to scroll up and choose "Properties", because what I want to take note of is the ID, the "Resource ID" here for the VM. So I'm just going to copy that. [Video description begins] The host scrolls down to reach the Resource ID and copy it. [Video description ends]

We could acquire that in many different ways, including from the CLI, it doesn't matter. But I'm going to want that information because I'm going to want to check that backup protection was enabled in the CLI. And I'm going to need the ID to do that. So let's go into the CLI. [Video description begins] The host opens up PowerShell. "PS /home/danlachance72> is already written on the screen. [Video description ends]

So to enable VM backup, I'm going to run the "az backup protection", after which I'll then specify I want to enable it for VM. So "enable- for- vm- -resource- group", it is "Rg1". That's where my virtual machine is deployed in my vault as well. "--vault-name". And I'm going to specify my vault which is called "Vaul1 -- VM" and it's called "AppServer2". And I also have to specify the backup policy I want to use. So "--policy-name", the policy is stored within the vault. I'll just use the default one which is called "DefaultPolicy" and I'll press Enter.

Well, if you don't spell the name of the vault correctly, you'll get an error. Let me just spell that correctly and press Enter once again. Okay, and we have our returned JSON output. So all looks good. Let's clear the screen. Now what I want to do is just check the status. And we can do that here with "az backup protection check -vm".

This is where I need the "VM ID", [Video description begins] The host clears the Powershell screen and pastes the vm ID that he copied previously. [Video description ends] you can see from the parameter of the same name. And I've pasted in the resource ID for the VM that we copied from the portal previously. Let's press Enter and see what it returns back. [Video description begins] A message appears in the Powershell that reads "Command group backup is in preview. It may be changed/removed in a future release". [Video description ends]

Okay, this is good. What it's really telling me is yes, that backup protection is enabled for that VM and it's associated with Vault1. We can do the same thing by going back into the GUI and taking a look. So why don't we do that just to make sure? [Video description begins] The host minimizes PowerShell, returns to the Overview blade of the AppServer2. [Video description ends] So I'm just going to flip over to a different blade here in "AppServer2"'s properties.

And let's go all the way back down, yet again, under "Operations", and click "Backup". Because remember last time, what we were seeing is it was prompting us to associate the VM with a vault. Well, now that's no longer the case because we associated it with a recovery services vault for backup purposes using the CLI.


Azure VM Backup and PowerShell
In this demonstration, I'm going to be using PowerShell to enable Azure VM Backup. Now, in order for that to happen, you need a recovery services vault. Let's just take a look for that here in the portal just for a second. So I'm going to go to "All resources", and well, actually, we can just filter it from here, that's just as well. So I'll just type in a couple of letters here to make it unique, there it is, "Vault1". I want to just double check, first of all, that there is a set of "Backup policies" in here.

There always are, there are a couple of default ones, including one called "DefaultPolicy". [Video description begins] The host is on the "Backup policies" tab of Vault1. [Video description ends] Okay, so we know we've got a vault called "Vault1". And we've got a couple of policies, specifically two of them that can be used for backing up Azure VMs. The policies themselves contain a lot of settings related to backup frequency and retention range, I want to keep the backups at the monthly and yearly level, for example.

[Video description begins] The host clicks on the Default policy. It displays the backup frequency and below it, it reads Daily at 1:30 AM UTC. It displays the retention range, the retention of daily backup point and the retain backup taken every day at 1:30 AM for 30 days. [Video description ends]

All right, let's go back and take a look at our VMs. I've got one in this list called "AppServer3", not yet associated with the vault but it will be when we're finished here in PowerShell. [Video description begins] The host opens up PowerShell. It reads PS /home/danlachance72. [Video description ends] So to get started, what I'm going to do is create a policy variable, so "$policy". What I'm going to store in there is the return result of running "Get-AzRecoveryServicesBackupProtectionPolicy", that's a long cmdlet name, that's what it is. And all I'm going to do is specify that the policy name I'm interested in is "DefaultPolicy".

Now, I don't have to put that in a variable, I can just specify it on the command line. So the first thing I'm going to do here in PowerShell, is I'm going to run "Get-AzRecoveryServicesVault". And I'm going to point to a vault named "Vault1". And I'm going to pipe that to the "Set-AzRecoveryServicesVaultContext" cmdlet. We need to set the context so we're essentially pointing to Vault1. [Video description begins] The PowerShell now displays four warning messages. [Video description ends]

Now, you might get some messages that this cmdlet will eventually be deprecated. You also have little note here that says if you want to suppress this message because it's not deprecated yet, then you can go to that web URL and figure out how to do that. I'm not going to suppress the messages, I don't mind it. The next thing I'm going to do is create a policy variable.

Now that we're pointing to the right vault in our context, I'm going to make variable called "$policy". It's going to store the result, retrieving the policy from the vault using the" Get-AzRecoveryServicesBackupProtectionPolicy cmdlet. [Video description begins] The host clears the PowerShell screen and pastes the $ policy again. [Video description ends] That's a mouthful, and I'm going to give it the name, the name of the policy that I want is called "DefaultPolicy".

So I'm going to go ahead and press enter to get that into the variable. Okay, now, that we've got that, we can actually enable protection or backup for an Azure VM using the "Enable-AzRecoveryServicesBackupProtection" cmdlet. I'm going to specify the resource group and the name of the virtual machine that I want to enable protection for. And then finally, "-Policy", I will pass it my "$policy" variable that we've set above.

Let's go ahead and press Enter and get this going. And before too long, we'll see that the operation is completed. So "ConfigureBackup Completed", so looks like it's been done. [Video description begins] The PowerShell screen reads: Workload name appserver3, operation configure backup, status completed, StartTime 4/3/2020 5:38:21 PM and EndTime 4/3/2020 5:38:52 PM. [Video description ends]

Let's just check our work here in the portal. So that was "AppServer3", so if I click on that, and [Video description begins] The host closes PowerShell and returns to the Azure portal. He clicks on Appserver3. [Video description ends] if I scroll down in the navigation bar, if we go down to "Backup", now, "Backup", of course is way, way down underneath the "Operations" section. So under "Operations", I'll click "Backup".

Normally it would be prompting us for associating the VM with a vault but it doesn't here, because it's already associated with the vault because we set it up in PowerShell. We can see here, "Vault1" is what it's associated with using a policy called "DefaultPolicy".

Azure VM Restore
Let's first check out what's there, what kind of backups are there. So it looks like we've got an "Application consistent" backup. And it looks like it was taken on a specific date and time, we can even click the "View All jobs link" and we would see here that a backup was taken and successfully completed. [Video description begins] The host closes the "View all jobs" link and goes back to "Backup". [Video description ends] Okay, that's perfect.

So now what we want to do is restore. Notice that we have a couple of options at the top, we can choose "Restore VM" and we can choose "File Recovery". As you might imagine, restoring the VM restores the entire virtual machine and you have a couple of options when you do that. And you'll see that if we click on it, we have the option of restoring to a new virtual machine or we can overwrite the existing one.

[Video description begins] The host is at the Restore tab which consists of two steps: 1. Restore point and 2. Restore configuration. [Video description ends] So I'm going to select my restore point and I'll click "OK". And this is where you'll see you can "Create new", or "Replace existing". So creating a new virtual machine means specifying a name for the VM and setting up the affiliation for the "Resource group", the "Virtual network" and the "Storage account". Whereas up the top if we chose "Replace existing", we get to determine that we want to replace the disks and we chose a storage account for a staging location to get the VM back to the point in time specified by the snapshot. So that restores the VM itself.

But what if the VM config is good, it's just some of the data within it that we need to restore? [Video description begins] The host closes the "Restore" tab and goes back to "Backup". [Video description ends] That's where file recovery kicks in. So let's click on file recovery, choose a restore point, and the next thing to do is to click "Download Executable". Because this is going to download a script that will let you mount the backup as a local drive where you run the script. And from there you can cherry pick which items you want to restore.

That's exactly what I'm going to do. So I'm going to download this executable. When I click that it generates a script and a password. So I'll see that down here after, which is unique to this mounting session. And after it generates it, the script will be available for download. So I'm going to go ahead and download it. [Video description begins] As soon as the host clicks on "Download", a cmd window pops up. It reads: "Please enter the password form the portal as is and press enter:". [Video description ends]

When I run the script, it asks me to enter the password that's provided in the portal and that was generated down here. So I'm going to go ahead and copy that to the clipboard. And, I'm going to paste it in here, where it's being asked for, and I'm going to press Enter. [Video description begins] A PowerShell window automatically launches. [Video description ends]

Now depending on your machine, you might have to download that script and run it with administrative privileges. But anyways, this is what it's going to look like, "Connection succeeded". It's going to attach the volumes for the recovery point. And then, we can see now here we have a new drive. [Video description begins] As the connection succeeds, a windows notification window pops-up to inform that there is a new drive. [Video description ends]

So let's go ahead and take a look at this in Windows Explorer. [Video description begins] The host is now in File Explorer, in drive F. Various folder directories can be seen. [Video description ends] So now here in the file system, I can see I now have a drive letter F, which is showing me the contents of what was backed up from that VM. So I could cherry pick the items I want to restore by copying and pasting. Back here in PowerShell where the script ran, we can see drive letter E was a system reserved disk and F, the windows partition of our backup VM.

Then says, open up Windows Explorer, browse for your files, copy them, and then go to the portal and go to step three where you need to unmount disks. So back here in the portal that's just down below here, step three, "Unmount the disks after recovery". So I'm going to go ahead and click that. And then we'll get a message after a moment that says that the unmount was successful. So we're done. We were able to restore or recover files from a backup Azure VM.


File Server Backup
You can enable protection for on-premises file servers, whether they're physical or virtual, so that you can back them up to the cloud. The only real requirement is having a recovery services vault and then installing a backup agent on the server that you want to protect. So to get started here, let's go into a vault that we've got defined previously, a recovery services vault here in the portal. And in the left hand navigator, I'm going to go into the "Getting started" section and I'm going to click "Backup".

Now it says, "Where is your workload running?" Well, in this case, it's going to be "On-premises". Then it asks, "What do you want to back up?" Well, we can see there's quite an array of options here. "Files and folders", "VMware", and "Hyper-V virtual machines" that we might be hosting on-premises, SQL servers, SharePoint Exchange, "System State", "Bare Metal Recovery". The list goes on and on.

In this example, we're going to select "Files and folders" that will go under the next step to "Prepare infrastructure". I'll click on that button. So it says you need to download the agent for Windows Server or for the Windows Client. Okay, so I can click that link to download and then install the agent. So I'm going to go ahead and click that link because I want it installed on this local host where I'm running this from and I'm going to click "Run".

[Video description begins] After clicking on "Download Agent for Windows Server or Windows Client", a small window pops up at the bottom of the screen. The host clicks on Run. [Video description ends] And I'll proceed through the installation wizard. I'll accept the default "Installation folder" and "Cache location". I'll click "Next". No proxy settings required to get to the Internet. Then I'll click "Install".

Alright, now that the installation is complete, the next phase of the configuration, if you will, is to proceed to registration. [Video description begins] The host clicks on the option "Proceed to registration". A new window opens up called Register Server Wizard. [Video description ends] We need to register this server with the recovery services vault.

For that, we need vault credentials. Well, back here in the background in step two after we've downloaded the" Recovery Services Agent", we can turn a check mark on to that effect after which we can download the vault credentials file, [Video description begins] The host enables the option that says "Already downloaded or using the latest recovery services agent" and the "Download" button is activated. [Video description ends] which we need to complete the registration. And that file is good for two days.

So I'm going to go ahead and download it. [Video description begins] The host clicks on the "Download" button and the Register Server Wizard window opens up again. [Video description ends] Back here during the installation, I'm going to go ahead and click on the "Browse" button to select the vault credentials file that I've just downloaded. [Video description begins] The host clicks on the Browse button, the field "Vault credentials" is filled in automatically and more details about the vault appear. [Video description ends]

So it knows the name of the "Backup Vault", the "Region", the "Subscription identifier", and of course it expires after two days as you know. So now that we've got that in there, let's go to next, we can either enter a "passphrase" or generate one. [Video description begins] The host is now at the next step, called Encryption Setting. [Video description ends] This is for protection of the backed up data.

So I'm going to go ahead and choose "Generate Passphrase" and we can then specify a location to save it. And after you specify that, you can proceed with the "Server registration". [Video description begins] The host is now at the last step. There is a message that reads "Microsoft Azure Backup is now available for this server", along with a warning message. [Video description ends] Alright, and the server has been registered, we just have a warning about storing that generated passphrase locally.
So I'm going to go ahead and "Launch the Microsoft Azure Recovery Services Agent" that's checked on by default. So I'm going to go ahead and click "Close". Okay, so it took us into "Microsoft Azure Backup", where over on the right I'm going to choose "Schedule Backup". And I'm going to go through the "Wizard", I'll click "Next" and I'm going to click "Add Items". And I'm going to select some files on a disk on this local host that I want to back up to Azure.
We have the configuration, now we have the back up actually taking place based on that configuration. [Video description begins] The host clicked on next and the wizard is now transferring the relevant data. [Video description ends] And after a moment, we can see that the job has completed. So I'm going to go ahead and click "Close".
Now back here in the portal, if we go back into our vault and if we look at "Backup items", then notice we have a reference here for "Azure backup agent". We have one listing here. [Video description begins] The host clicks on the listing and is redirected to a new page. [Video description ends] It's for drive D on a computer. Here's the computer name. And we can also see the last backup date and time.


Azure VM Soft Delete
In Azure, the soft delete option as it relates to Azure virtual machines is designed so that if you've enabled backup of Azure VMs, it will protect deleted backup data. So in other words, if you delete a VM and you haven't enabled backup for it already, then soft delete does nothing for you. So notice in this list, we do not see a server by the name of "AppServer1", [Video description begins] The host is at the Virtual Machines tab of the Azure portal. [Video description ends] It starts at "AppServer2" and goes on from there.
Well, if we go into an existing vault, then we're going to see references. [Video description begins] The host clicks on Appserver1 of the Azure portal. [Video description ends] When we go to "Backup items", choose "Azure Virtual Machines", I see a reference to "AppServer1". [Video description begins] Under Protected items, there is the Backup items option and the Replicated items option. The host clicks on Backup items. On the list, the host clicks on Azure Virtual machine option and he is now on a list with server names. [Video description ends]
So that was a virtual machine that at one point did exist, but the virtual machine has been deleted. Luckily for us, a backup was taken prior to it having been deleted. And so what I can do then is select "AppServer1" and I can choose to restore the VM or recover files from it. So for example, let's choose "Restore VM", so from here, I can choose a restore point, "OK".
Well, because in this particular scenario, the VM no longer exists, we would choose to "Create new". Now, that's for the VM, on the data side, if we were to choose "File recovery", [Video description begins] The host closes the window of Restore Configuration and returns to Appserver1. [Video description ends] then we would download the executable script which I'll click on. It's going to generate a password, so that we could mount the backup and still recover files from that backed up VM, even though the VM itself no longer exists.
And we can see it's made a connection and it's provided drive letters E and F to us. So those will show up on my local computer in Windows Explorer. And I can browse through the backup files and copy what I need. And once I'm finished, I can return to the portal and go into step 3. [Video description begins] The hosts minimizes the blue window and goes back to File Recovery on the Microsoft Azure portal. [Video description ends] Which I will do here, so if I scroll down, I can click "Unmount Disks".
And there you have it, that's how we can get data back if it's been backed up already from a VM that no longer even exists.

                    
Azure File Shares and Storage Overview
An Azure storage account can house multiple types of storage, including blobs or binary large objects. In other words, allowing files to be uploaded into the storage account. There are block blobs. Now block blobs are normally what we would use if we are uploading smaller files that might result from office productivity tools. 
Such as word processing apps, or presentation apps, or spreadsheet apps, that type of thing or maybe graphic logo files that would be considered block blobs. Append blobs, as the name implies, are a file that would normally by its nature need to be added to constantly. Think of log files, where they're constantly being written to at the end of the file. Then there are Page blobs. Now these are for larger files to support random access. Now what that means is they're not necessarily read or written to in a sequential format. Think of virtual machine hard disks, they would be uploaded and treated as page blobs in an Azure storage account.
Then the storage account can also house Azure files, which are essentially shared folders in the cloud. The idea is we can allow shared folder access for our cloud based Azure file share, from on premises devices or from devices in the cloud like virtual machines. So the operating system would need to support connecting to shared folders using SMB v3.0.
So it's kind of like what you might use even in UNIX and Linux or the macOS, when you mount a remote mount point to appear locally in your file system. Normally, that's done for NFS type of connections over the network using the NFS protocol, but in this case it would be for SMB compliant shares. The storage account also allows for what's called Azure Table Storage.
This is No-SQL based. What does that mean? Well standard SQL compliant solutions where SQL stands for Structured Query Language would include things like Microsoft SQL Server, Oracle Database Server, MySQL, all kinds of different variations where you have a strict definition of blueprint of what's allowed to be stored. So you'd have table definitions, and in each of those tables you would have columns or field definitions with data types.
And you can link tables together. Well, No-SQL doesn't do any of that. It's an unstructured schema, where the storage of one record can be completely different than the underlying blueprint for storing the next record. So it could be many different types of data. And it uses key and value pairs for storage, much like you might have experience with if you've worked a lot with Azure resource tagging, and key and value pairs.
A storage account can also accommodate storage queues. So we would have queue storage in the Azure cloud. And that's done within a storage account. And software developers can write code for app components, such as in our example app component 1, could write a message into a storage queue in Azure. And then app component 2, if it's busy or unavailable over the network.
When it does become available, it can read messages that it's supposed to read from app component 1. And this way, we have data exchange between different software components.


File Shares and the Portal
In this demonstration, I'm going to configure Azure file share. Azure file share is essentially an SMB compliant shared folder hosted in the cloud environment.  
You don't need your own server to set up a shared folder. So to get started here in the portal, I've navigated to an existing storage account.
And within that storage account, I'm going to scroll down in the navigation bar until I see File service, and I'll click File shares.
Now I don't have any file shares defined yet, but that's going to change in a moment.
So I'm going to click add a File share up at the top. And I want this to be called projects.
And I'll set a maximum Quota for storage, let's say to 5 GiB.
And then I'll click Create.
So we can now see we've got the project's file share here.
Now much like a blob container, you can go into it and start uploading content.
So uploading files, you can add a subdirectory if you really want to, but I'm not going to do that.
I'm just going to click Upload, and I'm going to upload a file or two.
So I specified a couple of file names here.
I'll just upload them and because they're small text files, it won't take long for them to show up.
So we can now see we've got Project_A, B, and C.
They're text files, and they're in the projects share. Now at this point, we need to talk about connectivity. So it's one thing to create the file share.  
But what about making a connection? Well, the connection is available. For example, if we click the Connect button at the top, it gives us instructions depending on the platform in question.
Whether we're mapping a drive letter in Windows, or whether we're making a connection as a Mount point from Linux or the macOS.


File Shares and the CLI
You can use the Azure CLI to configure an Azure file share, so essentially a shared folder in the cloud.
In order to do that, you have to think about the storage account where you want to define that Azure file share.
And you also have to think about an access key that you will use to get permission to create it from the CLI.
So we can see the name of our storage account in this example is storacct333325.
And down below, I can see of course, as is the case with every storage account there are two access keys.
So I'm just going to go ahead and copy the second access key. And I'm going to span a cloud shell environment.
Now, here in the CLI I'm going to run az storage.
So presumably file share are part of the storage nomenclature and -h for help.
After which I can then learn and start guessing at what would be next such as share for managing file shares.
That sounds about right. So if I do an az storage share.
And then specify -h for help, we'll learn more about how to use that syntax such as creating an Azure file share.
Let's get to it, az storage share, create --account-name.
So this is the name of the storage account, and then that in our case is storacct333325 --account-key. Well, this is where I'm going to paste in the key that I copied previously when we were in the portal a moment ago. --name, what I want to call this is budgets. So I'm going to put in budgets as the name of the share. I can also set the quota, --quota in GiB, so maybe I'll just put there 5. And that's pretty much it, I'm going to press Enter to create that azure file share.
And it says "created": true. Now, notice if I try to run other CLI commands like az storage share list it says well, not quite, you need to give us some credentials, such as with account name and account key.
No problem, so we can make that happen. az storage share list, not really should have stored those variables, but that's okay, --account-name. We know what storacct33325 and the --account-key parameter. And I can just see that up there, so why don't I just copy that again, just to make sure I still have it on the clipboard, and we'll Paste it in here, and we'll press Enter.
And now we're seeing everything that's listed but as usual, it's providing all of the metadata. I just want to see the names, okay? Let's clear the screen. Now, because we're in PowerShell, we can get away with either clear, the word clear or cls, it doesn't make a difference.
Up arrow key to bring up that previous command at the end I'm going to add --query, [ ] Because we've got an array of items being returned, multiple shares. And I want to call upon the .name property for each of them to only see the names. And there's the one that we've just created, budgets.
Let's take a look at it from the perspective of the GUI.
So here in my storage account in the portal, I'm going to scroll down in the navigation bar, until I see File service and File shares.
Just give it a moment to update, and there's budgets.


File Shares and PowerShell
In this demonstration, I'll use PowerShell to create an Azure file share.
Remember that a file share is a shared folder hosted in the Azure cloud through a storage account. So that means that we're going to need command line access then to the storage account. And one way to get that access is to use a storage account key.
So I'm going to go ahead and run the Get-AzStorageAccountKey cmdlet. I'm going to specify the resource group and name of an existing storage account. Whose keys I want to return.
Now returns both keys. Every storage account has two keys, you can change one for security purposes while the other one remains intact. Now if I want to get a specific one of these keys, I'll just use the up arrow key to bring the previous command back up. To get a specific key I can ask for example, the first one I'm going to make a variable here called $key equals Get a then contain the rest of the command as per I entered it previously.
But I'm going to change it a little bit, because what I want to do is place that entire command in parentheses. The reason is because I want to treat it as a single statement, after which I then want to call upon the. and then a property or call upon a property specifically in this case, the value property and I want value[0]. So I want the first item.
That's the first key, in other words when I press Enter, and if we return the key variable, you can see indeed that value zero really is the first item in the array.
It's the first item in the value property array.
So we've now got that stored in a variable. Great, next thing I want to do is make a context variable so that we can essentially lump together the name of the storage account and also the key and just refer to the context variable. So I'm going clear the screen cls and make a $ctx that's just for context and that's going to equal New-AzStorageContext and I'm going to give it the storage account name -storage account name which in this case is storeacct33325, that's the name of my storage account. And I also want to specify the -storageaccountkey. Well, we have a variable now so that's too easy. We just refer to $key for that. Alright, we now have a context variable.
Now what I want to do is actually create my file share. So now essentially we have pointers to the storage account. We have a storage account key to be able to do this. So we're good, so I'm going to run New-AzStorageShare. And the name I'm going to assign to this in this case, let's say is East-Logs. And then I'm going to specify my context variable. -context is going to be $ctx, then notice it returns an error.
Well, if I change the name here to reflect lowercase letters, and press Enter, it works.
So you'll find that a lot of items related to storage accounts are case sensitive. In other words, uppercase letters are not accepted. Anyway, it looks like it worked. Let's verify this we can run get-azstorageshare. Now notice it says don't have a storage context.
Well, that's the same thing that we did up here. When we built the share.
We use -context and gave it the variable, no problem. Let's bring the up arrow key up there to bring that previous command up on the screen -context $ctx.
And there it is, now we can see the existence of our new share east-logs.
And of course, we'll see the same thing if we go into the portal.
So if I Refresh my list of file shares for that storage account, there's east-logs.


File Share Mapping and Windows
In this demonstration I'm going to map a drive letter from an Azure Windows virtual machine to an Azure file share.
So here in the portal, let's start by looking at a storage account where the file share's been defined. So I'll scroll down in the navigation bar for the account. Go down under File service and choose File shares where we'll see we've got a projects file share.
And so if I open that up, it's got some files in it.
See Project_A, B, and C, they're text files.
So this is just essentially like a shared folder on a file server that you might have on-premises. Where you've got some content within it. But the connection to it is a little bit different. So I'm going to go ahead and click the Connect button at the top.
Where we can see syntax for making a connection to it by mapping a drive letter in Windows.
In this case, I want to map drive letter P, P for projects. So I'm going to go ahead and choose that from the drop-down list.
We can see it's got some PowerShell code here.  
That's going to be used to test the connection with the Test-NetConnection cmdlet and also actually mapping the drive. So in other words, it's going to actually make the connection by adding the storage account reference here for our shared folder. So I've pasted that.
I've copied and pasted that so we can see it in a bit more detail here in WordPad. So a variable $connectTestResult is going to be the result of running Test-NetConnection against a computer name.
Which is really just the URL of our specific account, and it's trying to connect to Port 445.
So if you were trying, for example, to map a drive letter from a Windows machine on-premises into the Azure cloud. You need to make sure that Port 445 is allowed in an outbound direction. And the fact is, most Internet service providers will not allow that traffic out. So if you don't have access to control outbound ports because maybe you only have a residential Internet connection, then that might be a problem.
Next thing we're doing is we've got an if statement here and we're testing the result. So if the TcpTestSucceeded so we could talk to our storage account and make a connection to Port 445. Then it's going to start saving some information here.
So it's going to store the user storage account name and the generated password here.
That is an actual storage account access key.
And then in PowerShell, the New-PSDrive cmdlet is being used. In this case to map drive letter P, we selected P for projects.
And we can see it's making a reference to the projects folder within the storage account.
And it's setting it as a persistent drive mapping so that drive P will be there every time that we sign in.
So, I'm going to go ahead and copy this again and I'm going to use it within a PowerShell command prompt environment.
Within an Azure virtual machine where I know Port 445 to the storage account is going to work.
So I've opened up here my virtual machine, my Windows virtual machine in Azure and I've copied the public IP address. And I've opened a connection to it using remote desktop client from my on-premises system.
So I'm going to continue going into that machine over RDP so we can map the drive letter to Azure file share.
Now within my remote session to my Azure Windows virtual machine, I'm going to go into the Start menu because I want to start the PowerShell ISE.
The Windows PowerShell ISE where I'm going to paste in that code that we went through that will map the drive letter here from this machine.
So I'm just going to click the new piece of paper icon here for a new script, so to speak, and I'll paste in all of that code.
And I'll just press Ctrl+ sign here so we can kind of zoom in.
So this is exactly what we were looking at to map drive letter P.
So I copied that for our specific configuration.
So I'm just going to go ahead and run all of this.
We can see it's down there. It's attempting the TCP connection. So remember, Port 445 needs to be open between this host and the target for this to work.
And it looks like drive P is probably mapped.
There are a number of ways we could do that here in PowerShell.
Let's navigate to drive P so P:\> dir, there are the project files.  
Of course most people that would use this would access that drive mapping from within Windows Explorer. Or through apps of some kind.
So if we go to This PC, we'll see that drive letter P showing up here.
So projects, and showing up there along with the contents of that.
So there are the files in that location.
