                    AZ900 Microsoft Azure Cloud Fundamentals 2021
                    Additional Material Course Notes Part 2


Storage Accounts and the Portal (Cont)
  - In which case, we might then start thinking about using a Content Delivery Network or a CDN
    - For the Performance option, it's set by default to Standard
    - Then down below, we have Account kind, storage v2 or storage v1
    - That's an older version of a storage account and you'll only use that if you absolutely had to, for backwards compatibility reasons
    - You could also specify that it's to be used for BlobStorage, specifically binary large objects
    - These are essentially files that would be stored in this cloud storage account, kind of as a cloud-based repository
  - Then down below, we've got Replication options. So Locally-redundant storage (LRS), means that you would have three copies of your data but not spread out across geographical regions within one locality. Geo-redundant storage (GRS), takes that a step further, so beyond your three LRS, local copies of data, you would get an additional copy replicated to a secondary region. So, if there's a problem the primary region, failover can be initiated so that the data is accessible in the secondary. If you don't have to worry about initiating a failover, you could use Read-access geo-redundant storage. However, if I were to switch up at the top here, the performance from Standard to Premium, notice that from the account kind drop-down list, things changed a bit. So we have BlockBlobStorage.
  - If we're going to be dealing with Blob storage items of files and we want to optimize it for the best possible performance for read and write, we could choose BlockBlobStorage. If we're going to instead going to be using this cloud storage account primarily to host shared folders, so Azure file shares, then we could choose to optimize it for FileStorage. I'm going to leave it on StorageV2.
Now, since we switched it from Standard to Premium, you'll also notice that down to Replication, the options are gone. Where they go? They don't apply when you've got the Premium performance selection, only Standard.
So all we have is Locally-redundant storage. Having done that, I'm going to click next for the networking options. 
The networking options for the storage account determines how accessible it is from a variety of different types of networks such as public based networks, so all networks with selected networks, or only privately. I'm just going to turn on Private endpoint and click next. Then I've got a number of options such as whether secure transfer is required to and from the storage account.
That's Enabled by default. Whether I want soft delete for blobs, so they can be recovered. That's Disabled by default, but it could enable it. And these options are changeable after the fact, as well. So I'm just going to accept those and click next for tags.
If this is going to be tied to a project, let's say Project ABC, then maybe I'll tag it with a Name of Project and a Value of ABC. You don't have to do this.
You can add multiple tags, you might tag it for billing purposes, or by department, it doesn't matter. But in this case, Project ABC, I'll click next to review and create the storage account. So the validation is passed based on my selections throughout the wizard. This is good.
I'm going to go ahead and click Create to create the storage account in resource group 1. After a moment, it says our deployment is complete, so we can click Go to resource.
We can also navigate, for example, in our left-hand navigation bar to view our Azure storage accounts from there. Of course, we could also go to the all resources view and see them. And there's our storage account.
Now, if I click on it to open it up, we'll see it opens up the navigation bar, and by default, I'm placed in the Overview blade. So I can see the Location of this storage account, I can see the subscription it's tied to.
There's the tag I added, Project : ABC. And as I scroll down in the navigation bar, I can see I have Settings such as Encryption settings for the specific storage account.
It's defaulted to using Microsoft Managed Keys to encrypt content stored here. I could click on Configuration, for example, if I started to maybe decide I want to change something such as Secure transfer required, and so on.
As I scroll down, I also see a section for blobs. So Blob service, including Azure Content Delivery Network, CDN. And finally, then I see my Monitoring options and so on.
Now, depending on the type of account that you create, how you create it, the choices you make when you're creating them, will determine some of the items that you see here under the navigation bar. So for example, notice all I see here is Blob service. Well, what about Azure files, tables, and queues? Well, let's create another account to examine that further. So I'm just going to click on Home here, I'll click Create a resource, we're going to create another storage account. So let's create a second storage account here.
And this time we're going to make a few different selections, so I'm going to go ahead and create it. It's also going to be deployed in this example, in the same resource group, so, our first one is Rg1, so I'll select that from the drop-down list.
Now down below, I'm going to give this a name. Again, it's got to be unique. So I'll put in some characters to make that a unique name, Canada Central. Now, we could, instead of using Premium like we did last time, leave it on Standard.
Now, it's on StorageV2 (general purpose v2), Locally-redundant with Hot access tier. I'm going to leave that, I'm going to click next. Again, I don't want it publicly visible so I'll change it to Private endpoint, although I'm not going to configure one. And I'm not going to change any of these advanced options.
And for tagging, let's say I don't tag this one. We could always tag it after the fact if we wanted to. Validation is passed, let's go ahead and create this second storage account.
  - Once again, before you know it, Your deployment is complete is the message you'll see
    - This time click Go to resource, so we're in our storage account once again, and we're looking at the navigation bar on the left as we did with our first one
    - But as we scroll down, we see not only Blob service listed over here on the left as we did before
    - But look, as we scroll further down, File service for Azure File shares, Table service, Queue service
  - Depending on how you create your storage account, depending on your selections
    - Will determine exactly what you see when you go into the properties of that storage account after the fact


Storage Accounts and the CLI
  - You can use the Azure CLI to create as well as to manage storage accounts and even to manipulate objects in the storage accounts such as uploading and downloading blobs. But to do that we have to know the syntax.
  - And we can figure that out here in the CLI, which I've launched from the portal Cloud Shell by starting with az -h for help. Now by looking through the alphabetical listing of next level commands, I could gather that storage would be the next level command I would be interested in. So therefore I could do az storage -h.
And then depending on what it is I need to manage would be determined by me looking at this list and finding the most likely item for example, I want to create a storage account.
So the next level item would be account. Okay, so having done that, I'm going to run az storage account -h. If I want to create a storage account, create would be the next level command. So I could just go ahead and ask for help on that as well.
And when I do that I get quite a bit of information.
And one of the things I would probably want to know is, for example, specifying the --sku for the storage account, whether it's going to be standard locally-redundant storage, or read-ahead geo-redundant storage RAGRS. We have to know what these values are when we pass the --sku parameter on the command line. So let's get to it.
I am going to run az storage account create -n, so I can specify the name of the storage account. And I'm going to make sure that I adhere to naming standards within the organization. So I'm going to go ahead and specify a name. And I'm going to specify the resource group I want to deploy the storage account into with -g. In this case, I already have a resource group called Rg1 -l for the location. Here I want to deploy this in canadaeast --sku we looked at that a moment ago. So I'm going to specify in this case locally-redundant storage and I'm going to go ahead and press Enter to create this storage account. And so after a moment, we get the JSON output, which indicates that it was successfully created. So we can go ahead and check our work here.
Of course, in the portal since we're in the Cloud Shell. Let me just scroll back up here. So the account here is storacct445888221. And, if we take a look at our Storage accounts here in the portal, we'll see that that will have been created.
So there it is, storract445888221. Let's go back though, into the CLI where I'm going to start by just perhaps clearing the screen with cls. Now the next thing I can do here is also view a list of storage accounts from the CLI with az storage account list.
But this gives me all of the properties which may be important but if all I'm interested in seeing for example is the name. Then I could bring up that previous command and use --query, open and close square brackets since we have an array of items and ask for .name. Now I'm seeing only the names of the storage accounts and certainly we can see the one that we've just created.
We can also show details about a specific storage account using az storage account show storage account, show. And then I can specify --name, and I can specify the name of the storage account. I'm just going to go ahead and copy the one that we just created, copy the name, and paste it in here for the name parameter, and of course, the resource group. Now, I could just specify, instead of specifying everything, I could use shorter parameters, -n for name and -g for the resource group, Rg1. And I'll press Enter, and so it returns information about that storage account.
And there's a lot of configuration settings as you can see, that might be enabled. Just as in if we were in the portal, if we click to open up that storage account in the properties blade for all of the configuration. As you can see, there's quite a few options. And so that is the kind of thing that we can do with the CLI. We can create storage accounts and we can start to manage them.
Don't forget that if you go back into the CLI you can always get help with storage accounts by running az storage account -h. We really focus primarily on the creation and listing and showing, which can also, delete them, you can also generate a shared access signature or an SAS so there is a lot of things that we can do.


Storage Accounts and PowerShell
  - PowerShell cmdlets can be used to create and also to manage Azure storage accounts.
  - But the first order of business is to determine the names of some of those cmdlets. And we can figure that out by using get-command. I'll use an asterisk wildcard symbol. And I'm going to guess that maybe azstorageaccount is part of the nomenclature. Of course, I can always look it up online.
  - Sure enough, we see a number of cmadlets that make sense for what our needs are, so such as Get-AzStorageAccount, Get-AzStorageAccountKey, New-AzStorageAccount, and so on. So we're going to build a new Azure storage account new-azstorageaccount.
First thing I need to do is specify the resource group into which I want this deployed so Rg1, then the name for the storage account so -name. I'm going to call this something that's in line with my organizational naming standards for storage account. So I'll go ahead and put something in here. I also want to deploy this in a specific location, in this case, canadaeast. And I'm going to specify a skuname in "standard_lrs", locally-redundant storage. Now you might wonder, how would you know to use that? Well, if you use get dash help for the new dash AZ storage account cmdlet, you'll see all of these types of details including all the parameters that we're specifying here on the command line. So let me go ahead and press Enter to create that storage account. And we can see that the provisioning succeeded. So I'm going to clear the screen.
We can also run get-azstorageaccount. So we can see what we've got listed here. And we can see even the newly created one, storacct64845.
That's what we've just created in the canadaeast region with this SkuName of Standard_LRS for locally-redundant storage. So that worked fine.
Now the next thing that we can also do is get details about a particular storage account. So for example, get-azstorageaccount. Well, let's actually do this. Why don't we get the storage account keys? get-azstorageaccountkey, now it's key singular, not keys plural. And storage account keys of which there are two with every storage account by default are used for programmatic access to the storage account contents including API access. So I'm going to specify the resource group that we want to look into to find the account. So our -resourcegroupname, in this case, is Rg1. And the account name, -accountname, we know in this case is storacct, store account, and we had called it 64845. I'm going to go ahead and press Enter. We can see the both of the keys have been returned here. Now we can also retrieve specific information about a storage account.
Let's see, get-azstorageaccount, now, we can filter it out and ask for certain properties, get-azstorageaccount. And we're going to specify here that we want the one that's in the -resourcegroup called Rg1 and at the -accountname, storacct and it was 64845. Okay, so I'll put that in. Now the problem, if you consider it a problem, is that it returns a lot of information. So we can see all of the properties going across the screen.
All I want is, let's say, the AccessTier. If I'm not sure what that property is called because this is a column header, AccessTier, it doesn't necessarily mean that's what the property is called. But we can verify this by doing the following. Let's use the up arrow key to bring up that command. I'm going to pipe it to get-member. And I'm going to tell it I only want to see property so -type property, and let's see what we have. So as we scroll back up through the output, we can see indeed there is a property by the name of AccessTier.
Okay, well, that's interesting. Let's go back up to a couple of previous commands and pipe the result of retrieving that storage account. To select, install all I want to see is the accesstier. Perfect, so we can see the Hot AccessTier has been configured for this particular item.
Now what I want to do is I want to set that to be cool. I want to use the cool AccessTier for less frequently accessed data which results in less cost. So for that, I will use the Set-AzStorageAccount cmdlet. I'll specify the resource group, in this case Rg1, where that account was deployed. And I'll use -AccountName, specify the name of our storage account. And I'm going to use -AccessTier and specify a value of Cool.
Now it's asking me, are you sure you want to do this? Well, let's just Ctrl+C out of that because what we can also do if I bring up that command is add -force at the end of it. This way we are prompted with anything and this really lends itself nicely if you want to automate this perhaps in a PowerShell script.
So it looks like it succeeded. Now we can verify our work. Let's just use the up arrow key here to go back up a little bit. And we want to select the AccessTier. And we can now see that the AccessTier indeed has been set to the Cool AccessTier.
Now the last thing that we're going to do is remove that storage account. So for that, I'll call upon the remove-azstorageaccount cmdlet. I'll specify the -accountname and then the -resourcegroup it's been deployed into. And I'm going to add -force at the end so it doesn't ask me for anything. And after a moment, it will have been removed.


Storage Account Network Access
  - When you create a storage account, you can determine network access options.
  - In other words whether the storage account should be accessible with a public endpoint, or from all VNets in Azure, or certain select VNets, you can also change that after the fact. So here in Azure, I'm going to go to my list of Storage accounts. Now if I don't see it in my recently visited links at the top here in the portal, I can always click in the left hand navigator and go all the way down to Storage accounts.
  - Either way, I'm going to open up an existing storage account. Now when I do that, I'm interested in taking a look at firewalls and virtual networks. You're going to see that down under Settings, there is Firewalls and virtual networks.
So think about how this storage account will be used, and which other components might require access to it. Such as a front-end web application, just as an example. Currently, we can see that we are allowing access from all networks, which does include the Internet. Now of course, if we don't have containers like blob containers with anonymous access enabled, it doesn't automatically mean anyone can get into the storage account. They would have to authenticate with either Azure AD, that would need maybe a shared access signature instead, or a storage account key. But nonetheless, we should limit the visibility as an added layer of security where possible. So I'm going to choose Selected networks.
And what I want to do is specify only certain VNets from which requests to access the storage account can be made. Down below, there are no virtual networks currently selected, so I'm going to click Add existing virtual network. Notice you can also build a new one at this point in time, but I already have one. So I'm going to choose the Add existing virtual network link. Of course, I'm going to choose that from the list.
So I've got my Subscription, I've got my Virtual networks. And so I'll select Vnet1, and I can choose a subnet within it, let's say Subnet1.
And I'm going to click Add, and now we can see that that has been added up above in terms of being on a network that is allowed to access this particular storage account.
Now I can also add an IP range to allow access from the Internet. So maybe beside software components in Vnet1, Subnet1 being allowed to access through storage account, I need to be able to access it from my on-premises computer. And I can see it already knows my public IP address. I'm going to go ahead and turn on that check mark to add that. Of course, I could also specify an alternate IP address or CIDR range as well.
And finally, down below, we can see it's set to allow trusted Microsoft services to access the storage account. So any other Azure resources that should be able to access this will be able to. And then we've got some logging in metric options that we could also enable here for exceptions. So I'm going to go ahead and Save this configuration. And in so doing we're limiting the visibility and the access of this storage account to the specifically listed Vnet, Subnet, and IP address.


Uploading Blobs Using the Portal
  - In this demonstration, I'm going to use the portal to upload some content into an Azure storage account.
  - To get started, I'm in the portal, I'm in the Storage accounts view. So I'm going to click on an existing storage account. I'm interested in uploading some blob files, binary large objects.
  - So I'm going to scroll down in the navigation bar until I see Blob service and I'm going to choose Containers.
So a blob service container is just a folder, the same way you would organize files on a USB drive, for example, by organizing them in folders. Well, I do the same thing here with containers. So I'm going to click + Container, and I'm going to start by creating a container called budgets.
The default Public access level is Private, so no anonymous access. But depending on what you might be dumping into this container might require that you enable something different, like anonymous read access for individual blobs or anonymous read access for containers and blobs within them. You might do that if you've got some public product brochures or documentation that, for example should be made available to anybody on a static host of web site. But in this case, I'm going to leave it on Private (no anonymous access) and I'm going to click Create.
So we can now see that we have a budgets folder.
Now I can select that folder and click Change access level at any point in time, but I'm not going to do that, said, I'm going to click to open it up to go into it.
So I'm going to go ahead and click the Upload button to upload some content into this blob container. And over on the right, I need to select one or more files, which I will do.
So I can specify whether I want to overwrite the files if they're already there. And if I open up Advanced, I can determine if I want to authenticate using the storage Account key versus Azure AD. And I can determine the Blob type, the default here is set to a Block blob.
When you're uploading things like Excel spreadsheet files, Block blob would be appropriate. But if you're going to be dealing with storing things like virtual hard disk files, page blobs are better. Append blobs are useful if you've got files such as logs that keep getting added to.
So I'm going to leave it on Block blob, and I'm going to go ahead down below and specify in this case that I wanted to use the Cool Access tier, because it's not going to be accessed frequently.

[Video description begins] The blade also includes a drop-down list box labeled "Access tier" in which an option labeled "Hot (Inferred)" is selected by default. He selects an option labeled "Cool" in the Access tier drop-down list box. [Video description ends]

And I'm going to go ahead and click on the Upload button. So we can now see that our content has been uploaded into this container.

[Video description begins] The Upload blob blade closes and the budgets blade displays in which two rows add in the budgets table. The first row entries under the Name, Access tier, and Blob type column headers are HR_EmployeeList.xlsx, Hot (Inferred), and Block blob respectively. The second row entries under the Name, Access tier, and Blob type column headers are Regional_Spending_2016.csv, Hot (Inferred), and Block blob respectively. [Video description ends]

Now I can also select a specific blob here and then I have options at the top, such as changing tier, so I can go ahead and do that. And from the drop-down list I can determine if I want it to be in the Hot, Cool, or Archive tier, but I also can acquire a lease.

[Video description begins] He selects a checkbox adjacent to the Regional_Spending_2016.csv row entry. Then he clicks a button labeled "Change tier" and its corresponding blade opens. It contains a drop-down list box labeled "Access tier" and two buttons labeled "Save" and "Cancel". In the Access tier drop-down list box, the Hot (Inferred) option is selected by default. [Video description ends]

When you acquire a lease on a blob, what you're doing is locking it. It's kind of like a resource lock on an entire Azure resource, the difference here being it's a blob within a resource, within a storage account. I can also click right on the Name of that uploaded blob and get some details about it.
So I can see the Properties, the URL to it, I can see the modification and creation date and timestamp. I can see the size of it, I have the option of downloading it, I can Delete it, and so on.
Actually, let's go back in there for one second, because there's something else that's important. When you go into an individual blob, you can also specify a shared access signature just for that specific blob. So notice here we have Generate SAS.
A shared access signature allows you to set an expiration on certain permissions that should apply and in this case, it's for a specific blob.
Whereas, if I were to back out of my budgets container and go back to the Storage account level, I can also specify that I want to create a shared access signature at that level. So you can do it at the Storage account level, as well as at the individual blob level.
Shared access signatures of course provide limited access to items within the storage account.


Uploading Blobs Using the CLI
You can use the Azure CLI to not only create and manage storage accounts, but also to work with the contents within storage accounts, such as uploading blobs, which is going to be the focus of what we're going to do here. 
So in the Azure portal, I've launched a Cloud Shell, specifically it's Bash shell. And we're going to learn how to make a reference to a storage account here in the CLI and upload a file. First thing we need to do is get a file here that we want to upload. Now if I haven't already, I have the ability of clicking this Upload/Download files button. So I'm going to choose Upload to get a file here in my Cloud Shell environment.
So I've just done this. So I'm going to go ahead and do a ls. And I can see I've got a file here called HR_EmployeeList.xlsx.
Now, if I just minimize this and if we just look at the storage account here in the portal, in the background, that we're going to be using, if I were to go all the way down, under Blob service, Containers, we'll see that there are none.
So a container is just essentially a folder that we use to organize blobs that we upload here. Now, at the same time, while we're here, why don't we take a look at the Access keys. Every storage account in the Azure Cloud gets two keys assigned automatically.
Now, these are used for programmatic or API access to the storage account's contents. But you might ask, why two keys, why not just one? Well, the idea is that we might have scripts and programming code that refers to, let's say key1. Now from a security perspective, you should be regenerating keys to change them periodically. Although, in practice in my experience that happens rarely, but it's what should happen.
The idea is that we could regenerate a second key, and at some point flip over our code to reference the second key and then regenerate the first key. Because you don't want to just regenerate a key without understanding that it will break any scripts or command-line API calls that refer to that key. They will no longer work after you change the key or regenerate it. Okay, so having said that, let's go into the CLI and let's get to work. The first thing I'm going to want to do is create a variable. And I'm going to create a variable, let's say, called ACCOUNT and it will equal the name of our storage account. So storacct333325, there we go. So if I do echo $ACCOUNT, we can see the value of the variable.
So, it's the name of our storage account, which is what we want.
Clear the screen and I'm going to do the same kind of thing for a storage account key. We can even view the keys from here. So, for example, az storage account keys list --account-name, actually I can use my variable here, $ACCOUNT. How handy is that? --resource-group. It's in a resource group called Rg1. And I can just press Enter to see the output of that and there's the two keys, key1 and key2. Let's say I want to use key1, it doesn't matter which one you use.
So I'm going to go ahead and copy that first one and dump that in a variable I'm going to call key.
So KEY equals open quote, let's just paste that in there, close the quote, done.
So if we echo $KEY, there's the value. Okay.
So we have an account variable, we have a key variable. Let's get to it. So what I want to do is create a storage account container, essentially a folder in my storage account, in which files I upload will be stored. So, az storage container create --name. I want to create a storage container called eastdata --account-name. We can use our $ACCOUNT variable name here, which contains simply a text string that references our storage account name. And also we'll specify --account-key, and let's pass our key variable $KEY. Okay, so let's press Enter.
Looks like it was created. We can even check our work here in the portal. If we just go back here and scroll down in the navigation bar for the storage account down under Blob service, Containers, we should see eastdata, and there it is.
So let's go back into the CLI. Now to actually upload content we're going to use az storage blob upload. --container-name, we just created a container, it's called eastdata I want it to go in there. The other thing I have to specify is the name I want to use for this file, so I'm going to call it HR_EmployeeList.xlsx, that's what I wanted to be called in the storage account once it uploaded. --file, I have to specify the actual file I want to upload. And I already have it here in my Cloud Shell storage. So it's called HR, it's actually called the same thing, EmployeeList.xlsx. Doesn't have to be the same. We can use the name to be the same or make it the same as the actual file that we're uploading, but it can be changed.
Either way, we've got that part done. So now we have to specify --account-name, we've got our handy variable here, $ACCOUNT, and --account-key, you guessed it, we have a $KEY variable. And it looks like the syntax is correct, az storage blob upload, container name, name file. Yup, looks good. Well, it will tell us if there's a syntax error.
And it looks like it finished, just like that, 100.0000%. So let's minimize this, let's open up eastdata here. And sure enough, we're going to see the presence of our HR_EmployeeList.xlsx file.


Uploading Blobs Using PowerShell
  - In this example, I'm going to use PowerShell to upload a blob to a storage account container.
So to get started here, the first thing I want to do is figure out which storage account we're going to work with. So I'm already in the portal where I've launched a Cloud Shell running PowerShell, going to minimize that for a second. And we're just going to go back here and take a look at our list of Storage accounts.
There's one here called storacct333325 that we're going to go into and work with, from the PowerShell perspective. And so, let's just scroll down here in the GUI to Blob service, Containers. There's already a container here that we're going to see, and it's called eastdata.
I want to create an HR container and upload a file. So we can see currently there is no HR container, at least not yet. Let's go back into PowerShell. Let's make this happen. So to do that, I'm going to create a variable here that I'm going to call context, ctx. And this variable is going to essentially point us to the storage account. To do that, I'm going to put =get-azstorageaccount. Because I don't want to keep repeating the name of the storage account, the resource group, -r for resource group it's Rg1. And -name and the name of the storage accounts, storacct333325. Okay, so what we're going to do, is we're going to store the result of running that command in the context variable. So $ctx. And it looks like we have a reference to that storage accounts, returning other properties that we didn't specify must be working.
Looks good, clear the screen. What's next? Well the next thing I want to do, is actually get the context property. What that means is if I run $ctx and pipe that to get-member to show me object properties and methods, although I'm going to say -type property, I only care about properties.
One of the properties of our variable here is called Context, and I need this. So, what I'm going to do then is the following. How about we overwrite same variable, it doesn't matter. We're not going to need it again anyway. So $ctx is going to =$ctx., and the name of the property we just looked at is context. Okay, so now let's just take a look at our $ctx variable.
Now what's got a reference pointer that points to that storage account. This looks different. This is good, and this is what we needed. So, I'm going to run new-azstoragecontainer, spell this correctly, storagecontainer -name. I want to make this call hr, human resources. And here's we're going to use my variable, I'm going to use -context. And, we have to do say, $ctx. So it knows everything about what I'm talking about. I don't have to tell it, at least not outside of this variable. The name of the storage account, the resource group and so on.
Well, it doesn't like it because it really needs to be 3 through to 63 characters long, no problem. Up arrow key, we will write out humanresources. Okay, now when we press Enter, it's going to love it. So we've now got a new storage container called humanresources.
Let's just go back here and refresh the GUI. There's humanresources. Now, we can populate it with stuff. So let's clear the screen. And I'm going to do that by, well first of all, let's see what we have here in the Cloud Shell, dir.
So we've got a file called HR_EmployeeList.xlsx. How about we upload that file? So I'll use set-azstorageblobcontent, quite a long cmdlet name, -file. Well the local file here is called HR_EmployeeList.xlsx. I just typed in hr and press tab. It's unique enough, so it found the name in the current directory, and it spelled it out for me. How convenient, -container. I want to put this in the humanresources container. So humanresources. That's the one we just created a moment ago. And I'm going to specify that the blob, let's say, will be called the same thing as the file. How about HR_EmployeeList.xlsx. Sometimes you want to change the name of what it will appear as in the storage account, versus what it actually is in the file system that you have. But I'm okay with using the same name. The last thing I'm going to do, is specify -context and pass it our $ctx variable.
Now that's not a large file, so it won't take very long for that to be pushed up into the cloud. Let's minimize this. Let's go take a peek. Let's open up humanresources. And after a moment, sure enough, we can see our file has been successfully uploaded.


Uploading Blobs Using AzCopy
  - The Microsoft AzCopy command line tool can be used when you need to transfer files into a storage account, or from it or even between storage accounts. 
  - So here in my web browser, I've navigated to Microsoft documentation where they discuss AzCopy. And if I scroll down little bit, they also provide the downloads for AzCopy. So I'm going to go ahead and download the 64-bit Windows AzCopy tool on my on-premises Windows 10 computer.
Now, I've chosen to extract that to a folder on my machine on drive D and I've changed to that directory and if I do a dir, I can see the azcopy.exe tool.

[Video description begins] He executes the dir command. The output includes an information about the azcopy.exe tool. The prompt remains the same. [Video description ends]

Now depending on how you plan on using this, you can add this to your path this subdirectory where you've got the tool. So that you can run it no matter which subdirectory you're in, in the command line. I'm not going to bother with that, I'm going to run it right from this current location.

[Video description begins] He highlights azcopy_windows_amd64_10.3.4 in the prompt. [Video description ends]

So if I just run azcopy, for example, -h for help, we should be able to tell if it's good to respond and it looks like it is. So we know that it's working and it's giving us some help on how to use the AzCopy command-line tool.

[Video description begins] He executes the cls command. The screen gets clear. The prompt remains the same. Then he executes the azcopy -h command. The output displays an example and supporting commands for the aforementioned command. The prompt remains the same. [Video description ends]

Now before you can actually use this to talk to as your storage accounts, you're going to have to log in, and you can do that with azcopy space login.

[Video description begins] He clears the screen. The prompt remains the same. Then he executes the azcopy login command. The output displays a message which reads, To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code E7QC8WSRS to authenticate. [Video description ends]

So what that does is it says, go to this URL and enter this code to authenticate. So I've entered that URL into my web browser, it asks me to enter a code which I've copied from that command-line output, so I'm going to click Next.

[Video description begins] He opens the https://microsoft.com/devicelogin URL in a browser and a page labeled "Microsoft Enter code" displays. He pastes the E7QC8WSRS code in a text box labeled "Code". Then he clicks a button labeled "Next" and a page labeled "Microsoft Sign in" displays. [Video description ends]

So I'm going to login with one of my Azure AD users that I know has the appropriate storage account and blob roles. They have the right permissions so that they can manage the account such as creating containers, and also have the ability to write blobs or upload blobs to storage account containers. So I've got that person's email address filled in, I'm going to click Next.

[Video description begins] He logins with the user name: lbrenner@quick24x7test.onmicrosoft.com in the Azure Storage AzCopy tool. [Video description ends]

Of course, I'll then specify the sign in password for that account and I'll click the Sign in button. And it then says, I've signed in to the Azure Storage AzCopy app on my device. I can close this window and get back to work at the command line using the AzCopy tool. Back here at the command line, we can see here that the Login succeeded so we're ready to go, so I'm going to clear the screen.

[Video description begins] He switches to the Command Prompt window. The prompt displays Login Succeeded message. The prompt remains the same. Then he clears the screen. The prompt remains the same. [Video description ends]

Now here in the portal I've navigated to a storage account that will be interacted with using AzCopy and I've gone to Access control (IAM). And on the right, I'm going to click View, Role assignments, I want to check out which permissions or indirectly through role assignments that Lucas Brenner or L Brenner has.

[Video description begins] He switches to the Microsoft Azure web page in which the storacct333325 | Access control (IAM) blade is open. It includes five tabs labeled "Check access", "Role assignments", "Deny assignments", "Classic administrators", and "Roles". The Check access tab is selected by default. He clicks a button labeled View in a subsection labeled "View role assignments" in the content pane. Its corresponding Role assignments tab opens. It includes a table with four columns and multiple rows. The column headers are Name, Type, Role, and Scope. [Video description ends]

So, let's take a look, and if we scroll down, we can see that L Brenner has the Storage Account Contributor. So we can manage the storage accounts such as working with containers, but he also has the Storage Blob Data Contributor, so he can contribute blobs burning on large objects, such as, uploading files. The next thing I just want to do is take a look at the properties of this storage account.

[Video description begins] He points to Storage Account Contributor and Storage Blob Data Controller row entries under the Name column header. [Video description ends]

I'm interested really in the primary blob service endpoint, because we're going to use that to make a connection, we have to specify basically the URL. So let me just kind of scroll over to the right here, and we could see the Blob service resource ID and below that the Primary Blob Service Endpoint.

[Video description begins] He clicks an option labeled "Properties" in the navigation pane and its corresponding blade opens. [Video description ends]

And really it's just the full DNS name of our storage account, so I'm just going to go ahead and copy that.

[Video description begins] He copies https://storacct333325.blob.core.windows.net/ in a text box labeled "Primary Blob Service Endpoint". [Video description ends]

So I'm going to use the azcopy command followed by make, because I want to make a container or in other words, a folder or directory in the storage account before I upload content. So this is where I've specified the primary blob service URL that we just copied. However, what I want to do is specify after that the name of the container that I want to make. In this case, I'm calling it, eastprojects, let's see what happens by pressing Enter. Now if you get an error message, it's probably because you don't have the appropriate permissions to create that.

[Video description begins] He switches to the Command Prompt window. Then he executes the following command: azcopy make "https://storacct333325.blob.core.windows.net/". The output displays a message which reads, Successfully created the resource. The prompt remains the same. [Video description ends]

And that's why it was important that this user that we authenticated with L Brenner, has the storage account contributor role. So it looks good successfully created the resource, excellent. Next thing we want to do is copy a file there. To do that, I'm going to run azcopy copy, and then in quotes, I'm going to specify a local path on my on-prem computer. And in this case, I've decided I want all of the txt files in the projects folder under samplefiles in drive d. So instead of specifying an individual file or blob, I'm specifying a bunch of them using a wild card asterisk. After which I am then specifying where the target is, where's that going?

So, after that the next parameter is my storage account blob service endpoint URL. Of course, with our newly created container eastprojects, that's where I want that stuff to go, so let's go ahead and press Enter. Now again, if this fails and you get some kind of a message about permissions or insufficient permissions. It's probably because the account you authenticated with, in our case, it was L Brenner, doesn't have the storage blob data contributor role. In this case it looks good, it looks like the number of transfers completed was 3 so that is indicative of the fact that there are 3 files.

[Video description begins] He executes the following command: azcopy copy "d:\samplefiles\projects\*.txt" "https://storacct333325.blob.core.windows.net/". The output includes a message which reads, Using OAuth token for authentication and a Job summary. The Job summary includes information about total number of transfers, number of transfers completed and skipped. The prompt remains the same. [Video description ends]

So why don't we check our work, well, we could do it in a number of ways including in the portal. Back here in the portal, I'm still looking at the navigation bar here for the storage account question.
So, why don't we just kind of scroll down until we see Blob service, Containers. Hopefully, we'll see eastprojects, which we do, and if I open that up, we should see whatever files should be there, in this case, Project A, B, and C.txt.
We asked for everything that had a txt file extension in that location on-premises to be uploaded here, and we did so using the AzCopy command.


Blob Lifecycle Management and the Portal
  - Lifecycle management is important when it comes to cloud stored data.
  - Sometimes it might be required for regulatory compliance that you configure how data is treated over time. Such as, it be archived and retained for a period of time, or for cost savings, maybe for infrequently accessed data you want Azure to automatically move it to the cool tier to save on costs. Either way we can do this with Blob lifecycle management. Here in the portal I'm in the navigation bar for an existing Storage account. I'm going to scroll down under the Blob service section where I'm going to click Lifecycle Management.
What I'm going to do here is add a lifecycle management rule. So I'm going to click Add rule. Now this rule is going to determine things like how many days we want to elapse before files stored here, Blobs, are moved to some other type of storage.
So, for example I'm going to call this first Rule name CoolStorage. And for blobs, I can choose to move blobs to cool storage a certain number of days after they were last modified. So maybe after 90 days, so that means they're not being written to. So I'll move it to CoolStorage, which is designed for infrequently accessed data.
And it really does this at a reduced charge. I can also Move blob to archive storage. Now you might be required to archive data and retain it for a period of time. So this would take care of the archiving portion at least in an automated fashion. We can also determine if we want to delete blobs after a period of time. So a certain number of days after they were last modified and same with Snapshots that might have been taken. We can delete blob snapshots, a certain days after the blob was created.

So we can go ahead and do that. But this is just the rule. The next thing we have to do is specify the filter set. In other words, to what in the storage account should this rule apply? Now perhaps it's the whole storage account, or maybe a specific container, or maybe only a certain type of file within this storage account. We're going to find out what to do by clicking next down below to add the Filter set. Now we can add a prefix here.
Now there's nothing here by default, which means that if we don't specify anything, we are looking at everything stored in this Azure storage account to determine when it was last modified, to determine, if it should be moved to cool storage. But we could specify containers or folders that we want to use as a prefix. So instead of typing that in, I'm going to click Browse, and from the drop-down list, I'm going to choose one of my containers.
In this case, let's say eastprojects, The entire container, and I'll choose Select. So it's been added down here to the list.
That's what I want this Filter set applied to, that is the filter set.
And I'm going to then click next down at the bottom for review and add, validation has passed, perfect. Let's click Add, so that we can create this lifecycle rule. And we can now see that we have our CoolStorage lifecycle rule and it's been Enabled.


Blob Container Access Levels
  - You create blob containers to organize the blobs that you might store within an Azure storage account. And each of those blob containers can have an access level, to determine what access is allowed to the container itself or the blobs within it.
To get started here in the portal, I'm looking at the navigation bar for an existing Storage account. So I'm going to scroll down and choose Blob service, Containers.
This way we'll see what's already here. For example, if I open up the eastdata folder, we'll see any files that might exist there.
And I'm going to upload a new file, so I'm going to click Upload, and I'm going to upload a JPEG logo file. So I'm going to go ahead and click Upload. And after a moment, we can see quite clearly that our logo file exists.
And if I click on that blob, then we can even see what it looks like. So when it opens up the properties, I'm going to click Edit which in this case shows me that we've got a fictitious logo for a fictitious organization.
Now the next thing we want to do is take a look at access to that item. So for example, if I go to the Overview for that blob or that file, I have a URL. And the URL, I'm going to copy because I'm going to paste that into a browser to see what kind of access we have to it. Now we can see that the URL consists of the name of the storage account, followed by the default suffix .blob.core.windows.net. Then after that we see the path /eastdata is the blob container and the file, of course, we just uploaded is called logo.jpg.
However, when I put that into a web browser it basically says can't find it, don't know what you're talking about. Let's find out why that message is showing up. To do that, we should go back and look at the folder. So I'm going to go back a couple of levels here, so we can jump in and find out what's going on.

[Video description begins] He switches to the Microsoft Azure web page and closes the eastdata blade. The storacct333325 | Containers blade displays. [Video description ends]

So it's eastdata, I can select that folder, and I can change the access level. Now notice, it's currently Private (no anonymous access).

[Video description begins] In the containers table, he selects a checkbox adjacent to the eastdata row entry under the Name column header. Then he clicks the Change access level button and the dialog box with the Public access level drop-down list box opens. The Private (no anonymous access) option is selected in the drop-down list box. [Video description ends]

That explains why we currently are unable to view that file or access it using the URL. But let's change it to, for example Blob (anonymous read access for blobs only). The third option is to allow the enumeration of the container so to list blobs, such as programmatically. Here I'm just going to choose Blob (anonymous read access for blobs only), so for individual blobs, and I'm going to click OK.

[Video description begins] He selects the Blob (anonymous read access for blobs only) option in the Public access level drop-down list box. A notification message displays which reads, Blobs within the container can be read by anonymous request, but container data is not available. Anonymous clients cannot enumerate the blobs within the container. [Video description ends]

So anonymous access, that means no authentication required.
Now there are times when that may be useful for public information posted on a web application and so forth. Let's go ahead and refresh the previous web browser session we had.
And this time, instead of saying resource not found, it's actually showing the blob to us. Well, naturally, that's because we've modified the blob container access level to allow access to individual blobs given that we have the URL for that individual blob.


Storage Account Queues
Within an Azure storage account, you can create queues. Let's scroll down here in the navigation bar for an existing Storage account.
I'll scroll down until I see Queue service and Queues and I'll click on Queues.
Now, what is the purpose of this? This is of great interest definitely to software developers, because it allows them to build modular code in a loosely coupled way. What that means is that multiple software components instead of requiring each to be online to transmit messages, they can instead drop messages into a storage queue where the other component can pick up that message when it's available or when it's up and running. So I'm going to go ahead and click the Add queue button.

[Video description begins] He clicks a button labeled "Queue" and a dialog box labeled "Add queue" opens. It contains a text box labeled "Queue name". [Video description ends]

And I'm going to call this queue1. Now notice, if I were to put in let's say Q in the name, it doesn't like it so lowercase letters only. Now this queue will be referred to programmatically by developers. We're going to go ahead and click OK.

[Video description begins] He types queue1 in the Queue name text box. Then he clicks a button labeled "OK" and the dialog box closes. A row adds in the queues table. The row entries under the Name and Url column headers are queue1 and https://storacct333325.queue.core.windows.net/queue1 respectively. He points to the queue1 row entry. [Video description ends]

So at this point, we've got a queue created called queue1. And I can see if I scroll over here, I can see the Url. It's using the storage account name, followed by the default DNS suffix of .queue.core.windows.net, and of course, then a reference at the end to the name of the queue. If I click to open the queue, one of the things I can do here is submit a sample test message.

[Video description begins] He clicks the queue1 row entry and its corresponding blade opens. It includes a button labeled "Add message" and a table with five columns and no rows. The column headers are Id, Message text, Insertion time, Expiration time, and Dequeue count. [Video description ends]

So I can click Add message, Hello world, and the default expiration is set for 7 days. I'm going to leave that, just click OK. And there's our Hello message being stored in the queue. You might do that if you're a developer and then you want to

[Video description begins] He clicks the Add message button and a dialog box opens. It includes a text box labeled "Message text". He types Hello world in the text box. Then he clicks a button labeled "OK" and the dialog box closes. A row adds in the table displayed in the queue1 blade. He points to Hello world row entry under the Message text column header. [Video description ends]

write some code to retrieve the message from it. Either way, we can put some sample messages in there. Now, we can also define an Access policy. If I click Access policy on the left, it is what you would expect it would be, determines what access is allowed to the queue. So for example, if I click Add policy, then the first thing we have to do is specify an Identifier.

[Video description begins] He clicks an option labeled "Access policy" under the Settings subsection in the navigation pane and its corresponding blade opens. It contains a section labeled "Stored access policies" which further contains a button labeled "Add policy" and a table with four columns and no rows. The column headers are Identifier, Start time, Expiry time, and Permissions. [Video description ends]

So I'm going to call this AccessQueue1. And I can specify the Permissions, let's say, the ability only to read messages stored in the queue. I can specify a start date and time of when that should apply in an expiration date and time of when that should stop. And that would, of course, be in accordance with the specified time zone information for both the start and explorations. Now why would I do this, you would create this access policy as it limited way for software components in this case to read messages in this queue. Now it's good to know it's tied queue1 because we're creating this access policy for queue1. So I'm going to go ahead and click OK. And then I'm going to Save that policy.

[Video description begins] He clicks the Add policy button and a dialog box opens. It includes a text box labeled "Identifier", a drop-down list box labeled "Permissions", and calendar text boxes labeled "Start time" and "Expiration time". He types AccountClosure1 in the Identifier text box. He clicks the Permissions drop-down list box and a drop-down list opens. It includes four checkboxes labeled "Read", "Add", "Update", and "Process". He selects the Read checkbox. Then he sets a Start time and Expiration time in their respective text boxes. Then he clicks a button labeled "OK" and the dialog box closes. A row adds in the table displayed in the Stored access policies section. [Video description ends]

Now what we can also do here, if we go back to the storage account level, is we can open up the Storage Explorer tool from the navigation bar that's in preview.

[Video description begins] He opens the storacct333325 | Queue blade. Then he clicks an option labeled "Storage Explorer (preview)" and its corresponding blade opens. [Video description ends]

 And what I can do is generate a shared access signature based on that access policy for the queue, which is kind of a cooler feature. We can do it all right in here. So for example, if I take a look at my QUEUES here, I can see we've got queue1, and if I right click on it, I can get a shared access signature.

[Video description begins] The Storage Explorer (preview) blade displays four folders labeled "BLOB CONTAINERS", "FILE SHARES", "QUEUE", and "TABLES". He expands the QUEUE folder. It contains a subfolder labeled "queue". Then he right-clicks on the queue subfolder and a flyout opens which contains two options labeled "Get Shared Access Signature" and "Delete". He clicks the Shared Access Signature option and its corresponding blade opens. [Video description ends]

Shared Access Signatures traditionally provide limited and in some case timed access where there's an expiration to resources within a storage account, as opposed to a storage account access key which gives access to the entire account. That's not the case here. It's only really Read access for a specific queue. Okay, so I'm going to choose my Access policy from the list here it's AccessQueue1. We can see the details for the start and expiration dates and times, and the Permissions which are Read.

[Video description begins] He clicks a drop-down list box labeled "Access policy" and its drop-down list opens. He selects an option labeled "AccessQueue1" from the drop-down list. [Video description ends]

So at this time when I created, I then can copy either the URI or the Query string depending on how, as a developer, I'm making a connection, to the Shared Access Signature to gain these privileges.


Azure AD Storage Account AD Authentication
There are times where you might want to grant storage account permissions to Azure AD users. And we can do this by assigning RBAC roles related to storage account usage.
So we get started here in the portal, I'm looking at the properties of an existing Storage account. And within that navigation bar, I'm going to click Access control (IAM), where I would normally go for RBAC role assignments. And I'm going to click Add and Add role assignment.
What I want to do is filter the list of roles for any that begin with the word storage, since, we're talking about a storage account. So from the Role drop-down list, I'll just give a click there and I'll type in storage. So the first thing I want to do is assign the Storage Account Contributor role because I want to allow a specific user in AD, Azure AD or a group perhaps, or even a service principal. I want to grant them the ability to manage the storage account. So such as creating storage account containers. So I'm going to select that role. And what I want to do is assign that to a group. So I'm going to type in the word east. And I've already got an Azure AD group I've defined previously called EastAdmins. I want the members of that group to have storage account contributor permissions. So I'm going to go ahead and select that. And I'll click Save.
If I also want, let's say that same group to be able to upload blobs, then I would work with a different role. So I'm going to click Add, Add role assignment. And the role I'm interested in here is going to be the storage blob data contributor role. Let's find that first. To make sure that's the correct name.

[Video description begins] He opens the Add role assignment blade. [Video description ends]

So I'm going to click on list roles. Once again, type in storage and it looks like we were right, Storage Blob Data Contributor role. And I'm going to assign that to the same group so they can also upload blob content to the storage account. Then I'll click Save.

[Video description begins] He selects an option labeled "Storage Blob Data Contributor" in the Role drop-down list box. He keeps the default value in the Assign access to drop-down list box. Then he selects the EastAdmins group. Then he clicks the Save button and the Add role assignment blade closes. [Video description ends]

So once that role has been assigned or those roles, we can click on View to view the role assignments.

[Video description begins] He clicks the View button under the View role assignments subsection in the content pane. The Role assignments tab gets selected. It displays the table with four columns and multiple rows. The column headers are Name, Type, Role, and Scope. [Video description ends]

And over on the right here, if I scroll down, we'll see in fact that EastAdmins has been given the Storage Account Contributor role at This resource, so wasn't inherited from a management group or subscription or resource group. And also the Storage Blob Data Contributor. So any member of the EastAdmins group, which by the way, why don't we just take a look at that specific group, so we can see who the members might be because it is the Members of the group that will have those permissions or those abilities at the storage account level.

[Video description begins] He clicks the EastAdmins row entry under the Name column header and its corresponding blade opens. It is divided into two sections: navigation pane and content pane. The navigation pane includes an option labeled "Overview". It is selected by default and its corresponding blade is open in the content pane. Then he clicks an option labeled "Member" under a subsection labeled "Manage" in the navigation pane. It displays a table with four columns and two rows. The column headers are Name, Type, Email, and User type.[Video description ends]

And here we can see its users Jen Hill and Marcia Lin. 


Storage Account Access Keys
  - Every Microsoft Azure storage account always has two storage account access keys.
  - Here in the properties of a Storage account, I can go down under Settings and click on Access keys to open the Access keys blade.
And when I do that, over on the right, I will see that there are two keys. Now there are also two connection strings, we're focusing primarily on the keys. These keys give access to the storage account, and it's access that would be granted for example, at the command-line level.

[Video description begins] He highlights the alphanumeric value of the key1. [Video description ends]

When using command-line tools, you could use the access key to gain access to the storage account. Even using GUI tools like Azure Storage Explorer, sometimes developers will be accessing Azure storage account APIs. And then we'll need to specify a key to gain programmatic access, either way, that's what it's for. But there are two of them, why two? Well, what you could do is you could refresh keys periodically. And as a matter of fact you should, from a security perspective, but if you're regenerating a key, what you're doing is changing it.

[Video description begins] He points to a button labeled "Regenerate" adjacent to the key1 text. [Video description ends]

So I've select a key1, the Regenerate icon, it says, the current key will become immediately invalid and can't be recovered. You want to regenerate access key1, I'm going to choose Yes. And when I do, it looks completely different, so if I had any code or scripts or command-line references to the old key1.

[Video description begins] He highlights the modified alphanumeric value of the key1. [Video description ends]

They will no longer work, they won't have access to the storage account any longer. So I would do this on a periodic basis and you'd have to make sure you change all references that use the old key. But because it could be disruptive in some cases, that's why you have two keys. Because you could have commands and scripts use key2 for a while, as you generate key1. Which you might use for new command line or programmatic access.

[Video description begins] He highlights the alphanumeric value of key2. Then he highlights the new alphanumeric value of key1. [Video description ends]

So you have the access of having a, or the ability rather, having a key that's still valid and useful while you refresh a different one.

[Video description begins] He highlights the alphanumeric value of key2. Then he points to the new alphanumeric value of key1. [Video description ends]

You can also do this at the command line, so let's go ahead and jump into Cloud Shell. And I'll just click Reconnect, since my session timed out. So here in PowerShell, I'm going to use the New-AzStorageAccountKey cmdlet to generate a new key.

[Video description begins] He opens the PowerShell command prompt. The PS /home/danlachance72> prompt displays with the following command: New-AzStorageAccountKey -ResourceGroupName Rg1 -Name "storacct333325" -KeyName "key1". [Video description ends]

I'll specify the resource group where that account was deployed, the name of that storage account. And the key I want to regenerate, in this case, key1 and I'll press Enter. Now we can actually retrieve information about that as well, using the Get-AzStorageAccountKey cmdlet.

[Video description begins] He executes the aforementioned command and its output displays a single column table with a single row. The column header is Keys and its respective row entry is {key1, key2}. The prompt remains the same. [Video description ends]

So that would be Get-AzStorageAccountKey, specify the resource group where the storage account was deployed. And the name of the storage account, and when I press Enter, it returns both key1 and key2.

[Video description begins] He executes the following command: Get-AzStorageAccountKey -ResourceGroupName Rg1 -Name storacct333325. The output displays a table with three columns and two rows. The column headers are KeyName, Value, and Permissions. [Video description ends]

Shared Access Signatures

[Video description begins] Topic title: Shared Access Signatures. The presenter is Dan Lachance. [Video description ends]

A shared access signature or SAS, S A S, which you'll see when you're looking at the navigation bar for a Storage account, you'll see it down here, Shared access signature. 

[Video description begins] The storacct333325 blade opens in the Microsoft Azure web page. [Video description ends]

This is a way to allow limited access to a storage account to particular services with perhaps only read access as opposed to read, list, and write. And even it can have an expiration date and time.

[Video description begins] He clicks an option labeled "Shared access Signature" under the Settings subsection in the navigation pane and its corresponding blade opens in the content pane. [Video description ends]

So the permissions are only good within a certain time frame. Now that's as opposed to Access keys, of which there are two for every storage account.

[Video description begins] He opens the Access keys blade. It includes key1 and key2 alphanumeric values and connection strings. [Video description ends]

If you have an access key, you have full access to everything in the storage account. Not quite so with the Shared access signature, depending on how it's configured. Let's take a look at how that works.

[Video description begins] He opens the Shared access signature blade. [Video description ends]

So I'm going to go into Shared access signature, and I only want to allow access, let's say, to blobs, not to Azure file shares, queues, or tables.

[Video description begins] The Shared access signature blade includes four checkboxes labeled "Blob", "File", "Queue", and "Table" for Allowed services. By default, all the checkboxes are selected. He removes checks from the File, Queue, and Table checkboxes. The Blob checkbox remain selected. [Video description ends]

Now, I only want to allow Read and List access. I don't want this Shared access signature to allow the creation of content at the blob level.

[Video description begins] The Shared access signature blade also includes eight checkboxes labeled "Read", "Write", "Delete", "List", "Add", "Create", "Update", and "Process" for Allowed permissions. The Update and Process checkboxes are grayed out and rest of them are selected by default. He removes checks from the Write, Add, Create, Update, and Process checkboxes. The Read, Delete, and List checkboxes remain selected. [Video description ends]

Now, if I scroll down further we'll also see the timing, the date and the time stuff. So the start and expiration date and time. So the starting date and time, the expiry date and time, which I'm going to leave. Notice here that on the same day, we have access starting at about now, 10:56 in the morning, and ending at about 6:56:15 PM. So we got 8 hours by default. Of course, you can change that, you can also specify an allowed IP address either individually or range, as implied with the faded or ghosted text in that field to help you along. It's going to be for HTTPS and I have to choose either key1 or key2 as the Signing key for this signature.

So I'm just going to leave it on key1, and I'm going to Generate SAS and connection string. And then down below, I'll see it's given me three items, a Connection string, a SAS token, which I would use for programmatic access, and also a Blob service SAS URL. So I'm going to use the Blob service SAS URL down at the bottom here. I'm going to copy it and I'm going to use that to make a connection to the storage account, using the Azure Storage Explorer GUI tool.

[Video description begins] He opens a window labeled "Microsoft Azure Storage Explorer". It is divided into three parts: menu bar, navigation pane and content pane. The navigation pane includes options labeled "Quick Access" and "Local & Attached". The Local & Attached option includes a suboption labeled "Storage Accounts" and its corresponding table with six columns and a row is displayed in the content pane. The column headers include ID, Message Text, and Insertion Time. [Video description ends]

Microsoft Azure Storage Explorer is a free downloadable tool, which I've already downloaded. What I want to do is create a new connection using the shared access signature. So in the left hand navigator here I'm going to right-click on Storage Accounts, and I'm going to choose Connect to Azure storage.

[Video description begins] He right-clicks on the Storage Accounts suboption and a flyout opens which includes an option labeled "Connect to Azure storage". He clicks that option and a wizard labeled "Microsoft Azure Storage Explorer - Connect" opens. It displays a page labeled "Connect to Azure Storage". [Video description ends]

What I want to do is, I want to make a connection using a SAS URI, shared access signature. So I'm going to go ahead and click Next. I'll paste in the URI.

[Video description begins] The Connect to Azure Storage page includes several radio buttons. A radio button labeled "Add an Azure Account" is selected by default. He selects a radio button labeled "Use a shared access signature (SAS) (URI)". [Video description ends]

Everything else is filled in, including the Display name. I can change that. I'm going to call this SASTest, just so we can distinguish it from anything else that's already there in the navigation panel.

[Video description begins] A page labeled "Attach with SAS URI" displays. It includes various text boxes. He pastes the copied Blob service SAS URL in a text box labeled "URI". The text boxes labeled "Display name", "Blob endpoint", "File endpoint", "Queue endpoints", and "Table endpoint" auto-populates with default values. Then he edits the Display name to storacct333325 -SASTest. [Video description ends]

I'll click Next and Connect. So in the left-hand navigator, we can now see our SASTest connection to the storage account. And if I expand it, I can see only Blob containers.

[Video description begins] A suboption labeled "storacct333325 -SASTest (SAS)" adds under the Storage Accounts suboption. He expands the storacct333325 -SASTest (SAS) suboption. It further includes a suboption labeled "Blob Containers". [Video description ends]

Now I have another example up here in the Azure Storage Explorer where I've connected to the storage account using an access key, which provides access to everything in that storage account. But here, we only have access to what the shared access signature says we have access to, which is Blob containers.

[Video description begins] He expands the StorAcct333325 (Key) suboption under the Storage Accounts suboption. It contains four suboptions labeled "Blob Containers", "File Shares", "Queues", and "Tables". Then he collapses the StorAcct333325 (Key) suboption. Then he expands the storacct333325 -SASTest (SAS) suboption. He points to the Blob Containers suboption. [Video description ends]

And if I take a look for example, under eastprojects, I can see some content there. But I will not be able to upload content because I don't have the ability to add items, only list and read. So I'm going to go ahead and try to upload a file here.

[Video description begins] He expands the Blob Containers suboption which further contains three suboptions labeled "eastdata", "eastprojects", and "humanresources". He clicks the eastprojects suboption and its corresponding table with nine columns and three rows displays in the content pane. The column headers include Name and Access Tier. The content pane also includes a quick access toolbar which includes buttons labeled "Upload" and "Download". [Video description ends]

But it's going to fail, says Insufficient credentials.

[Video description begins] He clicks the Upload button and a flyout opens with two options labeled "Upload Folder" and "Upload Files". He clicks the Upload Files option and its corresponding dialog box labeled "Microsoft Azure Storage Explorer - Upload Files" opens. It includes a text box labeled "Selected files" and a button labeled "Upload". The Selected files text box contains a file name labeled "CardData.txt". He clicks the Upload button and the dialog box closes, but no file uploads. [Video description ends]

It's not allowed because of the shared access signature, it doesn't allow the adding of content at the blob level.

Storage Account Replication

[Video description begins] Topic title: Storage Account Replication. The presenter is Dan Lachance. [Video description ends]

When you create an Azure storage account, at creation time you can determine whether or not you want a specific type of replication enabled for that account.

[Video description begins] The storacct333325 blade opens in the Microsoft Azure web page. [Video description ends]

Replication allows you to increase the data availability for whatever you have stored in the account. First of all, we can change this after the fact. And I'm going to do that here in the portal. So I've got the properties of an existing Storage account displayed. I've got the navigation bar. First thing I'll do is go down to Geo-replication. But when I click there, what I'm going to see is a map with my Primary location.

[Video description begins] He clicks an option labeled "Geo-replication" under the Settings subsection in the navigation pane and its corresponding blade opens. [Video description ends]

So where is the option to add additional locations for replication? Well, there's nothing, not even down at the bottom. All I see is that our current primary location is Canada Central. Well, that's because we have to enable replication, if it wasn't enabled when the account was created, by going to Configuration over on the left. So I'm going to go ahead and I'm going to do that. So we'll be able to select the type of replication that we're interested in.

[Video description begins] He clicks an option labeled "Configuration" under the Settings subsection in the navigation pane and its corresponding blade opens. [Video description ends]

If we take a look, currently it's set to Locally-redundant storage (LRS). So what this means is that we've got three copies of data within an Azure location. So, if we've got a problem such as fire in an Azure data center, we might lose all access to those three copies. And so for additional availability, you might select either Geo-redundant storage (GRS), or Read-access geo-redundant storage (RA-GRS).

[Video description begins] In the Configuration blade, he points to a drop-down box labeled "Replication". By default, it contains an option labeled "Locally-redundant storage (LRS)". [Video description ends]

The difference being that with geo-redundant storage if there's a failure in the primary region, you've got to initiate a failover to the secondary region where data was copied to in order to be able to access it. So I'm going to choose in this case, Geo-redundant storage (GRS).

[Video description begins] He clicks the Replication drop-down list box and a drop-down list opens with three options labeled "Locally-redundant storage (LRS)", "Geo-redundant storage (GRS)", and "Read-access geo-redundant storage (RA-GRS)". [Video description ends]

And I'm going to Save that config change here. So we're changing the configuration of an existing Storage account. It says it successfully updated it, perfect.

[Video description begins] He clicks a button labeled "Save" to save the changes in the Configuration blade. [Video description ends]

Let's go back and let's look at the Geo-replication screen. Previously, we had only the blue indicator on the map which according to the legend was our Primary location of Canada Central.

[Video description begins] He opens the Geo-replication blade. It displays a world map and a table with four columns and two rows. The column headers are Location, Data center type, Status, and Fallover. He points to Canada Central and Canada East row entries under the Location column header. [Video description ends]

Now it's automatically determined that geo-replication will be enabled for the green listed item on the map, which is a different location. It's another region but it is reasonably close to the primary, it's Canada East. So now, Canada Central will be replicated to Canada East. So at this point at the bottom, it says, well you can't even enable failover because replication is happening, you've just enabled this. And as you might imagine, depending on the amount of data in the account will determine how long it takes for this to complete. But at this point, we've increased the availability of the data by replicating it to an alternate or secondary Azure region.


Azure Storage Explorer Connectivity
Microsoft Azure Storage Explorer is a free GUI tool that lets you connect to various aspects of an Azure storage account, such as, if you want to manage blobs, or queues, or tables, and so on.

[Video description begins] The Azure Storage Explorer web page opens. [Video description ends]

So in my browser, I've navigated to the Azure Storage Explorer download page. You can search this up quite easily using your favorite search engine. And I'm going to go ahead and download and install Azure Storage Explorer for the Windows platform on my on-premises Windows 10 station. You can then start Microsoft Azure Storage Explorer from your Start menu like you would with any app. Now, the first thing I need to do here is determine how I'm going to make a connection to a storage account in Azure.

[Video description begins] He opens the Microsoft Azure Storage Explorer window. [Video description ends]

So for example, I can expand Storage Accounts here and I can right-click and choose Connect to Azure storage.

[Video description begins] In the navigation pane, he expands the Storage Accounts suboption. Then he right-clicks on it and a flyout opens. He clicks the Connect to Azure storage option from the flyout and the Microsoft Azure Storage Explorer - Connect wizard opens. In the wizard, the Connect to Azure Storage page is open. It includes several radio buttons. A radio button labeled "Add an Azure Account" is selected by default. [Video description ends]

And I have a number of ways I can do that using my Azure account credentials, or via Azure AD credentials, using a connection string, a shared access signature, a storage account name and a key to it, or I can attach to a local emulator for testing purposes. In this case, let's say I want to connect to a storage account using its name and key. We'll go ahead and click Next.

[Video description begins] He selects a radio button labeled "User a storage account name and key". Then he clicks the Next button and a page labeled "Connect with Name and Key" displays. [Video description ends]

You'll want a Display name. Now, I'm going to give it the name of the storage account StorAcct333325. And I have to give it an Account name that would be for the storage account and also the Account key. So I'm going to pop in the actual name of it, storacct333325. But I also need an Account key.

[Video description begins] He types StorAcct333325 and storacct333325 in text boxes labeled "Display name" and "Account name" respectively. [Video description ends]

So here in the portal in my storage account, I'm going to scroll down to Access keys of which there are two. Now, it doesn't make a difference which one I copy. So I'll just take the first one and click the copy icon. And I'll go ahead and paste that in the Account key field.

[Video description begins] He switches to the storacct333325 blade opened in the Microsoft Azure web page. Then he opens the Access keys blade. Then he copies the alphanumeric value for the key1. Then he switches back to the Microsoft Azure Storage Explorer window in which the Microsoft Azure Storage Explorer - Connect wizard is open. He pastes the copied key in a text box labeled "Account key". [Video description ends]

And that's all I'm going to change here. So I'm going to go ahead and click Next and then Connect.

[Video description begins] A page labeled "Connection Summary" displays. He clicks a button labeled "Connect" and the wizard closes. A suboption labeled "StorAcct333325 (Key) adds under the Storage Accounts suboption in the navigation pane. [Video description ends]

So now we can see the storage account listed in the navigator and in parentheses the word Key, since that is how we gained access to the account. So now I can check out what's in the account. I can drill down into it, expand Blob Containers. Here's all of the different blob containers we have. I can click on each one of those and see files, download, upload, content.

[Video description begins] He expands the StorAcct333325 (Key) suboption. It includes suboptions labeled "Blob Containers", "File Shares", and "Queues". He expands the Blob containers suboption. It further includes a suboption labeled "eastprojects". He clicks the eastprojects suboption and its corresponding table with nine columns and three rows displays in the content pane. The column headers include Name and Access Tier. [Video description ends]

I can also see any Azure File Shares that might have been created, of course, the contents of those file shares.

[Video description begins] He expands the File Shares suboption. It contains a suboption labeled "projects". He selects the projects suboption and its corresponding table with two columns and three rows displays in the content pane. The column headers are Name and Size. [Video description ends]

I can see any Queues that might have been defined, and those items are shown here and so on.

[Video description begins] He expands the Queues suboption. It contains a suboption labeled "queue1". He selects the queue1 suboption and its corresponding table with multiple columns and no rows displays in the content pane. The column headers are ID and Message Test. [Video description ends]

So really, the Azure Storage Explorer is another way to make a connection to a storage account. In our case, with the storage account access key, which gives access to the whole storage account from which we can then work with the content in the storage account.


Storage Account Blob Soft Delete
One of the many options you have when you create a storage account in Azure is whether or not you want the blob soft delete option enabled.

[Video description begins] The storacct333325 blade opens in the Microsoft Azure web page. [Video description ends]

It's disabled by default. Now you can check this out on an existing Storage account in the portal by going into the navigation bar, scrolling down under Blob service, and choosing Data protection.

[Video description begins] He clicks an option labeled "Data protection" under the Blob service subsection in the navigation pane and its corresponding blade opens in the content pane. It includes a toggle button labeled "Blob soft delete" with two options labeled "Disabled" and "Enabled". It is Disabled by default. [Video description ends]

You will see that the current state is as it was by default Disabled. I'm going to choose Enabled. And I've got a retention policy set for a default value of 7 days. This means that any data, blob data, that is overwritten or deleted can be recovered for up to 7 days. Now this doesn't apply, if we're talking about a container, essentially a folder that is deleted. You can't get those contents back after 7 days. It also doesn't apply if any of the metadata, such as tagging and so on related to blob items is modified. So I'm going to go ahead and click Save to save that change. And let's navigate to our Blob service Containers, and I'm just going to open a Container called eastprojects.

[Video description begins] He opens the Containers blade. Then he clicks the eastprojects row entry under the Name column header of the containers table. The eastprojects blade opens. It includes a button labeled "Delete", which is grayed out and a table with multiple columns and three rows. The column headers include Name and Modified. [Video description ends]

In here, I have a file named Project_A.txt. So I'm going to select that file and I'm going to choose to Delete it. It also asks would you also like to delete any blob snapshots, if there are any. Well, I don't have any, so I'm going to just choose OK. And we can now see that our blob is deleted, the file is gone, Project_A.txt.

[Video description begins] He selects a checkbox adjacent to the Project_A.txt row entry under the Name column header. Then he clicks the Delete button and a dialog box labeled "Delete blob(s) opens with a message which reads, Are you sure you would like to delete the selected blobs?. He clicks the OK button and the dialog box closes. The first row entry deletes from the table. [Video description ends]

Now notice within this view here over on the far right I have the option to Show deleted blobs. If I turn that on, we can clearly see Project_A.txt was deleted because the Status says as much.

[Video description begins] He clicks a toggle button labeled "Show deleted blobs" and the deleted row entry displays in the table. The first row entries under the Name and Status column headers are Project_A.txt and Deleted respectively. [Video description ends]

Now, what I can do is click directly on that blob. And when I'm in the properties of it over on the right I can click Undelete. So it says it successfully undeleted it.

[Video description begins] He clicks the Project_A.txt row entry and its corresponding blade opens. It includes a button labeled "Undelete". He clicks the Undelete button and a notification message displays which reads, Successfully undeleted blob. [Video description ends]

Let's just take a quick little peek here.

[Video description begins] He closes the Project_A.txt blade. [Video description ends]

So, if we close that current property window or blade, so close that out, we can now see Project_A.txt, instead of having a Status of deleted is now back at being Active.

[Video description begins] The status of the Project_A.txt row entry under the Status column header changes to Active. [Video description ends]

And we have the ability then to do this for the retention period, which by default is 7 days.


Storage Account Encryption
Encryption of data at rest has become more and more important over time, as we keep hearing media reports about compromised customer information for example, due to the fact that data was not stored in an encrypted format.
And really, in this day and age, that's completely unacceptable as there are so many freely available encryption tools out there. And in many cases, it's enabled by default, such as with an Azure storage account. Let's explore that a little bit. Here in the portal, I'm going to go into Storage accounts and I'm going to open an existing Azure Storage account. What we want to do is scroll down in the navigation bar and click Encryption.
When we do this, we'll see that it's set currently to Microsoft Managed Keys.
So yes, it is server-side encryption. It is enabled but the keys are controlled by Microsoft. Depending upon your regulatory compliance requirements, that might not work. You might need to have control of them. So we do have the option, as we can see here, to enable Customer Managed Keys. So down below, I can select a Key vault.
Now a Key vault is a centralized Azure resource. I say centralized only meaning it serves as a central repository for you to store secrets like PKI certificates, passphrases, and of course, as in our case, keys. And so other Azure resources or software code that you might develop can refer to this centralized storage location for secrets and call upon things. And in this case, I'm going to go and select a key vault. Because I want to choose a key from it that will be used to encrypt the storage account and it will be under my control.

[Video description begins] He clicks the Select a key value and key link and is corresponding blade labeled "Select key from Azure Key Vault" opens. It contains three drop-down list boxes labeled "Subscription", "Key vault", and "Key". An option labeled "Pay-As-You-Go" is selected by default in the Subscription drop-down list box. [Video description ends]

So from the drop-down list, I have a key vault I've created called KV1East1. And within it, I've got a key called Key1, that's something I created, I generated.

[Video description begins] He selects an option labeled "KV1East1" in the Key vault drop-down list box. Then he selects an option labeled "Key1" in the Key drop-down list box. [Video description ends]

So I'm going to go ahead and choose Select. And at this point, we've now got the required information to enable Customer Managed Keys here for our storage account.

[Video description begins] The Key vault and key information displays in the Encryption blade. The Key vault is kv1 east1 and Key is Key1. [Video description ends]

Now that that's filled in, I'm just going to go up at the top and choose Save. And it says it's updating the server-side encryption for the storage account. So at this point, it's now been enabled. So from this point forward, newly added items to the storage account will be encrypted.

[Video description begins] He saves the changes in the Encryption blade. A text box labeled "Current Key" and "Automated Key Rotation" displays with "https://kv1east.vault.azure.net/Key1" and "Enabled - Using the latest key version" values respectively. [Video description ends]

And of course, any existing items will be retroactively encrypted with the background encryption process.


Blob SAS Token
  - In the Microsoft Azure environment, a shared access signature is usually associated with the storage account.
  - In the portal, I'm looking at a Storage account, and if I scroll down and look under Settings, I'll see Shared access signature.
And the purpose of this is to allow limited, time-based access to some contents of the storage account, whereas the access keys provide full access to everything in the storage account. But we not only have the option of setting up a Shared access signature, for example, to allow access to blobs, but we can get even more specific to individual blobs. So for example, I'm going to scroll down further under Blob service and choose Containers. And I'm going to pick on a container called eastprojects, let's say, where I've got some sample files uploaded. One of which is called Project_A.txt.
I want to set a Shared access signature for that specific blob as opposed to all blobs.
So when I open up the properties on the right, I need to click on the Generate SAS option.
Now from here, I can choose the Permissions that would apply here. It's set to Read by default, which is it what I want, so I'm going to leave it at that. And I can see the Start date and time, and the time zone. And of course, the idea is that we can have an Expiry date and time as well for when this is good for, this Shared access signature. So I'm going to leave it as it is. I could also specify IP addresses from which access is allowed. And I'm just going to scroll down a little bit by scrolling over to the far right, and see everything.
And then finally, we have to specify some finalized details here, such as whether we're going to allow HTTPS or HTTP. Of course, HTTPS encryption makes sense. And Key 1 in our storage account will be used to generate the signature. So Generate SAS token and the URL. And I'm just going to scroll down here to reveal those items. So we have both a Blob SAS token and a Blob SAS URL.
So I'm going to copy the Blob SAS URL by pointing to the copy icon to the far right of it and choosing the copy option, so click, and it says it was Copied. So now, when I paste that blob SAS URL on my web browser, it will allow me to access the file. Now because it's a no MIME type in the browser, it's just the text file, it actually shows us the contents of the file as opposed to prompting us to download it.


Azure App Service Overview
  - Azure App Service is all about deploying web applications in the Azure cloud as a managed service
    - We can do this by deploying a code based web application or a Docker image based application
  - When you select a Docker imaged based application, you can select between the underlying VM running Windows or Linux
    - Docker allows us to containerize applications, in other words to have a logical boundary around all of the application components
    - That container can be moved to different Docker hosts to run the application
    - The great thing about it as opposed to running an entire VM is that, it relies on the underlying operating system that's already running
    - So loading up a dockerized application is very quick comparing to firing up a VM supporting your app
  - Let's talk about the web app as well as the app service plan. So these are two different types of resources in Azure
    - The web application lets you configure custom DNS domain names, so you don't have to stick with the default DNS suffix
    - Depending on what type of app service plan that you configure, will determine how many custom DNS domain names you can use
    - You can also work with deployment slots, the purpose of a deployment slot is for staging
  - You could have a production deployment slot with the production version of a web app, and as you are making changes and testing them
    - You could have a separate testing slot, then essentially once that comes through as testing successful
    - You can switch it to production so it's visible, for example, to the public once again
    - Deployment slots are a great way to work with a staging environment when you're making changes to a web app, essentially it's changing around domain names
    - We can also configure TLS/SSL settings for a web application, SSL is deprecated so it should never be used.
  - We should be using TLS, Transport Layer Security, to secure network connections. Vertical scaling allows us to increase compute power for underlying VMs. Horizontal scaling allows us to scale up by adding multiple VMs to handle a busy workload environment for a web app. You can also configure WebJobs. WebJob is essentially a tool that lets you schedule or run whenever you want some kind of a script or a program to perform some kind of maintenance on a web app. The app service plan, as we said, is a separate type of resource in Azure. And with it, it determines which resources are available to the web app, so the actual underlying horsepower.
You can also link multiple web apps with the single app service plan. The only thing about this to be careful is that if you have one very, very busy application, then it can starve other apps using that app's service plan. So you have to be careful about the planning and monitor the performance of the web apps. So you can view performance metrics at the app service plan level. So you can look at CPU metrics, memory, traffic in and out. You can also view file system usage per web application that's linked to that app service plan.
There are a couple of pricing tiers you should be aware of. First of all, they refer to Azure Compute Units or ACUs, ACUs are really just about CPU performance. So more ACUs means better performance. Now you can have a tier of dev/testing, or for production environments, production. You also have this option called isolated. The purpose of the isolated app service plan pricing tier is to have all of your web resources to support your app deployed into your own Virtual Private Network in Azure.
  - There are many different runtime services supported, so when it comes to languages for your application
    - It's pretty much anything that you might want to use like .NET Core, ASP.NET, Java, PHP, Node.js, Ruby, and so on
    - When you go to the Azure Marketplace to create a new resource, there are plenty of apps available, essentially preconfigured web applications
  - That's another option to consider when you're deploying a web app
    - Sometimes it might be quicker to look through the marketplace and select something and maybe tweak it to your own liking as required
  - You can manage Azure app service web apps using the portal, using ARM templates, using PowerShell
    - Or the CLI, and also using development tools of course, such as Microsoft Visual Studio
    - Where you might write the code for the app and then push it up into the Azure Cloud


Code Web App Deployment
  - Using the portal to deploy a code based web application.
  - To get started, click Create a resource and search for web then choose Web App
    - Now there are a number of things we'll have to specify,  just click Create.
    - Remember that a web application needs to be linked with an app service plan in Azure, that's a separate resource.
  - Either you can create one along with the web app here at this time, or you can use an existing one, you can link multiple web apps to a single app service plan. So let's deploy this into a specific resource group. And let's give this a Name.
I'm going to call this webapptest172yhz. It needs to be unique. And notice it's using the .azurewebsites.net DNS suffix by default. But you can change that. You can configure a custom DNS domain name or multiple DNS domain names if you wish.
Down below, we can select from either a Code based application where we can select the Runtime stack. So for the language support, notice the variances here of .NET, ASP, Java, Node.js, PHP, Python, Ruby.
A lot of options. And notice that we cannot choose between Linux and Windows when we select a Code based type of application. But if we choose a Docker containerized type of application, we can select from either Linux or Windows for the underlying host that supports that Docker container.
I'm going to go to code-based. And I'm going to put this in a specific region. How about in this particular example since it's near me, I'll select Canada Central. Down below, here's the App Service Plan affiliation. We can either select an existing one if we have it, we don't because there are none showing up in the list.
And so it's selected to create a new one automatically. And it's got a name for it, which is fine. Now I could change that but I'm going to go with that. Down below, the sku and the size. Looks like we have 210 total ACUs. An ACU is an Azure Compute Unit. That's the unit of measurement that's used to reference CPU compute power here for your app service plan. You can change the size, if I click Change size.
Then depending upon what I suspect the workload will be, not only for a specific web app, but if you're having multiple web apps linked with the app service plan, that might dictate how much horsepower you need. So at the top, notice we're looking at some Production pricing tiers. We also have Dev / Test and also Isolated. However I'm not going to change that. I'm just going to close that by clicking the x. I'll leave it as it is. I'm going to click Next: Monitoring> . Now, I'm not going to Enable Application Insights at this point.
But if you really want to track the performance of a web app, especially as you're testing it, to push it into production, you're going to want to do that. But we can turn that on later. Now, if it's not supported for our specific type of configuration, then you'll see that we can't turn it on. So it says Application Insights is not supported for your current selection here, Runtime Stack, Operating System, and so on.
So if we go back, if we were to make a change to some of the selections, let's go choose a Runtime stack. Let's say ASP.NET V4.7.
Okay, now let's go to Next: Monitoring > and notice that Application Insights is now available.
And so it wants to create a new configuration for Application Insights.
So we can choose to either not do that or do it. I'm going to choose No at this point.
Then I'm going to click Next for tags. I'm not going to add any tagged information so I'll click Next: Review + create >. It's going to verify that my selections make sense and that they will work.
And everything looks good. There's nothing that stands out here. So I'm going to go ahead and click Create to build this web application. And remember, it's also going to build our app service plan. We'll take a look at both of those in a moment once they're deployed.
Okay, so what we're going to do is go back home here and go to All resources, only because I want to make sure that we look at both the app service plan and the web app.
So I'm going to deselect all types here, and I'm going to choose App Service and App Service plan.
So we can see our app service plan resource and our web app or app service.
Let's start then by going into the app service plan and just poking around for a minute. So here in the Overview blade for the App Service plan, we can see some common metrics like CPU Percentage, Memory Percentage, Data In, Data Out.
This is all very relevant stuff to look at to determine the performance level of the apps that are linked to your service plan. Now, by the way, if you click on the Apps blade over on the left, you'll see the apps that are part of the service plan.
Currently, as we know, there is only one, our web app or our web app service. We can also take a look at the scaling up blade. So if we decide that, well, maybe we need less horsepower.
We're paying too much and we don't need the power, or we need more juice to be able to accommodate the web application workload.
This is the stuff that we saw when we were creating our web application and service plan. And also choose to scale out horizontally so we can configure auto scaling.
Now that's the app service plan. Let's go back to All resources and let's open up our actual app service or web application.
Because in here, we'll get a lot of details much like we did for the app service plan, but it's much more specific to our app.
So for example, we've got a URL here using the standard default DNS suffix. We've got a Browse button here we can click.
This is what the default page looks like based on my selections.
Naturally, you would change that, of course. But if we scroll down, we'll see some things that are available such as the Configuration blade.
There's a lot of stuff that you can configure here to tweak how your app behaves.
So we've got Connection strings such as for databases, the Default documents that'll be pulled up for different things such as the homepage. You've got Authentication / Authorization options.
So if you choose On here, you can select from quite a wide array of authentication providers such as Azure AD or Facebook, Google, Microsoft account, because by default, it's anonymous access. So we have a number of items here, Custom domains, TLS/SSL settings. We can also see here's where our WebJobs option is, and so on.
So at this point, we have deployed a simple code-based web application.


Docker Web App Deployment
  - Many developers these days deploy applications in containers.
  - A container is a logical isolation boundary in which you will find all of the application components. Now a larger application might consist of multiple containers with different modules or micro services. So luckily, we have an easy way to deploy containerized apps here in Azure. Whether you want to use a public container image, or you have your own private one that's tweaked to your needs.
Let's get started here in the portal. I'll click Create a resource. And just as if you were creating a regular web app as in not container based, you search up web, you click Web App, you click Create.
Now it's during the wizard, during creation, that we'll get to specify that we want a containerized application.
Now when you deploy this into a resource group, in this case, it's, let's say, I want to have a Linux-based VM hosting my containerized app. What I need to do is think carefully about the resource group placement.
I already have a resource group called Rg1 that already has a Windows-based web app. And mixing Windows and Linux when it comes to web apps and Docker containers and so on can cause problems in Azure. So in other words, you should have a separate resource group to deploy a Linux-based containerized app. So that's why I'm going to choose Rg7. There's nothing in there. And down below I have to specify the web app name. I'm going to call this dockerwebapptestyhz. And it's going to use the .azurewebsites.net DNS suffix, I can always change that later with the custom domain.
Now, here Code is the default, we don't want that. But before we switch it, notice we can select a Runtime stack depending on the language we want to use to write the code for our web app. But when you switch to Docker Container, you don't get that. So you have to put everything in the Docker Container. You get to choose whichever language or languages you want to use. So I can choose whether I want Linux or Windows as the back end VM engine. I'm going to leave it on Linux, let's say. And I'm going to put this in Canada Central.
And down below we've got an App Service Plan, it's going to create the App Service Plan. It contains the details about the sizing. We can see here it wants to use Premium V2 P1v2. 210 ACUs, an ACU is an Azure Compute Unit. It's a measure of the compute power that's available. Now that's fine. Having done that, I'm going to click Next to go to Docker. And this is where I can specify if I want to have just a single container.
So for a very small app, or maybe testing a single component, or a single microservice. Or I could have Docker Compose.
Docker Compose is a way to manage multiple related application containers. And you'll find that larger apps consist of multiple containers. In this case, though, I'm going to just go back to the simpler Single Container. And we have to choose where the container image comes from. A container image, you can think of is kind of like an operating system image.
Where it already has an operating system then the files and perhaps some configurations for that OS. And maybe even some apps and configurations. In the same way, a container image has all the software required to run a given piece of software. And maybe any tools and configuration settings available. So we can elect to pull an image from Quickstart. So we've got a couple of standard basic examples here.
This one's based on NGNIX. Or you can go to an Azure container registry that you might have created, where you've got your own private customized images, or maybe you want to go out to Docker Hub.
Docker Hub here lets you store publicly visible images.
And also you can store private ones up there if you have a Docker Hub account.
So let's say I go to Docker Hub. Now when I go to Docker Hub, I can search for something.
Let's say I'm looking for a WordPress type of website. So when I search for WordPress I'll have a lot of different container images.
And specifically here I've got the WordPress official image. And I can see the Docker command on a Docker host to pull down that container image locally would be docker pull wordpress. So wordpress is the name of that image.
That's important because back here in Azure, I need to specify that name here. And there are thousands upon thousands of container images available on Docker Hub.
You can optionally specify a start up command when the container starts. But the container does not house an operating system. That's one of the reasons containerized apps fire up so quickly. It's because they use the underlying OS already running. And in our case that's going to be Linux.
So the validation has passed. Let's go ahead and click Create to deploy our containerized web application. And after a moment, we can see the deployment is complete.
So let's click Go to your resource and let's check it out. So we will have created both a web app service as well as an app service plan.
Let's actually check that out, let's Duplicate this web page in the portal.
Now, we deploy this into a resource group called Rg7, so why don't we open up our navigation bar on the left, check out Resource groups.
And let's just click on Rg7, because in the Overview blade if we look towards the bottom right, we'll see the resources in that resource group.
And there's two of them, there's an App Service plan and an App Service, so that's our application.
All right, so that's fine, let's close the extra windows down we don't need them. So we're browsing our application. Now, depending on the container image you've selected will determine if there's a default webpage within that container.
So if I click Browse, don't be surprised if you don't get anything depending on the image you selected. So if you were to choose, let's say something like MySQL type of container image which is designed for the back end database, not for the front end web app. Well then you wouldn't get a webpage, it would pop-up. Because we selected the WordPress web app, then we do have this sample webpage that did pop-up.
But you can change this at any time, meaning you can change the container image that you're using. If you scroll down, you'll see that you can click on Container settings on the left because this is a containerized type of application.
So we can select the Image source, the same type of stuff we saw when we were creating this app. And we can see it's wordpress here.
You can simply type in the name of a different image, and optionally a tag. So a specific version if you want. And when you do that and Save the change, if you kind of look at the log at the bottom, you'll see new entries about it pulling down your new container. It may take a moment or two but it will do it. So it can pull down the container image and you can change it after the fact. But we have a lot of the same types of settings that we would for a regular web app.
Deployment slots for staging. So you're going to have a default production one that's always running when you build a web app.
You can change from anonymous to some kind of authentication, whether it's through Azure Active Directory, Facebook, Google, and so on.


App Service Plans and PowerShell
In this demonstration, I'm going to use PowerShell to deploy and manage an Azure website. So to get started, I've launched the Cloud Shell here in the portal. I'll just clear the screen.
To build our application, I'm going to use the New-AzWebApp cmdlet. And I'm going to specify the resource group that it will be deployed into. So -resourcegroup name, I've already got one called Rg7, specify that. And I have to specify a name for this. I'm going to call it lob, as in line of business, app1, and I'll just give it a couple of characters to make it unique.
I'm going to specify a location of CanadaEast, or actually how about we put in Canada Central. And next thing I'm going to do is specify an existing app service plan. You can build an app service plan. And remember, web apps are associated with an app service plan. I've already got one called AppSp1 as in service plan 1, let's go ahead and press Enter to see what happens.
And after a moment, we can see our web app has been created and it's currently listed as Running. Let's go ahead and run Get-AzWebApp, and we're going to specify that we want to see them in the resourcegroup Rg7. And we might as well just pipe that to select and tell it, we only want to see the Name instead of all the other details.
I can see there was already an existing web app in that resource group, but our newly created one is now showing up.
And we can also make changes, as well to some settings related to the web app.
Let's just flip over to the portal for a second here.
I'm just going to view my app services or web apps.
And I want to open up the line of business app that we just created.

[Video description begins] He clicks an option labeled "App Services" and a blade called "App Services" opens. It includes a list of web apps. [Video description ends]

So I'm just going to click to open that one up.

[Video description begins] He clicks a web app labeled "lobapp1yhz123" and the corresponding blade opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. [Video description ends]

Now once that opens up, we can see that indeed, we do have a sample web application. If we browse, it just got the standard welcome page the temporary or default web app page.

[Video description begins] He clicks a button labeled "Browse" and a web page opens in a new tab. It includes the text, "Hey, App Service developers!". [Video description ends]

So this is what it looks like. Let's just close that out.

[Video description begins] He closes the new tab. [Video description ends]

And also, let's just go down to the Configuration of this newly created web app, just to verify that there are no connection strings because we're about to add one by modifying this through PowerShell.

[Video description begins] In the navigation pane, he selects the Configuration option and its corresponding page opens in the content pane. [Video description ends]

So database Connection strings down at the bottom, there's nothing there. So let's go ahead and do that from PowerShell.

[Video description begins] He clicks a button labeled "Cloud Shell" and the PowerShell page opens. The prompt "PS /home/danlachance72>" is displayed. [Video description ends]

So the first thing I'm doing is establishing a variable called $cs for connection string and I'm initializing it as essentially an empty array or hash table. So we do that after the equal sign with an @ symbol, and then open and close curly brace. Next thing we're going to populate it. So $cs and in [ ] I'm creating an item called CustDb. Now I need to configure the value and type for that entry. So after that I'll put an = @{ I'm going to set the value to a sample connection string.

And then I'm going to set the Type to mysql and then I'll close the curly brace. So that's been done. Now we want to use that with the Set-AzWebApp cmdlet. So we're modifying your web app, we want to add that connection string to it. -resourcegroupname, it's Rg7, and the name of the app here was lb and so on. So I've got that there and then I'm going to use the -connectionstrings property and give it our variable $cs, let's press Enter.

[Video description begins] He executes the following command: Set-AzWebApp -resourcegroupname Rg7 lobapp1yhz123 -connectionstrings $cs. The output displays the lobapp1yhz123 web app and its properties. The prompt does not change. [Video description ends]

And it looks like it took so we can verify this by going back to the portal. Let's just Refresh our page here. And let's see if the connection string shows up now, and indeed, it does.
We can click on hidden value to actually see the connection string and the type here is listed as MySQL


Web App Container Image
In this demonstration, I'm going to change the container image used by a Docker based web application.

[Video description begins] The Microsoft Azure portal is open. In the portal, the App Services blade is open. [Video description ends]

So, here in the portal, I'm going to click on an existing web application that uses a Docker container.

[Video description begins] He clicks a web app called "dockerwebapptestyhz". Its corresponding blade opens. [Video description ends]

Now, we know this because if I scroll down in the navigation bar, we'll see Container settings. And that's actually where we want to go.

[Video description begins] In the navigation pane, he selects an option labeled "Container settings" and its corresponding page opens in the content pane. [Video description ends]

When you go to Container settings, you'll see the current association with this app with a container source. So at the top here we can see Azure Container Registry could be used. But what's selected as Docker Hub out on the Internet, or you might have your own private container registry that you've created on-premises. So I'm going to leave it on Public Repository Access for Docker Hub. Currently, it's using a wordpress container image.

[Video description begins] He points to the text, "wordpress" in a text box labeled "Image and optional tag (eg 'image:tag')". [Video description ends]

However, I can change it to any valid name and version of anything that's available on Docker Hub.

[Video description begins] He alters the text, "wordpress" to "mysql". [Video description ends]

So if I were to open up a new web browser window and go to Docker Hub, we would be able to specify what it is that we want to search for.

[Video description begins] He opens a web page called "Docker Hub". [Video description ends]

So if you search for mysql, you'll have to spell it correctly, of course. Then we'll get a lot of different search results.

[Video description begins] A page called "mysql" opens. [Video description ends]

And if we were to select, let's say, the first one we would see the Docker CLI command to reference that image to pull it down. docker pull mysql, so we know what's called mysql. So we can learn of the names and the tag information for images in this case, mysql.

[Video description begins] He switches to the tab in which the dockerwebapptestyhz blade is open. [Video description ends]

We can learn of that easily in this case by going to Docker Hub. Now that I've made that change, I'm going to go ahead and Save it.

[Video description begins] He clicks a button labeled "Save" and the text, "Settings updated successfully" appears. [Video description ends]

Now, it might take a moment or two before that actually gets applied. Because that would have to be then downloaded from Docker Hub. But that's going to be automatic. So if you scroll down and start looking at the date and time stamps.

[Video description begins] He points to a section called Logs. [Video description ends]

So you can see where it initially pulled down the WordPress Docker image from the public Docker repository.

[Video description begins] He highlights a log message. [Video description ends]

That's when it was set up initially. We go that way down towards the end, we'll be able to see that it's going to make a reference eventually that it's downloaded and applied the mysql container image from Docker Hub. And we can see here that we're starting to get messages. Now, I've clicked Refresh here to refresh the log where it downloaded the newer image for mysql. So mysql:latest is how it was tagged. And so we know that that is actually being used now within our web application.
Visual Studio App Deployment

[Video description begins] Topic title: Visual Studio App Deployment. The presenter is Dan Lachance . [Video description ends]

As a software developer, you might use a tool such as Microsoft Visual Studio to create and upload your web application to the Azure Cloud.

[Video description begins] A window called "Microsoft Visual Studio" is open. [Video description ends]

Have already downloaded and installed the free Microsoft Visual Studio Community Edition. I've already gone to manage my accounts to specify my credentials to log into Azure.

[Video description begins] In a pane called "Cloud Explorer", he points to an icon labeled "Account Management". [Video description ends]

And I can see my Azure subscription Pay-As-You-Go shown here. And if I examine that further by drilling down under it, I can see for example App Services. In other words, web applications and app service plans.

[Video description begins] In the Cloud Explorer pane, he points to a subnode labeled "dockerwebapptestyhz" under a node labeled "App Services". [Video description ends]

Remember that applications' web apps are tied to a service plan, and you can have multiple apps for a single service plan.

[Video description begins] He points to a subnode labeled "APPSP1" under a node labeled "App Service Plans". [Video description ends]

You can start to examine specific app services.

[Video description begins] He expands the dockerwebapptestyhz subnode. [Video description ends]

And look at the Deployment Slots that might be available for it, such as a testing one we see here and so on.

[Video description begins] Under a subnode labeled "Deployment Slots", he points to a subnode labeled "dockerwebapptestyhz(Testing)". [Video description ends]

But you can also create web applications directly here in Visual Studio and then publish them to Azure. So to get started, I'm going to go to File > New Project.

[Video description begins] A wizard opens. A page called "Create a new project" is open in the wizard. It is divided into two parts. The first part contains several recent project templates. The second part includes a list of templates. [Video description ends]

So in this example for ASP.NET Core web app, I'm going to select that and I'll click Next.

[Video description begins] In the second part, he selects a template labeled "ASP.NET Core Web Application". [Video description ends]

It's going to be called WebApplication4 I've got a local location, that's fine.

[Video description begins] A page called "Configure your new project" opens in the wizard. [Video description ends]

I'm okay with all of that. So I'm going to click the Create button to create this.

[Video description begins] A page called "Create a new ASP.NET Core Web Application" opens in the wizard. [Video description ends]

I'm going to deselect the Docker support. This isn't going to be a containerized app. It could be but I'm choosing not to here. I'll click Create and let it create my project.

[Video description begins] The wizard closes and a tab labeled "WebApplication4" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Publish" is selected and a page called "Publish" is open in the content pane. [Video description ends]

Now realistically, I would then start building my application and making changes to it. However, what I'm going to do here is publish it. So let's assume that we've made changes to our WebApplication4. So over the Solution Explorer towards the upper right, I'm going to right click on it and I'm going to choose Publish.

[Video description begins] He right-clicks a root node labeled "WebApplication4" and a list of options appears. [Video description ends]

I want to publish this as an Azure web application. So here in the main window, I'm going to click Start. And I want this to be App Service.

[Video description begins] He clicks a button labeled "Start" in the Publish page and a wizard opens. A page called Pick a publish target is open in the wizard. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "App Service" is selected and its corresponding page is open in the content pane. [Video description ends]

I want to create a new app service in the Azure environment.

[Video description begins] He points to a radio button labeled "Create New" in the content pane. [Video description ends]

So we'll go ahead and click on Publish.

[Video description begins] Another page called App Service Create new opens in the wizard. [Video description ends]

And here's the web application name it wants to use, it wants to use a unique name in Azure.

[Video description begins] He points to the name. [Video description ends]

Let's assume that that adheres to our company naming policy for applications in the Azure Cloud. Here's the subscription it will be tied to.

[Video description begins] He points to an option labeled "Pay-As-You-Go". [Video description ends]

And I can specify a resource group one that already exists, or I could let it create one if I really want to.

[Video description begins] He clicks a drop-down list box labeled "Resource group" and a drop-down list opens. [Video description ends]

But what I'm going to do is select an existing resource group, we do have the New button otherwise.

[Video description begins] He selects an option labeled "Rg3 (Canada East)". [Video description ends]

With the hosting plan, we can use an existing type of hosting plan or again, build a new one.

[Video description begins] He points to an existing hosting plan. [Video description ends]

So I'm going to go ahead and click Create.

[Video description begins] He points to a link labeled "New". [Video description ends]

So really all we're looking at here is yet another way to deploy a web app in Azure. The difference being that, as a developer, of course, you have the tools available in front of you to actually make core changes to the functionality of the app.

[Video description begins] The wizard closes. [Video description ends]

After a moment, if we look at the output window here at the bottom center of the screen in Visual Studio, we can see the Build succeeded. Looks like everything has been done successfully restart a web app. Let's check it out in the portal. Here are the portal I'm viewing my App Services.

[Video description begins] He opens the Microsoft Azure portal. In the portal, the App Services blade is open. It includes the newly created web application. [Video description ends]

And indeed, there's our newly created web application.

[Video description begins] He selects the web application and the corresponding blade opens. [Video description ends]

And if we were to click the Browse button at the top of the Overview blade, it would link to the URL and give us our sample page for this application.
App Services Custom Domains

[Video description begins] Topic title: App Services Custom Domains. The presenter is Dan Lachance . [Video description ends]

When you deploy a web application or app service in Azure, you get a default DNS domain suffix. Let's take a look at that, because you'll often want to change that.

[Video description begins] The Microsoft Azure portal is open. In the portal, the App Services blade is open. [Video description ends]

And that's the purpose of what we're doing here, to configure a custom DNS domain. I'm going to click on an existing web app.

[Video description begins] He clicks the dockerwebapptestyhz web app and the corresponding blade opens. In the navigation pane, the Overview option is selected and its corresponding page is open in the content pane. [Video description ends]

And in the Overview blade over on the right, when it pops up, I will see the URL, the default suffix of which is azurewebsites.net. And I can click the URL, I can click the Browse button, same thing. And depending on the nature of the app will determine what you see next.

[Video description begins] In a new tab, a WordPress web page opens. [Video description ends]

This is an app that has a web front end and it's a simple WordPress page. So that's what I'm seeing. So it is working but it's using the azurewebsites.net name. What if we want to use something different, we want to call it something different.

[Video description begins] He closes the new tab. [Video description ends]

So what I'm going to do then is scroll down in the navigation bar for the web app, and I'm going to go to Custom domains.

[Video description begins] He clicks an option called Custom domains and the corresponding page opens in the content pane. [Video description ends]

Any existing custom domains will be shown, we don't have any here, so I want to click Add custom domain.

[Video description begins] A blade called "Add custom domain" opens. [Video description ends]

I want this web app referred to as www.lanchanceit3.com.

[Video description begins] In a text box labeled "Custom domain", he enters the text, "www.lachanceit3.com". [Video description ends]

Where lanchanceit3.com is a DNS domain that I already own and have registered to a public DNS registrar outside of Azure. But I need to make sure or Azure needs to make sure that I really own that. So I'm going to click Validate.

[Video description begins] Several options appear in the blade. [Video description ends]

Here, I can select either CNAME or an A record and down below, it gives me instructions on what needs to be created in my DNS zone.

[Video description begins] He clicks a drop-down list box called Hostname record type and points to a list of options. [Video description ends]

Now this is all validated. It says the hostname is available and you own the domain.

[Video description begins] He switches to a tab in which a web page labeled "Domain Manager" is open. [Video description ends]

Well, how did it know? Well, I've already gone ahead and created a CNAME record that is instructed with the value of www and then the actual value of this current name.

[Video description begins] He highlights "dockerwebapptestyhz.azurewebsites.net". [Video description ends]

And now that that's there, it checked for that and that's why we have domain ownership.

[Video description begins] He switches to the Microsoft Azure portal. [Video description ends]

So I'm going to click Add custom domain.

[Video description begins] He points to www.lachanceit3.com in the Custom domains page. [Video description ends]

And we can see now, it's been added here to the list. However, it says Not Secure. It's not been secured with SSL. But that's a whole separate issue. Let's just see here. What happens if we go back to the Overview page.

[Video description begins] In the navigation pane, he selects the Overview option and its corresponding page opens in the content pane. [Video description ends]

And we used to have the default azurewebsites.net suffix, but notice now, we have our custom domain name, lachanceit3.com and then www.

[Video description begins] He points to a URL: "http://www.lachanceit3.com". [Video description ends]

So we can browse to that to make sure that it responds and it works perfectly.

[Video description begins] The WordPress web page opens in a new tab. [Video description ends]

The only thing is that it's not currently secured over HTTPS. But again, that's a separate issue. At this point, we've configured a custom DNS domain name for an Azure Web App.
App Services SSL/TLS Bindings

[Video description begins] Topic title: App Services SSL/TLS Bindings. The presenter is Dan Lachance . [Video description ends]

It's important to secure communications over the Internet to web app by using HTTPS. The S is for secure versus just plain old HTTP. But to do that, you need a PKI certificate. And you need to configure a binding to use that with your web application.

[Video description begins] The Microsoft Azure portal is open. In the portal, the All resources blade is open. [Video description ends]

We're going to do that. So we're going to start by generating a PKI certificate here in Azure. To do that, we need a Key Vault. Luckily, I've got a bunch of them.

[Video description begins] In a search box, he enters the text, "kv" and the search result displays two options. [Video description ends]

So I'm going to filter my list of all resources here for kv, and I've got one called KV1East1, that's Key Vault.

[Video description begins] He clicks an option labeled "KV1East1" and a blade called "KV1East1" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. [Video description ends]

You can store many different types of secrets in a Key Vault, including certificates. So I'm going to click Certificates.

[Video description begins] The corresponding page opens in the content pane. [Video description ends]


I can choose to generate or import one. I'm just going to generate a PKI certificate.

[Video description begins] He clicks a button labeled "Generate/Import" and a blade called "Create a certificate" opens. [Video description ends]

The idea being that I want to use it with an Azure hosted web application. It wants a certificate name. I'm going to call it CustomWebSite1. It's going to be a Self-signed certificate. The subject name will be cn, common name, so cn=www.lachanceit3.com. I've already configured this as a custom DNS domain name for my web application.

[Video description begins] He highlights the text, "www.lachanceit3.com". [Video description ends]

Now, that's important because what people are connecting to in the browser, for example, must match what's in the certificate. Otherwise, it's not going to work properly. It won't be secured.

[Video description begins] He clicks an option labeled "DNS Names" and a blade called "DNS Names" opens. [Video description ends]

For DNS Names, I'm going to click that and over on the right for the DNS Name, I'm going put in the same thing, www.lachanceit3.com. That's my custom DNS domain name. I'll click OK.

[Video description begins] The DNS Names blade closes. [Video description ends]

And that's really all I'm going to do here. So let's get this certificate created. I'll click Create. We're going to reference it in a minute when we go to the web app to enable our TLS or SSL binding.

[Video description begins] The Create a certificate blade closes. [Video description ends]

Now, SSL is deprecated. We should never use it. We should only be using newer versions of TLS for security reasons. Okay, I'm going to go into my navigation bar on the left. Go to choose App Services because I want to go to my web app where I want to use that certificate.

[Video description begins] The App Services blade opens. [Video description ends]

I've got one here, it's called dockerwebapptestyhz.

[Video description begins] The corresponding blade opens. [Video description ends]

If I click on that, notice in the Overview blade, we'll see the current URL.

[Video description begins] He points to the http://www.lachanceit3.com URL . [Video description ends]

It's only using HTTP.

But it is using a custom DNS domain name. And that has to match the subject name in our certificate, the common name, which it does. So let's get this working. I'm going to scroll down on the left, got to go to TLS/SSL settings.

And the first thing that I want to do is make sure I go to Private Key Certificates.

[Video description begins] The corresponding page opens in the content pane. [Video description ends]

And I need to make sure that I bring one in. I'm going to import a Key Vault Certificate.

[Video description begins] In the page, he selects a tab labeled "Private Key Certificates (.pfx)". [Video description ends]

Basically, the one we just created.

[Video description begins] He clicks a button labeled "Import Key Vault Certificate" and the corresponding blade opens. [Video description ends]

So I need to select the Key vault, KV1East1.

[Video description begins] He clicks a drop-down list box labeled "Key vault" and selects an option labeled "KV1East1". [Video description ends]

There's our certificate, CustomWebSite1.

[Video description begins] He clicks a drop-down list box labeled "Certificate" and selects an option labeled "CustomWebSite1 (Thumbprint:pending)". [Video description ends]

So I'm going to go ahead and choose Select. So after we've imported the Key Vault Certificate here, that's fine.

[Video description begins] The blade closes. The TLS/SSL settings page is open. [Video description ends]

But the next thing is we can then actually use it for an SSL, or TLS in our case, type of binding.

[Video description begins] He clicks an option labeled Custom domains and the corresponding page opens in the content pane. [Video description ends]

So to do that, over on the left, I'm going to go to Custom domains where I'm going to see the existing custom domain I have here. But it's not secured.

[Video description begins] He highlights the www.lachanceit3.com custom domain. [Video description ends]

All we have to do is click Add binding over here on the right.

[Video description begins] The corresponding blade opens. [Video description ends]

And we've already brought that certificate in here. So there's my custom domain, Choose certificate.

[Video description begins] He points to a drop-down list box labeled "Custom domain" in which an option labeled "www.lachanceit3.com" is preselected. [Video description ends]

There it is.

[Video description begins] He clicks a drop-down list box labeled "Private Certificate Thumbprint". A drop-down list opens, which contains one drop-down option. He selects the option. [Video description ends]

And I'll just choose SNI.

[Video description begins] He clicks a drop-down list box labeled "TLS/SSL Type" and selects an option labeled "SNI SSL". [Video description ends]

And then I'll choose Add Binding. So what we're doing is binding this self-signed certificate to our custom DNS domain name. And now it says SSL state secure. Well, it shouldn't really say SSL. Because whether you're using SSL or TLS, technically is defined by how your web browsers are configured and how your web server stack is configured. But at any rate, we'll let it go. Let's go up to Overview. Let's just check out what's going on here with the URL to our web application.

[Video description begins] He selects the Overview option in the navigation pane. The corresponding page opens in the content pane. [Video description ends]

Now it says HTTPS. And if we click that to browse to it, it says the site's not secured.

[Video description begins] He points to the https://www.lachanceit3.com URL and then clicks on it. A web page opens in a new tab. [Video description ends]

Well, of course, that's expected. It's a self-signed certificate. You can install the public root certificate for the signer if we really wanted to in all our devices to suppress this. I'm going to click Details and say no, it's good. Go on to the web page. We know this.

[Video description begins] The WordPress web page opens. [Video description ends]

And there's my web page, which is now being served up over HTTPS.
App Service Deployment Slots

[Video description begins] Topic title: App Service Deployment Slots. The presenter is Dan Lachance . [Video description ends]

In this demonstration, I'm going to use the Azure Portal to create a deployment slot. You can create deployment slots for testing purposes, so that you can keep a production version of your web app available while having a different URL, so different DNS name, for your deployment slot as you do testing.

[Video description begins] The Microsoft Azure portal is open. In the portal, the App Services blade is open. [Video description ends]

And then you can swap out deployment slots. So once your testing is successful, you can make that the production version of the web app. So here's how it's done.

[Video description begins] He clicks the dockerwebapptestyhz web app and the corresponding blade opens. In the navigation pane, the Overview option is selected and its corresponding page is open in the content pane. [Video description ends]

Here in the portal, I'm going to click on an existing web app, open up its navigation bar, and the first thing I'll do is scroll down and choose Deployment slots.

[Video description begins] The corresponding page opens in the content pane. [Video description ends]

We'll see that there is a default deployment slot for every web app and it's called PRODUCTION, we can see it's currently Running. So what I'm going to do then, is I'm going to click Add slot up at the top.

[Video description begins] A blade called "Add a slot" opens. [Video description ends]

I'm going to call this one Testing. And I'm going to choose to Clone settings from the original app that we're in in the first place.

[Video description begins] He clicks a drop-down list box labeled "Clone settings from" and a drop-down list opens. He then selects an option labeled "dockerwebapptestyhz". [Video description ends]

When you clone settings, you're cloning things like connection strings, HTTP version settings, and so on. So I'm going to choose to Clone settings from our source web application. Now after a moment, it says it successfully created the slots.

[Video description begins] A link labeled "dockerwebapptestyhz-Testing" appears in the page. [Video description ends]

So I'm going to go ahead and click Close, and sure enough we can see the slot is listed here as Running and it shows up as a link. Now that's because we are currently in the PRODUCTION slot.

[Video description begins] He points to dockerwebapptestyhz. [Video description ends]

If I click that link to open up our Testing slot, and in it, it looks and feels just like the whole web application.

[Video description begins] He clicks the dockerwebapptestyhz-Testing link and the corresponding blade opens. [Video description ends]

But notice at the top, we're in our Testing version of the app, a different deployment slot.

[Video description begins] He highlights "Testing (dockerwebapptestyhz/Testing)". [Video description ends]

And so when I go down to the Deployment slots from within it, notice that neither shows as a link because we're actually looking at it from the perspective of the deployment slot.

[Video description begins] He clicks an option called Deployment slots in the navigation pane and the corresponding page opens in the content pane. [Video description ends]

So I'm going to click the X to close out of here.

[Video description begins] He points to dockerwebapptestyhz and dockerwebapptestyhz-Testing. [Video description ends]

And I want to make sure we're back on the original app.

[Video description begins] In the navigation pane, he selects the Overview option and its corresponding page opens in the content pane. [Video description ends]

Now when I say original app, I mean the real App Service. We can see by looking at the name that we are in the real App Service.

[Video description begins] He highlights "dockerwebapptestyhz". [Video description ends]

Notice the URL happens to be a custom DNS domain name with an SSL binding.

[Video description begins] He points to the https://www.lachanceit3.com URL. [Video description ends]

But notice that if we go back into the Deployment slots, let's do this once again. I'm going to click on the link for the deployment slot. Let's look at its URL in the Overview blade so always keep your eye on the naming up here at the top.

[Video description begins] He clicks the dockerwebapptestyhz-Testing link and the corresponding blade opens. [Video description ends]

So notice that what we're looking at here is we have a different name for the deployment slot. It doesn't use our custom DNS name at all.

[Video description begins] He points to a URL labeled "https://dockerwebapptestyhz-testing.azurewebsites.net". [Video description ends]

So you get a different DNS name then for that purpose. And if you start making configuration changes, you would do it, for example, in your testing deployment slot. So let's say I go down to Configuration.

[Video description begins] In the navigation pane, he selects an option labeled "Configuration" and its corresponding page opens in the content pane. [Video description ends]

And maybe I'll go down and make a change to a connection string used for a database or something like that. So down below, there are no connection strings. Let's say, we want to add one, and I'm doing this in the deployment slot.

[Video description begins] He clicks a button labeled "New connection string" and a blade called "Add/Edit connection string" opens. [Video description ends]

So I'm going to call this BackendDB, and maybe the value is just going to be testdbstring, it's going to be for MySQL. We also can turn on this Deployment slot setting. When we do that, it means that this setting is only for the deployment slot. But I don't want to do that. So it's part of my testing, I'm going to click OK, and I'm going to Save that change.

[Video description begins] He clicks a button labeled "Save" and a pop-up box labeled "Save changes" appears. [Video description ends]

So I'll click Continue. Now the reason I didn't want that to be a sticky setting for the deployment slot only is because based on our testing, if it works out well, then we might want to make sure that that setting is propagated to our production slot. So let's close out of this one. And when I say this one, I'm referring to, if you look at the name, our deployment slot for testing.

[Video description begins] He clicks the "X" icon and the Testing (dockerwebapptestyhz/Testing) blade closes. [Video description ends]

And let's go back to our primary one. So we're in our primary web application.

[Video description begins] He points to the dockerwebapptestyhz blade, in which a page called "Deployment slots" is open. [Video description ends]

What I want to do, actually, we can do it either here in the Deployment slots view, we can Swap, or we can do it from the Overview page. It doesn't make a difference. You could have a swap option there.

[Video description begins] In the navigation pane, he selects the Overview option and its corresponding page opens in the content pane. [Video description ends]

Swapping means you want to take another Deployment slot and make it production, for example. So I'm going to click the Swap button.

[Video description begins] A blade called "Swap" opens. [Video description ends]

And what I want to do is I want the source to be testing, and I want to swap it with the target of production.

[Video description begins] He points to the text, "dockerwebapptestyhz-Testing" in a field labeled "Source". [Video description ends]

Notice down below, it picks up the change, the source change. The source, of course, is our deployment testing slot. That's great. So I'm going to swap this out. So I'm going to click Swap. And essentially, after you've tested your testing deployment slot and the web app store works correctly, by swapping it to production, it results in no downtime.

[Video description begins] He points to the text, "dockerwebapptestyhz" in a field labeled "Target". [Video description ends]

And so this is as opposed to as in the old days in the 90s and early 2000s, when you might visit a site and see a site under construction webpage, there's no longer a need for that when using Deployment slots. So we can see it successfully completed the swap. I'm going to close out here. So we're still looking at our main application as in not looking at it from the perspective of within a deployment slot.

[Video description begins] He highlights the dockerwebapptestyhz blade. [Video description ends]

And if I were to scroll down, let's say, and just go down to Settings and Configuration, I want to take a look at the connection string.

[Video description begins] The corresponding page opens in the content pane. [Video description ends]

And so when I scroll over to the right, and then of course scroll down, let's see what's going on. Notice that our connection string has been brought over from our testing deployment slot.

[Video description begins] He points to the BackendDB connection string. [Video description ends]

So that's just an example of a setting, as opposed to actually change the content in the site, that comes across when you perform the swap.
App Service Scaling

[Video description begins] Topic title: App Service Scaling. The presenter is Dan Lachance . [Video description ends]

When you deploy an application in the Azure Cloud, sometimes you won't know how much underlying horsepower you're going to need, or how many virtual machines you'll need to support the workload.

[Video description begins] The Microsoft Azure portal is open. In the portal, the App Services blade is open. [Video description ends]

We're talking here both about vertical scaling with horsepower, and horizontal scaling with the number of nodes supporting an application. So luckily, we can change that after the fact. Now remember that when you deploy a web app in Azure, it needs to be associated with an App Service plan. The App Service plan is actually where you configure the scaling.

[Video description begins] He clicks the lobapp1yhz123 web app and the lobapp1yhz123 blade opens. [Video description ends]

Let's take a look at this first from the perspective of an application, a web application service. So when I click on the web app to open it up, if I scroll down in the options, I'll see that I have Scale up and Scale out.

[Video description begins] He scrolls down in the navigation pane. [Video description ends]

Now, it says, App Service plan, here in parentheses. So, what I could also do is look at this from the perspective of the App Service plan.

[Video description begins] He opens the Home page. [Video description ends]

Let me open up an existing App Service plan here called APPSP1.

[Video description begins] A blade called "APPSP1" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. [Video description ends]

We'll see the exact same thing here.

[Video description begins] He scrolls down in the navigation pane. [Video description ends]

Under Settings, we'll see Scale up and Scale out.

[Video description begins] In the navigation pane, he points to options labeled "Scale up (App Service plan)" and "Scale out (App Service plan)". [Video description ends]

The scaling up or down means you're either increasing or decreasing respectively the horsepower, like number of CPU compute units, or ACUs, Azure Compute Units, as they're called for web apps.

[Video description begins] He selects the Scale up (App Service plan) option in the navigation pane and its corresponding page opens in the content pane. [Video description ends]

Scaling out would be for horizontal scaling, adding or removing virtual machine nodes.

[Video description begins] He points to the Scale out (App Service plan) option in the navigation pane. [Video description ends]

Let's start here with scaling up. Currently we can see our current pricing tier, 210 total ACU, 3.5 gig of RAM.

[Video description begins] Under a section labeled "Recommended pricing tiers", he points to an option labeled "P1V2 210 total ACU 3.5 GB memory Dv2-Series compute equivalent 103.72 CAD/Month (Estimated)". [Video description ends]

Let's say that we've determined that for the web apps associated with this App Service plan, remember, when you go to Apps, you will see one or more apps associated with this service plan.

[Video description begins] A corresponding page opens in the content pane. [Video description ends]

We also see we have a deployment slot here too.

[Video description begins] In the page, he points to several apps. [Video description ends]

So they are all consuming the resources that you would see here under Scale up, they are all together consuming the ACUs, the Azure Compute Units, and the 3.5 gig of RAM.

[Video description begins] He points to a type "slot" adjacent to an app labeled "dockerwebapptestyhz/Testing". [Video description ends]

So you might find over time that it's just not enough, and if that's the case, you can Scale up.

[Video description begins] He selects the Scale up (App Service plan) option in the navigation pane and its corresponding page opens in the content pane. [Video description ends]

So let's say we're going to switch it over to 420 total ACU 7 gigs of RAM.

[Video description begins] He points to the P1V2 210 total ACU 3.5 GB memory Dv2-Series compute equivalent 103.72 CAD/Month (Estimated) option. [Video description ends]

So I just simply select that and choose Apply.

[Video description begins] Under the Recommended pricing tiers section, he selects an option labeled "P2V2 420 total ACU 7 GB memory Dv2-Series compute equivalent 206.50 CAD/Month (Estimated)". [Video description ends]

Now as you might guess, you're going to pay more for this. So only do this, if you need it. Also, if you're just experimenting with these web applications in Azure, make sure you delete them when you're finished.

[Video description begins] A message appears with the text, "The plan 'APPSP1' was updated successfully!". [Video description ends]

Of course, not if you're using them for business purposes, but, because if you don't remove them, and they're left running constantly, you are paying for that, even though you might not be using it.

[Video description begins] He clicks an icon labeled "Notifications" and a notification with the text, "The plan 'APPSP1' was updated successfully!" is displayed. [Video description ends]

So be very careful with that. So at this point, if we're looking at our notification bar, it currently updated our service plan.

[Video description begins] He selects the Scale out (App Service plan) option in the navigation pane and its corresponding page opens in the content pane. [Video description ends]

We are now using the P2V2 pricing tier for production.

[Video description begins] In a section labeled "Choose how to scale your resource", he points to a radio button labeled "Manual scale", which is preselected. [Video description ends]

We also have scaling out options.

[Video description begins] He moves a slider adjacent to a field labeled "Instance count" and sets its value to "11". [Video description ends]

Currently, we can manually scale, pretty now we've got an instance count of 1.

[Video description begins] He points to the Apps option in the navigation pane. [Video description ends]

So we could manually drag the slider over to determine how many underlying instances are available for our applications.

[Video description begins] In the page, he selects a radio button labeled "Custom autoscale" in the Choose how to scale your resource section. [Video description ends]

Now this is the number of instances of course that are available for the apps associated with this App Service plan, we looked at that under the Apps blade.

[Video description begins] Adjacent to a field labeled "Scale mode", he points to a radio button labeled "Scale based on a metric", which is preselected. [Video description ends]

We could also choose auto scaling instead of just manually setting a fixed number of virtual machine workers.

[Video description begins] He clicks a link labeled "Add a rule" and a blade called "Scale rule" opens. [Video description ends]

So we can go down here and we could specify a metric.

[Video description begins] He points to a drop-down list box labeled "Metric name", in which an option labeled "CPU Percentage" is preselected. [Video description ends]

And we might say that after a metric has been violated or exceeded, we'll say, let's Add a rule here for that.

[Video description begins] He scrolls down through the blade and points to a text box labeled "Metric threshold to trigger scale action" with the text "70". [Video description ends]

Then we can add or remove virtual machine nodes.

[Video description begins] He points to a text box labeled "Instance count" with the text "1". [Video description ends]

So we could specify after the CPU percentage gets to a specific value, CPU percentage, then we could specify that we want to start adding items.

[Video description begins] He clicks an icon labeled "X" and the blade closes. [Video description ends]

So when it's greater than 70%, duration of 10 minutes, then we can tell it we want it increased by a single instance.

[Video description begins] He clicks a button labeled "Discard" and a pop-up box labeled "Discard" appears. He then clicks a button labeled "Yes" and the page refreshes. [Video description ends]

So we do have the option to enable horizontal scaling as well.

[Video description begins] He selects the Scale up (App Service plan) option in the navigation pane and its corresponding page opens in the content pane. [Video description ends]

I'm just going to Discard those settings.

[Video description begins] He points to the P2V2 420 total ACU 7 GB memory Dv2-Series compute equivalent 206.50 CAD/Month (Estimated) option. [Video description ends]

So currently, all we've really done here is juiced up the underlying Azure Compute Units or ACUs, and the amount of RAM available to the apps associated with this App Service plan.

[Video description begins] He selects the Apps option in the navigation pane and its corresponding page opens in the content pane. [Video description ends]
App Service Backup

[Video description begins] Topic title: App Service Backup. The presenter is Dan Lachance . [Video description ends]

You can easily configure backup for an Azure web application using the portal. Here in the portal, I've already navigated to an existing web application.

[Video description begins] The Microsoft Azure portal is open. In the portal, the lobapp1yhz123 blade is open. [Video description ends]

And in the navigation bar, I'm just going to scroll down under Settings and choose Backups.

[Video description begins] A corresponding page opens in the content pane. [Video description ends]

Backup has not been enabled here. So we can see it says, Backup is not configured. Click here to configure it. So we could do it there or we could click the Configure button at the top, it makes no difference. We have to think about where we want the backups stored.

[Video description begins] He clicks a button labeled "Configure" and a blade called "Backup Configuration" opens. [Video description ends]

So it says, Storage not configured. We're going to change that, so I'm going to click right on that.

[Video description begins] He clicks an option labeled "Storage Settings Storage not configured" and a blade called "Storage accounts" opens. [Video description ends]

I'm going to select an existing storage account where I want backups to be stored.

[Video description begins] He clicks a storage account labeled "storacct333325" and a blade called "Containers" opens. It includes a list of containers. [Video description ends]

And I'm going to add a Container.

[Video description begins] He clicks a button labeled "Container" and a blade called "New container" opens. [Video description ends]

I have to create a container here with the name of my web app, -backup. And I'll leave the Public access level to Private.

[Video description begins] In a text box labeled "Name", he points to the text, "lobapp1yhz123s-backup". [Video description ends]

And I'm going to Create this container.

[Video description begins] He clicks a button labeled "Create" and the blade closes. A message appears with the text, "Successfully created storage container 'lobapp1yhz123s-backup'." A new container labeled "lobapp1yhz123s-backup" is added in the list. [Video description ends]

That's where I want these backups for this app to be stored.

[Video description begins] He selects the lobapp1yhz123s-backup container. [Video description ends]

So I'm going to go ahead and select that container and click the Select button at the bottom. So now it has that.

[Video description begins] The blade closes. The Storage Settings Storage not configured option changes to "Storage Settings lobapp1yhz123s-backup". [Video description ends]

Next is scheduling. Do you want to backup manually or do you want it to be on an automated schedule? I'd like an automated schedule. So I'll click On.

[Video description begins] He sets a toggle button to "On" adjacent to a field labeled "Scheduled Backup". [Video description ends]

And down below, we can see it's set to backup once every day.

[Video description begins] He points to a text box labeled Backup Every with the text "1" and a toggle button, which is set to an option labeled "Days". [Video description ends]

Now having done that, that's fine. But I'm going to scroll down exactly when. So we can tell it when, on which date, we want to start the schedule. And the timing, well, I can change the timing or I can leave it as it is.

[Video description begins] He points to a text box labeled Start backup schedule from in which a date is specified and another text box in which a time is specified. [Video description ends]

So let's say we want this to happen at, 7 o'clock PM. And of course, we have to select the appropriate time zone when we want that backup to kick in. The default retention value is 30 days, I'm going to leave that. And if we have backups of databases, then that would be probably a good idea if your application consists of them. But we don't have any within this web application. So we don't have to worry about selecting databases to be backed up.

[Video description begins] He points to a table in a section labeled "Backup Database". [Video description ends]

At this point, I'll click Save and our Backup Configuration is now saved.

[Video description begins] The Backup Configuration blade closes. [Video description ends]

Now we can see the schedule is reflected here when the backup will next occur. However, what we can also do is start the backup.

[Video description begins] He clicks an option labeled "Backup configured, scheduled backup started on Tuesday, March 31, 2020, 7:0:0 PM ADT. Backup will happen every 1 Day(s)" and the Backup Configuration blade opens. [Video description ends]

So I'm going to do that by clicking directly on the Backup button. And it says, Successfully submitted backup request. Excellent, so now we've got both a scheduled backup, and at the same time we've manually started one.

[Video description begins] He clicks a button labeled "Discard" and the Backup Configuration blade closes. [Video description ends]

Back here on this main page where we clicked the Backup button, notice at the bottom the status says that the backup is currently in progress for our web application. So depending on how much content there is, and whether there are backend databases that contain a lot of data, will determine the size, which we see here is currently 0 MB, and how long it takes for the backup to occur.

And you can click the Refresh button and eventually you'll see that the backup Succeeded. We can see the backup date and time. We also have the option of clicking Restore. So there's no point in taking backups if you're not at least going to periodically test that Restore works correctly.

[Video description begins] He clicks a button labeled "Restore" and a blade called "Restore Backup" opens. [Video description ends]

So for the Restore source, I'm going to choose App backup and we can select the backup. We only have one here.

[Video description begins] He points to a drop-down list box labeled "Select the Backup to Restore" in which an option labeled "Backed up Tuesday, March 31, 2020, 2:30:17 PM ADT" is preselected. [Video description ends]

And we can determine the target App Service application or the web app where we wanted to restore this to. Let's just scroll over just a little bit so we can see a little bit more of what's happening. So the default is to Overwrite the destination.

[Video description begins] He points to a toggle button labeled "Restore destination" which is set to an option labeled "Overwrite". [Video description ends]

But we could tell it that we want to select a new or another existing app to restore this backup to. And we can determine if we want to ignore conflicting host names when we restore or ignore the databases as part of the restore. And then we would go ahead and click OK to begin restoring from the backup.
Azure Batch Overview

[Video description begins] Topic title: Azure Batch Overview. The presenter is Dan Lachance . [Video description ends]

Azure Batch is a cloud service in Azure that's used for automation and job scheduling. So what it's really about is Batch processing for on-demand jobs against a pool of computers.

[Video description begins] Azure Batch. [Video description ends]

So parallel processing or High-Performance Computing, HPC, you could say. Azure Batch requires you to first create an Azure Batch account. Next, within that, you can define a pool, which is the configuration for the operating system details related to the virtual machines that will run your batch jobs. You can then define a job and associate it with a pool.

[Video description begins] Azure Batch Workflow. [Video description ends]

So Azure Batch begins with uploading scripts or apps that will handle your workloads, whether it's for some kind of engineering application, or climate modeling, or some kind of medical model of some kind. The next thing that you need to do is make sure you create a job, after which you can add job tasks.

The job tasks, and you can get away with one task within a job, is what actually triggers running things like scripts or executables. Finally, you can schedule this to occur, either one time or on a recurrent interval. Now bear in mind, that you're going to need to make sure your Azure Batch account is associated with the storage account.
Azure Batch Accounts

[Video description begins] Topic title: Azure Batch Accounts. The presenter is Dan Lachance . [Video description ends]

In this demonstration, I'm going create an Azure Batch account. I'll create a Batch account so that I can define jobs I want to run on demand or on a schedule basis against a pool of VMs.

[Video description begins] The Microsoft Azure portal is open. In the portal, the Home page is open. [Video description ends]

So this is for batch processing of jobs. You don't need the compute power all the time.

[Video description begins] A blade called "New" opens. [Video description ends]

So to start, I'll click Create a resource and I'm going to search for Batch.

[Video description begins] A blade called "Batch Service" opens. [Video description ends]

And then, I'm going to choose Batch Service. And then I'll click Create.

[Video description begins] A blade called "New Batch account" opens. A tab labeled "Basics" is open in the blade. [Video description ends]

Okay, first thing I need to do is select a Resource group I want to deploy this Batch account into and give it a name.

[Video description begins] Adjacent to a field labeled "Resource group", he clicks a drop-down list box and a drop-down list opens. He then selects an option labeled "Rg1". [Video description ends]

I'm going to call this BatchEast1. Now notice it says it's not valid, it's because of the uppercase letters.

[Video description begins] An error message appears with the text, "The Batch account name "BatchEast1" is invalid". [Video description ends]

So let's just go ahead, put lowercase letters and it loves it. We'll put this in Canada East. I'll just click Next for Advanced.

[Video description begins] Adjacent to a field labeled "Location", he points to a drop-down list box, in which an option labeled "(Canada) Canada East" is preselected. [Video description ends]

Pool allocation mode, the pool is the collection of VMs that will process your Batch jobs.

[Video description begins] A tab labeled "Advanced" opens. [Video description ends]

I'm going to let it be handled by the Batch service, so that's fine. Next, no tags.

[Video description begins] He clicks a button labeled "Next: Tags" and a tab labeled "Tags" opens. [Video description ends]

Let's make sure the validation has passed, it has.

[Video description begins] He clicks a button labeled "Next: Review + create" and a tab labeled "Review + create" opens. [Video description ends]

Let's create the Batch account by clicking Create.

[Video description begins] A blade called "Microsoft.BatchAccount_2020_3_31_17_12_24" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. [Video description ends]

And after a moment that deployment is complete. Let's click, Go to resource and let's poke around a little bit.

[Video description begins] A blade called "batcheast1" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. [Video description ends]

Now the first thing that we want to really do here actually is link this Batch account with an Azure Storage account. So I'm going to click Storage account over on the left.

[Video description begins] A corresponding page opens in the content pane. [Video description ends]

Now you do this because depending on the nature of your job tasks that you're going to have running through Azure Batch. They might reference resources stored in the storage account, such as data files if you're doing big data processing.

[Video description begins] A blade called "Choose storage account" opens. [Video description ends]

Or you might need a storage account to store the output or the result of running your Batch jobs. Either way, I'm going to click Select a storage account. And I'm going to go ahead and choose one that I've already got created.

[Video description begins] He selects a storage account labeled "storacct333325" and the blade closes. [Video description ends]

All right, even though it's in a different region, it's okay. It still adds it, it's all good to go. So now that we've got the storage account associated with it, let's just go back to the Overview for a moment.

[Video description begins] He opens a window called "BatchExplorer: Login to Azure Public(Default)". [Video description ends]

You can also download the BatchExplorer GUI tool for free if you want to manage your Batch account using this interface instead of the portal. So I'm just going to go ahead and sign in with my Azure credentials so we can at least see it.

[Video description begins] A page called "Batch Explorer" opens in the window. In the window, several tabs are displayed. A tab labeled "Dash" is open. It is divided into two parts: navigation pane and content pane. [Video description ends]

So when I sign in, I can see over on the left, it's discovered in my pay-as-you-go subscription that we've got a Batch account called batcheast1 in canadaeast. We can also create a New Batch account over here. So I'm just going to go ahead and double-click on it.

[Video description begins] In the navigation pane, he double-clicks a batch account labeled "batcheast1" and its corresponding information is displayed in the content pane. [Video description ends]

And here I have all these great little metrics, Failed tasks, core number of minutes, things we're running, Task states, Current node states. I can also view Jobs, Job schedules, and Pools.

[Video description begins] He opens a tab labeled "Certificate". [Video description ends]

Packages for applications, perhaps PKI certificates that would be used for each pool virtual machine to authenticate to an external service. Back here in the portal we can also see we have the Open in Batch Explorer button here on the Overview blade.

[Video description begins] He switches to the Microsoft Azure portal, in which the batcheast1 blade is open. [Video description ends]

And we also have a few metrics here that we can see like the vCPU and Failed tasks, and so on. If you're going to be creating custom software that you want to run in Azure Batch, then you'll probably want to know which key to use.

[Video description begins] In the navigation pane, he selects an option labeled "Keys" and its corresponding page opens in the content pane. [Video description ends]

You've got Keys here that you use to authenticate, you've got a primary and a secondary key, it doesn't matter which one.

[Video description begins] He points to fields labeled "Primary access key" and "Secondary access key". [Video description ends]

You've also got the Batch account name and the URL and the ID and so on for the storage account. But the primary and secondary access keys can be used when you require programmatic access using the Batch API for Azure.
Azure Batch Applications

[Video description begins] Topic title: Azure Batch Applications. The presenter is Dan Lachance . [Video description ends]

When you configure Azure Batch you need to configure job tasks. And a task can reference scripts or programs such as executable programs that are used to do some kind of Batch processing, whether it's big data analytics, or whether it's looking at genetic engineering research, or climate modeling, or financial model, could be anything. So here on-premises, I've got a custom app executable.

[Video description begins] The File Explorer window is open. In the window, a folder labeled "Tmp" is open. It contains a file labeled "CustomApp1.exe". [Video description ends]

And what I need to do is zip it up. So I can just right-click and use tools such as 7-Zip to add it to an archive, which I'm going to do.

[Video description begins] He right-clicks the CustomApp1.exe file and a shortcut menu opens. [Video description ends]

It's going to be CustomApp1.zip, and I'll click OK.

[Video description begins] A dialog box labeled "Add to Archive" opens. [Video description ends]

Because that is what I can then upload as an app into my Azure Batch account.

[Video description begins] The dialog box closes. A folder labeled "CustomApp1.zip" appears. [Video description ends]

So here in the portal, I've navigated into my Batch account where I'm going to start by scrolling down and choosing Applications.

[Video description begins] He opens the Microsoft Azure portal. In the portal, the batcheast1 blade is open. [Video description ends]

From here, I'm going to click the Add button.

[Video description begins] A corresponding page opens in the content pane. [Video description ends]

I have to give this a couple of details, I've got to fill in an Application id a Version number, and then I have to select the Application package.

[Video description begins] A blade called "New application" opens. [Video description ends]

In this case, it's our on-prem zip file. So the Application id, I'm going to call this CustomApp1, Version number let's say, 1.0 and I'm going to select the file. So there it is CustomApp1.zip. Let's go ahead and Submit that.

[Video description begins] He clicks a button labeled "Submit". An application labeled "CustomApp1" appears in the page. [Video description ends]

Back here, my on-premises system, if you've got other files, here I've got a PowerShell Script called AnalyzeData.

[Video description begins] He switches to the File Explorer window. In the window, the Tmp folder is open. [Video description ends]

Well, you can zip that up as well.

[Video description begins] He points to the CustomApp1.exe file and another file labeled "AnalyzeData.ps1". [Video description ends]

And we could have zip them both up at the same time and put them in one zip file, but I'm going to go ahead and zip this up separately.

[Video description begins] He points to the CustomApp1.zip folder. [Video description ends]

So I'll just add it to an archive again.

[Video description begins] He right-clicks the AnalyzeData.ps1 file and a shortcut menu opens. He selects an option labeled 7-Zip. A flyout opens. He then selects an option labeled "Add to archive". The Add to Archive dialog box opens. [Video description ends]

And it's going to be called AnalyzeData.zip.

[Video description begins] He clicks a button labeled "OK" and a folder labeled "AnalyzeData.zip" appears. [Video description ends]

As you might guess back here in the portal, I'm going to click the Add button to add that as another application.

[Video description begins] He switches to the Microsoft Azure portal. In the portal, the batcheast1 blade is open. In the navigation pane, an option labeled "Applications" is selected and its corresponding page is open in the content pane. [Video description ends]

Now you might not want the package together if you plan on using them separately.

[Video description begins] The New application blade opens. [Video description ends]

But if you plan on using them together, make sense put them in the same zip file. This is going to be called Analyze Data PowerShell Script. I'm going to call it and Version will be 1.0 again. It doesn't like my spaces. So I'm just going to replace that with underscores.

[Video description begins] In a text box labeled "Application id", he enters the text, "Analyze_Data_PowerShell_Script". [Video description ends]

That's fine and then I'll select that Application package here.

[Video description begins] He selects a file labeled "AnalyzeData.zip" under a field labeled Application package  [Video description ends]

Once that's done, I'll click Submit and we'll have two applications added to add our Azure Batch account as we can see listed here.

[Video description begins] The New application blade closes. An application labeled "Analyze_Data_PowerShell_Script" appears in the page. He points to the Analyze_Data_PowerShell_Script and CustomApp1 applications. [Video description ends]

You can also click on an application you've added to the Batch account here and you can add more items within it.

[Video description begins] He clicks the Analyze_Data_PowerShell_Script application and a blade called "Analyze_Data_PowerShell_Script" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. It includes a table with a single row and several columns. [Video description ends]

What I could do there, I'll be adding versions.

[Video description begins] He points to a button labeled "Add". [Video description ends]

Currently we can see we've got version 1.0 of our zip file, and we can see the last activation time so when it was brought into the Batch account.

[Video description begins] In the table, he points to row entries labeled 1.0 ,zip and Mar 31, 17:24:43 under column headers labeled name ,Format and Last activation time respectively. [Video description ends]

And you can use the menu on the right to either Delete that version or even Update it.

[Video description begins] Adjacent to the row, he clicks an icon labeled "Context menu" and a menu opens. [Video description ends]

If you've got a new version for example of the PowerShell Script with changes that were required, or you could keep multiple versions because you could add a version 2.0, if you need to run an old version of something in a new version of something.

[Video description begins] In the menu, he clicks an option labeled "Update" and the New application blade opens. [Video description ends]

Remember, these are applications that will be used for Batch job processing.

[Video description begins] He clicks an icon labeled "X" and the New application blade closes. [Video description ends]

You might need an older version for handling certain types of file formats, for example, and a newer version to handle newer versions of those files that might need to be processed.

[Video description begins] He clicks the Add button and the New application blade opens. [Video description ends]

So maybe I'll put in version 2.0.

[Video description begins] He selects the AnalyzeData.zip file under the Application package field. [Video description ends]

And I could upload another application package which I will do and I'll Submit it.

[Video description begins] He clicks the Submit button and the blade closes. [Video description ends]

So what we'll see then is that we've got if I just click Refresh that we've got two versions of that app within a single application.

[Video description begins] A new added with a row entry labeled "2.0" is added in the table. [Video description ends]

That's how it's stored.

[Video description begins] He clicks an icon labeled "X" and the blade closes. [Video description ends]

So there's a bit of a hierarchy here, when you're working with these applications.

[Video description begins] He points to the Analyze_Data_PowerShell_Script and CustomApp1 applications. [Video description ends]

The applications ultimately get used when you start creating pools of virtual machines.

[Video description begins] In the navigation pane, he points to an option labeled "Pools". [Video description ends]

You can associate many items with a pool, including these application packages.
Azure Batch Pools

[Video description begins] Topic title: Azure Batch Pools. The presenter is Dan Lachance . [Video description ends]

Here in the portal, I've already got an Azure Batch account created.

[Video description begins] The Microsoft Azure Portal is open. In the portal, the batcheast1 blade is open. [Video description ends]

And I've already added a couple of applications such as scripts or custom apps, maybe executables that'll be used for job processing.

[Video description begins] In the navigation pane, he selects the Applications option and its corresponding page opens in the content pane. He then points to the Analyze_Data_PowerShell_Script and CustomApp1 applications. [Video description ends]

So now what I'm going to do is configure a pool within this Azure Batch account. The pool defines some details related to the horsepower that's actually going to get the job done.

[Video description begins] In the navigation pane, he selects the Pools option and its corresponding page opens in the content pane. [Video description ends]

In other words, virtual machine nodes. So under Pools, I'm going to click Add.

[Video description begins] A blade called "Add pool" opens. [Video description ends]

And I'll have to fill in well, quite a few details to be honest. The first of which is a Pool ID. Let's call it poolab567, just an ID. And the Display name here will be Pool1. Down below, I have to choose the location where I want to grab virtual machine images from.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "Image Type", and a drop-down list opens. [Video description ends]

So the standard Azure Marketplace, or maybe a Custom Image. I might have a Shared Image Gallery, or just a pure Custom Image, not shared at all. Or I might want to use a virtual machine image designed or optimized rather for Graphics and rendering, if that's the nature of my Batch jobs. But here I'm just going to choose Marketplace.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "Publisher", and a drop-down list opens. [Video description ends]

Publisher, in this case, microsoftwindowsserver, the offer's filled in with windowsserver. And then I choose the details here, let's say 2016-datacenter with a smalldisk.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "Sku", and a drop-down list opens. [Video description ends]

Maybe I know that the nature of the VM itself is that it won't need a lot of storage space. Because maybe my running task, whether it's a script or an exe is coded to maybe retrieve data feeds from a storage account, or something like that. So that's fine. So I don't need any additional data disks for that. And as I scroll down, I can select the sizing for each individual VM node within the pool that we're defining right now.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "VM size (View full pricing details)", and a drop-down list opens. [Video description ends]

And I could even Auto scale this.

[Video description begins] He sets a toggle button to an option labeled "Auto scale" adjacent to a field labeled "Mode". [Video description ends]

So I could write a formula to determine when items should be auto scaled, when we should start adding nodes.

[Video description begins] He points to a text box adjacent to a field labeled "Formula". [Video description ends]

For help, you can click the link down below to view some samples of what those formulas might look like.

[Video description begins] He clicks a link labeled "Click here to view sample autoscale formulas" and a blade called "Sample autoscale formulas" opens. [Video description ends]

So we see an example over here on the right where we can see it's setting the target dedicated nodes, or you can just leave it at Fixed.

[Video description begins] In the blade, he points to a line of code "$TargetDedicatedModes = $isWorkingWeekdayHour ? 20:10;". [Video description ends]

We aren't actually going to be running this, but you should have at least a minimum of 1.

[Video description begins] In the Add pool blade, he sets the toggle button to an option labeled "Fixed" adjacent to the Mode field. He then closes the Sample autoscale formulas blade. [Video description ends]

Well actually, let's do that. Let's set 1 target dedicated node. You'll see why in a moment. We can also determine if there should be a Start task that we want to configure here which would be executed when a new VM joins the pool.

[Video description begins] He opens a drop-down list box adjacent to a field labeled "Start task" and selects an option labeled "Enabled". [Video description ends]

But that doesn't apply here. So I'm just going to choose Disabled. And I'm going to go down and associate this pool with an existing application package.

[Video description begins] He selects an option labeled "Application packages" and a blade called "Application packages" opens. [Video description ends]

Now the application package will have software, whether it's scripts, or what not, or executables that we want to use for job processing.

[Video description begins] He clicks a drop-down list box under a field labeled "Application" and a drop-down list opens. [Video description ends]

So let's say I've got a PowerShell Script here, maybe I want the second version of it, and maybe I've got custom app here.

[Video description begins] In the drop-down list, he selects an option labeled "Analyze_Data_PowerShell_Script". A new drop-down list box appears under the Application field. [Video description ends]

Let's see what we got for only version 1.0, okay.

[Video description begins] He clicks a drop-down list box under a field labeled "Version" and a drop-down list opens. He then selects an option labeled "2.0". A new drop-down list box appears under the Version field. [Video description ends]

So version 1.0 of that, these were already created here within the Azure Batch account.

[Video description begins] He clicks the new drop-down list box under the Application field and a drop-down list opens. He then selects an option labeled "CustomApp1". A new drop-down list box appears under the Application field. [Video description ends]

So I'm going to Select that.

[Video description begins] He clicks the new drop-down list box under the Version field and a drop-down list opens. He then selects an option labeled "1.0". A new drop-down list box appears under the Version field. [Video description ends]

And I have to associate this with the virtual networks.

[Video description begins] He points to the Analyze_Data_PowerShell_Script and CustomApp1 options selected in the drop-down list boxes. [Video description ends]

So, because really, we are going to be running virtual machines, it's just that this is a managed service.

[Video description begins] He clicks a button labeled "Select" and the blade closes. [Video description ends]

It'll take care of a lot of the underlying work for us.

[Video description begins] In the Add pool blade, he selects an option labeled "Network Configuration Select a virtual network" and a blade called "Choose virtual network" opens. [Video description ends]

We're just giving it some details.

[Video description begins] He selects an option labeled "Vnet2" and the blade closes. [Video description ends]

So Vnet2, let's say I want the VMs to run in Subnet1.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "Subnet" and a drop-down list opens. He then selects an option labeled "Subnet1". [Video description ends]

I don't want the VMs to have public IPs unless they need them perhaps to access an external service to perhaps ingest data. And I don't have any existing Server licenses, No.

[Video description begins] He points to a toggle button labeled "Already have a Windows Server license?", which is set to "No". [Video description ends]

So I'll click OK.

[Video description begins] The Add pool blade closes. A message appears with the text, "Pool 'poolab567' was created successfully". A pool labeled "poolab567" appears and adjacent to it, an icon labeled "X" is present. [Video description ends]

Well, the pool was created successfully, but this little red circle with an X doesn't look good.

[Video description begins] He clicks the poolab567 pool and a blade called "poolab567" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. [Video description ends]

What's up with that? Let's click and let's read. The specified account has reached core quota. Click here for details.

[Video description begins] He clicks a link labeled "The specified account has reached core quota. Click here for more details" and a blade called "Resize errors - poolab567" opens. [Video description ends]

Okay, doesn't really tell us much. Alright, remember how we set the fact that we wanted one node, we didn't use auto scaling. Well, let's take a look here.

[Video description begins] He clicks an icon labeled "X" and the blade closes. [Video description ends]

Let's go back into our Batch account here, and let's scroll up here and go into Quotas.

[Video description begins] He switches to the batcheast1 blade. [Video description ends]

There are some default quota values here for a number of items.

[Video description begins] A corresponding page opens in the content pane. [Video description ends]

Such as the maximum Active jobs and schedules, the maximum number of Pools you can create in this account. And if we look down below, how many Low-priority vCPUs for VMs can we have, 0. Total dedicated VCPUs, 0. No wonder we have a problem. Okay, so that's not a good thing, but it's not a big deal. All we have to do is request a quota increase from Microsoft. To do that, I just click the link, I'm just following what's there in front of me with the messages.

[Video description begins] He clicks a button labeled "Request quota increase" and blade called "New support request" opens. In the blade, a tab labeled "Basics" is open. [Video description ends]

And for the selected option, it's Azure services, the issue here would be a Service and subscription limit quota increase.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "What is your issue related to?" and a drop-down list opens. He then selects an option labeled "Azure services". [Video description ends]

And there are few other details to specify, the quota type here is going to be for Azure Batch.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "Issue type" and a drop-down list opens. [Video description ends]

So I'll click the Next Solutions button.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "Quota type" and a drop-down list opens. [Video description ends]

We just have to then target a specific Batch account in a region where this is an issue for us.

[Video description begins] A tab labeled "Details" opens in the blade. [Video description ends]

So to do that, I'll have to click Enter details first.

[Video description begins] A blade called "Quota details" opens. [Video description ends]

And for the location here, let's just choose Canada East, only because I know that's where my Batch account is located.

[Video description begins] He clicks a drop-down list box labeled "Location" and a drop-down list opens. [Video description ends]

And I can tell it that look, I know I'm going to want to use D Series VMs in my pool.

[Video description begins] He then clicks a drop-down list box labeled "Batch account" and a drop-down list opens. He then selects an option labeled "batcheast1". [Video description ends]

So it really depends on your pool config, the sizing. But assuming that that was applicable, the Current limit is 0.

[Video description begins] He clicks a drop-down list box labeled "Select Quotas to Update (current values shown in parenthesis)" and a drop-down list opens. He then selects a checkbox labeled "D Series (0)". [Video description ends]

We could say, I want the New limit to be 2, or whatever the value is. However, we would click Save and continue, but I'm not going to I do that because I don't actually want to request that quota increase. So at this point, we've got the pool created within the Azure Batch account.
Azure Batch Jobs and Schedules

[Video description begins] Topic title: Azure Batch Jobs and Schedules. The presenter is Dan Lachance . [Video description ends]

When you want jobs to be processed through Azure Batch, you have to define jobs and schedules. So here in the portal, I'm looking at an existing Batch account.

[Video description begins] The Microsoft Azure portal is open. In the portal, the batcheast1 blade is open. [Video description ends]

And in the navigation bar, I'm going to scroll down under Jobs. I've already got an application in a pool configured a pool of VMs.

[Video description begins] In the navigation pane, he points to the Applications and Pools options. [Video description ends]

So I'm going to go to Jobs.

[Video description begins] A corresponding page opens in the content pane. [Video description ends]

So we're going to add a job and then within that, we're going to add at least one task. So I'm going to start by clicking Add.

[Video description begins] A blade called "Add job" opens. [Video description ends]

Let's get the job defined first. So job, put in a unique value here.

[Video description begins] In a text box labeled "Job ID", he enters the text "jobyhz56". [Video description ends]

And I'm going to select a pool, I have to associate the job with the pool.

[Video description begins] He clicks an option labeled "Pool Select a pool to run the job on" and a blade called "Select pool" opens. [Video description ends]

We've already got a pool created.

[Video description begins] He points to a pool labeled "poolab567". [Video description ends]

So I'm going to select it from the list and choose Select. There it is.

[Video description begins] The Select pool blade closes. The Pool Select a pool to run the job on option changes to "Pool poolab567". [Video description ends]

And that's it. I don't need any advanced settings or anything like that. I'm going to click OK. So there's the job.

[Video description begins] The Add job blade closes. A job labeled "jobyhz56" appears in the page. [Video description ends]

However, I need to go into the job and within it, add at least one task to actually get something done.

[Video description begins] He clicks the jobyhz56 job and a blade called "jobyhz56" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Tasks" is selected and its corresponding page is open in the content pane. [Video description ends]

So I'm going to click Add.

[Video description begins] A blade called "Add task" opens. [Video description ends]

And I'm going to enter a Task ID, and then a Display name, Run PowerShell, actually Run custom app, let's say Run custom app.

[Video description begins] He enters the text, "taskyhz24" in a text box labeled "Task ID". [Video description ends]

And let's say I've got a custom app called customapp1.exe.

[Video description begins] He enters the text, "customapp1.exe" in a text box labeled "Command line". [Video description ends]

Now that, of course, would be pulled from an application package. So customapp1.exe and I can determine how long it's allowed to run.

[Video description begins] He clicks the Application packages option and the Application packages blade opens. [Video description ends]

And down below, I'm going to associate with an application package that I've already uploaded with that executable can be found, so that would be in CustomApp1.

[Video description begins] Under the Application field, he clicks the drop-down list box and the drop-down list opens. He then selects the CustomApp1 option. [Video description ends]

And I want version 1.0, and I'll choose Select.

[Video description begins] Under the Version field, he clicks the drop-down list box and the drop-down list opens. He then selects the 1.0 option. [Video description ends]

Okay, so, at that point, we're ready to go, ready to Submit the task at least.

[Video description begins] The Application packages blade closes. [Video description ends]

So we've got a task within the job.

[Video description begins] He clicks a button labeled "Submit" and the Add task blade closes. A task labeled "taskyhz24" appears in the page. [Video description ends]

Let's go back here, because now I want to schedule a job.

[Video description begins] He switches to the batcheast1 blade. [Video description ends]

I don't need Certificates here because I don't have any of my scripts or custom apps that will need to authenticate with specific types of services.

[Video description begins] In the navigation pane, he selects an option labeled "Job schedules" and its corresponding page opens in the content pane. [Video description ends]

So I'm going to need to do that.

[Video description begins] In the navigation pane, he points to an option labeled "Certificates". [Video description ends]

Job schedules. Let's Add a schedule.

[Video description begins] He clicks a button labeled "Add" and a blade called "Add job schedule" opens. [Video description ends]

So I need a Job schedule ID. So I'm just going to fill in some details here.

[Video description begins] He enters the text, "job123567" in a text box labeled "Job schedule ID". [Video description ends]

The Display name, I'm just going to call it Job1. And sometimes, you might need to specify metadata for, well, it really depends on your scripts or your applications that you're running and what services they're talking to. However, I'll leave that empty for now. And I'm going to tell it I want it to run on a particular day.

[Video description begins] In a text box labeled "Do no run until", he clicks an icon and a calendar opens. He then selects a date "03/31/2020". The text, "12:00 AM" is populated in a text box adjacent to the Do not run until text box. [Video description ends]

Now it says here it has to run after certain date and time based on the current time right now.

[Video description begins] An error message appears with the text, "The value must be on or after 03/31/2020 5:41:21 PM. [Video description ends]

So I'm just going to put here, let's say 5:43 PM and it likes that.

[Video description begins] In the text box, he alters the text to "5:43 PM". [Video description ends]

It's going to be a Recurrence interval of Disabled. I just want it run one time and I have to click Update here to associate it with an existing pool. So I'm going to go ahead and choose that from the list.

[Video description begins] The Select pool blade opens. He selects the poolab567 pool. [Video description ends]

And then I'll choose Save. There's the pool it's selected.

[Video description begins] The Select pool blade closes. In a text box labeled "Pool ID", the text, "poolab567" is populated. [Video description ends] \

I can determine down below things like if I want an unlimited of time for this to run or retry count.

[Video description begins] He points to a toggle button labeled "Max wall clock time" set to "Unlimited" and then point to a toggle button labeled "Max task retry count" set to "None". [Video description ends]

And maybe what to do when tasks complete. However, I'm just going to go ahead and click Save to save the schedule.

[Video description begins] The Add job schedule blade closes. A job schedule labeled "job123567" appears in the page. [Video description ends]

So now we've got a job schedule, I can click on it.

[Video description begins] He clicks the job123567 job schedule and a blade called "job123567" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. [Video description ends]

Now I can check up on it to see if it's run by going under Execution info. Now there's no end time here, it says n/a so it's not yet run. So I can click Refresh if it's suppose to run soon to make sure that I see the results of running that job.

[Video description begins] He points to a link labeled "job123567:job-1" adjacent to a field labeled "Recent job id". [Video description ends]

And so after a few minutes, we can see here we've got a Recent job id, it's a link. I'm going to click on it to open it up and here we can get some stats as to where there's an active job currently it's running, what succeeded and what failed.

[Video description begins] A blade called "job123567:job-1" opens. [Video description ends]

Now, if we don't have anything that succeeded or fail, what does that mean? It could mean the job is still in the midst of running.

[Video description begins] He clicks a button labeled "Refresh" and the blade refreshes. [Video description ends]

Or it could mean that there's a problem.

[Video description begins] He clicks an icon labeled "X" and the blade closes. [Video description ends]

Now you can follow this link with the recent job URL here.

[Video description begins] He highlights a URL labeled "https://batcheast1.canadaeast.batch.azure.com/jobs/job123567:job-1" adjacent to a field labeled "Recent job url". [Video description ends]

Just paste that into another web browser window, which I'll do here. And you might gain some insight here we can see, well, it's not a big deal.

[Video description begins] A web page opens in a new tab. It includes several lines of code. [Video description ends]

We're just missing some items here. So the parameter value for api-version, for example, has not been supplied.

[Video description begins] He highlights a line of code, "key":"QueryParameterName","value":"api-version". [Video description ends]

So depending on your scripts or your code. If it's not using this specific value, such as in an HTTP request header, then you might get this kind of result.
Azure Container Solutions

[Video description begins] Topic title: Azure Container Solutions. The presenter is Dan Lachance . [Video description ends]

Azure Kubernetes Service, otherwise called AKS, deals with application containers in plural. It's an orchestration solution, if you've got an application or some kind of dependency between multiple containers. You can even migrate existing application containers that you might have on-premises into the Azure cloud, or you can define your AKS cluster and work with brand new containers.

[Video description begins] Azure Kubernetes Service (AKS). [Video description ends]

So it's clusters of containers, which means you'll have to specify some details about things like sizing for the nodes within the cluster. AKS replaces the older Azure Container Service or ACS that you might see some literature reference.

[Video description begins] Application Containers. [Video description ends]

An application container, as we see in the diagram, is a logical boundary in which we run an application, or an application component. I say that because you might have a larger app that uses multiple containers, each container runs its own specialized task or micro service. They all work together. So pictured in the diagram, we've got application containers running across the top, labeled as APP A, B, C, all the way through to G. Now, this runs on top of an operating system, a host OS, as we see labelled here, that would be running, for example, the Docker Engine.

And the binaries and libraries that might be referenced by our APP Components within the containers. Some of those might be within the container themselves, or they can be referenced by the container. Containers really show up as processes running in the host OS. So unlike a virtual machine, they don't contain the OS. They use the underlying existing OS it's already running. So containers start up very quickly because of this. So containers are based on container images, just like you might use an OS image to reimage a computer, if it's not behaving correctly.

The image itself contains software, and perhaps settings for running a container. So you could say that a container is a runtime instance of an image. In the container, you'll have application software components and settings, whether it's custom software or commercial off the shelf software. Maybe some app-specific libraries, maybe a runtime environment, and also some tools. All of this can exist within a single container.

[Video description begins] Azure Kubernetes Service. [Video description ends]

AKS, then, can be deployed using the CLI, using the portal. You can also manage it using Azure Cloud Shell, including using the kubectl, or kube control command line tool. You'll be used to that if you already have experience running Kubernetes outside of the Azure environment.
Azure Kubernetes Service

[Video description begins] Topic title: Azure Kubernetes Service. The presenter is Dan Lachance . [Video description ends]

Azure Kubernetes Service is a container orchestration service. Now, often instead of saying Azure Kubernetes Service, we'll call it AKS. Where we can have individual containers that run applications or application components, what if we have multiple containers, maybe a big app consists of multiple micro services, each of which is in a container.

[Video description begins] The Microsoft Azure Portal is open. In the portal, the Home page is open. [Video description ends]

You need a way to schedule when they should load up, and when to monitor them, and what kind of state they should be running in. And that's where Azure Kubernetes Service comes in. Let's click Create a resource, and I'm going to search for kubernetes.

[Video description begins] The New blade opens. [Video description ends]

And I'm going to choose Kubernetes Service, and then I'll click Create.

[Video description begins] A blade called "Kubernetes Service" opens. [Video description ends]

This is something that was developed at Google.

[Video description begins] A blade called "Create Kubernetes cluster" opens. In the blade, a tab labeled "Basics" is open. [Video description ends]

So I'm going to have to specify some details to build this, such as the Resource group into which I want to deploy this because we're going going to be building a cluster essentially of Linux virtual machines to handle our containerized application, or applications.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "Resource group" and a drop-down list opens. He then selects an option labeled "Rg1". [Video description ends]

So I'm going to call this AKS, so that's an Azure Kubernetes Service, Cluster1. Okay, after doing that, I specify the Region, the version of Kubernetes, the DNS name prefix. I will accept the defaults for that, and then I get to determine the node sizing for each node, and I can specify how many nodes I want in the cluster.

[Video description begins] He points to a slider adjacent to a field labeled "Node count". [Video description ends]

Notice that you can't get any lower than 1 but you can drag it way, way up.

[Video description begins] An error message appears with the text, "The maximum node count you can select is 4 due to the remaining quota in the". [Video description ends]

However, you're going to get to a point where you exceed the quota in your subscription. You can always request, like make a service request or support requests to ask for an increase, but I'm just going to go back and leave this down at, let's say, at 2.

[Video description begins] A tab labeled "Scale" opens in the blade. [Video description ends]

I'll click Next for scaling, I'm going to leave the default or VM scale sets being enabled here for scaling. I'll click Next for authentication.

[Video description begins] A tab labeled "Authentication" opens in the blade. [Video description ends]

We are going to let it create a new default service principle and we'll leave RBAC enabled if we want to use RBAC to control access to Kubernetes cluster resources.

[Video description begins] He points to a toggle button labeled "Enable RBAC", which is set to "Yes". [Video description ends]

And then I'll click Next.

[Video description begins] A tab labeled "Networking" opens in the blade. [Video description ends]

I want this to be a Private cluster, so I'm going to enable that only using private IP addresses. I can also determine if I want to have a customized network configuration by choosing Advanced, but I'm just going to let it do it itself, so I'll leave it on Basic.

[Video description begins] He clicks a button labeled "Next: Monitoring" and a tab labeled "Monitoring" opens in the blade. [Video description ends]

Next, I've got some monitoring options, which I'm going to leave as the default settings, Tags, and finally, we can validate this configurational.

[Video description begins] He clicks a button labeled "Next: Tags" and a tab labeled "Tags" opens in the blade. [Video description ends]

I'll click Next to review and create.

[Video description begins] A tab labeled "Review + create" opens in the blade. [Video description ends]

There was a quick message, it said I was creating the service principle, now it's running the final validation, it passed. Let's create our Azure Kubernetes cluster, so I'll click Create to do that.

[Video description begins] A blade called "AKSCluster1" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. [Video description ends]

Now that our cluster has been deployed in the Overview page, we can see over on the right for example that we've got 1 node pool. We can even monitor any containers, although there are none by default.

[Video description begins] He clicks an option labeled "Monitor containers" and a page called "Insights" opens in the content pane. [Video description ends]

Put any containers, after we get our containerized app running in the cluster, we'll be looking at things like CPU utilizations, and we can kind of monitor the health of it. Over on the left, I'm going to pull up the Node pools blade, we defined a node pool when we deployed the cluster.

[Video description begins] A corresponding page opens in the content pane. It includes a table with one row and several columns [Video description ends]

And we can see it's listed here, it's of type Linux, and there are two nodes. Now, I can either click the link for the 2, in this case, 2 nodes in the cluster. Or I can click the context menu, either way, we'll have an option for Scale.

[Video description begins] Adjacent to the row, he clicks an icon labeled "Context menu" and three options appears. He then points to an option labeled "Scale". [Video description ends]

So if I click on the 2, for example, we can configure manual as well as autoscaling.

[Video description begins] Under a column header labeled "Node count", he clicks a row entry labeled "2" and a blade called "Scale" opens. [Video description ends]

If we decide that we want to make sure the cluster accommodates our container workload properly, I'm just going to cancel that.

[Video description begins] He clicks a button labeled "Cancel" and the blade closes. [Video description ends]

But what we don't see are settings related to actually getting a container, an existing container in here. What if we already have containerized applications, how do we get them in the cluster? Let's move on the development side, but basically, you should really create an Azure Container Registry, upload container images to it. You're also going to need a Kubernetes manifest file, a YAML file, in order to get your apps in here. We do have the option here of Dev Spaces over on the left.

[Video description begins] In the navigation pane, he selects an option labeled "Dev Spaces" and its corresponding page opens in the content pane. [Video description ends]

So you can use Dev Spaces here to start to build solutions and debug them that'll run in containers within the cluster.
Azure Container Instance

[Video description begins] Topic title: Azure Container Instance. The presenter is Dan Lachance . [Video description ends]

You can deploy Azure Container Instances, or ACIs, when you have a single container that you want to run.

[Video description begins] The Microsoft Azure portal is open. In the portal, the Home page is open. [Video description ends]

Now if you have multiple containers and you need to manage them as a unit, then you're better off looking at AKS, Azure Kubernetes Service. But for a single container, ACI or Azure Container Instances is fine. So here in the portal, let's get this configured.

[Video description begins] The New blade opens. [Video description ends]

I'm going to click Create a resource.

[Video description begins] A blade called "Container Instances" opens. [Video description ends]

And I'm going to search for container instance, and I'll choose Container Instances, and I'll click Create.

[Video description begins] A blade called "Create container instance" opens. [Video description ends]

So I'm going to deploy this into an existing Resource group.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "Resource group" and a drop-down list opens. He then selects an option labeled "Rg1". [Video description ends]

And I'm going to call this, for lack of a better name, Container1. Now, the only thing is it won't like the uppercase letters, so let's put lowercase c and this time, it's good, passes all the validations for the nomenclature.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "Region", and a drop-down list opens. [Video description ends]

For the Region, I'm going to go ahead and specify something in Canada that's near me such as Canada Central. And now what do I use as the source for this application container image, it can be a quick start image.

[Video description begins] He clicks a drop-down list box adjacent to a field labeled "Image", and a drop-down list opens. [Video description ends]

So whether we want to use a standard helloworld example to get started, running in Linux, or using nginx as the HTTP engine, or Microsoft IIS web server, we have the choice of that. We can also point to an Azure Container Registry, or ACR.

[Video description begins] He selects a radio button labeled "Azure Container Registry" adjacent to a field labeled "Image source". [Video description ends]

You can build an ACR in Azure as a repository where you store your own custom container images and you can reference them from here. Or you can go online to Docker Hub and look at either public or private images that are available up there.

[Video description begins] He selects a radio button labeled "Docker Hub or other registry" adjacent to the Image source field. [Video description ends]

I'm just going to go ahead and choose Quickstart images and I'm going to use, let's see, well actually, let's use the helloworld Linux variant.

[Video description begins] He clicks the drop-down list box adjacent to the Image field, and the drop-down list opens. [Video description ends]

I can also choose the sizing here, the horsepower I need to support the workload running in the container.

[Video description begins] In the drop-down list, he selects an option labeled "microsoft/aci-helloworld (Linux)". [Video description ends]

I'm not going to change that, but I am going to click Next for networking.

[Video description begins] He points to an option labeled "1vpcu 1.5 Gib memory, 0 gpus" adjacent to a field labeled "Size". [Video description ends]

So I can make this publicly available, so I need a DNS name label.

[Video description begins] A tab labeled "Networking" opens in the blade. [Video description ends]

So let's call this containeryhztest, and it's going to use the .canadacentral.azurecontainer.io DNS suffix by default. And depending on what is running in that container instance, will determine which ports need to be open. It's already got port 80 open for this quick start sample, that's fine. I'm going to click Next for Advanced.

[Video description begins] A tab labeled "Advanced" opens in the blade. [Video description ends]

I'm not going to configure anything here, I'm just going to click Next, no tags.

[Video description begins] A tab labeled "Tags" opens in the blade. [Video description ends]

So after that, we're just going to have it validate our selections.

[Video description begins] He clicks a button labeled "Next : Review + create" and a tab labeled "Review + create" opens in the blade. [Video description ends]

So it's running the final validation we see in the upper left. We can see the validation has passed, let's click Create to build our container instance.

[Video description begins] A blade called "Microsoft.ContainerInstances-20200331181558" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. [Video description ends]

And with the deployments complete, I'm going to click Go to resource and let's check it out.

[Video description begins] A blade called "container1" opens. It is divided into two parts: navigation pane and content pane. In the navigation pane, an option labeled "Overview" is selected and its corresponding page is open in the content pane. [Video description ends]

So I'm in the Overview blade of our container instance, we can see a few details. We can see some metrics, how busy is it? Well, there's not very much going on here in terms of CPU utilization, not a lot of memory is really being used. And down below, network transfer for bytes received versus transmitted is minimal. Now the next thing we should do though, is take a look at the containers. Let's click Containers.

[Video description begins] In the navigation pane, he selects an option labeled "Containers" and its corresponding page opens in the content pane. It includes a container labeled "container1". [Video description ends]

Here we're going to see a reference for the container that was deployed. In this case it was our helloworld, and it's called container1, and notice the state of it is such that, it's currently Running.

[Video description begins] In the page, a tab labeled "Events" is open. It includes a table with several rows and columns. [Video description ends]

And down below we can see some events, the container was Created, Started, and it pulled the image here from a repository.

[Video description begins] He points to the row entries in the table. [Video description ends]

And also what's interesting, we can even view some log information here about what's been happening in the background.

[Video description begins] He opens a tab labeled "Logs" in the page. [Video description ends]

So we can see our container, in this case is listening on port 80. Containers won't always do that, it depends on the nature of what's inside it.

[Video description begins] A tab labeled "Connect" opens. A pop-up box labeled "Choose Start Up Command" is open in the tab. [Video description ends]

Here I can click Connect as well, if I want to interact with the contents of the container, such as, I'll use /bin/sh S-H, make a connection, and here we go. Now we can see we're in the file system.

[Video description begins] He selects a radio button labeled "/bin/sh" and clicks a button labeled "Connect". The prompt "/usr/src/app #" is displayed. [Video description ends]

So if I do an ls, for example, I can even see index.html.

[Video description begins] He executes the following command: ls. The output displays several files. The prompt does not change. [Video description ends]

So if we go back to Overview, speaking of index.html, we're going to see the URL here, the Fully Qualified Domain Name, FQDN.

[Video description begins] The corresponding page opens in the content pane. [Video description ends]

I'm going to copy that and we're going to open that app in another web browser window.

[Video description begins] He points to a URL adjacent to a field labeled "FQDN". [Video description ends]

And here we can see it's pulling up the contents of the web page within that container. But again, containers don't have to serve up a web application.

[Video description begins] He clicks an icon labeled "Copy to clipboard" adjacent to the URL and the icon name then changes to "Copied". [Video description ends]

It could be a background component that does anything, it doesn't even have to expose port 80.

[Video description begins] A web page opens in a new tab. It includes an image and the text, "Welcome to Azure Container Instances!". [Video description ends]

But in this case, based on our container image that we selected, it does.
