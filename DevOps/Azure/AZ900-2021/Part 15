                    AZ900 Microsoft Azure Cloud Fundamentals 2021
                    Course Notes Part 15


Azure Application Gateway
  - In a very general sense, the Azure Application Gateway is a load balancer for web application traffic. 
    - That's where the similarities stop because with a traditional load balancer
      - Traffic gets routed to backend virtual machine instances through the load balancer based on things like the IP address and port number
    - However, with the Azure Application Gateway, we have many options above and beyond what you can do with a traditional load balancer.
  - As an example of this, the Azure Application Gateway could load balance and get clients connected to backend virtual machines based on routing rules that might be based on an incoming URL passed to the application from the client. So pictured in the diagram, we've got the Internet listed over on the left. The Azure App Gateway is then connectable from the Internet. It will have a public facing IP address if it's designed to be made publicly visible.

The Azure App Gateway will then have access to backend VMs, listed here as VM1, VM2, and VM3, Although it doesn't have to be three; it could be two, it could be more than three. Also, we can configure options like session affinity. This can be used so that a user that's got an established session on VM1, let's say, the next time that they make a connection which could be moments later, they will still have their session directed to that same backend server.

Remember that when we talk about web applications over HTTP or HTTPS, bear in mind that HTTP and HTTPS are really stateless. In other words, once we contact a web server and ask it to do something and it does it, that's it. So we need to have a way therefore where we can maintain session affinity information on the backend. And this is a configuration option within the Azure Application Gateway among many others.

The application gateway also supports a web application firewall, or a WAF, W-A-F. So when you deploy an Azure Application Gateway, you have a web application firewall that can be configured. This is a specific type of firewall that's designed to look for web application exploits, such as cross-site request forgeries, or directory traversals, where attackers might try to go further back in the file system outside of the location of files that make the website run, which could give them unauthorized access to other files in the operating system.

Cross-site scripting is also another type of attack that can be prevented, and SQL injection which might allow a user to input query statements in fields that get sent to a database. And those fields are validated properly and so might reveal more sensitive information than it was designed to do. Now there are many other types of web application exploits that are protected with a web application firewall.


Configure Azure Application Gateway
  - The Azure application gateway takes incoming client requests for an application and forwards it off to a backend server that can host that request.
  - That might sound like a load balancer, and it is a load-balancing solution. But what makes the application gateway different than a traditional load balancer is that beyond just looking at IP addresses and port numbers, the application gateway can look at the incoming URL request.

And it can make a routing decision to a backend virtual machine based on that. So if a client requests something in the URL that includes /jpg images, that can be forwarded to a backend host that's been optimized to serve up that kind of content. So let's get started here in the portal by clicking Create a resource.
  - Start by deploying two virtual machines that are going to be running Windows Server 2016 Data Center.

[Video description begins] From the Azure Marketplace column, he selects Compute. A Featured column appears. It has the following options: Windows Server 2016 Datacenter, Red Hat Enterprise Linux 7.2, Ubuntu Server 18.04 LTS, etc. He selects Windows Server 2016 Datacenter. A page titled Create a virtual machine appears. It has the following tabs: Basics, Disks, Networking, etc. Basics tab is currently open. It has drop-down menus for Subscription and Resource group. The default value for Subscription is Pay-As-You-Go. The default value for Resource group is cloud-shell-storage-eastus. At the bottom there are three buttons: Review + create, Previous, and Next: Disks. [Video description ends]

The key here is I want two virtual machines deployed into their own specific virtual network and subnet.

[Video description begins] He scrolls down the page. A section titled Instance Details is displayed. It has an input box for Virtual machine name. There are drop-down menus for Region, Availability options, and Image. The Region is East US, Availability options is No infrastructure redundancy required, and Image is Windows Server 2016 Datacenter. The Size is Standard DS1 v2. [Video description ends]

And these virtual machines will be used as our backend pool for our application gateway. So I'm going to go through and tie this to a resource group, and I'm gonna call this webapp1vm1.

[Video description begins] He clicks the drop-down menu for Resource group. A list of options appears. He selects Rg1 from the list. [Video description ends]

[Video description begins] In the input box for Virtual machine name, he types webapp1vm1. [Video description ends]

Now, I'm gonna copy that because I'm gonna make a second one afterwards, where the only difference is going to be vm2 instead of vm1. So I'm going to put this in the Canada East location.

[Video description begins] He clicks the drop-down menu for Location. A list of options appears. He selects Canada East from the list. [Video description ends]

And I'm going to scroll down and specify the username and password information.

[Video description begins] He scrolls down the page. A section titled Administrator Account appears. It has input boxes for Username, Password, and Confirm Password. Below it there is a section titled Inbound Port Rules. It has two options with radio buttons for Public inbound ports. These options are: None and Allow selected ports. None is selected by default. It also has a drop-down menu for Select inbound ports. [Video description ends]

And then for inbound port rules, I'm going to allow incoming RDP on port 3389 for management. I don't have to enable port 80 or 443, because these will be running in the backend pool. They don't need to be publicly accessible.

[Video description begins] In the input box for Username, he types cirving. He then types the password and confirms the password. He selects Allow selected ports for Public inbound ports. He clicks the drop-down menu for Select inbound ports. A list of options appears. He selects RDP from the list. [Video description ends]

So I'm going to go ahead and click Next.

[Video description begins] He clicks the Next: Disks button. The screen shifts to the next tab titled Disks. It has a drop-down menu for OS disk type. Premium SSD is selected by default. At the bottom there are three buttons: Review + create, Previous, and Next: Networking. [Video description ends]

I'm okay with Disks but I'm interested in the Networking.

[Video description begins] He clicks the Next: Networking button. The screen shifts to the next tab titled Networking. It has drop-down menus for Virtual network, Subnet, and Public IP. The default value for Virtual network is EastVnet1. Below this, there is a link for Create new. The default value for Subnet is EastSubnet1 (10.1.1.0/24). Below it there is a link for Manage subnet configuration. The default value for Public IP is (new) webapp1vm1-ip. Below it there is link for Create new. For NIC network security group, there are three options with radio buttons: None, Basic, and Advanced. None is selected by default. At the bottom there are three buttons: Review + create, Previous, and Next: Management. [Video description ends]

I'm going to create a new VNet called webapp172Vnet.

[Video description begins] He clicks the Create new link present below Virtual network. A page titled Create virtual network slides onto the screen. It has an input box for Name. There is a section titled Address Space. It has a table with the following columns: Address Range, Addresses, and Overlap. It has one row of data. The Address Range is 10.0.0.0/16, Addresses is 10.0.0.0 - 10.0.255.255 (65536 addresses), and Overlap is None. There is another section titled Subnets. It has a table with the following columns: Subnet Name, Address Range, and Addresses. Subnet Name is default, Address Range is 10.0.0.0/16, and Addresses is 10.0.0.0 - 10.0.255.255 (65536 addresses). At the bottom there are two buttons: OK and Discard. In the input box for Name, he types webapp 172Vnete. [Video description ends]

And I'm going to specify the address range I want to use for that, which would have been planned ahead of time, that's for the VNet. And then I'm going to make a subnet here called Subnet1 and we'll configure a range for the subnet that falls within what is being used here in the VNet.

[Video description begins] In the table for Address Space, he changes the Address Range to 10.1.0.0/16. [Video description ends]

Just make sure we're using CIDR notation here, with the slash for the number of bits in the subnet mask.

[Video description begins] In the table for Subnets, he changes the Subnet Name to Subnet 1, and the Address Range to 10.1.1.0/24. [Video description ends]

And I'm going to go ahead and click OK. So now we've got that configured, and now I'm going to click Review and create.

[Video description begins] He clicks the OK button. The Virtual network changes to (new) webapp 172Vnete. [Video description ends]

Once the validation passes, I'll go ahead and I'll click the Create button.

[Video description begins] He clicks the Review + create button. The screen shifts to the Review + create tab. It has the following sections: Product Details, Terms, and Basics. At the bottom there are three buttons: Create, Previous, and Next. He clicks the Create button. [Video description ends]

And while that's happening, I'm going to go ahead and deploy a second virtual machine. Everything will be the same except the name will end in vm2 instead of vm1.

[Video description begins] A new page opens up. It has a navigation pane with the following options: Overview, Inputs, Outputs, and Template. The Overview page is currently open. It has the following heading: Your deployment is underway. The page has a table with the following columns: Resource, Type, Status, and Operation Details. [Video description ends]

Now I should say, if you've got existing virtual machines hosting your app, you can use those. It just so happens, I'm deploying them from scratch here. And, of course, what you would do is install, in this case, the IIS web server and any other components within each virtual machine that you need to support your web application. Okay, so the next thing I'll do is actually deploy the application gateway. So I'll click Create a resource, and I'll type in application gateway.

[Video description begins] He shifts to the Microsoft Azure home page and clicks on Create a Resource. A page titled New opens. [Video description ends]

And I'll select it from the list, and I'll choose Create.

[Video description begins] In the search bar, he types application gateway. Two options appear: Application Gateway and Azure Application Gateway Analytics. He clicks on Application Gateway. A page titled Application Gateway appears. It has a drop-down menu for Select a software plan. Application Gateway is selected by default. At the bottom there is a Create button. He clicks the Create button. [Video description ends]

I'm going to call this webapp172appgw, for app gateway.

[Video description begins] A page titled Create application gateway opens. It has three steps listed: Basics, Settings, and Summary. A page for Basics is currently displayed. It has an input box for Name. There are drop-down menus for Tier, Instance count, SKU size, Subscription, Resource group, and Location. The default value for Tier is Standard, Instance count is 2, SKU size is Medium, Subscription is Pay-As-You-Go, and Location is Canada East. At the bottom there is an OK button. In the input box for Name, he types webapp172appgw. [Video description ends]

And if I leave it on the Standard tier, I can see the SKU sizes available are Small, Medium, and Large. And these relate to the amount of throughput that can be handled by the application gateway. If I were to choose a Web Application Firewall tier, then all I have are Medium and Large available as sizing.

[Video description begins] He clicks the drop-down menu for Tier. A list of options appears. He selects WAF from the list. [Video description ends]

So I'm going to choose Medium.

[Video description begins] He clicks the drop-down menu for SKU size. Two options appear: Medium and Large. He selects Medium. [Video description ends]

I'm going to leave it at 2 for Instance count, and I'll pop this into an existing resource group.

[Video description begins] He clicks the drop-down menu for Resource group. A list of options appears. He selects Rg1 from the list. [Video description ends]

And the same location where I've deployed my virtual machines in their own VNets, so I'll click OK. And for the virtual network on the next page, I'm going to choose an existing virtual network.

[Video description begins] He clicks the OK button. The Basics page closes and a page for Settings appears. It has a section titled Subnet configuration. It has a field for Virtual network. A link for Choose a virtual network is present here. Below it there is a drop-down menu for Subnet. There is a section titled Frontend IP configuration. Here there are two options with radio buttons for IP address type: Public and Private. Public is selected by default. For Public IP address, there are two options with radio buttons: Create new and Use existing. Create new is selected by default. Below it there is an input box with the following value: webapp172appgw-ip. At the bottom there is an OK button. The presenter clicks on the link for Choose a virtual network. A page titled Choose virtual network opens. It has three options: EastVnet1, EastVnet2, and EastVnet3. A fourth option webapp172Vnete is present but unavailable. Above these, there is a Create new option. [Video description ends]

Now, notice here how the webapp172Vnet that we created is unavailable because we need another empty subnet as indicated here by the information screen.

[Video description begins] He points to the info icon present next to the fourth option. It reads: This virtual network doesn't have an eligible subnet for this deployment. It should contain an empty subnet or a subnet with no other resource types besides application gateways. [Video description ends]

No problem. So I've opened up another web browser window where I've navigated to Virtual networks.

[Video description begins] In a new tab, the Virtual networks page is open in the Microsoft Azure web page. It has the following buttons on the top: Add, Edit columns, Refresh, etc. It has an input box for Name, and drop-down menus for resource groups, locations, tags, and grouping. Below these fields, there is a table with the following columns: Name, Resource Group, Location, and Subscription. Four rows of data are present in the table. [Video description ends]

I'm going to open up that virtual network and I'm going to click Subnets, and I'm going to add a new Subnet.

[Video description begins] From the table, he clicks on webapp172Vnete. A page titled webapp172Vnete opens up. It has a navigation pane and other details. From the navigation pane, he clicks on Subnets. A page for Subnets opens up. It has two buttons on the top: +Subnet and +Gateway subnet. It has a table with the following columns: Name, Address Range, Available Addresses, and Security Group. [Video description ends]

I'm going to call it Subnet2.

[Video description begins] He clicks on + Subnet. A page titled Add subnet opens up. It has an input box for Name and Address range(CIDR block). In the input box for Name, he types Subnet2. There are drop-down menus for Network security group and Route table. None is selected for both. Under the heading Service Endpoints, there is a drop-down menu for Services. No service is selected. Under the heading Subnet delegation, there is a drop-down menu to Delegate subnet to a service. No subnet is selected. At the bottom, there is an OK button. [Video description ends]

And for the address range, I'll use 10.1.2.0/24 for bits in subnet mask. And I'll just go ahead and OK that to add a second subnet.

[Video description begins] In the input box for Address range(CIDR block), he types 10.1.2.0/24. He clicks the OK button. The screen shifts to the Subnets page. In the table, Subnet2 is present. [Video description ends]

So now when I go to select the virtual network, and you might have to close this screen of the wizard and go back one step and come back in, which I've done.

[Video description begins] He shifts to the previous tab. [Video description ends]

I can now select that virtual network and it's got Subnet2, select it.

[Video description begins] From the list of four options in Choose virtual network page, he selects webapp172Vnete, which is now active, as the Virtual network. [Video description ends]

This is going to be a public facing application gateway, so I'll leave the IP address type as Public, as opposed to Private for an internal line of business app, for example. We'll let it create a new public IP address, and I'm going to accept all the defaults here for HTTP port 80, and I'll click OK.

[Video description begins] He scrolls down the Settings page. There is a section titled Configure public IP address. Here SKU is Basic. For Idle timeout (minutes), there is a scale with a pointer. The pointer is at 4. The input box for DNS name label is empty. For Assignment there are two options with radio buttons: Dynamic and Static. Dynamic is selected by default. There is a section titled Listener configuration. For Protocol there are two options with radio buttons: HTTP and HTTPS. HTTP is selected by default. For Port there is an input box. The value here is 80. Under Additional Settings, there are two options for HTTP2: Disabled and Enabled. Disabled is selected by default. Under Web application firewall, there are two options for Firewall status: Disabled and Enabled. Enabled is selected by default. For Firewall mode, there are two options: Detection and Prevention. Detection is selected by default. [Video description ends]

Then I'll click OK on the Summary screen.

[Video description begins] He clicks the OK button. The Settings page closes and the Summary page opens. It has the details of the application gateway. At the bottom there is an OK button. He clicks the OK button. The home page of Microsoft Azure is displayed. [Video description ends]

And we can now see our application gateway is being deployed. But we're not finished configuring it yet. We have to link our backend virtual machines to the backend pool for the gateway. So now if I go to the All resources view, and if I filter it for web, we can see that we've got a number of resources with that prefix such as our web application 172 app gateway.

[Video description begins] From the navigation pane, he clicks on All resources. The All resources page opens. In the input box for name, he types web. He points to the resource named webapp172appgw in the table. [Video description ends]

I'm going to go ahead and click on it to pull up its Properties blade.

[Video description begins] He clicks on webapp172appgw. A page titled webapp172appgw opens up. It has a navigation pane and a few details such as Resource group, Location, Virtual network/subnet, etc. [Video description ends]

And in the Properties blade, if I scroll down to the Backend Pools, I've got my backend pool listed here.

[Video description begins] He clicks on Backend pools in the navigation pane. A page for Backend pools opens. It has two buttons: Add and Refresh. A table with the following columns is also present: Name, Rules Associated, and Targets. It has the following Backend pool listed: appGatewayBackendPool. [Video description ends]

However, from the dropdown list, I can choose virtual machines.

[Video description begins] He clicks on appGatewayBackendPool. A page titled Edit backend pool opens. It has the following buttons: Save, Discard, and Delete. It has a drop-down menu for Targets. IP address or FQDN is selected by default. It also has an input box for Name. [Video description ends]

And when I go to select a virtual machine, I'll see the two virtual machines that I deployed in that virtual network that this application gateway is associated with.

[Video description begins] He clicks the drop-down menu for Targets. A list of options appears. He selects Virtual machine from the list. Drop-down menus for Virtual Machine and Network Interfaces appear. He clicks the drop-down menu for Virtual Machine. Two options appear: webapp1vm1 and webapp1vm2. [Video description ends]

So I'm going to go ahead and choose the appropriate network interface for both of those virtual machines.

[Video description begins] He selects webapp1vm1. He then clicks the drop-down menu for Network Interfaces. One option appears. He selects it. It is webapp1vm198 (10.1.1.4) Another set of drop-down menus for Virtual Machine and Network Interfaces appears. [Video description ends]

Now again, these would be configured with our web application.

[Video description begins] He clicks the drop-down menu for Virtual Machine and selects webapp1vm2. He then clicks the drop-down menu for Network Interfaces. One option appears. He selects it. It is webapp1vm2581 (10.1.1.5) [Video description ends]

And then I'll click Save to save that backend pool configuration.

[Video description begins] He clicks the Save button. The screen goes back to the Backend pools page. [Video description ends]

We can also click on Web application firewall in the Properties blade to ensure that the Web application firewall is enabled. If we go to Rules, we can see the ruleset that's being used.

[Video description begins] From the navigation pane, he clicks on Web application firewall. A page for Web application firewall opens. It has three buttons on top: Save, Discard, and Refresh. The page has two tabs: Configure and Rules. The Configure tab is currently selected. It has two options for Tier: Standard and WAF. WAF is selected by default. The Firewall status is Enabled. For Firewall mode, there are two options: Detection and Prevention. Detection is selected by default. A section titled Exclusions is also present here. It has a table with three columns: Field, Operator, and Selector. All three columns have drop-down menus. [Video description ends]

If you really want to, you can enable Advanced rule configuration to determine exactly which type of web application firewall rules that you want enabled.

[Video description begins] He goes to the Rules tab. It has a drop-down menu for Rule set. The default value is OWASP 3.0. For Advanced rule configuration there are two options: Enabled and Disabled. Disabled is selected by default. He clicks the drop-down menu for Rule set. Two options appear: OWASP 3.0 and OWASP 2.2.9. [Video description ends]

[Video description begins] He clicks Enabled for Advanced rule configuration. A table with the following columns appears: Enabled, Name, and Description. A list of items is present in the table. There are check boxes with tick marks present under the Enabled column for each item. [Video description ends]

However, I'm not worried about making a change there. Also, if we go to Rules, we also have the option of configuring additional path-based rules to look at incoming URLs for routing purposes. That would require creating a front-end listener as well.

[Video description begins] From the navigation pane, he clicks on Rules. A pop-up message with the following text appears on the screen: Your unsaved edits will be discarded. It has two buttons: OK and Cancel. The presenter clicks the OK button. A page for Rules opens. It has a navigation pane and two buttons on top: +Basic and +Path-based. Below it there is a table with the following columns: Name, Type, and Listener. There is one row of data in the table. [Video description ends]

And we can click Health probes to determine the configuration for how often we're going to check backend servers to make sure that they are responsive.

[Video description begins] He clicks on Health probes from the navigation pane. A page for Health probes opens. It has an Add button. It has a table with the following columns: Name, Protocol, Host, Path, and Timeout (Seconds). The table is empty. [Video description ends]


Content Delivery Networks (CDNs)
  - A Content Delivery Network or CDN is a strategy that we can employ in Azure to make sure that content is available to users locally. 
    - The overall goal then is to speed up the user experience when content is delivered to them
    - Whether it's basic standard website files, graphic images, audio-video media, whether it's streaming or not
    - We want to make sure that gets to end-users as quickly as possible. 
    - That can be done with a CDN because the Azure content delivery network has geographical point of presence servers in Azure regions all over the world.
  - We can create configurations in Azure to specify details about what should be cached 
    - Also for how long on these geographical point of presence servers in different parts of the world. 
    - The idea is that users that request content in one region should get that content served within the same region 
      - Instead of having to retrieve it across multiple regions which will slow down the end-user experience.
  - The Content Delivery Network process begins with the user requesting content via a URL. 
    - Now that URL is then sent to a content delivery network point of presence server
    - We will have configured data caching, or the client might have sent HTTP headers that have TTLs related to caching content and how long it should stay there. 
    - Otherwise, by default, content that gets cached sits on the CDN servers for seven days.
  - Now, in the event that a user makes a request for content that is not cached already
    - Then the CDN server will make the request to the origin server, which in turn will feed the content back to the user through the content delivery network. 
    - There are a number of features to be aware of that you might want to configure while you're configuring your Azure content delivery network settings
      - One of which is geo-filtering.
  - Geo-filtering lets you specify the type of content that should be cacheable based on the country of the origin request. 
    - Content compression allows us to enable compression for files so that they are more quickly delivered throughout the CDN
    - We could potentially incur lesser bandwidth charges since we're sending less data. 
    - Caching rules can be used to specify exactly how data gets cached and for how long.
  - There are a couple of different types of caching rules that you can configure, that we'll see when we configure a demo. 
    - Whether we're talking about just generic mobile caching rules or query string caching rules based on incoming query strings with HTTP requests. 
    - There's also a site acceleration option where you can configure this as you add endpoints to your CDN configuration to speed up access to content. 
    - Finally, you can also use HTTPS custom domain names to map more to your organizational presence on the Internet 
      - This is done using your fully qualified domain name in your configuration.


Configure the Azure Content Delivery Network
   - Delivery network or CDN is used so that we can take web application content and place in geographically near users that will need it.
  - Content can stem from static web pages on a private website that we host on Azure. We can have files from Azure Blob Storage cached. 
    - We can even reference other publicly accessible web applications and have their content cached. 
  - Click on it to open up its Properties blade, we can see the URL.
  - Just copy the URL and pop that into another web browser window to make sure at least that works.
  - We can see the default page where it states that our App Service application is up and running.
  - So back in the Azure portal, now what I want to do in the Properties blade for that application is scroll all the way down to the networking section.
  - When I select networking over on the right, I can see Azure CDN, content delivery network, and I can choose the link to configure Azure CDN for my app.
  - Go ahead and create a new CDN profile, a new configuration and name appropriately
    - Then go ahead and choose the standard Microsoft pricing tier.
  - The pricing tiers that I can select from the drop-down list really determine the feature set, such as, if I want dynamic site acceleration I would have to use the Standard Verizon or the Standard Akamai, or Premium Verizon configuration. Standard Microsoft doesn't support features like dynamic site acceleration. The standard Microsoft pricing for CDN also doesn't support features such as mobile device rules.
  - For this example I'm going to stick with Standard Microsoft. 
    - For the CDN endpoint name I'm going to call it webapp172cdn and it's going to tack on the .azureedge.net DNS suffix, at least by default. 
    - Notice that there's a link up above to migrate custom domains to content delivery network configurations here in Azure.
  - So at this point I'm going to go ahead and click Create.

And after a moment we can see that our content delivery network endpoint is now listed with the status of running.
  - Even though it may be true, it may not be available for a period of time depending on the pricing tier that you've selected. 
    - The thing to do then is to use that URL to test connectivity
    - Pop in the URL here, it includes CDN to make sure that our web application is up and running and should say, our app service app is up and running.
  - We now know that we can serve content through our configured Azure content delivery network.


Moving to the Cloud
  - Organizations looking at moving to the cloud, means that they will have to consider some of the migration options 
    - To migrate data that they might currently host on-premises into the cloud
    - Or migrating applications are currently run on-premises in the cloud
    - And also, any servers that they have running on-premises that might serve up files 
    - Or that might actually run application workloads can also potentially be migrated into the cloud computing environment.
  - With cloud migration, you can either migrate from your existing on-premises environment. But at the same time if you're already using cloud computing, you might consider migrating from an existing cloud service provider, to a new cloud service provider. Now the benefits of moving to the cloud would include first of all, reduced infrastructure expenses. At least compared to what you might have to do on-premises.

On-premises, you have capital expenditures related to purchasing the hardware to create the supporting IT infrastructure. Things like physical servers, storage arrays, UPS backup systems. However, in the cloud that's done by the cloud service provider. Another benefit of moving to the cloud, is minimizing capacity boundary issues. Cloud providers have the benefit of economies of scale where they have such a vast pool of resources made available to cloud customers. They can offer it at a reduced charge compared to what we would have to do if we were doing this ourselves entirely on-premises.

The other thing is that when you run out of capacity on-premises such as storage, you have to then acquire additional hardware and configure it to have that additional storage available. That takes a lot longer than it would to simply allocate more cloud storage through a public cloud service provider. Another benefit is the reduced total cost of ownership, or TCO over time. Now, that can be gauged by comparing the ongoing operational expense of cloud computing charges against the on-premises capital upfront expenditures required to acquire all of the equipment to support the infrastructure.

Another benefit of moving to the cloud, is the increased global scope and access to redundancy. Public cloud service providers have data centers around the globe, and so the benefit of that, for example, if you're hosting a public facing website, is that you've already got that availability to place that website near users that might access it. You also have access to redundancy by replicating content, whether it's files stored in the cloud, or even replicating virtual machines running out workloads to alternate locations around the planet. Moving to the cloud means standardizing on file formats.

You want to make sure that you don't move to a public cloud service provider that has a proprietary or customized way of dealing with file formats and data exchange, you want to use open standards. That way you have an easy exit strategy, if you need to switch to a different cloud service provider. The other consideration when you move to the cloud is that the service offerings, whether they are new ones that will be introduced or changing existing ones, there are going to be changes with the way things are done over time with a cloud computing provider, and that even includes with the management tools be the command line based or graphically based.

So be aware that there are changes that are made, and we kind of have to go with the flow, don't have a choice because we don't have the underlying control of the infrastructure, the cloud service provider does. The other consideration is privacy and security. Now moving to the cloud, it does not mean you have less security. Instead, we should consider the security accreditations or the compliance that the public cloud service provider has, with various security audits to determine which one we should use.

So your organization might be very concerned with privacy and security, and there's no reason that can't be achieved in the cloud as it would be on-premises. The only distinction being, perhaps less configuration, flexibility and control when it comes to security in the public cloud. The other consideration when moving to the cloud is integration. For instance, you might have on-premises software components that you're currently running, that you want to leave on-premises.

You might want to integrate them with cloud services. For example, developers could make API programmatic calls from on-premises software components to talk to cloud services. The other consideration are the various cloud models available and the offerings within each. First we have software as a service. Whenever we refer to a cloud service offering, it usually ends with as a service.

[Video description begins] Software as a Service is abbreviated as SaaS. [Video description ends]

It means it's delivered and available over a network, hosted on equipment that is the responsibility of the cloud provider. So software as a service or SaaS is normally used by end users, it's prepackaged software. You might think of things like Office 365, or Google Classroom, or Google documents. Platform as a service, or PaaS, is of the most interest to developers. It provides operating system, and application, and database stacks, and programming tools like centralized code repod... repositories that support continuous integration and delivery, the ability to host custom APIs in the cloud and so on.

Infrastructure as a service, or IaaS is of primary interest to IT technicians, administrators. Where we're talking about the underlying virtual machines and the storage that is available in the cloud, and also the virtual network capabilities that we can configure. So we've got software, platform, and infrastructure available as cloud service models. The other thing to consider when moving to the cloud is the cloud provider service-level agreements, or SLAs.

There will always be an SLA for each type of cloud service offering. So if you're looking at storage in the cloud, there might be multiple storage SLAs, if there are multiple different service offerings for different types of storage in the cloud. Just like there would be an SLA for virtual machine instances in the cloud, which guarantees things like uptime on a monthly basis. The other consideration is looking into the security accreditations that the cloud service provider has acquired.

For example, if they're PCI DSS compliant that might be important if you are running an e-commerce site and you have to deal with credit card holder information. The other thing to consider are the management tools available, whether they're command line based, API programming based, or GUI based, and then determining if there are automation and orchestration techniques available with that cloud service provider. One of the benefits of the cloud is for repetitive types of tasks, you can automate a lot of those, which speed things up and makes a resilient against human failure.


Cloud Computing Roles
There are a number of definable roles when it comes to a cloud computing ecosystem. The first role is the cloud service provider, otherwise called as CSP. Where they bear much of the responsibility for making sure that the underlying infrastructure supporting cloud services remains up and running, and that things perform well according to SLAs for cloud services. Also at the CSP level, they have the ultimate configuration flexibility because they control the actual physical hardware, the physical servers, the physical storage arrays, the physical network switches and routers, and so on in their data centers.

Cloud consumers also called cloud customers or cloud tenants, have a multitude of different cloud models they can work with in terms of offerings. So developers, for example, will be interested in platform as a service or PaaS, which would be useful for developing custom apps. So the cloud service provider has offerings that facilitate those tasks. Next, we have common office staff or end users that would be interested primarily in Software as a Service or SaaS. For example, using cloud-based email or office productivity tools like spreadsheets and word processors, all in the cloud. In other words, having that software delivered over a network.

At the IT level, then we have Infrastructure as a Service or IaaS. This would be for cloud administrators or cloud technicians that would be responsible for determining which cloud services need to be deployed, and then deploying and managing those cloud services. Things like virtual machines or applications, custom applications, running in the cloud and allocating storage and controlling access to all of those cloud resources. So that's really part of the IT support team's responsibilities.

Other roles include the Cloud Service Brokerage or the CSB. Think of this kind of as a mortgage broker, an intermediary that has the ability to look at your computing needs as it pertains to the cloud and then going out and negotiating and finding the best cloud service provider that meets those needs. Cloud architects are the technicians that will design your organization-specific use of cloud services to achieve organizational objectives. Cloud auditors are those people that will audit the usage of cloud activities to ensure things like legal and regulatory compliance, and also to ensure peak optimum efficiency.

So having things running smoothly at an efficient cost level. Finally, we've got cloud carriers. Cloud carriers come in a few different forms, the most common of which, when it comes to public cloud service providers are internet service providers. They are the cloud carriers that provide the network link between an on premises network or an individual customer to the cloud provider. Other types of cloud carriers would also include local telco or cable companies. Anyone that can provide a dedicated network circuit were available in different regions around the world, from an on premises network directly to the cloud without traversing the internet. That would be another example of a cloud carrier role.


On-premise vs. Cloud
To further illustrate the benefits of cloud computing, sometimes it's important to compare it against the equivalent on-premises solutions. So we're going to take a look at running IT services on-premises and in the cloud.

[Video description begins] Screen title: On-premise IT Solutions. [Video description ends]

The first thing to consider is that when you run things on-premises. Because it's running on your equipment and everything is your responsibility. That also means by extension, you have more configuration control. There's more flexibility in how that IT solution is configured and how it's maintained over time. But then there is the issue of hardware acquisition. So if you need to support a new line of business app, for example, on-premises. You need to make sure you have the underlying hardware to support it. Whether that includes servers, whether that includes network routing equipment or switches, storage arrays, and so on.

That means it costs money. It costs more money to acquire all of this hardware than it would to simply rent it or use it on an as needed basis in the cloud. It also means waiting for it to arrive. So if you place an order for hardware, it takes time for it to be shipped to your on-premises network or data center. The other consideration is software. You need to acquire software that you're going to use on-premises. Not only that, but you also need to license it. Now the same thing would be true in the cloud, the difference being it's a little easier in the cloud.

Even to the point where you can bring your own existing licenses that you might have already previously acquired, and reuse them in the cloud, when you adopt the cloud. With on-premises IT solutions, you also have the responsibility of ongoing management. That's the responsibility of the organization, that owns that infrastructure. So normal administration, such as making sure that backups occur. Making sure that user accounts are created for newly hired employees, applying updates and so on. That's all the responsibility of the IT team on-premises. Deploying resources on-premises, such as a new application, usually involves the on-premises IT team and the help desk, and maybe even some training staff.

However, in the cloud, often new software that is made available is simply available to use over the network immediately. There's no need to deploy it in most cases. I say most cases because depending on what types of solutions you're using in the cloud. There still might be some software components you need to download and install on user devices. Whether that device is a smartphone, or a laptop or a desktop. Then there is the cost factor. With on-premises, there are ongoing costs related to acquiring hardware such as server hardware. Which is really considered a capital expenditure, otherwise shortened to CAPEX. Then there's the power consumption, for all of the IT infrastructure equipment.

You've got to pay the power bill and the heating and cooling bills as well. Then there's the amount of real estate or the space that you need to accommodate all of this equipment. In a server room or even in your own on-premises data center. In the cloud, you only pay for the resources that you use, kind of like electricity, or water. It's metered based on your consumption, you pay a certain amount. That's an operational expense otherwise shortened to OPEX. So the prices will adjust depending on how much you consume.

That's why it's important in the cloud, to ensure when you're finished with something. Such as a virtual machine or database that was used for testing, that you immediately shut it down, and if you don't need it in the future, delete it. Otherwise leaving things running means incurring unnecessary charges. Then there's the control of things like data and the configuration of your IT solutions. With on-premises you have full control of every aspect of the data life cycle. From its creation, its storage, it's sharing. You also have full configuration control of your IT solutions. In the cloud, in some cases, data ownership could be questionable. Especially where you start replicating cloud stored data to alternate regions around the world.

Where that data could be subject to the laws within the jurisdiction that the data center falls within, and of course in the cloud we have limited configuration control. Because some of the responsibility for the underlying IT infrastructure falls upon the cloud service provider. Certainly at the hardware level all of the responsibility falls on the cloud service provider. When comparing on-premises computing to cloud computing, security always comes up. Now with on-premises environments, you might have sensitive data or systems that are highly classified, that require a high level of privacy.

Now that could be related to government agencies, including military and law enforcement, or banking. However, in the cloud, there is a potential for a security breach, just as there is on-premises. Now one of the arguments that you'll hear is that, well, public cloud service providers are more of a target. They're centralized target where there are multiple customers or tenants storing potentially sensitive data. Which you could also liken to saying, you shouldn't store your money in a bank.

Because the bank stores money for a lot of customers, it's a larger target. Remember, public cloud service providers are in the business of earning a profit. It's bad for business if there are security breaches. So chances are, public cloud providers probably have much more security in place than most private sector organizations would be able to afford. So there could be public records, intellectual property, whether it's on-premises or in the cloud, that needs to be protected. But we want to move away from a statement as simple as saying, that security is not as strong in the cloud for data as it would be on-premises.

Because that's definitely not the case. Then there's compliance, we have to think about on-premises compliance with regulations and laws, especially as it applies to sensitive data. In the cloud the same thing is really true. So what to look for with cloud service providers is what is relevant to your organization in the type of data that it will be dealing with. So you might look at legislative acts such as HIPAA for the protection of medical information, or GDPR for the protection of European Union citizen data, or PCI DSS for the protection of credit card holder information.


IaaS
Infrastructure as a Service or IaaS is a cloud computing service model that allows for self service, and that is actually a cloud computing characteristic, self service or self provisioning of cloud based resources. This also includes not only the provisioning, but the monitoring of deployed resources, and also having access to them, such as being able to use SSH to remotely administer a Linux deployed virtual machine in the cloud. So compute would include things like virtual machines.

Networking would include things like virtual network definitions in the cloud into which virtual machines are deployed, and also the configuring of cloud-based storage. All of these items are configured compute infrastructure. Of course, at the end of the day in the data center, these are all based on underlying physical hardware. But the underlying physical hardware is the responsibility of the cloud service provider.

The software deployment of those items as we see here, is the responsibility in terms of management and patching of the cloud service customer. Some characteristics of infrastructure as a service include the fact that the resources, the virtual machines, the storage, it can be provisioned as a service, and as a service means that there's an easy to use interface, whether it's command line based or graphically based.

Costs are based on consumption. So for instance, for every minute that a virtual machine runs, you incur a charge. When you don't need that virtual machine running therefore, you should shut it down to save on costs, and many cloud providers will give you a way to automate the... or schedule the shut down of virtual machine instances. The other thing about infrastructure as a service in the cloud is that it's highly scalable.

Because there are so many pooled underlying resources made available by the cloud service provider, it's very quick and easy to all of a sudden, ask for a more powerful virtual machine. In other words, to resize it, or to group virtual machines together to support a busy application or to increase the amount of storage that's available. So we have control of the infrastructure at the software level as cloud customers with infrastructure as a service.

[Video description begins] Screen title: IaaS. [Video description ends]

So virtualization technology then would apply to servers and operating systems. So in a matter of seconds, potentially you could deploy a Linux or a Windows based virtual machine, once you select the appropriate operating system image version. You can also virtualize networks. You can define a virtual network with one or more subnets and you can specify the IPv4 or the IPv6 address ranges that you want to use. Networking also includes things like network ACLs, access control lists, essentially firewalls where you can control inbound and outbound network flow.

Then there's the storage side, such as provisioning additional storage space that will be used for users to upload content to the cloud. Infrastructure as a service has many different possible use cases for many different types of organizations such as companies that want to avoid high hardware and software costs. Because you weren't paying the upfront cost for the entire hardware infrastructure with cloud computing, you're only paying for what you are using. Also for companies that are experiencing rapid growth. Because of rapid elasticity in the cloud in just a matter of seconds, we can spin up new virtual machines or new storage space that's available or configure a new virtual network into which we deploy virtual machines. All of this can happen very quickly. So for companies experiencing rapid growth, this lends itself to it nicely.


SaaS
Software as a service, or SaaS, otherwise called SaaS, is another form of cloud computing. It's another cloud service model that's often referred to as cloud application services. Arguably, it's the most common way that cloud computing gets used by a vast number of users, such as those using cloud-based email or even personal cloud storage and of course, at the enterprise level as well. So what happens with software as a service is we have prepackaged software that's ready to use that's made available over a network, such as the Internet.

[Video description begins] Screen title: SaaS: Delivery. [Video description ends]

The vendor, in this context, the cloud service provider, is responsible for managing the underlying infrastructure that supports the SaaS solution. So the underlying data storage, the underlying servers that run the software. One of the great advantages about software as a service is rapid elasticity. So in the example of cloud-based email, if your organization hires ten new employees, you can very quickly provision new cloud-based email accounts, and not have to worry about licensing, and so on, in the cloud. Now, they do have to be licensed, but it's already available immediately and conveniently with the cloud provider solution. Scalability is another advantage.

As things get busy, scaling adds more underlying compute horsepower to handle the increased workload. That, in this context, with software as a service would be the responsibility of the cloud service provider. There would be a service level agreement, or an SLA for the specific service such as cloud-based email, a guaranteed level of performance and uptime. Another advantage of software as a service is integration. For example, you might be able to integrate previous used software like email on premises and import messages or archives into the cloud, but it really depends on the specific SaaS solution.

Upgrades are not the responsibility of the cloud customer when it comes to upgrading the underlying software that supports the specific solution such as cloud-based email. That's the responsibility of the cloud service provider, and so from the cloud customer's perspective, that definitely works out to be an advantage. Cloud service providers also strive to make these solutions very very easy to use for the average user. So some characteristics of software as a service. It is centrally managed by the cloud service provider. It's accessible over a network such as the Internet when it comes to public cloud computing.

Vendors are responsible for managing updates to the underlying software, and it's hosted remotely on cloud service provider equipment. So organizations that use software as a service will benefit in many ways. For example, startup companies. It's a very inexpensive way to provision cloud resources at the software level very quickly and easily. It can be used for short-term projects because you're only paying for what you're using and when you remove access to that application, you no longer are charged. Also, it can be used for web and mobile applications.

[Video description begins] Screen title: SaaS: Considerations. [Video description ends]

Now there are some limitations, with software as a service, one being potential vendor lock-in. If you're using a specific cloud service provider's software as a service solution, it might be specific to that provider, and so it could be difficult for you to get your data out of it or to integrate it with other components. But it really depends on the specific solution question, at least it's a consideration.

So integration support falls under that, it might only be limited abilities. You might have very limited customization capabilities, since you don't control the actual underlying servers, that house that software. Then there's the issue of data security. Now, data security isn't solely the responsibility of the cloud service provider, especially in this context. So users might opt, for example, to encrypt documents they create with a cloud-based word processor. S

o some of that responsibility then for data security will certainly fall on users and also cloud users determining, which physical geographical location data is stored in, which means that the data could be subject to laws of that area. Now remember that software as a service runs centrally on cloud provider equipment.

So it's controlled by that third party, the cloud service provider. Because we don't control as customers, the underlying network and storage and servers that run software as a service solutions, performance could be an issue but also at the same time on the other side of the coin. Remember that performance details are specified in the service level agreement and if the cloud service provider does not abide by those terms, then the consequence would be service credits for you the cloud customer against your next cloud computing bill.


PaaS
Platform-as-a-Service, or PaaS, is yet another cloud service model. It's also called cloud platform services. This one serves as a great framework for software developers and testers, which we'll explore in further detail soon. So the infrastructure that supports platform as a service is managed by a third party. Of course, in this context, that third party is the cloud service provider.

[Video description begins] Screen title: PaaS: Delivery. [Video description ends]

So developers then can leverage, platform as a service solutions in the cloud to create and test software and also deliver it to users of that software. A lot of this can be automated. For example, when a developer checks in a new code change that can trigger a series of tests to automatically be run against that for quality assurance, and upon successful testing, then the software could be packaged up and through a push notification sent out to mobile devices or automatically published on a website for download.

A lot of that can be automated. Some advantages of platform as a service, it's scalable because it's running on cloud provider equipment, and cloud providers pool resources together for use by cloud customers. It's highly available, that's especially true when you start configuring replication of your cloud based data to alternate locations. It's highly customizable, and that comes at many different levels. Such as customizing the code that you actually host in the cloud, customizing testing and Automation and customizing the packaging and delivery of the software. So automation is an important part of that.

We even have the option of migrating some of your existing software development data from on-premises into the cloud. That would even include things like databases used by custom software. So characteristics of platform as a Service, it is a virtualization type of technology in a broad sense. It uses a number of underlying virtualization Technologies such as virtual machines and even application containerization, where application files and settings are stored within their own logical boundary. There are variety of services available. That's definitely true. Where you could host custom functions or collections of functions API's in the cloud.

Also, you have different types of databases that can be deployed automatically, kind of as a stack where you'll have certain operating system, certain developer tools and a certain type of database that can be deployed really with just a few clicks. Database integration, is always very important with Platform as a Service. Databases whether they be SQL based or no SQL based where no SQL doesn't really have a rigid storage blueprint as SQL does. These can be used depending on the type of application being constructed. Also accessibility. Platform as a Service, is a service model in the cloud, and one characteristic of the cloud is, self provisioned resources.

So it doesn't take very much for developers to begin provisioning additional items in the cloud. You might say what kinds of items, it could be a code repository that supports code check-in. It could be an automated code pipeline. That includes automated testing that's triggered as we've mentioned, when code is checked-in by developer to a code repository that's cloud based. So who will use platform as a service? Well, organizations that are looking at making customized software applications even for internal use, such as line of business apps, will benefit from platform as a service.

So also the deployment of the app will benefit from platform as a service in the cloud. That would be continuous integration and continuous delivery, such as automated testing, automated packaging and pushing out of software changes. Of course, we We always have to consider the security of data that results from the use of platform as a service offerings. That could mean enabling encryption, for example at the database level. So this would fall upon the responsibility of the cloud customer, in this case, a software developer, to make sure security is implemented correctly.

The other thing is integration such as with existing services, we have to consider any potential runtime issues that might cause Flaws in the software, so it stops functioning. Now again if we have rigid and automated testing in place, then that type of issue should be minimized. Then there are operational issues. Remember that when you use cloud computing, you are essentially outsourcing the responsibility. It's a risk to a third party, and the third party is the cloud service provider. Even though they need to abide by service level agreements, still a risk that at least needs to be considered.


Private Cloud
There's a common misconception that if you run virtualization on premises. So if you're running virtual machines, you have a private cloud. This is not the case. In order to have a cloud, you not only have to use virtualization technologies, but self-provisioning of resources needs to be in place. You need to have a large number of resources pooled together. You need to track and charge based on resource consumption. It needs to be made available over the network. So virtualization is only about one component of cloud computing. So you might wonder then, well, what does constitute a private cloud?

First of all, we're talking about private IT infrastructure that resides behind a firewall. So for example, it could be equipment owned and managed by a single organization on their own network, that adheres to cloud computing principles. Such as rapid elasticity, and self-provisioning, and metered usage. So it's used by one organization and that's where the private comes from. There is a fee per unit time model. In other words, just like with public cloud computing, you are charged based on what you consume, what you use. Now you might say, how can an organization charge itself? This is often used in a private cloud within an organization for departmental charge back.

So different department managers might have access to a web based GUI where they can provision licensing, for example for email users, with just a click of a button, or they can provision virtual machines for testing purposes and that is tracked and at the end of each month, each department is billed accordingly from IT or from headquarters. So what are some advantages of a private cloud? There's no question that you have entire and full control of everything, including security control, not to mention predictable performance.

You can predict what happens in terms of network bandwidth performance and individual virtual machine performance in a private Cloud. Because you control all aspects of it, in the same way you have full configuration flexibility. Again, because you have full control of every component all the way down to the hardware level. Now one important private cloud consideration is the cost of it. Because a private cloud means a single organization uses all of its own infrastructure, all of that infrastructure needs to be paid for somehow up front, and so that's a capital type of expenditure and so that's a cost that needs to be considered.

Then there's the ongoing maintenance, making sure things run smoothly, working through help desk tickets, making sure things are patched, adding updates as they occur and so on. So when should an organization use private cloud computing then? Well, one reason would be because they require a virtualized environment with cloud computing flexibility. Remember, virtualization unto itself does not constitute a cloud. Also, organizations that have privacy or compliance concerns about running their services in the public cloud, could opt to have full control. So that they are compliant, by running it in their own private cloud.


Public Cloud
A public cloud, is accessible over a network such as the Public Internet, or even through a Dedicated Circuit from an organization's on-premises network to the cloud without going over the Internet. But either way, public cloud computing makes shared resources available to subscribers. This would include things like virtual machine servers, storage in the cloud, network configurations, even VPN solutions going to the cloud. All of this can be provisioned through cloud computing in a public sense, as well as the use of software applications.

Things like Office 365 or Google Documents or Google Classroom. All of these things allow end-user productivity software to be made available over a network. In the case of public cloud computing, it's available to anybody that wants to subscribe. So when should organizations use public cloud computing services? Well, the first reason to use it is for rapid provisioning of IT services. So if you need to provision 100 new email accounts, you can do it very, very rapidly in the public cloud. Including taking care of the licensing that goes along with that, compared to what you might need to do on-premises.

Where you might all of a sudden realize you don't have enough hardware to handle that capacity. So first you have to acquire the hardware before you can configure it to be used to support your ten new email users. If you need IT system and data storage scalability. For example, we realize that for a project that we're working on, we need an additional amount of storage space. Well on-premises, you have to physically have that space available in your storage arrays. Now the same thing is true in the public cloud, but the public cloud has enormous capacity, and so you're more likely to be able to have that available immediately in the public cloud, than you would be on-premises.

Organizations that have no desire or don't have the budget to implement a private cloud. Might also be likely candidates for using public cloud computing. Scalability in the public cloud, is based on large hardware installations. That's the vast amounts of pooled hardware resources that are made available to cloud customers by the cloud service provider. So it allows for scalability. For example, with just a few clicks, I could resize an existing cloud based virtual machine, to add more CPUs, more virtual processors to increase its compute power or add more RAM.

This can be done very, very quickly with a minimal effort. Also, scalability means that we can respond to demand for services in real time. For example, you might deploy a load balancer in the cloud in front of your application, maybe a custom application, and as requests for the app increase.

You can have it automatically scale by adding more virtual machine instances to handle the increase in the workload. You can also have it automatically remove those virtual machines when they're not needed to save on costs. Because when you have virtual machines running, you're paying for them. The other thing to think about, is that you're saving in many ways with public cloud computing to what you might alternatively do on-premises.

[Video description begins] Screen title: Costs Savings. [Video description ends]

First thing is that you only pay for the resources that you are using in the public cloud. So for example, if you need a virtual machine to test out a new configuration. You can do that in the cloud, very quickly by spinning up the virtual machine, and then when you're finished, shut it down. You aren't paying for it. Now on-premises, if you have enough people doing that. You might need to actually acquire additional hardware to support that increased demand for testing purposes, let's say with virtual machines. In the cloud, licencing is very convenient and easy to use.

So if you provision a Windows operating system in a virtual machine in the cloud. The price permitted, for example, while the VM is running will also include the licensing costs. That's not quite the case on-premises, you'd have to acquire the licensing and make sure you are compliant with the license terms. Also, you will require less IT staff on-premises. If you are using public cloud computing, than if you exclusively used on-premises IT services. Because there's no hardware to acquire and maintain, and depending on the specific services being used in the public cloud, you might not even require servers on-premises.


Hybrid Cloud
A Hybrid Cloud computing model, combines both private and public clouds. Where a private cloud refers to private infrastructure owned and used by a single organization, that follows cloud computing characteristics, such as metered usage, self-provisioning and so on, as well as using public cloud provider solutions. But a hybrid cloud can also mean that you are linking your on-premises IT infrastructure with the public cloud. Examples of this would include, using a site-to-site VPN, between your on-premises network and the cloud.

Essentially, extending your on-premises network environment into the cloud environment or even linking your on-premises identity store like Microsoft Active Directory with Active Directory in the cloud, to allow users to sign-in once with their on-premises credentials, yet still be authorized to use cloud apps. So there are a number of variations then on what a hybrid cloud is. Now in the public cloud, you might use this, so you could work with services, that don't deal with sensitive data, and also you want the benefits of scalability in the public cloud. Whereby, you might use the private cloud to store more sensitive data. However, that's not to say in any way that storing anything in the cloud is less secure than storing it on-premises.

So we can use a hybrid cloud environment for big data operations. Big data refers to the vast amounts of data, even from streaming over the network, over the Internet, such as data coming in from news feeds, data coming in from IoT devices, it could be coming from anywhere. But when we have vast amounts of data, it makes sense that we have a scalable environment to analyze that data, and an easy and cheap way to do that is in the public cloud, but that's public cloud.

What's the take on hybrid? Well, the hybrid kicks in, because you might have some of those data feeds sourced from your on-premises network, or perhaps your analysis tools are on-premises, but you want big data stored in the cloud. Another use case would be, cloud backup and replication. For instance, you might install an agent on your on-premises servers or even devices, doesn't have to be a server that periodically on a schedule backs data up to the cloud environment, the public cloud. So you've got a link between your on-premises environment and the cloud in terms of backup, even replication.

So not only backups, but you might have live replica data, replicated from an on-premises file server into the cloud, and whether content is changed in the cloud or on-premises, it synchronizes to the other location. Then of course, you might use a hybrid solution for the short term because you are adopting cloud computing. You want to migrate some of your on-premises components into the cloud, such as data, or applications, or virtual machines, that type of thing. The other thing to think about with the hybrid cloud is that, at least on the public cloud computing side, you're only paying for resources that are used.
So you should therefore always avoid idle cloud resources, especially things like databases that you deploy in the cloud as a managed service, meaning you don't have to worry with the underlying servers to get that up and running. Don't leave those things running because you will incur charges. Only leave them running, if they need to be left running.


Community Cloud
A community cloud, is used amongst organizations that have similar IT needs. Such as similar underlying compute requirements, perhaps for graphics processing. Similar storage requirements, such as within national boundaries. Similar security requirements, such as the protection of sensitive data, using very specific tools and methods, and also scalability. So in essence, a community cloud is cloud computing, but it's kind of a subset of it where it's a little bit more specialized and caters to more specific needs. So community cloud characteristics include a shared infrastructure. Well, this is true with all cloud computing models except for private.

Also, understand that the organizations or entities that might have similar computing needs, could be both in the private sector and/or at the government level. So some public cloud service providers, offer government cloud solutions. So when should an organization use the community cloud solution? Well, you probably have to, if for example, it's a government agency that must meet very strict security requirements. So for regulatory compliance related to processing, storing, and collecting things like health information, financial records, legal documents. So it's common then to see in the healthcare industry, for example, community clouds being used that meet the specific security and operational requirements, of that type of industry.


Cloud Migration Risks and Benefits
Organizations that assess moving to the cloud, need to weigh the benefits of cloud computing along with the risks to determine which action should be taken. One of the benefits of migrating to the cloud is reduced capital costs. Now, in the public cloud computing environment, we are using the cloud service provider's underlying infrastructure. Their physical servers, their storage arrays, their network equipment. Which means that we as the customer, do not have to put up the money upfront to acquire that hardware infrastructure, hence, reduced capital costs.

On-demand scalability is a benefit of the cloud. If we determine that we need more power in a virtual machine, we can resize it with a click of a button, and add more RAM or virtual CPUs. If we need more storage space, we can do that quickly. If we need to have more virtual machines running in a cluster to support an app, to improve performance, we can do that very quickly and easily without any underlying technical knowledge. So on demand scalability, is a very important benefit related to cloud computing.

Disaster recovery, many organizations actually use the public cloud as an alternate recovery site. Now this takes proactive planning ahead of time, meaning that you might replicate virtual machines which run applications and data to alternate geographical locations, essentially, to other data centers owned by the cloud service provider. So that in the event of a regional disaster, for example, you've already got your systems and your data running elsewhere. So that can minimize business disruptions. Remote access to applications. Well, when you're running things in the cloud, then you can access them from anywhere.

Now, of course, we have security rules that are in place to limit traffic flow, but the potential is there to allow that to happen, and depending on the specific type of migration scenario you're talking about, you could result with less administrative responsibility. So for example, imagine that you are moving from an on-premises mail server that your IT team must maintain, where all the user mailboxes are stored. Let's say you're moving from that, to a cloud hosted email solution. You don't have to worry about the server anymore.

You can just add users and licenses with a click of a button, and so that means then in that particular example that you don't have to worry about updating the mail server software or the underlying operating system running the mail server. That would then become the responsibility, of the cloud service provider. So that's definitely a perceived benefit. But there's no gain without some kind of undertaken risk. One is proprietary technologies. If a cloud service provider is offering their services or data exchange formats over the network and with files in a very specific format, that could make it difficult to get your data out of that cloud, back on premises or to a different cloud provider.

Then there's network latency and downtime of services, which are potential risks. However, remember that public cloud service providers have a service level agreement that guarantees uptime on a monthly basis, and so usually the risk is more prevalent on the customer side, meaning that if we only have a single Internet connection, linking an on premises office to the cloud and we depend on the cloud, then we should probably consider having a secondary Internet connection to the cloud from a different Internet service provider to increase resiliency against failure.

The other thing to think about is data sensitivity. So, you might have certain laws or regulations that require data to be collected, processed, stored, shared, and archived in a very specific way. So in order to comply with these laws and regulations, it would be upon you, the cloud customer, to configure settings appropriately, to meet those data sensitivity requirements.


Common Cloud Vulnerabilities
One important aspect of properly using cloud computing is thinking about common cloud vulnerabilities. Many of which are no different than what you would experience on-premises. So it all boils down to how you configure and use these services. Let's start by talking about data assets, such as databases or files containing sensitive information. One problem is not encrypting that information. Often, encryption is automatically put in place over the network such as through HTTPS communications, very common.

But what's less common is enforcing encryption for everything that gets stored, at least everything that is considered sensitive. Now, many public cloud providers will automatically encrypt content stored in the cloud. But otherwise, it's always an option for the cloud customer if it's not turned on automatically, and also, customers will always have the ability to use their own custom encryption keys that are in their control for their cloud data that's encrypted. The other possible issue related to data assets is more on the administrative side. Where a data asset is important, also cloud resources are important such as cloud virtual machines running a mission critical app.

So the principle of least privilege, or PoLP, states that only the permissions required to perform a job task should be granted and nothing more, and so principle at least privilege abuse could be a problem where we might simply grant too many permissions to cloud resources, such as to other administrators, and therefore they might mistakenly delete virtual machines that are critical, or deploy too many of them and not shut them down, which means the organization is paying for those unnecessarily, and so what can be done then is to use role-based access control or RBAC.

In other words, if you need someone to be able to manage your virtual machine in the cloud, let's say, but not actually getting to the data within it, we could use a role, that would allow them to manage the virtual machine, and then that would take care of that problem. They wouldn't have any additional permission. So RBAC is an important consideration when it comes to security in cloud computing. Then there's users and devices. For example, instead of going with just username and password, which constitutes single factor authentication, because it's both something you know, you might use multi-factor authentication for all cloud user accounts.
Now, multi-factor authentication uses another authentication factor, such as requiring the possession of a smartphone, where a six digit PIN might be sent. That must be used in addition to a username and password to authenticate. So something you know, plus something you have. The other thing is to harden all user devices. All it takes is a single compromised smartphone that has access to cloud resources to start a security breach or some kind of a malware infection in the cloud.

So always remember that every endpoint device, whether it be a smartphone, a tablet, an industry specific device connected to the cloud. All of these items need to be secured to reduce their attack surface. Then there's the insider abuse. There is the potential for staff or cloud administrators to damage or exfiltrate information. One of the things that we can apply in a cloud computing environment is data loss prevention policies, otherwise called DLP policies.

Data loss prevention, has rules that looks at the type of information or data being worked with, and if it, for example, determines that maybe there's credit card numbers in it, it can automatically encrypt and prevent forwarding of that information through email, as just one example.Then, of course, auditing. Auditing allows for accountability. We can track not only user activity, but also device activity that might be abnormal, such as devices authenticating to a VPN in the middle of the night when that normally does not happen, and many public cloud service providers have mechanisms in place to automatically detect things like this, suspicious login activity.


Azure Virtual Machines
One of the great things about deploying virtual machines in the Azure cloud is how easy and rapidly those virtual machines can be provisioned.
Whether using command line tools or the Azure portal, you can deploy Windows and Linux virtual machines in the Azure cloud. The usage fees that we are charged for that is based on a couple of items, such as the virtual machine size, which really determines the horsepower that virtual machine has when it's running.
And speaking of when a virtual machine is running, you are also charged for the amount of time virtual machines are left running. So when you don't need them to be running, perhaps if you're testing something, make sure to shut down virtual machines, and you might even delete the virtual machine if you no longer need it. There are a lot of factors to consider when you deploy and manage virtual machines in Azure.
We've mentioned the VM size, which consists of things like the number of virtual CPUs, the amount of RAM, and the disk IOPS, the input/output operations per second. So more of these items is better for performance but, of course, you're going to be paying more. But you might need more of RAM or more vCPUs to support the workload running within the VM.

When you deploy a VM, you deploy it into an Azure region or location. And so you should consider this because you might want to deploy it in a region that is geographically close to the user base that will require access to that virtual machine. Azure Virtual Machines have an operating system disk. But you can create separate independent managed disks that you can then attach to virtual machines or detach as needed, and they show up as data disks within the virtual machine operating system.

So in the virtual machine operating system, you still have to treat it as a new disk and initialize a partition and format it. Virtual machines can also have extensions. These are like little software agents that run within the VM operating system. And you might do this for the purposes of things like security. You might want some kind of anti-malware scanner running as an extension within your VM, or a backup agent, or even script support agents, such as for PowerShell desired state configuration.

When you deploy your Azure Virtual Machine, be it Windows or Linux, you also have to consider the Azure virtual network and subnet into which you are deploying it. Which also means that we have to think about the IP addressing that will be assumed from a subnet, or whether or not you need a public IP address for a virtual machine if you need to access it from the outside, such as from an on-premises network.

The thing to consider is, let's say that you're going to deploy five virtual machines into the same Azure virtual subnet. Well, instead of assigning five public IP addresses to each of them, you might consider assigning only one, which gives you a way in, kind of as a jump box. And once you're in, then you connect to the private IP addresses of the other four virtual machines. With Azure Windows Virtual Machines, we need to specify the logon credentials.

In other words, the username and the password that we'll use when we authenticate to it using Remote Desktop Protocol, or RDP. You need to make sure that any firewalls between a client device trying to connect to your Azure Windows Virtual Machine and it allows RDP traffic over port 3389. You can also, when you are deploying or creating a new virtual machine, add it to an availability set. Availability sets group virtual machines together for high availability.

However, the virtual machines in the set don't have to be exactly the same. But you can only do that when you are creating the virtual machine added to an availability set. You should also consider your backup strategy for your Azure virtual machine. Whether you're going to have extensions in the VM that support backup, or whether you're going to be using some kind of a backup vault, and we'll talk about that later.

Azure Linux Virtual Machines can use either username and password authentication or public key authentication, where you don't have to use the password. However, you have to have a public and a private key pair, where the public key is defined with the Azure Linux Virtual Machine, and you would keep the private key, for example, with your on-premises station. We can connect using Secure Shell, or SSH, over port 22, and so your firewalls have to allow SSH traffic for this to work.

Just like when working with Windows Azure Virtual Machines, when we deploy a Linux virtual machine at that time, we can also add it to an availability set a virtual machine availability set for high availability. And we should also consider our backup strategy, whether it's an extension, or whether we have a script running within the virtual machine, or whether we're going to use some kind of a recovery services vault backup solution. When you deploy a manual virtual machine in Azure, meaning it's Infrastructure as a Service, or IaaS,

[Video description begins] Screen title: Azure Virtual Machine Control. [Video description ends]

it means that you have full configuration control of that virtual machine and the operating system and software running within it. Which means that you are responsible for updating those things. However, there's also the notion of managed VMs. This means that virtual machines in some cases can be deployed automatically for you depending on the service you choose, like when you deploy a higher level service like Azure SQL Database. So as such, you have limited configuration control for managed virtual machines. To work with virtual machines in Azure, we can use the Azure Portal.

[Video description begins] Screen title: Azure Virtual Machine Management. [Video description ends]

There's also Azure PowerShell commandlets, the Azure CLI. An ARM template can be used, where you define one or more virtual machines, even other types of resources, that can be deployed and managed through the ARM template. And the ARM template can be itself deployed through the Portal or through PowerShell or the CLI. And developers can also use client SDKs and REST APIs to programatically talk to Azure resources like virtual machines.


Windows Azure Virtual Machine Deployment
There are a few ways that you can end up having a virtual machine running in the Azure Cloud. One way would be to migrate an on-premises server into the cloud.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. The address bar contains the URL: https://portal . azure. com /#home. The page is divided into 2 sections. In the left section, is a menu bar with menus such as Create a resource, Home, Dashboard, All services and Favorites . The right section shows the page linked to the menu item clicked on the left. He clicks Virtual machines in the navigator. Its window displays on the right. It has tabs named Basics, Disks, Networking, Management, Guest config, Tags, and Review+create. The Basics tab is active now. There is a section titled PROJECT DETAILS. It has fields captioned Subscription and Resource group. Another section called INSTANCE DETAILS is present. It has fields such as Virtual machine name and Region. On the left side of the window are 2 buttons- Add and Reservations. No virtual machines display there. He closes this window and clicks Create a resource in the navigator. A page titled New opens on the right. It has a blank search field at the top. Below are two columns titled Azure Marketplace and Popular. In the Azure marketplace column are menus such as Get started, Recently created, Compute, Networking and others. The Popular column has quickstart tutorials for different operating systems with their logos. [Video description ends]

Or you might use a managed service in Azure. In other words, you might configure a service offering that takes care of setting up the virtual machines for you. And of course, you could then manually deploy virtual machines,

[Video description begins] He clicks Compute in the Azure Marketplace column, and then clicks the See all link . A window titled Compute opens. The top of the window has a blank Search field. Below this are various filter options such Pricing, Operating System, and Publisher. Below is a section titled Recommended with large logos of various quickstart tutorials such as Windows Server and Red Hat Enterprise Linux. The next section is titled Operating Systems. [Video description ends]

in this case using the Azure portal. So one way to do that here in the Azure portal is to click Virtual machines when you're looking at the Azure home page.

[Video description begins] He clicks the drop down arrow in the Operating System field. The menu has Select all option at the top and it is checked now. Below are check boxes grouped by operating systems such as Windows and Linux. He unchecks Select all. [Video description ends]

That puts you in the Virtual machines view where you could click Add to add a virtual machine.

[Video description begins] He checks the Windows 2016 Server check box in the Windows group. The search results show a list of tutorials. [Video description ends]

But there are other ways. We could also click Create a resource over on the left. And under the Compute section, we can see some featured virtual machine images like Windows Server 2016 Datacenter. But we can also click See all, where we can even filter this list of virtual machine images. So for Operating System, for example, I can uncheck Select all and maybe I'm only interested in Windows Server 2016. So I can turn that on and the list gets filtered to show me only that.

[Video description begins] He clicks Create a resource in the navigator. A window titled New opens. In the search field, he types template and selects Template deployment from search results. A new window titled Template deployment opens. It has brief explanation about template deployment. A button captioned Create is at the bottom of the window. [Video description ends]

Notice that we are getting not only Windows Server 2016 but also apps installed within it like SQL server.

[Video description begins] A new window titled Custom deployment opens. There are 3 sections here- Learn about template deployment, Common templates, and Load a GitHub quickstart template. The first section has 2 links- Read the docs and Build your own template in the editor. The next section has 4 links- Create a Linux virtual machine, Create a Windows virtual machine, Create a web app, and Create a SQL database. In the last section is a field captioned Select a template. [Video description ends]

BYOL, as seen here, stands for Bring Your Own License. And so it would let you reuse any SQL Server 2016 Enterprise licenses you might already have here in the cloud. Another option for deploying a virtual machine here in the portal would be to click Create a resource. And if I search for template, I could choose Template deployment, then I can click Create. We're talking about ARM templates here, Azure Resource Manager. And what we could do is build our own template and

[Video description begins] He closes the window without saving any changes. [Video description ends]

manually specify that we want to create one or more virtual machines. We could even import any existing template files, you might have to do that.

[Video description begins] He returns to the Azure home page and clicks Virtual machines again. Then he clicks the Add button. [Video description ends]

There's also templates here to create a Linux virtual machine, Windows.

[Video description begins] The Create a virtual machine window opens on the right. [Video description ends]

We can ever refer to some templates available on the GitHub community that deal with the creation of the virtual machines.

[Video description begins] In the PROJECT DETAILS section, he leaves the default value of Pay-As-You-Go in the Subscription field, and selects Rg1 in the Resource group field. [Video description ends]

So there are a lot of ways to do it and this is just in the portal. We haven't even talked yet about how to do that in the command line tools, but we'll do that on the demos. So I'm going to go ahead and close out of this. And I'm going to go back to the Virtual machines view on the left and I'll click the Add button here, we're going to do it this way. So the first thing we have to do is tie this to a subscription and then deploy it into a resource group. So I'm going to deploy this into an existing resource group I have called Rg1, then the virtual machine name. It's very important that we're aware of what types of characters are allowed.

[Video description begins] He types a name in the Virtual machine name field. Since the name does not fulfil naming convention rules in Azure, the field gets highlighted in red and rules for naming appear below the field. There are 3 rules in all, and as he types any name, the rule which is violated gets a red cross mark in front of it. [Video description ends]

So here, I've got a bunch of capital letters and weird symbols of my virtual machine name. And it tells me that the virtual machine name can't contain non-ASCII or special characters.

[Video description begins] He leaves the default value of No infrastructure redundancy required in the Availability options field. [Video description ends]

Well, that's fine. Now like all Azure resource deployments, we have to have first considered a naming standard. I'm going to call this eastwindowsvm1. So that's the name of my virtual machine. Then I have to deploy it in a specific Azure region. So I'm going to go ahead and choose here Canada East. I'm not going to configure any availability options, but I'm certainly interested in the image. Here, it's got Ubuntu server, well, that's Linux. If I open this drop down list, I can see I can choose from other items including Windows Server 2016 Datacenter. Now you always have to consider what kind of workload will run, because that's going to determine which operating system you need to support that workload. So in this case, if I've already thought about that,

[Video description begins] A new window titled Select a VM size opens. It has a Search field on top and various filter options, namely Size, Generation, Family, and Premium disk. There is an Add filter button. A table with 12 of 165 VM sizes display. The table has columns VM SIZE, OFFERING, FAMILY, VCPUS, RAM, DATA, MAX IOPS, TEMPORARY STORAGE, PREMIUM DISK STORAGE, and COST/MONTH. [Video description ends]

I'll choose Windows Server 2016 Datacenter. Now at the same time, I've got a link to browse all images and disks if I want to see more, but that's the selection I need. So I'm good with that. The sizing here determines how much horsepower is available. So here, we've got one virtual CPU and 3.5 gigabytes of memory.

[Video description begins] The default size is Standard DS 1 v2. [Video description ends]

Again, if we consider the workload that this virtual machine will be

[Video description begins] The next section is titled ADMINISTRATOR ACCOUNT. It has 3 fields- Username, Password, and Confirm password. [Video description ends]

supporting, we'll be able to determine if that makes sense or not. And if it doesn't, I can click Change size. Naturally, the more vCPUs and RAM and the faster disk speed for Max IOPs that you select, the more cost you will incur. And we can see that over here in the cost per month estimation over on the right hand column.

[Video description begins] Naming rules for Username field appear. Rule 1 is that Username cannot contain special characters or end with period. Rule 2 is that Username must not include reserved words. Rule 3 is that the value is in between 1 and 32 characters long. [Video description ends]

However, if I'm happy with the default sizing that was selected, I can leave it.

[Video description begins] The next section is INBOUND PORT RULES. It has one compulsory field- Public inbound ports with 2 radio options - None and Allow selected ports. The default value is None. The next field is Select inbound ports. [Video description ends]

The next thing is credentials for our new virtual machine. So I'm going to fill in a username and a password and I'll confirm that same password.

[Video description begins] The last section is SAVE MONEY. There is just one field -Already have a Windows license? And is has two radio options- Yes and No. No is the deafult value. [Video description ends]

Now bear in mind, you won't be able to use things like Administrator because that's considered a reserved word. So I'm just going to use a user here, cirving, I've specified and

[Video description begins] The next tab, Disks, gets activated now. Its first section is titled DISK OPTIONS. It has one drop-down field- OS disk type, with a default value of Premium SSD. An additional field is Enable Ultra SSD compatibility (Preview) with 2 radio options- Yes and No. No is the default value. This field is disabled now. [Video description ends]

confirmed a password. I can also at this point in time determine what type of inbound network traffic I want to allow. I'm going to leave the default selections because we'll be talking about firewalls and inbound and outbound allowed traffic in other demos. And down below it says, do you already have a Windows license?

[Video description begins] The next section is titled DATA DISKS. No data disks are available now. There are links to create and attach a new disk, and to attach an existing disk. [Video description ends]

Well, we do not, so I'm going to leave it on the default of No. We don't have a license that we can reuse. I'm going to click Next to go to the disks configuration. Here we can determine if we want to use Premium SSDs for

[Video description begins] The Networking tab gets activated now. Its first section is NETWORK INTERFACE. It shows no available network interfaces. The next section is titled CONFIGURE VIRTUAL NETWORKS. It has fields-Virtual network, Subnet, Public IP, NIC network security group, Public inbound ports, and Accelerated networking. [Video description ends]

the utmost in performance, or Standard magnetic hard disk drives, HDD's. Now that would incur less cost, but of course, that comes with less performance. I'm going to leave it on Premium SSD. I can also attach data disks, whether they already exist or they want to Create a new one. Because what we're going to be creating here is essentially the operating system disk for the virtual machine. I'm okay with the defaults here of not having an additional data disk. So I'll click Next to move on to the Networking section. You need to deploy the virtual machine into an Azure Virtual Network, a VNet. Now, we can create a new Virtual network. Or I can choose from the drop down list if I've already created any.

[Video description begins] The value in Subnet is EastSubnet 1 with an IP address. [Video description ends]

And I have, I've got one called Eastvnet that I've deployed into a resource group called Rg1 which we also see listed here. So I'm going to leave that selection.

[Video description begins] The value in Public IP is ( new ) eastwindowsvm 1 - IP. [Video description ends]

A VNet is organized into one or more subnets. And down below, I can choose the appropriate subnet within that VNET that I actually want to deploy the virtual machine in. And always take note of the IP addressing because that reflects what addressing will be used, at least within that subnet for your Azure virtual machine.

[Video description begins] The default value in NIC network security group is Basic, in Public inbound ports is None and in Accelerated networking is Off. [Video description ends]

I can determine whether I want a public IP address available here.

[Video description begins] The last section is titled LOAD BALANCING. It has one field- Place this virtual machine behind an existing load balancing solution? It has 2 radio options -Yes and No. No is the default value. [Video description ends]

It's going to make a new one automatically

[Video description begins] The next tab- Management- gets activated. Its first section is titled MONITORING. It has 3 fields- Boot diagnostics, OS guest diagnostics, and Diagnostics storage account. [Video description ends]

that uses a name of the virtual machine with -ip at the end of it. Now, I want the public IP because I want to be able to connect to this virtual machine from outside of Azure from across the Internet.

[Video description begins] The default value in OS guest diagnostics is Off and the value in Diagnostics storage account field is eaststorageaccount 1. [Video description ends]

So we're not going to worry about changing any of the security settings or inbound ports because we'll be focusing on that in another demonstration. Much like we'll be talking about load balancing later on as well.

[Video description begins] The next section is titled IDENTITY and it has just 1 field, System assigned managed identity. Its default value is Off. [Video description ends]

So we will leave all the default selections for those. Then I'll click Next.

[Video description begins] The next section is titled AUTO-SHUTDOWN and it has just 1 field, Enable auto-shutdown. Its default value is Off. [Video description ends]

Boot diagnostics, which is used to capture things like boot up screens, is on by default and we've got a diagnostic storage account where that will be stored. I can also turn on operating system guest diagnostics if I want

[Video description begins] The last section is titled BACKUP, and it has 1 field, Enable backup with a default value of Off. [Video description ends]

metrics about the performance of that virtual machine gathered periodically.

[Video description begins] The tab Guest config gets activated. It has 2 sections- EXTENSIONS and CLOUD INIT. [Video description ends]

We can also assign a system assigned managed identity. You would use that if, for example, you had an app within this virtual machine that needed to talk to an Azure Key Vault to get credentials of some kind. We can also enable auto shutdown so that if we forget to turn off virtual machines at the end of the day, they'll turn off based on our configuration so we don't keep incurring costs.

[Video description begins] When he clicks the link Select an extension to install in the EXTENSIONS section, a new window titled New resource appears in the far-right side. It lists extensions with their logos. He closes this window. [Video description ends]

And we can determine whether we want to enable backup so I'm going to leave all of these default selections as they are. I'll click Next. I can also add extensions within the virtual machine.

[Video description begins] The tab Tags gets activated now. It has 3 drop-down fields- NAME, VALUE, and RESOURCE. He selects Project in the NAME field and Project A in the VALUE field. The value in RESOURCE field is 7 selected. When he has populated these fields, a new row with blank fields appears for adding new tags. [Video description ends]

If I choose Select an extension to install, we've got essentially agents that run within the virtual machine operating system for things like backup. Or for additional cloud security or script extensions if we want to run custom scripts, PowerShell Desired State, to maintain a baseline configuration, and so on. But I'm not going to do that, I'm going to click Next for tagging.

[Video description begins] The Review+create tab gets activated now. A progress bar at the top shows the review progress is going on. When it completes, a message says:Validation passed. PRODUCT DETAILS and TERMS shows the values he added in all the previous steps. [Video description ends]

And I will assign this to the ProjectA project,

[Video description begins] A window appears in the top-right corner showing the progress of the deployment process. The window has the text: Initializing deployment. [Video description ends]

I've already got that tag and value, otherwise I could add new ones. And then I'm going to click Review and create.

[Video description begins] After the window text changes to Submitting deployment, a screen titled Your deployment is underway appears. It has Cancel and Refresh buttons enabled on the top. [Video description ends]

So at this point, it's going to run a little validation based on my selections. And it now says validation passed and this is very important.

[Video description begins] The All resources window opens. [Video description ends]

We can see here what the US dollar cost per hour is approximated at here, so this is going to be important for determining the pricing for this. I'm okay with all of these settings. So I'm going to go ahead and click Create to build our Windows virtual machine. That pops us into this Your deployment is underway screen. And I could even click on All resources on the left, which I will do,

[Video description begins] Under the NAME column, 5 items for eastwindowsvm 1 are present. In the TYPE column, the item types are Virtual machine, Disk, Network interface, Public IP address, and Network security group. [Video description ends]

to see what's happening. Now, because a virtual machine really consists of a number of moving parts like an IP address, a network security group, a network interface, you'll notice that you could end up with more than just the virtual machine resource listed here when you're looking at the All resources view. And as I refresh the All resources view, notice I'm seeing more and more. I'm seeing the operating system disk for that virtual machine. And of course, I can also see the virtual machine itself. And as is the case with all Azure resources, if I were to click on the link for the name of that virtual machine, it opens up the properties blade where I could see all the items that I could configure about this virtual machine.

Linux Azure Virtual Machine Deployment

[Video description begins] Topic title: Linux Azure Virtual Machine Deployment. The host for this session is Dan Lachance. [Video description ends]

In this demonstration I will use the Azure portal to create a new Linux virtual machine. To get started, in the upper left, I'm going to click Create a resource.

[Video description begins] The Microsoft Azure portal home page opens in a browser window. He clicks Create a resource in the navigator pane. [Video description ends]

Now I can see the most popular virtual machine images here, including Ubuntu Server, which I'm going to use. Now I can see more options by clicking the Compute category on the left. And then on the right, I can click the See all link. Here I can filter, for example, by operating systems. So instead of selecting all operating systems, I could choose only the Linux variants shown here.

[Video description begins] In the Compute window, he clicks the drop-down arrow of Operating System field. He unchecks Select all and checks all the 6 check boxes in the Linux group. [Video description ends]

Now when I do that and then close the drop down list, the filter is effective. So in this case for example, I'm going to choose Ubuntu Server 18.04 LTS. When I click on it, it gives me a little brief synopsis about that.

[Video description begins] A new window title Ubuntu Server 18.04 LTS. It has a brief explanation about the server and a section titled Legal Terms. Its publisher and documentation links are also displayed. A Create button is placed at the window bottom. [Video description ends]

And I'm going to go ahead and click Create. Then I get details that need to be filled in.

[Video description begins] A Create a virtual machine window opens. The Basics tab is active now. [Video description ends]

So I've got the Subscription already filled in. I'm going to put this into an existing Resource group.

[Video description begins] He selects Rg1 in the Resource group field. [Video description ends]

And I'm going to call this, eastlinuxvm1. For the region, in this case I'll chose Canada East, because that's the closest proximity where I am working from. And I'm going to make sure that the Ubuntu image here is what I want, it is.

[Video description begins] The value in the Image field is Ubuntu Server 18.04 LTS. [Video description ends]

I'm going to leave the default virtual machine sizing. Otherwise, if I need to accommodate a busier workload, I might need more than 2 vcpus and 8 GB of memory. Notice that when I change size, it's not only increasing or scaling up vertically. But I can also scale down, that means choosing less horse power. So for example, maybe I'll choose a standard general purpose type of sizing. When I click Select, it now reflects the change, only 1 vcpu and 2 GB of memory.

[Video description begins] He selects Standard B1ms in the Select a VM size window. [Video description ends]

With Linux you can either use SSH public key authentication or standard password authentication, which I'll do here.

[Video description begins] He selects the Password radio option in the Authentication type field. [Video description ends]

With password authentication you've got to specify a username and confirm a password. But with SSH public key, you need to paste in the SSH public key for the specific username that you specify. And of course, you need to have the related private key in your possession on your station.

[Video description begins] When he selects the SSH public key radio option, the Password and Confirm password fields disappear, and are replaced by a field captioned SSH public key. [Video description ends]

So I'm going to go ahead and configure password authentication here. Once I've done that, as we scroll down further, we can control things like inbound port rules for network traffic.

[Video description begins] He leaves the default value of Off in the Login with Azure Active Directory field. [Video description ends]

However, I'm going to leave the defaults, I'm going to click Next.

[Video description begins] The Disks tab gets activated now. [Video description ends]

So here we have the option, just like with the Windows virtual machine, as to whether we want the better performing SSD, or the slower performing HDD, hard disk drive type of disk system. So I'm going to leave it on Premium SSD. I'm not going to attach any additional data disks. I'll just stick with the operating system disk here. When I go to Next, I can then place this within a virtual network in subnet, which I can either create newly or I can choose from the drop-down list.

[Video description begins] The Networking tab gets activated now. [Video description ends]

I'm going to leave this in my existing Vnet and Subnet. I wanted to create a Public IP, so I can reach into that virtual machine from across the Internet. I'm not going to change any of the other settings here related to inbound ports,

[Video description begins] The value in Virtual network field is EastVnet 1 and the value in Subnet field is EastSubnet 1 and an IP address. [Video description ends]

public configuration, or NIC security group options. I'm not going to change load balancing options. So in other words, I'm just going to click Next.

[Video description begins] The Management tab gets activated now. [Video description ends]

I'm going to leave the defaults for boot and OS guest diagnostics and auto-shutdown, I'll click Next.

[Video description begins] The Guest config tab gets activated now. [Video description ends]

Now, on the Guest config, I could click Select an extension to install, which is an agent that exist in the VM, just like it does for Windows. So for virus scanning, or for backup purposes, and so on.

[Video description begins] The New resource window pops up. [Video description ends]

But I'm not going to do that. I'll click Next for tagging.

[Video description begins] The Tags tab gets activated now. [Video description ends]

And here I could tie it to a project. Now I can tie it to an existing project, in this case ProjectA. That's a value, that's already been filled in, or I'm going to define something new here, Project B.

[Video description begins] He selects Project A in the VALUE field and changes A to B. [Video description ends]

Then I'm going to click Review + create. I'm going to check that all my options passed the final validation.

[Video description begins] A message- Validation passed- displays on the top of the window. [Video description ends]

Here we can see it has, listed here at the top. So I'm okay with this. I can see the pricing per hour on a US dollar basis, then I'll click Create. And that's going to give us a little deployment screen so we can see how far along the deployment is.

[Video description begins] The Initializing deployment window pops up in the top-right corner of the window. [Video description ends]

And of course, I can go to the All resources view on the left. And as I refresh it here, we'll see it has started to create the various resources that are required to run my Linux virtual machine.

[Video description begins] He clicks the All resources menu in the navigator and its window opens . He keeps clicking the Refresh button to update the list of resources displayed below. [Video description ends]

That would include things like an IP address, a network security group, and other items like the network interface, that it's going to create as we keep going. Here we can see the network interface, and even the virtual machine itself. So when I click on that virtual machine link to open up its properties blade, we can see from here we have all management options available in the portal. Including the ability to start, stop, and restart the virtual machine.

[Video description begins] He clicks eastlinuxvm 1 link under the NAME column and its window opens. [Video description ends]

Just like we have the option to do for a Windows virtual machine.


Connect to Azure Virtual Machines
  - Once you've deployed a virtual machine into the Azure cloud, how do you connect to it?
  - There are a few ways to do it, and our perspective in this demo will be how to do it from outside of Azure. 
    - In other words, from over the Internet from our on-premises network. 
    - Here in the Azure portal, I've already clicked on the Virtual machines view on the left. 
    - There are two virtual machines here, one running Linux, one running Windows, one is in the midst of being created and one is running.
  - Our Windows virtual machine should currently running. 
    - First step to talk about is about how to connect to a Windows virtual machine deployed in the Azure cloud. 
    - Click on the link for the name of that Windows virtual machine.
  - What is of interest in here is its public IP address
    - Configure it with a public IP so I can reach into it from over the Internet. 
    - Hover over it, there should be the little two pieces of paper icon over on the right, which implies copying, like the tip tells me. 
    - Click to copy that to my Windows clipboard.
  - Next is to fire up the Remote Desktop Protocol, or RDP client, here on my Windows 10 station.
    - Paste that public IP address assigned to my Azure Windows virtual machine, and then I'm going to click Connect.

[Video description begins] A warning message displays in a window. He clicks the check box captioned Don't ask me again for connections to this computer, and clicks the Connect button in the window. [Video description ends]

I'm going to tell it, Don't ask me again for connections to this computer, about trusting it, and I'll click Connect again, Now, notice I'm getting a message that says, Remote Desktop can't connect to it. Well, we know it's running, and we know that that is a valid IP address, and obviously we are connected to the Internet to see this screen in the first place. So it's probably related to some kind of blockage, not allowing port 3389 traffic, which is what is used by Remote Desktop Connections. So I'm going to go ahead and click OK, and let's go back into Azure and take a look at this.

[Video description begins] A window showing the progress of the connection displays. The text: Initializing remote connection- displays there. [Video description ends]

[Video description begins] He closes all windows and returns to the Azure page. [Video description ends]

So I'm still in the portal, I'm still looking at the Properties blade for my Windows virtual machine. I'm interested in clicking on Network in the Properties blade.

[Video description begins] He clicks Networking in the Settings group in the navigator. [Video description ends]

On the right I can see that VNet, so virtual network inbound traffic, is allowed. It says allowed over on the right, so is load balancer traffic, but everything else is denied. Well, no wonder we can't make a connection. So I'm going to go ahead and click Add inbound port.

[Video description begins] The Networking window opens on the right. The Inbound port rules tab is active now and it shows a table with all the active ports. The table has columns titled PRIORITY, NAME, PORT, PROTOCOL, SOURCE, DESTINATION, and ACTION. There are 3 ports listed in the table. 2 ports have Allow in the ACTION column, and 1 port has Deny. [Video description ends]

[Video description begins] A new window titled Add inbound security rule displays. [Video description ends]

The source here can be configured as a specific IP address, or an Application security group, or I'll leave it here on Any. Then I can specify the source port.

[Video description begins] The first field is Source and it has 4 options in the drop-down menu. They are Any, IP Addresses, Service Tag, and Any. The default value is Any. [Video description ends]

Well that's fine, but the destination here, I can specify as being any or a specific IP address. I'm going to leave it here on any, but the destination port range is important.

[Video description begins] He leaves the default value of * in the Source port ranges field. [Video description ends]

[Video description begins] There are 4 options in the Destination field drop-down menu. They are Any, IP Addresses, VirtualNetwork, and Application security group. Any is the default value. [Video description ends]

Here I want to allow traffic to 3389.

[Video description begins] He clears the Destination port ranges field and types 3389. [Video description ends]

And that's going to be TCP based, or I could specify UDP, or just leave it on Any, and in this case I want to allow not deny it.

[Video description begins] He selects Any in the Protocol field and Allow in the Action field. [Video description ends]

So I have to also specify the priority. Notice the default priority here is 100. Let's also change the name here to reflect the new port number for Remote Desktop Protocol.

[Video description begins] He types Port_ 3389 in the Name field. [Video description ends]

Then I'm going to go ahead and click Add. Now, that's going to add it to the list of inbound rules that we see listed in the background.

[Video description begins] A window with the text- Creating security rule- pops up in the top-right corner of the window. [Video description ends]

It's important to note that the rule is at the top of the list, because these rules are checked from top down. And so we don't want this Port_3389 rule underneath the DenyAllInBound, because it would never get used. So let's go ahead and try to Remote Desktop into this virtual machine again. Well, this is much better.

[Video description begins] The newly-added rule is at the top of the list. [Video description ends]

[Video description begins] A window titled Windows Security displays. It has the text - Enter your credentials- and 2 fields. The first field has cirving and the second field has an encrypted password. [Video description ends]

I've specified my username and password that I defined when I deployed that virtual machine, and I'm going to go ahead and click OK. We can see here we're being asked to trust the identity of the computers. I'll say, Don't ask me again, I trust it, and I'll choose Yes.

[Video description begins] A window shows the progress of the remote desktop connection. Then another window titled Remote Desktop Connection displays. He clicks the check box in the window, and the Yes button. [Video description ends]

And after a moment, we can see that we are actually now being sent into a Remote Desktop session of that Windows Server 2016 virtual machine, which is running in the cloud.

[Video description begins] The 2 windows close and a new desktop screen appears. [Video description ends]

And before you know it, we're in. So it's just another Windows virtual machine. In this case, it happens to be running in the cloud.

[Video description begins] A panel titled Networks display on the right. It is asking for access permissions. He clicks the Yes button. [Video description ends]

Much quicker and easier to set up than we might do if we were trying to set this up ourselves manually on-premises. And if I go into the Start menu here, and let's say we go to a command prompt. So I'm going to run cmd. You can see in the background it's automatically launching the Server Manager GUI tool, which is normal for new installations of the Windows Server operating system.

[Video description begins] He clicks Run from the Start menu and types cmd. Then he clicks cmd from the best-matched results. A new window titled Select Administrator C:\Windows\System32\cmd.exe displays. [Video description ends]

But what I want to do here is simply type ipconfig. And notice here that we don't see a reference to the public IP address we connected to, because that's not configured within the virtual machine operating system, it's a separate Azure resource.

[Video description begins] At the command prompt, he types and executes the following command: ipconfig. The output displays. It is the Windows IP Configuration of the remote machine. He highlights the IP address 10.1.1.4. [Video description ends]

However, what we do see is an IP address that's been assigned based on the subnet address range that we deployed the virtual machine into. So that's it, we are now able to get into our Windows virtual machine. Well, that's fine for Windows, but what about Linux? Back here in the portal, I've gone back to my Virtual machines view and we can see our Linux virtual machine now has a status of Running.

[Video description begins] He closes the command prompt window and returns to the Azure portal. The Virtual machines window displays here. [Video description ends]

So I'm going to click on it so that we can see its public IP address.

[Video description begins] He clicks eastlinuxvm 1 from the list and its window opens. He points to the Public IP address 52.235.38.158. [Video description ends]

Now, what you want to do is use an SSH client of some kind. So if you're using a Linux machine already, you can use the SSH command line to connect to your Azure Linux virtual machine. Or, I'm using Windows, I could also use the free PuTTY tool. I've downloaded and installed the free PuTTY tool. And when I fire it up, I can paste in the public IP address from my Linux VM running in Azure, along with Port 22, which is used by SSH.

[Video description begins] He opens the PuTTY Configuration tool. It has a navigation pane on the left and Basic options for your PuTTY session on the right. The Linux IP address displays in the Host Name for IP address field, and the number 22 displays in the Port field. Connection type field has the SSH radio option clicked. [Video description ends]

I've already gone, made some other changes, like the window appearance to increase the font, and I've saved it into a setting called Azure Linux VM.

[Video description begins] In the navigation pane, he clicks Appearance in the Window menu group. New settings display on the right. [Video description ends]

So I can load that up at any point in time.

[Video description begins] Then he clicks Session in the navigation pane. Azure Linux VM displays in the Saved Sessions field. 3 buttons- Load, Save, and Delete are also present here. [Video description ends]

Now, to make the SSH connection, I would click Open.

[Video description begins] He clicks the Open button in the window and a new window with the IP address in the title bar opens. The window is blank. [Video description ends]

And it's trying to make the connection, but remember with the Windows virtual machine there was no default inbound port enabled? That's the problem here. Let's go back and let's explore that here in the Linux virtual machine in Azure.

[Video description begins] He closes the window and returns to Azure. The Networking window displays here. [Video description ends]

So I'm going to go to networking and again, we can see our inbound ports. There's no allowance here for port 22, so I'm going to click Add inbound port, and I'm going to specify a destination port of 22, so TCP 22 for SSH allow.

[Video description begins] The Add inbound security rule window opens and he types 22 in the Destination port ranges field, selects TCP in Protocol, and Allow in Action. He types Port_22 in the Name field. [Video description ends]

And I'm going to change the name here to reflect the port number, and I will go ahead and click Add. And we can now see the rules at the top. It's allow rule, so it should allow our traffic in.

[Video description begins] Port_22 displays at the top of the inbound ports list. [Video description ends]

Let's go back and test it out. So back here in PuTTY, let's try again.

[Video description begins] He again opens the PoTTY configuration window and clicks the Open button. [Video description ends]

I'm going to click Open. This time we get something immediately.

[Video description begins] The IP address window opens again and a security alert message displays in a window. He clicks Yes in the window. [Video description ends]

So it's asking me, do we trust the unique fingerprint for the server, because it's the first time we've connected. I'll choose Yes, and it wants me to log in. Well, I've specified credentials when I deployed this. So we're using username and password authentication as opposed to public key authentication, which is a choice when you deploy a Linux virtual machine.

[Video description begins] He returns to the IP address window and the text- login as- displays there. He types cirving and presses Enter. A line of text appears. It reads: cirving @52.235.38.158's password. [Video description ends]

So it now wants the password for this account. So I'll go ahead and supply that. And after I've done that, if the credentials are correct, we will be logged into the virtual machine remotely over the Internet. And we can see in fact, that's been done, and if I do an ifconfig to show the interface, we can see not the public IP, just like with Windows, but rather the private IP, which is derived from the address range assigned to the subnet that this Azure virtual machine was deployed into.

[Video description begins] The command prompt changes to cirving@eastlinuxvm1. He types and executes the following command: ifconfig. The output displays. It shows the configuration details of the remote machine. He highlights the public IP address 10.1.1.5. [Video description ends]

Azure Virtual Machine PowerShell Management

[Video description begins] Topic title: Azure Virtual Machine PowerShell Management. The host for this session is Dan Lachance. [Video description ends]

In this demonstration, I'll be using PowerShell to create a new Azure virtual machine. Here in the PowerShell ISE, I've already got a script ready to go. In the first line of the script, it's actually lines 1 and 2 but I've got the back tick symbol here as the line continuation character. I've got a statement using a PowerShell cmdlet called Get-AzVMImage.

So this is important because we can specify the image name that we want to build the new virtual machine from. And so, let's go ahead and highlight that first set of code for Get-AzVMImage. And I'm going to go ahead and run that selection.

[Video description begins] A Windows PowerShell ISE window displays. There is a menu bar and a tool bar at the top. A tab titled it_clazfd_ enus _06.jps1 is active. The screen below is divided horizontally into 2 scrollable sections. The top section has lines numbered from 1. Code is written in lines 1 through 19. In lines 1 and 2, the following command is written and highlighted: Get -AzVMImage -Location "Central US" -PublisherName "MicrosoftwindowsServer" -Offer "windowsserver" -Skus "2012-R2-Datacenter". He clicks the Run button denoted by a page and a right-facing arrow. The highlighted command displays in the bottom section of the window. [Video description ends]

And down below, we can see some of the images that are available here based on Microsoft Windows Server.

[Video description begins] The command output displays in the section below. It is a table with all the images and their Version, FilterExpression Skus, Offer, PublisherName, Location, and Id. [Video description ends]

So we can see here that the SKU names are listed in the list. However, I'm going to go ahead and comment those back out in my script. And I'm going to clear the screen down at the bottom.

[Video description begins] He types a # in the beginning of lines 1 and 2. In the bottom section, he types the command cls at the command prompt. [Video description ends]

Now to actually work with a virtual machine. To build it through PowerShell, the first thing I'm doing is building a variable here called $creds for credentials. And we're using the PowerShell Get-Credential cmdlet, which will pop up a graphical dialog box where I can specify both a username and a password. And so that's going to be stored in the $creds variable that I will refer to later.

[Video description begins] He highlights the following command in line 6: $creds = Get -Credential -Message "New VM username and password?". [Video description ends]

Then I'm creating a variable called vmconfig. And I'm setting the resource group that I want to deploy this virtual machine into. I'm setting the name of the virtual machine, the location, the image I want to create the virtual machine from, in this case Win2016Datacenter. I'm also giving a name for the public IP address resource. Here's the $creds I'm passing for the credential. And then I'm opening port 3389. So what these all are in the vmconfig section here, ResourceGroupName, Name,

[Video description begins] He highlights the following code written in lines 8 through 17, line by line: $vmconfig = @ { ResourceGroupName = 'rg1' Name = 'vm33452' Location = 'Canadaeast' ImageName = 'win2016Datacenter' PublicIPAddressName = 'eastwindowsvm2_ pubIP' Credential = $creds OpenPorts =3389 }. [Video description ends]

Location, ImageName, these are parameters. And I could just as well use dash in front of each of these parameter names, and then pass the values. All I'm doing here is organizing it into a single resource or a single variable rather called $vmconfig that I simply refer to here. And I pass it to the appropriate cmdlet. The appropriate cmdlet here is New-AzVM to build a virtual machine based on the configuration defined above, the parameters, and their values.

[Video description begins] He highlights the following command in line 19: New - AzVM @vmconfig. [Video description ends]

So let's go ahead and run this entire script by clicking the Run Script button.

[Video description begins] He clicks the run script button denoted by a right-facing arrow. A new window titled Windows PowerShell credential request displays. It has a line of text, New VM username and password?, and 2 fields- User name and Password. [Video description ends]

And sure enough, it pops-up and it says, new VM username and password, that comes from -Message up above. So after I've specified those credentials, I'll go ahead and click OK. And it's going to go ahead and create my virtual machine based on the settings defined here in PowerShell.

[Video description begins] The bottom section shows a progress bar with the text : Creating Azure resources. [Video description ends]

Once the script completes, we're going to go ahead and switch over to the Azure portal to check for our new virtual machine, vm33452.

[Video description begins] Once the process completes, configuration of the VM resource displays. [Video description ends]

And sure enough, here in the portal, if I go to the Virtual machines view, which I've done. We can see our new virtual machine listed, and it's running. So by default, when you deploy a virtual machine, even through PowerShell, its state is set to Running. So it's started up, and ready to go.

[Video description begins] He opens the Microsoft Azure portal in a browser window. The Virtual machines window is open now and vm33452 displays in the list of VM there. Its Status is shown as Running. [Video description ends]

Azure Virtual Machine Scale Sets

[Video description begins] Topic title: Azure Virtual Machine Scale Sets. The host for this session is Dan Lachance. [Video description ends]

Microsoft Azure virtual machine scale sets are used for load balancing, where we have a series of identical virtual machines working together to serve up some kind of an application. It also supports auto-scaling. So for example, depending on the demand, we can increase the number of backend virtual machines supporting the application through the scale set.

So we can control this through the instance count property. This is the number of instances that are running in the scale set, and we can even set that to a minimum value. Pictured on the screen, we have a diagram where, on the left, we've got a client that is trying to access a web application over port 80.

[Video description begins] Screen title: Azure Virtual Machine Scale Sets. On the left is a man's icon labelled Client (Port 80). On the right, are three rectangular boxes, one inside the other. There are 3 boxes inside the smallest rectangle. All the 3 boxes have the text VM (port 80) written inside them. The smallest rectangle depicts Subnet . The next rectangle depicts VNET. [Video description ends]

So that connection goes to the load balancer. So if the client is typing in www.app.com, that is resolving to the public IP address of our load balancer. And so that's how the request gets from the client to the load balancer.

[Video description begins] An arrow points from the client to a Load Balancer, depicted by a load balanced on a circle. [Video description ends]

Now, the load balancer periodically checks that the backend virtual machines, of which we have three here, listed on the far right. It periodically checks to make sure that they are responsive. Because if we have a virtual machine that is not responsive, then client requests are not forwarded to it. Otherwise, we have three virtual machines in the backend in our scale set, in this diagram, that can be used to service client request. And so it increases performance while providing high availability. Because if we have virtual machines in the backend that aren't running, then client requests are simply directed to other ones that are still responsive. We manage our scale sets using the Azure portal.

[Video description begins] 3 arrows emerge from the load balancer and go towards the 3 rectangles on the right. [Video description ends]

[Video description begins] Screen title: Scale Set Management. [Video description ends]

We can use the Azure CLI. For example, you can use the az vmss virtual machine scale set create command to create one. In PowerShell, the equivalent to create a new virtual machine scale set would be New-AzVmss. And then finally, we can also use an ARM template, where we can specify our resource type of Microsoft.Compute/VirtualMachineScalesets.

Deploy an Azure Virtual Machine Scale Set

[Video description begins] Topic title: Deploy an Azure Virtual Machine Scale Set. The host for this session is Dan Lachance. [Video description ends]

In this demonstration, I will use the Azure portal to deploy a new Azure Virtual Machine Scale Set. To get started, I'm going to click Create a resource over on the left, and

[Video description begins] The Microsoft Azure portal homepage displays in a browser window. He clicks Create a resource in the navigation pane and a window titled New opens. [Video description ends]

I'm going to search for the word scale. And here it is, Virtual machine scale set. I'm going to go ahead and choose that, and then I'll click Create.

[Video description begins] A Virtual machine scale set window opens. It has a brief description of scale sets and a Save for later button. The publisher name and documentation links are also present. [Video description ends]

The purpose of creating this virtual machine scale set is to make sure that we have a number of identical backend virtual machines supporting an application. So, basically, we're going to have a frontend load balancer that supports this capability.

[Video description begins] A new window titled Create virtual machine scale set displays. It has a section titled BASICS with many fields. [Video description ends]

So I need a name for my virtual machine scale set. I'm going to call it webapp3 and vmss, virtual machine scale set. So because the backend virtual machines all need to be identical, when you define the scale set, which we're doing, you need to choose the Operating system disk image, okay?

[Video description begins] He types webapp3vmss in the Virtual machine scale set name field. [Video description ends]

So, let's say it's going to be Windows Server 2016 Datacenter. Of course, you could also have some kind of a custom image that has an application loaded within it. Next thing I'm going do here is deploy it to a resource group, and specify the location, and down below I need to specify credentials. Username and password, in this case, for the Windows operating system since that's the image I selected for my scale set. Notice this is different than if you create an Azure load balancer, which we'll see in another demo.

[Video description begins] He clicks the drop-down arrow in the Operating system disk image field. A list of OS display, grouped under Windows and Linux. [Video description ends]

[Video description begins] He leaves the default value of Pay-As-You-Go in the Subscription field, and selects Rg1 in the Resource group field, and Canada East in the Location field. [Video description ends]

[Video description begins] He types cirving in the Username field and the password in the Password and Confirm Password fields. [Video description ends]

Because with an Azure load balancer, as opposed to specifying the operating system image and the credentials here, the load balancer can reference existing virtual machines that are already out there. And they don't even all have to be identical. So that's a little bit different than what we're doing here with the virtual machine scale set.

Here's the Instance count property, where it defaults to having 2, but I can change that. I can also set the instant size, which determines things like the amount of CPU power and the amount of memory. I'm going to click Change size, I'll just choose something very basic, let's say 1 VCPU and 1 GB of RAM.

[Video description begins] He selects 81s VM SIZE in the Select a VM size window. [Video description ends]

And I'll go ahead and select that. And as we scroll further down, I'm going to let it use managed disks, which is by default. Under advanced settings, I can determine whether I want to allow scaling beyond 100 instances. I shouldn't need that, so I'm not going to turn that on.

[Video description begins] He clicks Show advanced settings link below the Use managed disks field. Enable scaling beyond 100 instances field shows up and he leaves its default value of No unchanged. [Video description ends]

And I can also enable autoscaling. Autoscaling changes the number of backend instances automatically based on things like CPU busyness or threshold.

[Video description begins] He selects Enabled in the Autoscale field. [Video description ends]

So here, we can see that if we've got a CPU threshold above 75%, then we can increase by a virtual machine. One VM based on the image that we specified when we were creating this.

[Video description begins] In the Scale Out section, he points to the value in the CPU threshold field. It is 75. Then, he points to the value in the next field, Number of VMs to increase by. It is 1. [Video description ends]

That's for scaling out, adding virtual machines to support a busy workload. The opposite is scaling in, so both of them are horizontal scaling, but scaling it reduces the virtual machines based on a CPU threshold. And this is a good setting. It's important because we don't want to have virtual machines running we don't need, because we're paying for that. And, as I go further down,

[Video description begins] In the Scale in section, he points to the value in the CPU threshold field. It is 25. Then, he points to the value in the next field, Number of VMs to decrease by. It is 1. [Video description ends]

I'm going to decide whether I want to use an application gateway for load balancing, although I don't have any already defined. I could also choose load balancing as a solution, while I am defining the scale sets, I'm really doing two things at once.

[Video description begins] He scrolls down and reaches the field Choose Load balancing options. He selects the radio option Load balancer. [Video description ends]

So I can give a public IP address name for the load balancer IP address. So, if we scroll back up at the top here, the name of this scale set is webapp3vmss. I'll copy that, and I'm just going to go ahead and use that as part of the name here, I'll call it pubIP at the end.

[Video description begins] He pastes the Virtual machine scale set name in the Public IP address name field and adds IP after it. [Video description ends]

And then I can use a domain name label to which the following suffix listed down here, .canadaeast, that's my region, .cloudapp.azure.com will be added.

[Video description begins] He pastes the Virtual machine scale set name in the Domain name label field. [Video description ends]

Of course, that can be customized, but I'll accept that default. And then finally, I have to choose a virtual network. So I'm going to choose EastVNet1, and I've got 1 subnet, that's important because that's where we will be deploying these virtual machines. They're going to assume IP addresses from that subnet address range.

[Video description begins] He selects EastSubnet 1 (10.1.1.0/24) in the Subnet field. [Video description ends]

So it's important to make the correct selection. Do we need a public IP address for each and every instance, it's set to off? I'm going to say, no, because these are running in the backend to support an app. And you might wonder, how do I gain access to them if I need to manage them? Well, you might have another virtual machine outside of the scales set running in that subnet that does have a public IP address.

And, so you can connect to it, for example, from on-premises, and once you're connected to it, you would be on the private network. And you could then manage these additional virtual machines from this scale set. So it means having less public IP addresses, which saves on cost. Okay, so the next thing we're going to do is just click Create. So now let's go to the All resources view, and let's take a look at our newly created scale set.

[Video description begins] He clicks All resources in the navigation pane and its window opens on the right. [Video description ends]

So I'm going to filter this view for vmss, and here we can see we've got our webapp3vmss virtual machine scale set. We can also see the load balancer and the public IP address resources.

[Video description begins] He types vmss in the Name field. 3 items display. They are the VM scale set he just created , the load balancer, and the Public IP address. [Video description ends]

I'm going to go ahead and click on the virtual machine scale set to open up its Properties blade. And in the Overview section on the right, we can see the public IP address here, that's actually for the load balancer component.

[Video description begins] He highlights the Public IP address of the webapp3vmss virtual machine. It is 40.80.249.17. [Video description ends]

And if I click on Instances on the left, we can see the virtual machine instances here in their current state.

[Video description begins] He clicks Instances in the Settings group. 4 instances display on the right. [Video description ends]

And if I were to click, for example, on Scaling, this is where during the creation we had the option of configuring autoscaling. So for scaling out and also for scaling in.

[Video description begins] He clicks Scaling in the Settings group and points to the Scale mode field on the right. [Video description ends]

If I were to click Operating system, we can see here that it's the Windows Operating System, based on the image we selected. Same with the sizing, we can see the size of the virtual machine, which determines the underlying horse power, like the number of VCPUs and the amount of RAM.

[Video description begins] He clicks Operating system and then Size. The VM size he selected before is highlighted [Video description ends]

I'm going to close out of that, and I'm going to click on our load balancer that was created for the scale set.

[Video description begins] He returns to the All resources window and clicks the second item in the list. [Video description ends]

And notice, again, that we've got the public IP address here, that's the frontend for client connectivity to the backend configuration.

[Video description begins] The load balancer window opens on the right, and he highlights the Public IP address field value. It is 40.80.249.17. [Video description ends]

And notice that if I were to click the Backend pools here, we can see that we've got a backend pool that was created for us automatically, and here are the virtual machine instances. And, of course, we can see the private IP addresses that they've been assigned.

[Video description begins] He clicks Backend pools in the Setting group. A list of 4 instances displays on the right. Their names, NETWORK INTERFACE, and PRIVATE IP ADDRESS properties display. [Video description ends]

Now while we've got virtual machines instances listed here, if I click on the Virtual machines view over on the left, I don't see virtual machines here that result from the use of a scale set.

[Video description begins] He clicks Virtual machines in the navigation pane of the Azure home page. [Video description ends]

Azure Load Balancing

[Video description begins] Topic title: Azure Load Balancing. The host for this session is Dan Lachance. [Video description ends]

The Azure Load Balancer is used to take incoming client requests and spread them out amongst backend virtual machines that support an application. This means we have a result of increased performance because we've got more virtual machines to service client requests. It also supports high availability. So client requests bypass unresponsive VMs.

What this means is that the load balancer is configured to periodically probe backend virtual machines to make sure they respond. And for those that do not respond, client requests will not rerouted to those specific instances. We can configure a public load balancer. That means that the load balancer is Internet-facing and it will be assigned a public IP address.

And so when clients enter the URL for a web app, it needs to resolve to that load balancer public IP address. So that's for inbound Internet traffic. But we can also define an internal load balancer that would be used not over the Internet, but instead within an Azure VNet, maybe for some kind of internal line of business application running in the cloud.

It can also be used for on-premises traffic that's coming into Azure, for example, through a VPN in a hybrid cloud configuration scenario. With the Azure Public Load Balancer, we have health probes that verify the backend virtual machine responsiveness. And that actually gets configured within what's called a load balancer rule. You'll see that when you open up a load balancer in Azure and take a look at its properties blade. So in the diagram, we've got clients on the Internet that make a connection to the load balancer, which in turn will send a request to backend hosts.

[Video description begins] A diagram displays progressively. At the top is a cloud icon. An arrow emerges from the icon bottom and leads to a load balancer icon. 3 arrows emerge from the bottom of the load balancer icon and lead to 3 computer icons depicting 3 clients. [Video description ends]

Load balancers in Azure can be managed like most resources in a number of ways, such as through the Azure Portal, the web GUI, or the Azure CLI.

[Video description begins] Screen title: Azure Load Balancer Management. [Video description ends]

So for example, to create a load balancer in the CLI, we could issue the az network lb, for load balancer, create. In PowerShell, the equivalent would be the New-AzLoadBalancer cmdlet. And if you're using an ARM template to deploy load balancer resources, then you would refer to the Microsoft.Network/LoadBalancers resource type.

Configure Azure Load Balancing

[Video description begins] Topic title: Configure Azure Load Balancing. The host for this session is Dan Lachance. [Video description ends]

In this exercise, you're going to start by using the Azure portal, so the web graphical interface, to create a storage account. Then, after the account is created, upload a file to it using the portal. Then you will create an Azure file share, which is essentially a cloud-based shared folder. Next, you will create a key vault and then store a secret within the vault. Think about how you might approach each of these items by pausing the video.

And then after you've thought about it, come back to view the solutions. Here in the portal, I can create a storage account by going to the Create a resource link over in the upper left. Then I can choose the Storage category, and choose Storage account.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. He clicks the Create a resource menu from the navigation page and then Storage category in the Azure Marketplace column displayed in the New window. Then he clicks Storage accounts in the Featured column. [Video description ends]

So I have to specify things like a resource group into which to deploy this new Storage account.

[Video description begins] Create storage account window displays. He selects Rg1 in the Resource group field. [Video description ends]

Storage account name, not using uppercase letters. So let's say we call this stor1990. Then I have to specify the Azure location to deploy this to.

[Video description begins] He selects Canada east in the Location field. [Video description ends]

And I have to determine whether I want it to be Standard or Premium, and the account kind. So if I want BlobStorage, I would choose that.

[Video description begins] He leaves the default value of Standard in the Performance field and selects Blob Storage in the Account kind field. [Video description ends]

Let's say I want the Cool access tier. And assuming that's all I want to do, I would just review my settings, let the validation succeed, and then create the storage account.

[Video description begins] A window with a progress bar and text- Submitting deployment- displays in the top-right corner of the screen. [Video description ends]

Once that's done, I can go to the Storage accounts view on the left, and I will see my newly created storage account. I may have to refresh. And here I'll see my newly created storage account, stor1990. If I click it, from within here, I can upload content.

[Video description begins] He clicks Storage accounts in the main navigation panel and stor1990 displays in the list of items on the right. When he clicks its name, its properties window displays. [Video description ends]

For example, by going to Blobs, where I could create a container, which I will call pics.

[Video description begins] He clicks Blobs in the Blob service group in the navigation pane. A New container window opens on the right. [Video description ends]

I'll leave it as Private, no anonymous access to the content.

[Video description begins] He types pics in the Name field and leaves the default value of Private in the Public access level field. [Video description ends]

And within pics, I can then select to upload content.

[Video description begins] He clicks the OK button and pics blob displays in the content list. He clicks its name and pics window opens. He clicks the Upload button on the top and an Upload blob window appears on the far-right. [Video description ends]

From here, I can then click the Select a file icon over on the far right.

[Video description begins] He clicks the folder icon next to the Files field. [Video description ends]

And once I've specified a file, I can click Upload to upload that file.

[Video description begins] He selects the file CustomerTransactions.xlsx and clicks the Upload button. The file name displays in the Current uploads section of the Upload a blob window. A window with the text : upload completed for CustomerTransactions.xlsx appears in the top-right corner of the screen. [Video description ends]

Now, the next thing I need to do is create an Azure file share. Now, what we can do is within the Properties blade for a storage account, we can work with files. Now, notice here as I look through the Properties blade of this, we're looking at the Blobs within the storage account. So if I back up one level, let's go back into that, as you scroll down through, sometimes in a storage account, depending on how it was created, you'll see the Files option. Other times, as in this one, you will not. That's because of the way that this was created for Blob storage.

[Video description begins] He closes the cross on all the 3 open windows and reaches the Storage accounts window. He clicks stor1990 in the list and scrolls through its navigation pane, looking for the Files menu. [Video description ends]

So if I were to open up a different storage account, like stor1989, and scroll down. Notice here that the Files service is available.

[Video description begins] He closes this window and goes back to the Storage account window. He clicks stor1989 and its properties page displays. He locates the Files menu in the File service group in the navigation pane. [Video description ends]

So I'm going to go ahead and click Files. I'll click File share and call it something.

[Video description begins] He clicks File and its window opens on the right. He clicks the File share button with a large plus icon and a File share window opens on the far right. There are 2 fields -Name and Quota, and 2 buttons- Create and Discard. [Video description ends]

So for example, if this is going to be for budgets, then I would call it budgets. And for the Quota, maybe I'll set a size of 4 gigabytes, and I'll click Create.

[Video description begins] A window with the text - Successfully created storage file share- appears in the top-right corner of the screen. Budgets file share displays in the properties window now. [Video description ends]

Now, when I go into budgets, I then have to bear in mind that if I click Connect, here I can see the commands that could be used to connect to it from either an on-premises machine or even a virtual machine deployed in the Azure cloud.

[Video description begins] A budgets window opens. It has buttons- Connect, Upload, Add directory, Refresh, Delete share, and Quota. Location is budgets and no files are listed below. [Video description ends]

[Video description begins] A Connect window opens in the far right. It has 3 tabs- Windows, Linux, and MacOS. Windows tab is active now. Drive Letter is Z and 2 commands displays with a copy icon beside them. [Video description ends]

For instance, using the net use command on a Windows host to map drive letter Z to this specific shared folder. The last thing I need to do here is create a key vault and create a secret within it. I'm going to choose Create a resource, and I'm going to type in key vault, and I'm going to click Create.

[Video description begins] He clicks Create a resource in the main navigation pane and types key vault in the Name field. Then, he selects Key vault from the drop-down results and a Key Vault window opens. [Video description ends]

So I have to give it a name, I'm going to call this kv1991. And I'm going to deploy this into an existing resource group, and I'll accept all of the other defaults, and I'll click Create.

[Video description begins] In the Create key vault window, he types kv1991 in the Name field and selects Rg1 in the Resource group field. [Video description ends]

Now, a key vault needs to have secrets in it that are accessed by code. Which the code might need in turn to authenticate to other services elsewhere. So if I go to All resources, my view, and I filter, let's say by kv, we'll see our new vault, kv1991.

[Video description begins] When the key vault kv1991 is created, he closes the window and clicks All resources in the main navigation pane. He types kv in the Name field to filter by name. kv1991 displays in the results below. He clicks kv1991. [Video description ends]

Within it, I can click Secrets if all I want to do is to find, for example, a secret password as opposed to security keys, cryptographic keys, or PKI certificates.

[Video description begins] He clicks Secrets in the Setting group in the kv1991 navigation pane. No secrets display on the right. [Video description ends]

So I'm going to choose Generate/Import, and I'm going to manually create a secret here called secret2. And I'll put in a secret value here, and then I'll click Create.

[Video description begins] A window with the text - Deployment succeeded- displays in the top-right corner of the window. He closes it and clicks the Generate/Import button at the top of the window. [Video description ends]

[Video description begins] A Create a secret window opens. The Upload options contains Manual. He types secret2 in the Name field and types a value in the Value field. A window with the text- Creating the secret 'secret2' - appears at the top of the screen. Secret2 displays in the list of secrets in the kv1991 storage vault. [Video description ends]

Now, here within the portal, I can actually click on secret2 and follow down through that to the point where I can click the Show Secret Value button to actually expose that key vault secret item.

[Video description begins] When he clicks on secret2, its properties window displays. It shows 1 item in the CURRENT VERSION section with a status of Enabled. [Video description ends]

[Video description begins] When he clicks the item, its window opens. He scrolls down to the Secret section and clicks the Show Secret Value button. The field below displays the text testing, and this is the value he typed while creating secret2. [Video description ends]

Azure Serverless Computing

[Video description begins] Topic title: Azure Serverless Computing. The host for this session is Dan Lachance. [Video description ends]

Microsoft Azure has a number of service offerings that are under the classification of serverless computing, but what does this mean? Because in the end, there's always an underlying server that's used, for example, to support a database application and code that's running. However, we're talking here about automated server deployment and management, what this means is a managed service. So that we don't have to worry about actually deploying a virtual machine and the operating system and the tools within it that will run our code.

So, really we're talking about focusing more on code and applications that result from that. So, really this is of primary interest to developers. An example of this would be working with what are called Azure functions, which we'll talk about in more detail later. Azure functions allow you to create and run code on-demand in the cloud without having to worry about provisioning a server that has the appropriate engine that can run that code. It's taken care of for you.

Now we can implement Azure functions in a number of different ways. It could be used for a web application, it could be a mobile device app that we're developing, that is configured to talk to Azure resources through our functions. We could look at Internet of Things, or IoT, received data, such as through the Azure IoT Hub. In Azure, that could trigger a function that we've created as an Azure function.

And so the key is here, we've got a container, so to speak, in which we can run our code without having to define the underlying server operating system details to support the running of that code. You might even have an Azure function through serverless computing that takes a look at files that people might upload to an Azure storage account. And when that file is uploaded, that is a trigger that fires off the Azure function that maybe categorizes or adds metadata to that file or does something specific with it.

Deploy an HTML Azure App Service

[Video description begins] Topic title: Deploy an HTML Azure App Service. The host for this session is Dan Lachance. [Video description ends]

In this demonstration, I'm going to use the Azure portal to deploy an HTML Azure app service, in other words, an HTML website.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. [Video description ends]

So here in the Azure portal, I'm going to start in the upper left by clicking Create a resource. And then under the Web category, I'm going to choose Web App.

[Video description begins] In the navigation pane, he clicks Create a resource and the New window displays. He clicks Web in the Azure Marketplace column, and a list of apps with their logos display in the Featured column. He clicks Web App from here. [Video description ends]

I'm going to call this web app webapptest172. And notice it that's going to be part of the url, because it's going to add .azurewebsites.net as a DNS domain name suffix. Although I can configure custom DNS domain names if I wish.

[Video description begins] The Web App window displays. He types webapptest172 in the App name field. The same text gets displayed in the Resource Group below too. [Video description ends]

I'm going to stick with that one, and I'm going to put this in an existing resource group. Although you could build a brand new resource group into which you deploy all of the items that will be related to this web application.

[Video description begins] He clicks Use existing in the Resource group field, and selects Rg1 from the drop-down menu. [Video description ends]

I can choose either Windows or Linux for the backend operating system hosting my application, my web app. I'm going to leave it as just code, as opposed to using a darker image to run the app.

[Video description begins] He leaves the default value of Windows in the OS field and Code in the Publish field. [Video description ends]

And then I have to deal with the service plan. And I'm going to click on Service plan and we're going to create a new one.

[Video description begins] He clicks the arrow in the App Service plan/Location field. The App Service plan window appears on the right. He clicks the Create new button there. [Video description ends]

Going to call this testwebapp172_ or dash rather, serviceplan.

[Video description begins] A New App Service Plan window appears on the far-right side. He types testwebapp172-serviceplan in the App Service plan field. [Video description ends]

The next thing I'm going to do is specify the location, which in this case will be Canada East. And notice that in this service plan for the app, this is where I can specify the pricing tier or the sizing for the underlying virtual machine or machines that will support my app.

[Video description begins] He clicks the arrow in the Pricing tier field. A new window with Recommended pricing tiers displays. There are 3 tabs in the window, namely Dev/Test, Production, and Isolated. He clicks the first tab. [Video description ends]

So I'm going to go ahead and choose the Dev / Test category. And I'm going to choose this F1 pricing tier, where I've got 1 gigabyte of memory and I'm going to go ahead and click Apply, and then I'll click OK.

[Video description begins] 3 Recommended pricing tiers display. He selects the first one named F1, and clicks the Apply button. F1 Free displays in the Pricing tier field now. testwebapp172-serviceplan displays in the App Service plan field now. [Video description ends]

So we can now see that that app service plan is now tied to this web application. And then I'm going to go ahead and click Create to build the web app. After a moment, over on the left, if I go to App Services, I will see that my application now exists and that its status is listed as Running.

[Video description begins] He clicks App Services in the main navigation pane and all the available app services are listed on the right. webapptest172 displays there. [Video description ends]

Otherwise I can keep clicking Refresh up at the top until I see it. Of course, I can always look up my alerts until I see that the deployment succeeded for this specific resource.

[Video description begins] He clicks the bell icon located next to the Search field in the Azure window. All the notifications display. Deployment succeeded displays there. [Video description ends]

So I'm going to go ahead and click on my web app, and in the overview panel, what I'm interested in to start with is the URL.

[Video description begins] He closes the notifications window and clicks webapptest172. Its properties window displays. [Video description ends]

So notice the URL here is comprised of the name of the resource with .azurewebsites.net which we saw while we were creating it. I'm going to go ahead and copy that.

[Video description begins] The URL is https: //webapptest172.azurewebsites.net. A copy button is present next to it. When he clicks the button, the text Copied displays as a tip. [Video description ends]

And we're going to open up that website in a new web browser window. And this is what I can expect to see by default, an Azure page that says, Your App Service app is up and running.

[Video description begins] He pastes the copied URL in a new browser window and a Microsoft Azure page displays. [Video description ends]

And if I go back to the Azure portal, indeed, we can see that is the URL, and indeed everything is working. Now, if I scroll down, we also have a lot of configuration settings for our web applications. So if I go to Application settings, we can determine the language support in the back end. For example, the version of PHP, which can matter, depending on what kind of functionality you're writing into your PHP scripts.

[Video description begins] He clicks Application settings in the Settings group in the navigation pane. Its window displays on the right. v4.7 displays in the .NET Framework version field. He clicks the drop-down arrow in the PHP version field. 5 options display, namely Off, 5.6, 7.0, 7.1, and 7.2. [Video description ends]

Also, we can see the .NET Framework version, Python and Java, if we're going to be using those. So we have a number of options here that we can configure for our specific application. As I go further down on the application settings page, I can also see the default documents. So these are the documents that will be pulled up when the URL is connected to.

Such as Default.htm or, what we're going to be interested in in a moment, index.php. As I scroll further and further down, we can also specify custom domain names. Now, in this particular case, we'd have to upgrade the app service plan type in order to do that, but we can do it.

[Video description begins] He clicks the Custom domains menu in the navigation pane and a page opens on the right. It is titled Custom Hostnames and it is used to configure and manage custom hostnames assigned to your app. There is a button with a caption- Click here to upgrade your App service plan to assign custom hostnames to your app. [Video description ends]

So what I'm going to do then is I'm going to take an existing on-premises PHP file I've created. And we're going to upload it here to our web app and make sure that it takes effect. So here's my sample PHP file on-premises. It really just comes back and says, sample PHP page hosted in Azure. And sets the title in the browser to My Azure Web App.

[Video description begins] He opens a document in MS-Word. It has HTML code for the main page of his web app. Between the title tags is the text - My Azure Web App. [Video description ends]

What I want to do is save this file locally on-premises and then upload it to the site, and I'm going to do that through FTP. So back here in the portal, I'm still looking at the properties blade for my web application. I'm going to scroll back up and choose Overview. And then from here, I can see I've got the FTP hostname, which is important, but what I want to do is get the publishing profile.

[Video description begins] He goes back to the web app window and clicks Overview in the navigation page. He clicks the Get publish profile button denoted by a download symbol. [Video description ends]

This is going to provide me with the credentials, not just the FTP username, but also the FTP password. So I'm going to go ahead and download the publishing profile. Once that's been downloaded, I'm going to go ahead and click to open it up.

[Video description begins] The downloaded publish profile displays in the start bar of Windows and he clicks it. A Notepad file displays. [Video description ends]

What I'm interested in primarily is the username here listed and also the user password for FTP.

[Video description begins] He highlights userName and userPWD in the file. [Video description ends]

I've downloaded and installed the free FileZilla FTP GUI tool. So the first thing you need here is the host.

[Video description begins] He opens FileZilla. It has a menu bar and a tool bar at the top. Next, are 4 fields, namely Host, Username, Password, and Port. Then there is a Quickconnect button. All the files and folders in the network display below in a hierarchial format. [Video description ends]

So back here in the portal, I'm on the Overview part of the Properties blade. So I'm going to go ahead and copy the FTP hostname and paste that into FileZilla.

[Video description begins] He goes back to the Azure window. He clicks the copy button next to FTP hostname and pastes it in the Host field in FileZilla. [Video description ends]

Next, I'm going to go to the publishing profile I downloaded and copy the FTP username and password and then paste them into the appropriate fields here in FileZilla. And once I've done that, I'll then click, Quickconnect. And after a moment, we can see on the right, under the Remote site section, we have access to our web application, but in the underlying file system through FTP. So if I go to wwwroot, the root of the website, we've got the default Azure placed hostingstart.html file.

[Video description begins] Below the fields and Quickconnect button, the screen is divided into left and right sides. The left side shows files and folders in the Local site, and the right side shows the Remote side. In the Remote side section, he clicks site located in the root. [Video description ends]

[Video description begins] 3 folders display under site. One of them is wwwroot. When he clicks it, hostingstart.html file displays below, on the right side. [Video description ends]

But what I want to put there is my index.php. So that is available on my local machine under samplefiles, which I'll choose on the left.

[Video description begins] He goes to the Local site section in the left, and clicks samplefiles folder there. [Video description ends]

There's index.php, so I'm just going to drag that over and drop it so that it shows up into the wwwroot folder for my site.

[Video description begins] index.php file appears on the left side below. [Video description ends]

And here in a browser, I've still got the URL for my site, but if I refresh, I'm now going to see it's picking up my Sample PHP page that I've uploaded.

[Video description begins] He closes FileZilla and goes to the new Azure window there. A line of text displays there. It says: Sample PHP page hosted in Azure. [Video description ends]

So you can use other tools to manage the content and the code for your website, such as Visual Studio. You might run that on-premises, so that you can work with your code and then push it up into the cloud into your Azure web application.

Azure Functions

[Video description begins] Topic title: Azure Functions. The host for this session is Dan Lachance. [Video description ends]

Azure Functions fall under the classification of serverless computing. These allow developers in the cloud to create and run code. And so the fees that are charged are based only on when that code is actually running. With Azure Functions, developers don't have to worry about deploying virtual machines and virtual networks, and taking care of all of that underlying infrastructure. Because this is a managed service, developers can focus more on the code and the applications that they need to think about and work on, instead of the supporting infrastructure.

So this is really for software developers. And as a software developer, you would be interested in knowing whether or not you can use the language of your choosing, that you're familiar with, with Azure Functions. There are a wide variety of languages that can be used, including PHP, Java, Node.js, C#, and F#. Now, what happens is we have to think about what will trigger the functions to execute.

[Video description begins] Screen title: Azure Function Usage. [Video description ends]

There are plenty of different types of triggers that can be defined for an Azure Function, such as a CosmosDBTrigger. This means that when data is either modified or placed into a Cosmos DB database, then the code can be triggered at that point in time. If users upload content to a storage account container, then the BlobTrigger would kick in, and we could have it execute an Azure Function of our choosing.

You might do that to further organize uploaded files, or to do something specific to them. Such as maybe adding a watermark to a video image that's uploaded or to a graphic file image. The HTTPTrigger, as the name implies, gets triggered based on a specific type of HTTP request. And so when that is triggered, we can define which Azure Function runs. There's also a QueueTrigger, which is based on messages coming into an Azure storage queue that developers could query. And then when that occurs, an Azure Function could run.

Azure Functions, because we're talking about development here, can be defined in a number of different places, such as through the Azure portal. Or you might use a tool that you're familiar with, such as Visual Studio. You might use the Azure CLI to work with functions. And of course, you might use specific language tools related to languages such as Java and Python.

[Video description begins] An infographic displays. It has a cloud with a hammer and screw driver in the center. 4 branches emerge from the symbol. Each ends in a caption.- Azure Portal, Visual Studio, Java and Python, and Azure CLI, respectively. [Video description ends]


Azure App Event Grid
  - The purpose of Event Grid is it lets developers configure certain triggers by events such as making a change to an Azure resource. That can then connect to some kind of endpoint or hook into some other aspect of an application for notifications. And in our particular case, we're simply going to set it up such that when a change is written to an Azure virtual machine, we want to be notified via email.
  - The first thing we'll do here, to get started is we will create a Logic App. Here in the Azure portal, I'm going to click Create a resource over on the left, and I'm going to type in the word logic and then from the results, I'll choose Logic App.
[Video description begins] He clicks Create a resource in the navigation pane, and types logic in the Search field. He selects Logic App from the drop-down results. A Logic App window displays. It has a brief explanation about logic apps and a Create button. [Video description ends]

Then I'm going to go ahead and click on Create so we can get to the point where we start configuring this resource. So after specifying a name, here I'm going to call it vmchange_logicapp, and in this case, I'm going to put it into an existing resource group and I've specified the location. After having done that I'm simply going to click on Create.

[Video description begins] The Logic App window displays. He types vmchange_ logicapp in the Name field. He leaves the default value of Pay-As-You-Go in the Subscription field. He leaves the default option- Use existing- in the Resource group field, and selects Rg1 in the field below. He selects Canada east in the Location field, and leaves the default value Off in the Log Analytics field. [Video description ends]

And after a moment, if I go to my All Resources view and if I type in logic, then we could see our Logic App listed.

[Video description begins] He clicks All resources in the navigation pane and types logic in the Name field on the right. vmchange_ logicappdisplays in the list below. He clicks it and its properties page displays. [Video description ends]

If I click on it, it starts the Logic App's designer where we can get some help on how to work with this and we can also choose from some basic templates.

[Video description begins] The Logic Apps Designer window opens. Basic templates are listed there. [Video description ends]

So like when a message is received in a queue, or when an http request is received, and so on. And if I scroll down a little bit beyond all that, I can choose to build a blank Logic App which I'm going to do here.

[Video description begins] He scrolls down and clicks the tile with a large plus symbol and caption Blank Logic App. A new page opens It has buttons, Save, Discard, Run, Designer, Code View, Templates, Connections, and Help. A Search field is also present to search connections and triggers. Below are 6 tabs- For You, All, Built-ins, Connections, Enterprise, and Custom. The For You tab is active now and there are no recent connections to show. [Video description ends]

And I'm going to search for event grid.

[Video description begins] He types event grid in the Search field and clicks the All tab. Many event grids with their logos display below. [Video description ends]

So I'm going to choose Azure Event Grid. And then when a resource event occurs for Azure Event Grid.

[Video description begins] He clicks the Azure Event Grid and a new tile appears. It has a field, Tenant, with the text Default Directory written in it. There is a Sign in button below the field. [Video description ends]

And then I'm going to click Sign in to authenticate to my Azure subscription And then I'm asked to confirm that I want to allow the provisioning to provide access to Azure Event Grid.

[Video description begins] A confirmation dialog box appears. He clicks Allow access. [Video description ends]

And I'm going to choose Allow Access. And then I have to fill in this detail related to the subscription and also the resource type that I'm interested in in this particular case. So I'm going to choose Microsoft.Resources.ResourceGroups for the resource type and I'm going to set the resource name to a resource group that I already have Rg1 that I know virtual machines have been deployed into. And then I'm going to go ahead and save this Logic App.

[Video description begins] A new tile appears titled When a resource event occurs. He selects Pay-As-You-Go in the Subscription field. [Video description ends]

[Video description begins] He clicks the Save button in the Logic Apps Designer window. [Video description ends]

Now, I'm going to go back into the Logic app designer here in my Logic app.

[Video description begins] In the vmchange_ logicapp window, he clicks Logic app designer in the Development Tools group in the navigation pane. [Video description ends]

And underneath, when a resource event occurs, I'm going to click New step, and then I'm going to choose Built-in and I need some kind of conditional way to determine what's going to happen next. But to do that I'm going to scroll down and choose Condition. That's a control.

[Video description begins] A Choose an action window opens. He selects the Built-ins tab. [Video description ends]

[Video description begins] He scrolls down to the section with 2 tabs- Triggers and Actions. All the actions are listed in the Action tab and he selects Condition. [Video description ends]

And I'm going to specify data.operationName is equal to and what we're looking for is any right activity for our Azure virtual machines related to the resource group.

[Video description begins] A tile titled Condition opens. It has boxes with text and drop-down arrows. At the top is a box with text And. It branches down into 2- one a check box with 3 boxes captioned data.operationName, is equal to, and Microsoft Compute. The second branch has text +Add and a drop-down arrow. [Video description ends]

So that's my condition. Now, down below, for true, and also, of course, if that turns out to be true versus false, we can add an action. So if it's true, if a change has been made to write to a virtual machine, I'm going to click Add an action.

[Video description begins] Below the tile, are 2 more tiles titled if true and if false. He clicks Add an action in the if true tile, and a Choose an action box window appears again. [Video description ends]

And from here I can choose what it is exactly that I want to do. So for example I could search for email if I want to send off an email notification. And lets say I choose Gmail.

[Video description begins] He types email in the search field and clicks Gmail icon in the search results. A new window with actions related to Gmail pops up. [Video description ends]

And then what do you want to do in Gmail? Well what I want to do is send an email message. And from here what I would have to specify are the details related to working with Gmail. If it's the first time I've ever done this, I'm going to have to sign into my Gmail account. Because I've already done that I can specify who I want to send the message to. So a list of email addresses, and I can also add other additional items such as the subject and body here of the message.

[Video description begins] He clicks the action Send email and a new window pops up. It is titled Send email and has fields such as To, Body, and Subject. He checks the elements he wants in his email. [Video description ends]

So maybe in the body, what I want to do is add, let's say, the specific type of event and if I scroll over maybe for the subject, I want to list the subject of the event. And again up here, I can specify some email addresses. So I'm going to go ahead and do that. Email addresses should receive this notification and then I'll click the save button.

[Video description begins] He clicks the Body field and a panel pops up in the right side. It has 2 tabs- Dynamic content and Expression. There is a Search field on the top and various events listed below. Some of them are Event Time, Event Type, and ID. He clicks all the events he wants. [Video description ends]

[Video description begins] He types an email address in the To field. [Video description ends]

After that's done, if I were to go for example to a virtual machine and open up its properties blade and make a change to it such as let's say go to sizing and just choose a different size and click on resize.

[Video description begins] He goes back to the Virtual machines page and clicks Size in the Settings group in the navigation pane. [Video description ends]

I'm writing to that virtual machine, and so our Logic app should capture that event.

[Video description begins] He clicks 81s in the VM SIZE column. A window with the text- Resizing virtual machine- pops up at the top of the machine. [Video description ends]

And so if I go back, let's say to all resources, the view filter for logic, and there's our Logic app. Under the overview part of that if I scroll down I can see for example the status is succeeded down under the run history for our current configuration.


SQL Overview
  - Structured Query Language, or SQL, is the language that's used to access relational database objects and their data. So with a SQL-compliant type of database system, data tables are related via common fields. This is called normalization, and it's a technique that's used to reduce the amount of repeated data. We'll see that in a moment when we see an example of how we might link tables together.

SQL objects include the server that hosts one or more databases. Within a database, we can have one or more tables that actually store the data. Within the table, we have it broken down by fields or columns. So, for example, we might have a table called Customers, and one of the fields might be Customer ID. When we actually populate a table with data, we end up with a record otherwise called a row.

In our example with the Customers table, the record or row would include everything about a customer. So a customer ID, the first and last name, mailing information, and so on. Databases can also contain stored procedures, essentially which are scripts that can be run against items within the database.

We can also create views within a SQL-compliant database that can bring together columns from different tables so we can view it all in one place. And, of course, we can construct a multitude of different types of queries, essentially asking questions about the data stored in tables, such as show me all customers that have spent more than $10,000 in the last quarter.

[Video description begins] Screen title: SQL Table Relationship. [Video description ends]

Pictured on the screen, we've got two tables, and this is used to demonstrate the relationship between tables.

[Video description begins] Two tables are displayed on the screen. The first table is titled Customers table. It has the following three columns: CustID, Lname, and Fname. It contains two rows of data for customer IDs 001 and 002, respectively. The second table is titled Purchases table. It has the following three columns: CustID, Date, and Amount. It has two rows of data for customer ID 001. [Video description ends]

At the top, we've got a Customers table, where we have three columns: Customer ID, Lname for last name, and Fname for first name. Then, we have a second table called Purchases table. It's got three columns, but notice what it has in common with the Customers table, the Customer ID. So Customer ID 001 exists only once in the Customers table.

However, that customer, hopefully, will have more than one purchase with us, and so we can expect to have repeating entries for that Customer ID in the Purchases table. But we don't want to repeat the last name and the first name and everything else about a customer. All we need is one unique item, in this case, the Customer ID to be repeated to link all the purchases in the Purchases table to the customer in the Customers table.

Common SQL-compliant database products would include Microsoft SQL Server, MySQL, Oracle Database, and Sybase to name just a few. In other demonstrations, we're going to take a look at how we would deploy Microsoft Azure SQL Database in the cloud, which is a managed service where we don't have to worry about the underlying virtual machine deployment and the SQL software; it's already built in.


Azure SQL Database
  - One characteristic of cloud computing is rapid provisioning of resources and rapid elasticity, and that's definitely true with Microsoft Azure SQL Database. With SQL Database, we're talking about database as a service, called DBaaS, which is also platform as a service in the cloud.

[Video description begins] Platform as a Service is abbreviated to PaaS. [Video description ends]

It's a managed service, and that's where the rapid elasticity comes in because we don't have to worry about deploying virtual machines and then installing the Microsoft SQL Server software. All of that is taken care of for us when we deploy Azure SQL Database. So, it's very quick to get up and running. We can also bring our own license. BYOL, bring your own license, will let you reuse any existing SQL Server additional licenses that you want to reuse in the cloud when you deploy Azure SQL Database.

You also have the option of migrating your on-premises SQL data into Azure, so you can reuse your data instead of having to recreate it in the cloud. Azure SQL Database supports scaling in the form of horizontal scaling. This means scaling out, by adding database replicas and also database sharding, which allows us to have more information split up horizontally. What this really means is taking large datasets and breaking them into smaller pieces to improve performance, that's where sharding comes from.

But also, Azure SQL Database allows us to scale vertically, increasing or decreasing the underlying horsepower for each SQL Server instance. And we can do that by configuring virtual machine instance sizing. We can manage Azure SQL Database using the GUI, through the Azure portal, or through the Azure CLI. For example, we could use the az sql db create command to create a database. The equivalent in PowerShell would be New-AzSqlDatabase.

And if you're using ARM templates to deploy and manage Azure resources, you would be looking at a resource type of Microsoft.Sql/Servers. With Azure SQL Database, there is a specific database server firewall enabled, and that's on by default for SQL. So if you want to make a connection into Azure SQL Database from externally, you are going to have make sure you create a firewall rule to allow inbound port 1433 traffic.

Port 1433 is what's used by SQL Server by default. There is even an option where you can add your client IP. So when you are using the portal and you are viewing the firewall information for this, for SQL Database, then what you'll notice is that it'll show your current client IP address that you are connected from, your public IP address if you are behind a NAT router.

And so you can conveniently simply add that as the IP you want to allow through the firewall. And then I would allow you, for example, to use tools like SQL Server Management Studio on-premises to reach into the Azure cloud to your SQL Database instance to manage it.

[Video description begins] Screen title: Azure SQL Database Details. [Video description ends]

When you deploy Azure SQL Database, whether it's through the GUI or through command line tools, there are a number of things you have to take into account, one of which is whether you want to deploy a new SQL Server instance or use an existing one that you might have already deployed. SQL Server instances have the DNS domain suffix of .database.windows.net by default.

You need to specify a unique server and a database name when you are deploying Azure SQL. You have to determine which location, or Azure region, into which you want to deploy Azure SQL Database. From a performance standpoint, you also have an option of selecting database transaction units, or DTUs.

This is a culmination of factors that control the performance when it comes to reading and writing to and from databases. It includes things like the amount of virtual CPU, the amount of memory, and how fast disk I/O is.

The last consideration is that if you're deploying Azure SQL Database for testing purposes or any other temporary reason, make sure that you remove any unused databases and server instances as soon as you are finished. You don't want to leave these things running in the background because you are charged for all of the time that it's left running. So make sure to delete it when you are finished with it.


Azure SQL Database GUI Deployment
  - Azure SQL database is a managed service, and in the cloud, what this really means is that we have an easy way to quickly provision something, in this case, an Azure SQL database, without worrying about the underlying complexities, like virtual machines, and the operating systems, and installing the database software, in this case, Microsoft SQL Server.

[Video description begins] A Microsoft Azure webpage is displayed on the screen. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present with the following options: Create a resource, Home, Dashboard, All services, and Favorites. The main body of the page has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

So here in the portal, let's see how this works by starting with clicking on Create a resource in the upper left.

[Video description begins] He clicks on Create a resource from the navigation pane. A screen titled New appears. It has a search bar and a column titled Azure Marketplace. Some of the items here are: Get started, Recently created, Compute, Networking, Databases, etc. A column titled Featured is also present on this screen. Some of the items here are: Azure SQL Managed Instance, SQL Database, SQL Data Warehouse, etc. [Video description ends]

And in the Databases category, on the right, I will then choose SQL database.

[Video description begins] From the Azure Marketplace column, he selects Databases. From the Featured column, he selects SQL Database. A page titled Create SQL Database appears. It has four tabs: Basics, Additional settings, Tags, and Review +Create. The Basics tab is currently open. It has drop-down menus for Subscription and Resource Group. The default value for Subscription is Pay-As-You-Go. The default value for Resource Group is cloud-shell-storage-eastus. [Video description ends]

Now the first thing I have to do is tie this to a resource group. I've already got one, so I'm going to put it in that resource group, and I have to give this a Database name.

[Video description begins] He clicks the drop-down menu for Resource Group. A list of options appears. He selects Rg1 from the list. He then scrolls down the page. A section titled Database Details appears. It has an input box for Database name and a drop-down menu for Server. There is a question that reads: Want to use SQL elastic pool? It has two options with radio buttons: Yes and No. No is currently selected. For Compute+storage, there is a link for Configure database. At the bottom, there are two buttons: Review+Create and Next: Additional settings. [Video description ends]

So I'm going to start by calling this sqldb172. Now, this name needs to be checked for uniqueness. And once it is okay, and it's been typed in correctly, and there are no invalid characters, we'll get this little green check mark over on the right.

[Video description begins] In the input box for Database name, he types sqldb172. [Video description ends]

Now, down below, I can either tie this to an existing SQL server instance hosted in Azure or I can click Create new, which I'm going to do here.

[Video description begins] There is a link titled Create new below the drop-down menu for Server. He clicks the link. A screen titled New server slides onto the screen. It has input boxes for Server name, Server admin login, Password, and Confirm password. A drop-down menu for Location is also present. The default location is Canada East. Below it, there is a check box for Allow Azure services to access server, which is currently checked. At the bottom there is a Select button. [Video description ends]

And I'm going to call this sqlsvr, for SQL Server, 172. Again, it has to wait for the name to be checked, and it looks good. Then I'm going to specify some server admin login info, so user name, and I will confirm the password.

[Video description begins] In the input box for Server name, he types sqlsvr172. [Video description ends]

[Video description begins] In the input box for Server admin login, he types cirving. He types the password and confirms the password. [Video description ends]

And after that, I'm going to go ahead and click on Select.

[Video description begins] He clicks the Select button. The New Server screen disappears. The value for Server is (new)sqlsvr172 (Canada East). [Video description ends]

So we're creating a new SQL server instance, which is good. I'm just going to scroll down here, I'm going to leave it on the default Compute and storage configuration.

[Video description begins] The value for Compute+storage is Standard S0 10DTUs, 250 GB. [Video description ends]

So 10 DTUs, that's database transaction units, and 250 gigabytes. Although we could click on Configure database and depending on our workload, we could choose the amount of data that we want to be able to accommodate and the database transaction units using these two sliders. So it's always dependent upon your specific workload.

[Video description begins] He clicks the Configure database link. A page titled Configure appears. It has three options: Basic, Standard, and Premium. Basic is currently selected. It has two sliders for DTUs and Data max size. The current DTU is 0 and Data max size is 250 GB. At the bottom, there is an Apply button. He clicks it and the screen shifts to the previous page. [Video description ends]

In this case, I'm going to click Next: Additional settings.

[Video description begins] He clicks the Next: Additional settings button. The screen shifts to the next tab: Additional settings. It has three options for Use existing data: None, Backup, and Sample. None is currently selected. For Collation, there is an input box with the following default value: SQL_Latin1_General_CP1_ CI_AS. At the bottom, there are three buttons: Review + Create, Previous, and Next: Tags. [Video description ends]

Then, I can determine whether I want to have a blank database or use some kind of existing data from a sample data set or a backup. I'm going to leave it blank by leaving it on None. Then I'll click Next.

[Video description begins] He clicks the Next: Tags button. The screen shifts to the next tab, Tags. It has drop-down menus for Name, Value, and Resource. The Resource is Database. At the bottom, there are three buttons: Review + Create, Previous, and Next: Review + Create. [Video description ends]

I can tag this, perhaps to tie it to a project or department, but I'm going to leave that as it is. And finally, on the Review page, I can see the estimated cost per month.

[Video description begins] He click the Next: Review + Create button. The screen shifts to the next tab, Review + Create . It contains Product Details, Terms, Basics, etc. At the bottom, there are two buttons: Create and Previous. [Video description ends]

So we wana be careful with this. This is one of those types of resources in Azure you wanna make sure you shut down or even delete the moment you no longer need it, so you don't incur charges.

[Video description begins] He highlights the estimated cost per month, which is 16.50 USD, listed under Product Details. [Video description ends]

So I'm going to go ahead and click Create.

[Video description begins] He clicks the Create button. An overview page appears. It reads: Your deployment is complete. It has a button labelled Go to resource. It has a navigation pane with the following options: Overview, Inputs, Outputs, and Template. The Overview page is currently open. There is a table on this page. It has following columns: Resource, Type, Status, and, Operation Details. The table has three rows of data. [Video description ends]

And after a moment, we have a message that says our deployment is complete. See it's created a firewall rule here to allow inbound port 1433 traffic to SQL. Then we've got the database and the server.

[Video description begins] The presenter points to the data in the table. He then closes the Overview page and shifts to the home screen of Microsoft Azure. [Video description ends]

Of course, we're going to see all those items here if we go to the All resources view and start to filter the view.

[Video description begins] From the navigation pane, he clicks on All resources present under Favorites. A page titled All resources appears. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. A few rows of data are present in this table. [Video description ends]

So if I just type in sql, here we can see our SQL server deployed in the cloud.

[Video description begins] He types sql in the input box for Name. Two rows of data can now be seen in the table. [Video description ends]

But we didn't have to worry about all the complexities that would normally be involved with that if we had deployed a SQL server on premises ourselves. So let's click on the SQL server here in Azure to pop up its Properties blade.

[Video description begins] He clicks on sqlsvr172 present in the table. A screen titled sqlsvr172 appears. It has a navigation pane. The main body contains details about the server. At the bottom, there are two tabs: Notifications and Features. The Features tab is currently selected. It has four tabs: All, Security, Performance, and Recovery. [Video description ends]

And from within here, for example, if I go to the SQL databases view, I can see it is hosting one of our SQL databases, sqldb172, which currently has a status of Online.

[Video description begins] From the navigation pane, he selects SQL databases. A page titled sqlsvr172-SQL databases appears. It has a table with the following three columns: Database, Status, and Pricing Tier. It has one row of data. The Database is sqldb172, Status is Online, and Pricing Tier is Standard S0: 10DTUs. [Video description ends]

And I'll just close out of this.

[Video description begins] He closes the current screen. [Video description ends]

If we go into our SQL database instance, so I'll click on it to pull up its Properties blade, then we have options we can configure, such as Geo-Replication, if we want it replicated to other locations in different Azure regions.

[Video description begins] On the All resources page, from the list of resources present in the table, he clicks sqldb172(sqlsvr172/sqldb172). A page titled sqldb172(sqlsvr172/sqldb172) opens. It has a navigation pane and the following buttons: Copy, Restore, Export, Set server firewall, etc. A list of information about the server is also displayed here. [Video description ends]

[Video description begins] He selects Geo-Replication under Settings from the navigation pane. A world map is displayed on the screen. [Video description ends]

And as we go further down, we'll see that we have a number of options related to things like security. So we've got some Advanced Data Security options available for the database, so vulnerability assessments, also, Dynamic Data Masking to mask some kind of important information, such as the entering of credit card numbers, and so on. And this is configured by configuring what are called masking rules.

[Video description begins] In the navigation pane, there is a section titled Security. It has the following options: Advanced Data Security, Auditing, Dynamic Data Masking, and Transparent data encryption. He clicks on Advanced Data Security. A page for Advanced Data Security opens up. It has a button labelled Enable Advanced Data Security on the server. [Video description ends]

[Video description begins] He clicks on Dynamic Data Masking, and the page for Dynamic Data Masking opens. It has a section titled Masking rules, where there is a table with two columns: Mask Name and Mask Function. The table is currently empty. Below it, there is a section titled Recommended fields to mask, where there is a table with three columns: Schema, Table, and Column. The table is currently empty. [Video description ends]

And if I go back to the Overview here for our database, I can see the SQL server name. This is what you need if you want to make a connection to this, for example, from on-premises. Now, at the same time, even from here within the database Properties blade, I could click the Set server firewall button, and, I can see my current Client IP address as seen on the Internet.

[Video description begins] He shifts to the page titled sqldb172(sqlsvr172/sqldb172). From the list of information, he points to the Server name, which is sqlsvr172.database.windows.net. [Video description ends]

[Video description begins] He clicks the Set server firewall button. A page titled Firewall settings appears. It has three buttons: Save, Discard, and Add client IP. For Allow access to Azure service, there are two buttons: On and OFF. On is currently selected. Client IP address is 71.7.176.108. There is a table with input boxes for Rule Name, Start IP, and End IP. [Video description ends]

[Video description begins] He highlights the Client IP address. [Video description ends]

And so from here, we have the option of making sure that we add a rule that could, for example, contain that IP address or other address ranges that we want to allow access from. Notice we've got an Add client IP button at the top that fills all that stuff in for me to allow connectivity.

So I'm going to go ahead and save that firewall rule because the machine I'm sitting at right now that does have this public IP address I do want to allow in through the firewall for SQL purposes.

[Video description begins] He clicks the Add client IP button. A new row gets added in the table. The Rule Name is ClientIPAddress_2019-3-13. Start IP is 71.7.176.108 and End IP is 71.7.176.108. He clicks the Save button. [Video description ends]

[Video description begins] A pop-up message appears. It reads: Successfully updated server firewall rules. The presenter clicks the OK button. The pop-up message closes. He then closes the Firewall settings page. [Video description ends]


Azure SQL Database CLI Deployment
The first thing I'll do is run az sql --help. This is a great way to get a sense of what the syntax will be as you begin working with this.

[Video description begins] In the command prompt window, he types az sql -- help. The group name and its function appear. This is followed by a list of subgroups and their definitions and a list of commands and their definitions. [Video description ends]

So notice, I can work with Azure SQL databases as well as servers, and so on.

[Video description begins] From the list of subgroups, he highlights db and server. The definition of db is Manage databases. The definition of server is Manage SQL servers. [Video description ends]

So I'm going to clear this screen, and I'm going to start by running az sql server create --name. Let's say, I call it sqlsvr456. And then, I'm going to put that in a --resource-group that I've already got called rg1. And --location. I'll put canadaeast, and then --admin-user for the SQL server, specify a value for that.

And then --admin-password. Now make sure you have the two dashes in front of these parameters, otherwise you get some kind of an error related to that. And I'm gonna go ahead and specify the password here that I want to use for that deployment. I'm going to go ahead and press Enter to build our Azure SQL Server instance.

[Video description begins] He types cls and presses Enter. The screen is now clear. He then types az sql server create -- name sqlsvr456 -- resource-group rg1 -- location canadaeast -- admin - user cirving -- admin - password Pa$$w0rdABC123. He presses Enter. A result is being generated. [Video description ends]

Now that that's successfully completed, I'm going to go ahead and build a SQL database tied to that server.

[Video description begins] A list of information is generated in the result. It includes details of administrator login, administrator login password, fully qualified domain name, id, identity, kind, location, name, resource group, state, tags, type, and version. [Video description ends]

So az sql db create, so I've got to deploy this into a resource group. So --resource-group rg1 in this case and --server. I've got to tie it to a server, so in this case, sqlsvr456. And I want to call this database --name, let's say, db456.

[Video description begins] He types cls and presses Enter. The screen is now clear. He then types az sql db create --resource-group rg1 -- server sqlsvr456 -- name db456. He presses Enter. A list of information is generated in the result. Some of these are: longTermRetentionBackupResourceID, maxLogSizeBytes, recoverableDatabaseID, sampleName, etc. [Video description ends]

Now that, that's done, the next consideration is that if you're gotta be using any kind of code or tools on-premises to reach into Azure to work with that SQL database, then you're going to need to have a firewall exception created in Azure. So let's go ahead and deal with that under that assumption. So I'm going to clear the screen with CLS, and I'm going to run az sql server firewall-rule create.

We're creating a firewall rule for SQL server, --resource-group rg1, and the server, --server sqlsvr456, and -n. What do you want to call this rule? How about AllowInboundSQL? And then --start-ip-address. Now because I'm behind a NAT firewall, I need to specify the public IP address as known out on the Internet for my connection here for this to work properly. So I'm going to go ahead and specify that address.

And after I've done that, I can then begin to specify the ending IP address. In this case, it's going to be the same thing because it's one IP. So once I've verified that that is correct, and it looks correct, I'm going to use --end-ip-address. And in this case, I'm going to use the exact same thing because it's only one IP I want to allow in, and that's my public IP address. So I'm going to make sure I don't have any typos here. And I'm going to press Enter to create that, and it looks like it's created. Let's go ahead and check our work in the Azure portal.

[Video description begins] He types cls and presses Enter. The screen is now clear. He then types az sql server firewall -rule create --resource-group rg1 -- server sqlsvr456 - n AllowInboundSQL --start -ip-address 71.7.176.108 --end -ip-address 71.7.176.108. He presses Enter. The following details are generated in the result: endIpAddress, id, kind, location, name, resourceGroup, startIpAddress, and type. [Video description ends]

[Video description begins] A Microsoft Azure webpage opens. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present on this screen. The options here are: Create a resource, Home, Dashboard, All services, and Favorites. The main body of the page has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

Here in the portal in the left-hand navigator, I'm going to click SQL databases. Here's db456. We can see it's tied to our server.

[Video description begins] He clicks on SQL databases from the navigation pane. A page titled SQL databases appears. It has the following buttons on the top: Add, Reservations, Edit columns, Refresh, etc. It has a table with the following columns: Name, Status, Replication, Server, Pricing Tier, Location, and Subscription. The table has one row of data. The SQL database name is db456 (sqlsvr456/db456). He clicks on this name. A page titled db456 (sqlsvr456/db456)appears. It has a navigation pane. The main body of the page has details about the following options: Resource Group, Status, Location, Server name, Elastic pool, etc. [Video description ends]

So if I go take a look at it, it look like it's online and ready to go.

[Video description begins] He points to the Status. It reads Online. [Video description ends]

I'm going to go to All resources, and I'll filter the list of Azure resources with things that start with SQL.

[Video description begins] From the navigation pane, he clicks on All resources present under Favorites. A page titled All resources appears. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. A few rows of data are present in this table. [Video description ends]

[Video description begins] He types sql in the input box for name. Two rows of data are now present in the table. [Video description ends]

There's our SQL server, sqlsvr456, and in the Properties blade, I'm going to scroll down under the Security section until I see firewalls and virtual networks, and notice here on the right, sure enough, we've got our AllowInboundSQL rule for our public IP address.

[Video description begins] He clicks on sqlsvr456 in the table. A screen titled sqlsvr456 appears. It has a navigation pane. The main body has details about the server. Some of these are: Status, Location, Subscription, etc. At the bottom, there are two tabs: Notifications and Features. The Features tab is currently selected. It has four tabs: All, Security, Performance, and Recovery. [Video description ends]

[Video description begins] In the navigation pane, there is a section titled Security. It has the following options: Advanced Data Security, Auditing, Firewalls and virtual networks, and Transparent data encryption. He clicks on Firewalls and virtual networks. A page for Firewalls and virtual networks opens up. For Allow access to Azure services, there are two buttons: On and OFF. OFF is currently selected. Client IP address is 71.7.176.108. There is a table with input boxes for Rule Name, Start IP, and End IP. One row of data is present in this table. The Rule Name is AllowInboundSQL, Start IP is 71.7.176.108, End IP is 71.7.176.108. [Video description ends]

Azure SQL Database PowerShell Deployment

[Video description begins] Topic Title: Azure SQL Database PowerShell Deployment. Your host for this session is Dan Lachance. [Video description ends]

In this demonstration, I'm going to use PowerShell to deploy an Azure SQL database. Here in this PowerShell ISE, I've got this in a script. I've commented out the first line, that's what the hashtag or pound symbol means because I've already connected to my Azure account and authenticated it.

[Video description begins] A window titled Windows Powershell ISE opens up. It has a tool bar and a menu bar. A tab titled Create_SQL_Server_DB.ps1 is open. It has 8 code lines. A Console pane is also present on this window. [Video description ends]

[Video description begins] He highlights code line 1. It reads: # Connect-AzAccount. [Video description ends]

So the first thing we're doing here is building a new Azure SQL server using that cmdlet. We are tying it or deploying it into a resource group. I am specifying a SQL server name. We are specifying the Azure location or region, and then we are specifying -SqlAdministratorCredentials. Now I've got the back tick symbol here that's not just a single quote, it's a back tick, and that allows me to continue the expression on the next line here in PowerShell.

[Video description begins] He points to code line 3. It reads: New-AzSqlServer -ResourceGroupName rg1 -ServerName sqlsrv3362 -Location canadaeast -SqlAdministratorCredentials `. [Video description ends]

And what I'm doing is then running new object of type System.Management.Automation.PowerShell or PSCredential. And the argument list is going to have the username, in this case cirving. And then I'm going to convert to a secure string, a password that I'm specifying here, within double quotes.

[Video description begins] He points to code line 4. It reads: $ (New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList "cirving" , $ (ConvertTo-SecureString - String "Pa$$w0rdABC123" -AsPlainText -Force)). [Video description ends]

Then what's happening is we're building our new Azure SQL database and tying it to our SQL server instance that we've created above. And I'm calling this database db112.

[Video description begins] He points to code line 6. It reads: New-AzSqldatabase -ResourceGroupName rg1 -ServerName sqlsrv3362 -DatabaseName db112. [Video description ends]

And then I'm adding a new Azure SQL Server firewall rule to allow incoming SQL traffic from the appropriate IP address, which happens to be my public IP address for my on-premises environment.

[Video description begins] He points to code line 8. It reads: New-AzSqlServer FirewallRule -ResourceGroupName rg1 -ServerName sqlsrv3362 -FirewallRuleName "AllowIncoming SQL" - StartIpAddress 71.7.176.108 -EndIpAddress 71.7.176.108. [Video description ends]

So I'm going to go ahead and run this script by clicking the Run Script button up at the top.

[Video description begins] He clicks the Run Script button present in the tool bar. A list of details is displayed in the Console pane. [Video description ends]

And after a moment or two, we can see it looks like the script has completed running. So let's go check our work in the portal. Let's take a look for sqlsrv3362 and db112.

[Video description begins] He highlights sqlsrv3362 in code line 3, and db112 in code line 6. [Video description ends]

Here in the portal, I've gone to the All resources view and filtered for anything that starts with SQL, S-Q-L, and we can see indeed, we've got sqlsrv3362.

[Video description begins] A Microsoft Azure webpage opens up. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present on this screen. It has the following options: Create a resource, Home, Dashboard, All services, and Favorites. The All resources page is currently open. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. In the name input box, sql is entered. A list of sql resources is displayed in the table. [Video description ends]

And, if I open that Properties blade up, and go down under Firewalls and virtual networks, we can see our Allow incoming SQL firewall rule that was created.

[Video description begins] He clicks the 1st sql resource listed in the table: sqlsrv3362. A page titled sqlsrv3362 appears. It has a navigation pane. The main body has details about the server. Some of these are: Status, Location, Subscription, etc. At the bottom, there are two tabs: Notifications and Features. The Features tab is currently selected. It has four tabs: All, Security, Performance, and Recovery. [Video description ends]

[Video description begins] In the navigation pane, there is a section titled Security. It has the following options: Advanced Data Security, Auditing, Firewalls and virtual networks, and Transparent data encryption. He clicks on Firewalls and virtual networks. A page for Firewalls and virtual networks opens. For Allow access to Azure services, there are two buttons: On and OFF. OFF is currently selected. Client IP address is 71.7.176.108. There is a table with input boxes for Rule Name, Start IP, and End IP. One row of data is present in this table. The Rule Name is AllowIncoming SQL, Start IP is 71.7.176.108, and End IP is 71.7.176.108. The presenter closes this page and shifts to the All resources page. [Video description ends]

And we can also see that we've got DB or database 112 that was created as the result of our PowerShell script.

[Video description begins] He points to the 2nd sql resource listed in the table: db112 (sqlsrv3362/db112). [Video description ends]

Now the only other thing to bear in mind is don't leave these database resources running in Azure if you're not using them. Because you will pay for using them even if they're running, and you're not actually using them. So remove these resources when you no longer need them immediately.

Connect to Azure SQL Database

[Video description begins] Topic Title: Connect to Azure SQL Database. Your host for this session is Dan Lachance. [Video description ends]

Once you've deployed Azure SQL database in the Azure cloud, how do you connect to it? That's going to be the focus of this demonstration.

[Video description begins] A Microsoft Azure webpage opens. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present on this screen. The options here are: Create a resource, Home, Dashboard, All services, and Favorites. The All resources page is currently open. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. In the input box for name, sql is entered. A list of sql resources is displayed in the table. [Video description ends]

Here in the Azure portal, I've already deployed Azure SQL database. So I've got a SQL server instance and a database already up and running.

[Video description begins] He points to the two sql resources listed in the table: sqlsrv3362and db112 (sqlsrv3362/db112). [Video description ends]

So I'm going to go ahead and click on the link to open up the Properties blade for my SQL server instance.

[Video description begins] He clicks on sqlsrv3362. A page titled sqlsrv3362 appears. It has a navigation pane. The main body contains details about the server. Some of these are: Status, Location, Subscription, etc. At the bottom, there are two tabs: Notifications and Features. The Features tab is currently selected, which has four tabs: All, Security, Performance, and Recovery. [Video description ends]

And the first thing I'll do is scroll all the way down under Security and look at Firewalls and virtual networks.

[Video description begins] In the navigation pane, there is a section titled Security. It has the following options: Advanced Data Security, Auditing, Firewalls and virtual networks, and Transparent data encryption. He clicks on Firewalls and virtual networks. A page for Firewalls and virtual networks opens up. For Allow access to Azure services, there are two buttons: ON and OFF. OFF is currently selected. The Client IP address is 71.7.176.108. There is a table with input boxes for Rule Name, Start IP, and End IP. One row of data is present in this table. The Rule Name is AllowIncoming SQL, Start IP is 71.7.176.108, and End IP is 71.7.176.108. [Video description ends]

I've already added a firewall exception to allow my current client IP address, my public IP.

[Video description begins] He highlights the client IP address. [Video description ends]

I've made a firewall rule to allow traffic from this address. This is my on-premises public IP as it's known out on the Internet.

[Video description begins] He highlights the Start IP and End IP in the table. [Video description ends]

The other thing that we can do here, let me just close this out, is open up the Properties blade for our deployed SQL database in the cloud.

[Video description begins] He closes the current page and shifts to the All resources page. [Video description ends]

And from here, we can see the server name that we can simply copy.

[Video description begins] He clicks on db112 (sqlsrv3362/db112). A page titled db112 (sqlsrv3362/db112)appears. It has a navigation pane. The main body has details about the server. Some of these are: Status, Location, Subscription, Server name, etc. He copies the Server name. The Server name is: sqlsrv3362.database.windows.net. [Video description ends]

So what I'm going to do now is go to my on-premises environment and launch the SQL Server Management Studio tool.

[Video description begins] A window titled Microsoft SQL Server Management Studio appears. It has a menu bar and a tool bar. It has a section titled Object Explorer. It has a Connect button with a drop-down arrow. A few more buttons are present here. [Video description ends]

Specifically, this is the Microsoft SQL Server Management Studio tool for SQL Server 2014. What I'm going to do here is click Connect over on the left.

[Video description begins] He clicks the Connect button. A list of options appears. These are: Database Engine, Analysis Services, Integration Services, Reporting Services, and Azure Storage. [Video description ends]

What I want to do is connect to a database engine.

[Video description begins] He selects Database Engine. A window titled Microsoft SQL Server 2014 appears. It has drop-down menus for Server type, Server name, Authentication, and Login. An input box for Password is also present. The default value for Server type is Database Engine. The default value for Server name is sqlsrv3362.database.windows.net. The default value for Authentication is SQL Server Authentication. The default value for Login is cirving. At the bottom, there are four buttons: Connect, Cancel, Help, and Options. [Video description ends]

And I want to make sure that I've got the SQL Server name that I copied from Azure listed here, and I do.

[Video description begins] He highlights the Server name. [Video description ends]

Now when I deployed that SQL Server, I specified an admin name of cirving, so I've got that there. Now, I just have to supply the password that I specified when I deployed that SQL server instance. Once I've done that, I can go ahead and click on the Connect button.

[Video description begins] He enters the password. He clicks the Connect button. In the Object Explorer section, a server named sqlsrv3362.database.windows.net opens. It has two folders: Databases and Security. [Video description ends]

Because the firewall allows connectivity from this host behind a NAT firewall, we can see now that we are indeed connected to our Azure SQL database instance. And if I start going down under Databases to take a peek, here's db112 or database 112, where if we flip back to the portal, we can see indeed that is the name of our Azure deployed SQL database.

[Video description begins] He expands the Databases folder. It has two folders: System Databases and db112. He then expands the db112 folder. It has a list of folders. Some of these are: Tables, Views, Synonyms, etc. He shifts to the Microsoft Azure webpage. The page titled db112 (sqlsrv3362/db112) is currently open. [Video description ends]

[Video description begins] He highlights the title of the page. [Video description ends]

Azure Database Migration Service

[Video description begins] Topic title: Azure Database Migration Service. Your host for this session is Dan Lachance. [Video description ends]

The Azure Database Migration Service allows you to keep your existing data and simply move it into the cloud. So we're talking about moving database workloads from an on-premises IT environment into Microsoft Azure. Now, the movement of that data can happen through a site-to-site VPN tunnel that you would've first defined between your on-premises network and an Azure virtual network or you might do that movement of data through an ExpressRoute circuit.

ExpressRoute does not go through the Internet. Instead, it is a dedicated network circuit from your on-premises network directly into the Azure cloud. And depending on where you are in the world, this may not be an option. But generally, it is conceptually a choice that we at least have to examine when we're going to be moving or migrating data from on-premises into Azure.

The Azure database migration process begins with discovery. What we're talking about discovering are database items available on-premises. The next thing is assessing the workloads that use those databases to determine whether or not they can be migrated into Azure.

[Video description begins] Screen title: Azure Database Migration Process. [Video description ends]

The convert part of the process means that we want to take a look at the database schema on-premises. The schema is the blueprint of what type of data is allowed to be stored, and we want to make sure that, that schema will function correctly in the Azure environment. This is normally not an issue unless, on-premises, you've customized your database schema to support non-standard data types, for example.

Now, that's all considered pre-migration in terms of tasks. The next thing that we have is to actually migrate the schema and data objects. Depending on the amount of data you're talking about and the speed of your network link to the Azure cloud, we'll determine how long it will take to bring across very large data sets.

Next, we've got data synchronization, so the data that's migrated into Azure is kept in sync with on-premises data during this transitory process. Finally, at the cutover stage, we actually cut ties with the on-premises data source. And so there is no longer synchronization between on-premises and Azure cloud hosted data.

[Video description begins] An illustration appears. There are two boxes titled: Pre-migration and Migration. The Pre-migration box has Discover, Assess, and Convert. The Migration box has Migrate schema & data object, Data sync, and Cutover . Discover is connected to Assess which is then connected to Convert. Convert is connected to Migrate schema & data object, which is then connected to Data sync. Data sync is connected to Cutover. [Video description ends]

As we'll see in a different demonstration, we start the process of working with Azure Database Migration by actually creating a database migration instance. And we can do that, for example, through the Azure portal. From there, it will take us through all of these steps in the database migration process.

SQL Server Migration Assessment

[Video description begins] Topic Title: SQL Server Migration Assessment. Your host for this session is Dan Lachance. [Video description ends]

The SQL Server Migration Assessment tool allows you to run this on-premises, so you can assess what you currently have running and which are likely candidates for being migrated into the Azure cloud.

[Video description begins] The Microsoft webpage is open on the screen. The Download Center page is currently open. It has a list of options at the top. Some of these are: Windows, Office, Web browsers, etc. The page has a section titled Microsoft Data Migration Assistant v4.2. A Download button is present in this section. [Video description ends]

So here, I've gone to the Microsoft.com website, and I've searched the downloads for the Migration Assistant. So we can see here, Data Migration Assistant v4.2, at least at the time of this recording. So I have to go ahead and download that tool.

[Video description begins] He clicks the Download button. A File explorer opens up. The Downloads folder is currently open. It has a file named DataMigrationAssistant.msi. [Video description ends]

Once it's downloaded, I'm going to go ahead and run the installer, so it's called the DataMigrationAssistant.msi. So I'm just going to right-click on that and choose Install.

[Video description begins] He right-clicks on the file. A list of options appears. He selects Install from the list. A window titled Microsoft Data Migration Assistant Setup is launched. It has three buttons at the bottom: Back, Next, and Cancel. [Video description ends]

I'll choose Next, I will accept the terms of the license agreement, I'll click Next again, and it'll just go ahead and run the installation.

[Video description begins] He clicks the Next button. The End-User License Agreement appears on the next screen. It has a check box for accepting the terms of the License Agreement. He checks the box. At the bottom there are four buttons: Print, Back, Next, and Cancel. He clicks the Next button. A Privacy Statement appears on the next screen. It has three buttons at the bottom: Back, Install, and Cancel. He clicks the Install button. A progress bar displaying the installation status appears on the next screen. At the bottom, there are three buttons: Back, Next, and Cancel. Once the installation is complete, the screen reads: Completed the Microsoft Data Migration Assistant Setup Wizard. This screen has a check box for Launch Microsoft Data Migration Assistant. At the bottom, there is a Finish button. [Video description ends]

Before you know it, it's done. So, there's a check box here on the installation screen to launch the Microsoft Data Migration Assistant. Of course, I could launch it after through my Start menu, but I'm going to go ahead and turn that check mark on, and I'm going to click Finish.

[Video description begins] He checks the box for Launch Microsoft Data Migration Assistant and clicks the Finish button. [Video description ends]

Now it's loading the Microsoft Data Migration Assistant.

[Video description begins] A window titled Data Migration Assistant opens up. On one side of the window, there is a toolbar. [Video description ends]

So the first thing I'll do here is click the new button, the plus sign, to create a new migration project.

[Video description begins] He clicks the + sign in the toolbar. A window titled New appears. It has two options for Project type: Assessment and Migration. Assessment is selected by default. There is an input box for Project name. Drop-down menus for Source server type and Target server type are also present. The default value for Source server type is SQL Server. The default value for Target server type is Azure SQL Database. At the bottom, there is a Create button. [Video description ends]

Notice, we can build in assessment project, which is what we're going to do, to assess our on-premises SQL databases to test their suitability to be migrated to Azure. However, we can also actually perform a migration. However, we're not going to build a migration project here, just assessment. So the project name here is going to be HfxProj1 because my city, where this is happening on-premises, is Halifax.

[Video description begins] In the input box for Project name, he types HfxProj1. [Video description ends]

And the source server will be SQL, the target will be Azure SQL database. I'll click create, then I'm going to click Next.

[Video description begins] He clicks the Create button. A page titled HfxProj1 appears. It has three steps of creation. The first step called Options is currently displayed. Three options for report type are present here. These are: Check database compatibility, Check feature parity, and Benefit from new features. The first two are selected by default. At the bottom, there is a Next button. [Video description ends]

I'm going to give it some details, such as the name of the on-premises server that I want to use.

[Video description begins] He clicks the Next button. The screen shifts to the next step, which is Select sources. It has two buttons: Add sources and Remove sources. A window titled Connect to a server slides onto the screen. It has drop-down menus for Server name and Authentication type. The default value for Authentication type is Windows Authentication. For Connection properties, there are two options with check boxes. These are: Encrypt connection and Trust server certificate. Both the options are checked by default. At the bottom, there is a Connect button. In the drop-down menu for Server name, he selects srv2016-1. He retains the default value for Authentication type. [Video description ends]

So I'll fill that in, that's my on-premises SQL server. It uses Windows Authentication, but I could choose the appropriate authentication type. If you're not sure what to choose here, talk to your on-prem SQL people and I'm going to click Connect. We're not going to change anything else here.

[Video description begins] He clicks the Connect button. The window titled Connect to a server disappears. A new window titled Add sources appears. It has a check box for srv2016-1. Below it, there are four options with check boxes for sources. These are: CM_S01, ReportServer, ReportServerTempDB, and XTrans. At the bottom, there is an Add button. [Video description ends]

So I know it's made a good connection because I have a list of valid databases that are being hosted on that SQL server instance. So I'm just going to choose one of the databases in question that I'm thinking about migrating to Azure, and I'm going to click Add.

[Video description begins] He selects CM_S01. srv2016-1 gets automatically selected. He clicks the Add button. The window titled Add sources disappears. On the screen for the second step, which is Select sources, CM_S01 is added. At the bottom of this screen, there are two buttons: Back and Start Assessment. [Video description ends]

So we can see it's been added here. And we can add and remove sources at will here to determine what we want our assessment to be run against. So I'm going to go ahead and click Start Assessment in the bottom right.

[Video description begins] He clicks the Start Assessment button. The screen shifts to the third step, which is Review results. On one side of this screen, there are two options with radio buttons. These are SQL Server feature parity and Compatibility issues. SQL Server feature parity is selected by default. Below these options, there is a search box and below this box, srv2016-1 is present. In the main body of the screen, a tab titled Feature parity appears. It has a list of Unsupported features, and a section titled Cross-database references not supported in Azure SQL Database. This section has two sub-parts: Details and Databases. At the bottom, there is an Export report button. [Video description ends]

Once the assessment is complete, we can see that we are in step 3, where we're reviewing the results. And so we can see our SQL server on-premises listed over here on the left. And then we can see our listed items of unsupported features.

So the service broker feature not being supported in the Azure cloud and when we select that unsupported feature, we get some details listed over here on the right.

[Video description begins] From the list of Unsupported features, the presenter selects Service Broker feature is not supported. Its details appear in the Details section of the page. He scrolls down the Details section. A section titled Recommendation appears. [Video description ends]

Then we also get some recommendations about what we might be able to do to resolve this issue once the database has actually been migrated into the Azure Cloud.

[Video description begins] He highlights the following lines from the Recommendation section: Once the database has been migrated to Azure, you can look into Azure Service Bus functionality to implement a generic, cloud-based messaging system instead of Service Broker. [Video description ends]

Now, also remember that once you're happy with this, you can actually add an actual migration project,

[Video description begins] He clicks the + sign in the toolbar. The window titled New appears. He selects Migration for Project type. [Video description ends]

where you can actually start moving data into the cloud. So this migration assistant is a great tool then for you to evaluate your on-premises SQL databases and how likely they are as candidates for running in the Azure cloud.

[Video description begins] He closes the window titled New. [Video description ends]

Azure SQL Geo-Replication

[Video description begins] Topic Title: Azure SQL Geo-Replication. Your host for this session is Dan Lachance. [Video description ends]

To increase fault tolerance and availability for Azure SQL, we have the option of enabling Geo-Replication.

[Video description begins] A Microsoft Azure webpage displays on the screen. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present here with the following options: Create a resource, Home, Dashboard, All services, and Favorites. The main body of the page has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

Here in the portal, I've already got Azure SQL deployed. So if I go to the All resources view, and if I filter that view for anything that has a prefix of SQL, we can see both.

[Video description begins] From the navigation pane, he clicks on All resources present under Favorites. A page titled All resources appears. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. A few rows of data are present in this table. [Video description ends]

We've got a SQL Server and a single SQL database instance hosted on that server.

[Video description begins] He types sql in the input box for name. Two rows of data can be seen in the table. [Video description ends]

If I click on the server to open up its Properties blade, you'll notice that we don't have any options related to Geo-Replication, at least not at the server level.

[Video description begins] He clicks on sqlsvr172 in the table. A screen titled sqlsvr172 appears. It has a navigation pane. The main body contains details about the server. At the bottom, there are two tabs: Notifications and Features. The Features tab is currently selected. It has four tabs: All, Security, Performance, and Recovery. [Video description ends]

However, if I get back out of that, if I go into my database property sheet, notice that Geo-Replication is an option.

[Video description begins] He closes the sqlsvr172 page and shifts to the All resources page. He clicks on the 2nd sql resource listed in the table. A page titled sqldb172(sqlsvr172 /sqldb172) opens up. It has a navigation pane. The main body contains details about the server. Some of these are: Status, Location, Subscription, Server name, etc. He selects Geo-Replication from the navigation pane. A world map is displayed on the screen. [Video description ends]

Now currently, we can see that we've got an area on the map here in Eastern Canada where we've currently got our current SQL database deployed. That's the Azure region or location.

[Video description begins] The East Canada region has a blue tick mark on the map. [Video description ends]

Now if you're not so great with your geography, don't worry if you don't know what you're looking at on the map. Because when I scroll down a little bit, I can see indeed Canada East is that current region.

[Video description begins] He scrolls down the page. Below the map, there is a table with three columns: Server/Database, Failover Policy, and Status. In the table, there are two sections: Primary and Secondaries. Under Primary, Canada East is listed. Its Server/Database is sqlsvr172 /sqldb172, Failover Policy is None and Status is Online. [Video description ends]

And I can see the status of that replica is that it's online. Down below, it says for secondaries, Geo-Replication is not configured, and we can see here the list of target regions.

[Video description begins] He scrolls down the page. A section titled Target Regions appears. Some of the regions listed here are: West US, Canada Central, Brazil South, North Europe, etc. [Video description ends]

So let's say, for example, I want this to be replicated to Canada Central as a different region.

[Video description begins] He clicks on Canada Central from the list. A page titled Create secondary appears. It has the following criteria: Region, Database name, Secondary type, Target server, Elastic pool, and Pricing tier. The Region is Canada Central, Database name is sqldb172, Secondary type is Readable, Target server is Configure required settings, Elastic pool is None, and Pricing tier is Configure required settings. Lock icons are present next to Region, Secondary type, Elastic pool, and Pricing tier. At the bottom, there is an OK button. [Video description ends]

Now the secondary type is by default set to a readable replica of our Azure SQL database. Then for the target server, I have to configure settings. Now, what that means is I need another Azure SQL server instance.

[Video description begins] He clicks on Target server. A page titled Server appears. It has a button titled Create a new Server. No servers are listed on this page. Next to it, another page opens up. It is titled New Server. It has input boxes for Server name, Server admin login, Password, Confirm password, and a drop-down menu for Location. Below these fields, there is a check box that reads: Allow Azure services to access server. This check box as a tick mark. At the bottom, there is a Select button. [Video description ends]

Now if I don't have one, I have to create one here. So I'm going to call this sqlsvr172_central. You'll notice that it's going to tell me over here if it likes underscores, upper case letters, lower case letters. So notice here, it doesn't like a lot of the items that are specified here in the name.

[Video description begins] In the input box for Server name, he types sqlsvr172 _central. An error message pops up. It reads: Your server name can contain only lowercase letters, numbers, and '-', but can't start or end with '-' or have more than 63 characters. He then types sqlsvr172 central. [Video description ends]

So I'm just going to call it sqlsvr172central. And I'm going to specify the credentials and password here which do not have to be the same as they are for the primary server holding the master writable replica.

[Video description begins] The credentials for Server admin login, Password, and Confirm password appear. The login id is cirving. [Video description ends]

Once that's been filled in, I'm just going to go ahead and click Select.

[Video description begins] He clicks the Select button. The pages titled Server and New Server close. [Video description ends]

So really we're creating a new SQL Server instance to accommodate our Geo-Replication to a different Azure region. I'm going to leave the standard pricing tier as it is, and I'm going to click OK.

[Video description begins] In the page titled Create secondary, Target server changes to sqlsvr172 central (Canada Central) and Pricing tier changes to Standard S0: 10 DTUs, 250 GB. He clicks the OK button. The Create secondary page closes. [Video description ends]

Now currently, we have a message about the deployment being in progress up here in the upper right in the Azure portal.

[Video description begins] He points to the pop-up box titled Deployment in progress. [Video description ends]

And if I kind of scroll up here, and take a look here, after a moment, we'll see that it will reflect that we've got Geo-Replication from the Canada East region to the Canada Central region.

[Video description begins] On the map, a green dot with a check mark appears in the Canada Central region. [Video description ends]

And before you know it, you'll have this little check mark in these regions that are filled in with the solid color. You can see the other regions that are not filled in, and they do not have a check mark. So therefore, we don't have a replica of this SQL database in those locations.

And if we scroll down, we can see that represented in textual form. So, not only do we have our original online master replica in Canada East listed here at the top, but we can also see we've got a secondary now in the Canada Central region, and it's currently listed as being readable.

[Video description begins] He scrolls down to the table. Under Secondaries, Canada Central is listed. Its Server/Database is sqlsvr172 central/sqldb172. The Status is Readable.... [Video description ends]

Now if you click the ellipsis button, the three dots with the context menu next to the word readable, you'll have the option to force a failover which essentially promotes this to be the primary replica, and the other current primary would then become a secondary. It does say that this can cause some data loss while you're doing this.

[Video description begins] The presenter clicks the three dots next to Readable. Three options appear: Pin to dashboard, Forced Failover, and Stop Replication. He clicks on Forced Failover. A pop-up box titled Failover appears. It has two buttons: Yes and No. [Video description ends]

Also notice that we do have the option also of stopping replication, so, for instance, if there's a failure or a disaster in our primary region.

[Video description begins] He again clicks on the three dots next to Readable. He then points to Stop Replication from the list of options. [Video description ends]

NoSQL Overview

[Video description begins] Topic title: NoSQL Overview. Your host for this session is Dan Lachance. Screen title: NoSQL Databases. [Video description ends]

In the Microsoft Azure Environment, you can choose to deploy a SQL compliant type of database or a NoSQL database, so it's important to know the difference between the two. With NoSQL databases, we have a less rigid schema than with a traditional, relational database, such as MySQL or Microsoft SQL Server.

The schema, remember, is the blueprint of what type of data is allowed to be stored. And, so, with NoSQL, it's really designed to be much less structured to allow or accommodate for the storage of many different types of data. NoSQL is also designed for high scalability because it's really what is often used to work with very large data sets.

[Video description begins] Screen title : NoSQL Database Characteristics. [Video description ends]

So high performance and availability are a big part of NoSQL. Essentially, the manipulation and analysis of big data. With NoSQL, each stored row can actually store different types of data. That's unlike a relational database structure that has a blueprint or schema that defines exactly what can be stored in each row within a table.

We don't have that kind of structured limitation with a NoSQL database. There are a number of different types of storage configurations for NoSQL databases, such as key and value pairs, or NoSQL document stores, or graph database stores, but in the end, a NoSQL database is not relational.

[Video description begins] Screen title: NoSQL Horizontal Scaling. [Video description ends]

NoSQL uses horizontal scaling extensively as a traditional relational database system can as well.

[Video description begins] A diagram appears on the screen. It has a box with four blocks placed side by side. Below the box, there is a forward arrow. [Video description ends]

What this means is scaling out, as we see pictured in the diagram by adding database servers to handle the workload. Now this can be done for clustering purposes, for load balancing, and for replication of data.

[Video description begins] Screen title: Common NoSQL Database Products. [Video description ends]

Common NoSQL products include Azure CosmosDB, Azure Redis memory caching, which allows us to take data and cache it in memory. Data that is accessed frequently, so that subsequent requests are a service from the cache, which is much quicker than reading it from disk.

There are also numerous database options, including for NoSQL available to the Azure marketplace. So you can choose to deploy a new Virtual Machine instance that has a variety of different NoSQL products installed and configured for you already.


CosmosDB
  - Azure CosmosDB is a NoSQL database option available in Microsoft Azure. So it's a NoSQL solution that is globally distributed across Azure regions. 
    - This global distribution means that users can contact the nearest replica of CosmosDB to work with the data. 
    - That way, there's a better user experience instead of accessing it across multiple Azure regions.
  - Azure CosmosDB supports default encryption of data at rest, and it's used by a lot of popular services that you've probably heard of, like Xbox, Office 365, and Skype. When you start to deploy Azure CosmosDB, you begin by creating an Azure CosmosDB account, as we'll see in another demonstration. You also get to select the appropriate API for the account type.

Now, we might choose, for example, a certain type of account type like Gremlin if we want to use graph databases, or MongoDB if we're using a document type of database, and so on. So we'll see that as well when we configure Azure CosmosDB in a demonstration.

We can import data into CosmosDB from a number of different sources, including SQL databases. Now, even though CosmosDB is generally considered NoSQL, we still have the option of bringing in SQL data to store it in here. We also can specify CSV or comma separated value files as a data source or JSON files, and even standard NoSQL compliant databases like MongoDB.


Deploy CosmosDB
  - Microsoft Azure CosmosDB is a great choice when you have vast amounts of unstructured data that you want to store and manage in the cloud. I'm going to start here in the left-hand navigator in the Azure Portal by clicking Create a resource, and I'll search for cosmos.

[Video description begins] A Microsoft Azure webpage displays on the screen. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present here with the following options: Create a resource, Home, Dashboard, All services, and Favorites. The main body of the page has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]
  - From here, I'll choose Azure Cosmos DB, and then I'll click Create.

[Video description begins] He selects Azure Cosmos DB from the list of options. Some information about Azure Cosmos DB is displayed on the screen. Below it there is a Save for later button. A drop-down menu for Select a software plan is present on the screen, in which Azure Cosmos DB is selected by default. At the bottom, there is a Create button. He clicks the Create button. A page titled Create Azure Cosmos DB Account opens up. It has four tabs: Basics, Network, Tags, and Review + create. The Basics tab is currently open. It has two sections: Project details and Instance details. The Project details section has drop-down menus for Subscription and Resource Group. The Instance Details section has an input box for Account Name and drop-down menu for API. The default value for Subscription is Pay-As-You-Go. The default value for Resource Group is cloud-shell-storage-eastus. The default value for API is Core (SQL). At the bottom, there are three buttons: Review + create, Previous, and Next: Network. [Video description ends]

The first thing I'll do is place this into a resource group, and then, down below I need to create a Cosmos DB account name.

[Video description begins] He clicks the drop-down menu for Resource Group. A list of options appears. He selects Rg1 from the list. [Video description ends]

[Video description begins] He scrolls down the page. A drop-down menu for Location is also present on this page. Its default value is Australia East. For Geo-Redundancy, there are two options: Enable and Disable. Enable is selected by default. For Multi-region Writes, there are two options: Enable and Disable. Disable is selected by default. [Video description ends]

So I'm going to call this cosmosdb-acct172. Now, be careful because in some cases in Azure if you start to use weird symbols like underscores, it'll tell you. So luckily we have this kind of easy notification that there's something wrong with the name, so, just be aware of that.

[Video description begins] In the input box for Account Name, he types cosmosdb_acct172. An error message pops up. It reads: The name can contain only lowercase letters, numbers, and the '-' character, and must be between 3 and 31 characters. Name is invalid. He then types cosmosdb-acct172. [Video description ends]

Now for the API, I can determine exactly what it is I want to configure Cosmos DB as because really it's kind of like a multi-model type of solution. So, do we want to treat it as a core SQL solution?

Or do we want it to adhere to the MongoDB API standard, or Cassandra, or is it a table type of data store or a graph type of NoSQL data store? So in this example, I'll choose Azure Cosmos DB for Mongo DB API.

[Video description begins] He clicks the drop-down menu for API. A list of options appears. He selects Azure Cosmos DB for MongoDB API. [Video description ends]

Now, I would do that if I knew that I had perhaps an application or some code that was already written that needs to talk to the MongoDB API to access data. I'm going to specify an appropriate location.

[Video description begins] He clicks the drop-down menu for Location. A list of options appears. He selects Canada East from the list. [Video description ends]

I'm going to disable geo-redundancy. Notice, that was enabled by default for Cosmos DB. I also, of course, want to leave multi-region writes disabled since I've disabled geo-redundancy. When I click Next, I then have to place this into an Azure Vnet. So I'll choose a Vnet and a subnet.

[Video description begins] He clicks the Next: Network button. The screen shifts to the next tab titled Network. It has drop-down menus for Virtual Network and Subnet. He clicks the drop-down menu for Virtual Network. A list of options appears. He selects EastVnet1 from the list. A section titled Configure Firewall appears. For Allow access from Azure Portal, there are two options: Allow and Deny. Allow is selected by default. For Allow access from my IP (71.7.176.108), there are two options: Allow and Deny. Deny is selected by default. He clicks the drop-down menu for Subnet. A list of options appears. He selects EastSubnet1 from the list. At the bottom, there are three buttons: Review + create, Previous, and Next: Tags. [Video description ends]

And right now it's set to allow access from the Azure Portal, which is great. So I can use this portal GUI interface to make a connection to my Cosmos DB and also to connect to it and look at performance metrics and things of that nature.

And conveniently, it also has my current public IP address listed here, and I can click Allow to add, essentially, a firewall exception for CosmosDB, so that if I need to get in from on-premises, maybe I'm using a MongoDB GUI management tool, for example, that I will be able to get in, or maybe I've got some code segments running on-premises on a server that need to talk in Azure to my Cosmos DB to work with that. So I'm going to turn on Allow for that, and I'm going to click Next for tagging.

[Video description begins] He clicks on the Allow button for Allow access from my IP (71.7.176.108). [Video description ends]

Well, there's no tags in here to assign here so I'll just go to Review and create, and once the validation says it succeeded, I will create my Cosmos DB deployment.

[Video description begins] He clicks the Next: Tags button. The screen shifts to the next tab titled Tags. It has input boxes for Key, Value, and Resource Type. The default value for Resource Type is Azure cosmos DB account. At the bottom, there are three buttons: Review + create, Previous, and Next: Review + create. [Video description ends]

[Video description begins] He clicks the Next: Review + create button. The screen shifts to the next tab titled Review + create. A list of information is displayed on the screen. It has three sections: Basics, Virtual Network, and Firewall. At the bottom, there are two buttons: Create and Previous. [Video description ends]

[Video description begins] A pop-up message appears at the top of the screen. It reads: Validation Success. The presenter clicks the Create button. A page titled Microsoft.Azure.CosmosDB-20190313130002-Overview appears. It has a navigation pane with the following options: Overview, Inputs, Outputs, and Template. The Overview tab is currently selected. The main body of the screen has the following heading: Your deployment is complete. Above the heading, the following buttons are present: Delete, Cancel, Redeploy, and Refresh. It has a Go to resource button. At the bottom there is a table with the following four columns: Resource, Type, Status, and Operation Details. The table has one row of data. [Video description ends]

And after a moment we can see our deployment is complete, and we've even got a view over on the left here called Azure Cosmos DB, and I can see my deployed instance listed here.

[Video description begins] From the navigation pane of the home page, the presenter clicks on Azure Cosmos DB. A page titled Azure Cosmos DB appears. It has the following buttons: Add, Reservations, Edit columns, and Refresh. It has a table with the following columns: Name, Status, Location, and Subscription. One row of data is present in the table where the Name is cosmosdb-acct172, Status is Online, Location is Canada East, and Subscription is Pay-As-You-Go. [Video description ends]

I'm going to click it, and here we can see a number of interesting items.

[Video description begins] He clicks on cosmosdb-acct172. A page titled cosmosdb-acct172 appears. It has a navigation pane. The following buttons are present on this page: Add Collection, Refresh, Move, Delete Account, etc. Below the buttons, there is a list of details. These include: Status, Resource group, Read Location, Write Location, etc. [Video description ends]

For example, as I scroll down in the Overview part of the Properties blade, I can see the region into which it was deployed. This looks like Eastern Canada.

[Video description begins] He scrolls down the page. A section titled Regions appears. It has a world map. The East Canada region has a blue tick mark. [Video description ends]

And as I scroll down, I've also got this Data Explorer option, where I have buttons to create a new database or a new collection to begin working with data.

[Video description begins] From the navigation pane, he clicks on Data Explorer. A Data explorer page opens up. The following buttons are present here: New Database, New Collection, and Open Full Screen. [Video description ends]

Of course, you can do this programatically or using command line tools or even GUI tools that you might even run on-premises. You would just need to make sure you have a way to access Cosmos DB, and we're talking really here about adding a firewall exception, so here in the Properties blade, if I go to Firewall and virtual networks, notice here that my client IP, my public IP on the Internet, has been added here as being allowed in.

[Video description begins] He clicks on Firewall and virtual networks from the navigation pane. A page for Firewall and virtual networks opens up. For the field, Allow access from, there are two options with radio buttons: All networks and Selected networks. The Selected networks option is selected by default. A section titled Virtual networks is also present. It has a table with the following columns: Virtual Network, Subnet, Address Range, Endpoint Status, Resource Group, and Subscription. One row of data is present here. Virtual Network is eastvnet1, Subnet is 1, Address Range is 10.1.0.0/16, Resource Group is rg1, and Subscription is Pay-As-You-Go. Below it, there is a section titled Firewall. The following IP address is listed here. 71.7.176.108. [Video description ends]

[Video description begins] He highlights the following IP address: 71.7.176.108. [Video description ends]

But you would also need to go to Connection String because you would have to have the correct Cosmos DB host name, the port number to connect to, as well as the Cosmos DB user name, and either the primary or secondary password.

[Video description begins] From the navigation pane, he clicks on Connection String. A page for Connection String opens up. It has two tabs: Read-write Keys and Read-only Keys. Read-write Keys is currently open. It has the following criteria listed: Host, Port, Username, Primary Password, Secondary Password, Primary Connection String , Secondary Connection String, etc. The presenter highlights the values for Host, Port, and Username. The Host is cosmosdb-acct172.documents.azure.com. Port is 10255, and Username is cosmosdb-acct172. [Video description ends]

So you would do that, for example, if you were using some kind of MongoDB type of GUI tool on-premises that you wanted to reach into the cloud to this instance to make changes to.


Big Data Overview
  - Microsoft Azure provides numerous offerings related to working with Big Data. With Big Data, as the name implies, we're talking about vast datasets, large quantities of data that need to be processed and analyzed. Now, this has become more and more of a thing in recent years due to the Internet revolution and how much data is being produced on a daily basis.
  - Well, we might be getting this data from Internet of Things or IoT devices like baby monitors or surveillance cameras. Big Data sources can also include financial information, financial transactions for customers in a banking institution for instance or through medical research or even through cookies.

Cookies are preference files used on web browsers to track user preferences on websites, and also sometimes to track security authentication tokens used by users on websites. And so that can be a valuable source of data for things like marketing companies to know people's web browsing habits and their preferences, and that could be derived from cookies.

But all of this data needs to somehow be collected in a location that makes sense that can accommodate that amount of data, so a NoSQL database. And then it needs to be processed so we can draw meaningful insights from that data. Big Data has a number of characteristics that we need to consider, such as the amount of data that needs to be transmitted over a network. And then stored in some kind of a storage location, whether it's a data lake or a specific single database.

We have to think about the rate at which data is produced. How much data do we expect will be produced per day? Because when we have incoming data into our Azure solution for Big Data, we are paying a fee depending on how much data is coming in or going out in addition to being stored and being computed through a cluster.

We have to think about the wide variety of data types that we might be interested in working with such as financial transactions or customer web surfing habits through the collection of cookie data. And then we have to think about the accuracy of that data. One of the things we can do with Big Data is transform it to a different format that would be acceptable for our processing engine, at the same time, we can weed out irrelevant data.


Azure SQL Data Warehouse
The analysis of big data involves both the storage of vast datasets along with the processing of that raw data to result in meaningful insights. So part of Azure SQL data warehouse is certainly the Data storage component, but we've also got Parallel processing. This is done by having a cluster of compute nodes that work together to analyze big data stores.
So it can execute complex queries using what's called PolyBase. PolyBase differs a little bit from standard structured query language because it's designed to run against large datasets that get read from Apache Hadoop. And Apache Hadoop is a clustering solution designed for Big data analytics. Pictured on the screen, we have a sense of what the architecture looks like for Azure SQL data warehouse. Beginning on the left, we've got an application or an application component, that issues transact SQL or T-SQL commands.
Now, this gets sent to what's called the control node. The control node, like the name implies, controls the underlying cluster of compute nodes that actually perform the work. And so we can send a transact SQL command to the control node. The control node is then responsible for allocating that to compute nodes. And because we've got more than one compute node, plural nodes, it means that we can run some of these tasks at the same time or in parallel. Now, this is using underlying Azure storage to store, not only the data that we run the queries against but also any transformations that might result from the execution of those queries.
[Video description begins] An illustration appears. An icon titled App T-SQL commands is connected to a Control node. The Control node is further connected to Compute nodes on two sides. The Compute nodes then connect to an Underlying Azure storage. [Video description ends]

When you configure Azure SQL data warehouse, one setting you will specify is the data warehouse units or DWUs, which is a combination of performance factors related to things like CPU computing power, the amount of memory, and database input and output. All that together forms a data warehouse unit.

And the more data warehouse units you have, then the better performance you'll have when processing big datasets using the compute nodes within the cluster. Just like when deploying Azure SQL database, Azure SQL data warehouse also uses firewall rules to control inbound traffic.

So for example, you would have to add a rule for the appropriate IP address, or addresses, to allow inbound traffic to SQL over port 1433. To save on costs, you can also pause processing of data by the compute nodes. So therefore, you're only being billed for the storage related to Azure SQL data warehouse. And when you have sporadic testing that might be taking place, this is an important strategy to reduce costs.


Create an Azure SQL Data Warehouse
Azure SQL Data Warehouse is different than a standard Azure SQL database deployment, in that it's designed for parallel processing, so that we can quickly get results when we wanna run complex queries against large amounts of data.

[Video description begins] A Microsoft Azure web page opens up. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present on this screen. It contains the following options: Create a resource, Home, Dashboard, All Services, and Favorites. The main body of the page has a section titled Azure services. It contains the following options: Virtual Machine, Storage Account, App Services, etc. [Video description ends]

To get started with deploying an Azure SQL data warehouse here in the portal, I'll click Create a resource in the upper left.

[Video description begins] In the navigation pane, he clicks on Create a resource option. A section titled New opens. It has two columns: Azure Marketplace and Popular. The Azure Marketplace column contains the following options: Get started, Recently created, Compute, etc. The Popular column contains the following options : Windows Server 2016 Datacenter, Ubuntu Server 18.04 LTS, Web App, etc. [Video description ends]

And from the categories, I'm going to choose Databases and then on the right, I'm going to choose SQL data warehouse.

[Video description begins] From the Azure Marketplace column, he selects Databases. A column titled Featured appears. It contains the following options: Azure SQL Managed Instance, SQL Database, SQL Data Warehouse, etc. [Video description ends]

[Video description begins] He selects SQL Data Warehouse. A new window titled SQL Data Warehouse appears. It has input boxes for Database name and Collation. Drop-down menus are present for Subscription, Resource group, and Select Source. The default value for Subscription is Pay-As-You-Go. The default value for Select source is Blank database. The default value for Collation is SQL_Latin1_General_CP1_CI_AS. Selection fields for Server and Performance level are also present. The default value for Performance level is Gen2:DW1000c. At the bottom, a Create button is present. [Video description ends]

Now, you're going to need to use an Azure SQL server instance here. And if you don't already have one, you'll be able to create one throughout this process. So let's start by giving a database name here. I'm going to call this sqldatawarehousedb172, and I'm going to put this in an existing resource group.

[Video description begins] In the input box for Database name, he types sqldatawarehousedb172. [Video description ends]

[Video description begins] He clicks the Resource Group drop-down menu. A list of options appears. He selects Rg1. [Video description ends]

And for a data source I can have a Blank database, I could choose a Sample such as AdventureWorksDW, or I could simply take the source from a Backup of a database. In this case, why don't we go with some sample data from AdventureWorksDW.

[Video description begins] He clicks the Select source drop-down menu. A list of options appears. He selects Sample. He clicks the Select sample drop-down menu. A list of options appears. He selects AdventureWorksDW. [Video description ends]

Then I've got to specify the SQL server instance here. I'm going to click on that. And on the right, any existing SQL servers that I might want to tie this Data Warehouse to, I could. But in this case, we don't have any, so I'm creating a new one. We're going to call this sqlsvr172, and I'm going to specify the server admin for SQL server and I'll confirm the passwords.

[Video description begins] He clicks the Server field. A page titled Server opens. It has a Create a new server button. The presenter clicks the button. A page titled New Server opens. It has input boxes for: Server name, Server admin login, Password, and Confirm password. A drop-down menu for Location is also present. The default value for Location is Canada East. Below it there is a check box for Allow Azure services to access server. It has a tick mark. A Select button is present at the bottom. [Video description ends]

[Video description begins] In the input box for Server name, he types sqlsrv172. In the input box for Server admin login, he types cirving . He enters a password in the input boxes for Password and Confirm password. [Video description ends]

I'm going to deploy this SQL server instance in the Canada East Azure location or region and then I'll click Select. So we got the server taken care of, but the problem is I have a little notification symbol here that says, SQL Data Warehouse Generation 2 is not supported in this region, okay.

[Video description begins] He clicks the Select button. The Server and New Server pages disappear. The Server is: sqlsrv172 (Canada East). [Video description ends]

[Video description begins] He points to a red notification icon present next to the Server field. [Video description ends]

Well, that's set automatically as a default down below the performance level.

[Video description begins] He clicks on the field for Performance level. A page titled Configure performance opens. It contains two tabs: Gen2 and Gen1. Gen2 is selected by default. It has a scale with a pointer for Scale your system. The pointer is currently at DW1000c. At the bottom there is an Apply button. [Video description ends]

So if I choose Generation 1, Gen1, then the error message goes away.

[Video description begins] He shifts to the Gen1 tab. It has a scale with a pointer for Scale your system. The pointer is currently at DW400. The price of the system mentioned here is 5.32 USD/hour. [Video description ends]

At least for the region that I've selected it in. And this ties into the fact that some specific Azure service configurations are only available in some regions. Now, I can also determine which data warehouse unit selection or DWU that I want. And as I kind of scale my system up, notice of course the price per hour, US dollars goes up the more data warehouse units or DWUs that you allocate to your data warehouse.

[Video description begins] He moves the pointer and places it at DW1500. The price changes to 19.96 USD/hour. [Video description ends]

Remember that a data warehouse unit, or DWU, is a collection of performance factors like CPUs and memory. And so the best way to work with this, before you've got experience running your workloads in data warehouse is to start at a reasonably small DWU value and then gauge the performance as you run queries against the data. And if you need to, you can scale this up later or scale up back down.

[Video description begins] He moves the pointer again and places it at its original position DW400. The price again goes down to 5.32 USD/hour. [Video description ends]

So at this point, I'm going to click Apply, and down below, I'm going to click Create.

[Video description begins] He clicks the Apply button. The Configure performance window closes. [Video description ends]

[Video description begins] He clicks the Create button on the SQL Data Warehouse page. [Video description ends]

And we can now see the deployment is in progress.

[Video description begins] The Microsoft Azure home page is open. The presenter points to a notification at the top right corner. It reads: Deployment in progress. [Video description ends]

So SQL data warehouse is similar to when you deploy Azure SQL database in that you've got to determine how you need to make a connection into the database, such as from a non-premises environment perhaps where you're running SQL Server Management Studio. And, again, it's gonna make a connection over standard SQL ports like 1433 and so you'd have to add a firewall exception to allow that to happen. So now, on the left, I'm going to go to the SQL data warehouses view where we can see, we've got our SQL data warehouse database.

[Video description begins] In the navigation pane, under Favorites, he clicks on SQL data warehouses. A page titledSQL data warehouses opens. It has three buttons: Add, Edit columns, and Refresh. This page has a table with the following columns: Name, Status, Replication, Pricing Tier, Location, and Subscription. The table contains one row of data. The name is sqldatawarehousedb172. [Video description ends]

And if I click on it and open it up, then we can see if we scroll down, in the properties blade, for example, if I go to Quick start.

[Video description begins] He clicks on sqldatawarehousedb172. A page titled sqldatawarehousedb172 opens. It has a navigation pane with the following options: Overview, Activity log, Tags, etc. In the main body, the following buttons are present: Pause, Scale, Restore, New Restore Point, and Delete. Below the buttons, a list of information is present. It includes details about: Resource Group, Status, Server name, etc. [Video description ends]

I can see that we have a number of tools that we can use so that we can work with data in SQL data warehouse.

[Video description begins] In the navigation pane, under Settings, he clicks on Quick start. In the main body, a new page titled sqldatawarehousedb172 - Quick start opens. It has three sections: Get the tools, Integrate with your app, and Learn more. [Video description ends]

And that is available through the Microsoft Azure SDK, Azure PowerShell and also the Azure SQL Data Warehouse Migration Tool.

[Video description begins] He points to the options present under Get the tools section. [Video description ends]

And we also have information about Integration with our application, because the idea is that we'll have some kind of an application that is going to be interested in running these types of complex queries and gaining insights from data that is stored and managed by SQL data warehouse. Now, I do have a Geo-backup policy which takes a snapshot on a daily basis. However, this is kind of unlike the standard Azure SQL database geo-replication, because that same type of geo-replication option is simply not available with Azure SQL data warehouse.

[Video description begins] In the navigation pane, under Settings, he clicks on Geo-backup policy. A new page for Geo-backup policy opens. It has two buttons for Geo-backup policy: Enabled and Disabled. Currently, enabled is selected. [Video description ends]

The other thing to watch out for is if I scroll down as we were talking about, if I go to Firewalls and virtual networks. We can add allowances for which IPs are allowed to make a connection into SQL data warehouse.

[Video description begins] In the navigation pane, under Security, he clicks on Firewalls and virtual networks. A page for Firewalls and virtual networks opens. At the top, the following buttons are present: Save, Discard, and Add clientIP. For Allow access to Azure services, there are two buttons: ON and OFF. Currently, ON is selected. The Client IP address is: 71.7.176.108. A table is displayed with three columns: RULE NAME, START IP, and END IP. [Video description ends]

Again, over port 1433, the standard SQL port, and we can even add our current client's IP address in and I'll just go ahead and save that if we really wanted to.

[Video description begins] He clicks the Add client IP button. A row is displayed in the table. The RULE NAME is: ClientIPAddress_ 2019-3-14, the START IP is: 71.7.176.108, and the END IP is: 71.7.176.108. He clicks the Save button. [Video description ends]

[Video description begins] He clicks the Save button. [Video description ends]

Also, as we scroll down, notice here that we've got a preview feature here called Query editor.

[Video description begins] In the navigation pane, under Common Tasks, he clicks on Query editor (preview). A page for Query editor (preview) opens. It has a drop-down menu for Authorization type. There are input boxes for Login and Password. The Authorization type is: SQL server authentication. The Login is: cirving. At the bottom, there is an OK button. [Video description ends]

And so if I put in the credentials that I specified when I configured the SQL server.

[Video description begins] He enters the password and clicks the OK button. [Video description ends]

Then we can go ahead and actually start to peruse and work with some of the data in a very simple way, at least here directly in the portal.

[Video description begins] The Query editor (preview) is open. It has four buttons: Login, New Query, Open query, and Feedback. The window has two sections: sqldatawarehousedb172 (cirving) and Query 1. Below Query 1, there is a section with two tabs: Results and Messages. The Results tab is currently open. Under the heading sqldatawarehousedb172 (cirving), three pointers are displayed: Tables, Views, and Stored Procedures. [Video description ends]

So if I expand tables, let's say, I see that we've got, for example, a dbo.DimCustomer as a table, and I can even start working with queries.

[Video description begins] He clicks on Tables. It expands. The following options appear: dbo.DatabaseLog, dbo.DimCurrency, dbo.DimCustomer, etc. He clicks ondbo.DimCustomer. [Video description ends]

So maybe select all of the columns from dbo.dimcustomer, and then I can run that query, and we'll start to get the results listed here.

[Video description begins] In the Query 1 section, in line 1, he types: select * from dbo.dimcustomer. He clicks the Run button. [Video description ends]

Now, this is just a quick way to look at this, of course, you're going to have an application or some kind of a way to hook into this using other tools to actually work with this data properly for analysis.

[Video description begins] In the Results tab, a table appears. It has the following columns: Customer Key, Geography Key, Customer Alternate Key, and Title. [Video description ends]

Bear in mind, one of the reasons you might use Azure SQL data warehouse over just standard Azure SQL database is because when you run queries, now this is not a complex query, so imagine a much more in depth, detailed complex query. But when you do run queries here, what's going to be happening is that the query is going to be handled by a specific back end node that's got its own compute resources, like CPU and memory, as opposed to standard Azure SQL database, which does not support multiple parallel processing.

[Video description begins] He clicks the Close button at the top right corner of the Query editor (preview). A message box appears with the text: Your unsaved edits will be discarded. He clicks the OK button. [Video description ends]

The other thing to keep in mind is, you actually have the option of pausing your Azure SQL database warehouse if you're not actually going to use it.

[Video description begins] The SQL data warehouses page is open. He clicks onsqldatawarehousedb172 in the table. The sqldatawarehousedb172 page opens. [Video description ends]

So for the storage portion, you would still be paying, but not for the compute portion. And you can see up at the top here that we do have in the overview part of the properties blade, a pause button, which we could use to do just that and then we could resume it when we want to continue processing.

[Video description begins] He points to the Pause button. [Video description ends]

Azure HDInsight

[Video description begins] Topic title: Azure HDInsight. Your host for this session is Dan Lachance. [Video description ends]

Azure HDInsight is a Big data analytics solution that's hosted in the cloud, and so it's considered a Managed service, and with managed services in the cloud we're talking about something that's easy to provision and configure compared to if you had to set it up yourself manually on-premises. Azure HDInsight uses a number of underlying open source frameworks but it does allow for Node clusters working together to process large amounts of data, whether that data is like a real time feed through a data pipeline or whether that data is coming from some kind of massive data storage warehouse.

HDInsight Underlying Technologies includes but it is not limited to Apache Hadoop. Apache Hadoop is an open source framework that's used for distributed processing clusters. Apache Spark is similar in that, it is distributed in parallel processing, but what makes it a little bit different is it uses in-memory caching to speed things up.

Apache Kafka is another open source component that allows for real time streaming data pipelines to feed HDInsight. Another aspect of working with HDInsight is Extract, Transform, and Load or ETL, you might be familiar with this term with other database solutions. It's not exclusive to HDInsight, it's more of a standard methodology more than anything else, where we can start by copying a data from source, whether it's a data store of some kind in the database or whether it's real time streamed data.

In the next step, for transform, we can convert the data to a different format so it can easily be consumed by the target that might expect things in a different format, such as dates. Finally, we can load the data into some kind of a storage facility, whether it's a data warehouse or whether it's going to be treated as a real time data feed that's gonna be fed into some other component.

[Video description begins] Screen title: HDInsight Usage. [Video description ends]

So what do we use HDInsight for? Well, we know it's about big data analytics, but can we be a bit more specific than that? While using HDInsight, it can be related to Machine learning or ML, where we can gain insights from vast amounts of data that are fed into it. You can run very large petabyte-scale types of queries against this type of information, or it can be automated so the insights are gained based on code that's written, which can result in predictive analysis for future trends.

On the IoT side of things, the Internet of Things, we can have a large amount of IoT device telemetry that is fed into the HDInsight solutions. So we can draw conclusion from large datasets, whether those are related to the security of IoT devices or due to the nature of those IoT devices. We can draw conclusions, such as those related to monitoring industrial control networks and so on.

Deploy an Azure Hadoop Cluster

[Video description begins] Topic Title: Deploy an Azure Hadoop Cluster. Your host for this session is Dan Lachance. [Video description ends]

In this demonstration, I'm going to use the Azure portal to deploy an Apache Hadoop cluster. This is useful when you need to have multiple parallel processing for big data analytics.

[Video description begins] He opens a Microsoft Azure web page. It has a menu bar on the top. A search bar is also present. On one side is a navigation pane. It contains several options: Create a resource, Home, Dashboard, All Services, etc. Currently Dashboard is displayed. A list of Azure services is also present: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

To get started here in the portal, I'm going to click Create a resource in the upper left, and then I'm going to choose Analytics because what I'm really talking about doing here is using the HDInsight as your offering.

[Video description begins] He clicks on Create a resource. A page titled New appears. It contains a search bar at the top. The page has two columns. The first column is named Azure Marketplace. It has the following options: Get Started, Recently created, Compute, Networking, Analytics, etc. The second column is named Popular. It has the following options: Windows Server 2016 VM, Ubuntu Server 18.04 VM, Web App, SQL Database, etc. [Video description ends]

Now, when I select HDInsight, I've got to give a name for the clusters.

[Video description begins] In the first column, he clicks the Analytics option. A column titled Featured appears. It has the following options: Azure Data Explorer, HDInsight, Data Lake Analytics job, etc. He selects HDInsight. A new page titled HDInsight opens up. The page has the following two tabs: Quick create and Custom. Currently, the Quick create tab is selected, which has the following three steps: 1. Basics, 2. Storage, and 3. Summary. At present, step 1: Basics is selected. A page titled Basics is open. It has an input box for Cluster name, Cluster login username, Cluster login password, and Secure Shell (SSH) username. There are drop-down menus for Subscription, Resource group, and Location. There is a field for Cluster type. At the bottom, a Next button is present. The default value for Subscription is Pay-As-You-Go. The Cluster login username is admin. [Video description ends]

So I'll call it hdinsightcluster172. And it's going to use the .azurehdinsight.net DNS suffix by default.

[Video description begins] In the Cluster name input box, he types hdinsightcluster172. Below the input box, he highlights the following text: .azurehdinsight.net. [Video description ends]

and after a moment we'll have a check mark here that indicates that, that name is valid and unique, then I have to specify the cluster type. And this is where from the Cluster type drop-down list, I can specify I want to use a specific framework, in this case, Hadoop. It's going to use the Linux operating system.

[Video description begins] He clicks on Cluster type. A new page titled Cluster configuration appears. It has drop-down menus for Cluster type and Version. There are two options for Operating system: Linux and Windows. He clicks the drop-down menu for Cluster type. A list of options appears. He selects Hadoop from the list. The Version changes to Hadoop 2.7.3 (HDI 3.6). For Operating system, Linux gets selected. A section titled Features appears. [Video description ends]

And then I can choose from variations of the version of Hadoop, depending on how I'm going to interface with the cluster and what exactly I'm going to do with that. So I'm going to go ahead and just leave the default selection.

[Video description begins] He clicks the Select button at the bottom. The Cluster configuration page closes. [Video description ends]

I have to specify a Cluster login username, which I'm going to do here, and password. This is what I can use, for instance, if I log into the website to view overall metrics and details related to my Apache Hadoop Cluster.

[Video description begins] He types cirving in the Cluster login username input box. He types a password in the Cluster login password input box. [Video description ends]

And if I plan on using SSH for cluster access, then I can use the SSH username.

[Video description begins] The Secure Shell (SSH) username is set as sshuser. Below it, there is a check box for Use cluster login password for SSH. It has a tick mark. [Video description ends]

Notice here it's set to use the cluster login password also for SSH. So I'm going to tie this into an existing Resource group. I'm going to specify the appropriate Azure location for my config, after which I'll then click Next.

[Video description begins] He clicks the drop-down menu for Resource group. A list of options appears. He selects Rg1. He clicks the drop-down menu for Location. A list of options appears. He selects Canada East. [Video description ends]

[Video description begins] He clicks the Next button. In the HDInsight page, step 2: Storage is selected. A page titled Storage is displayed. It has a drop-down menu for Primary storage type. The Primary storage type is set as Azure Storage by default. For Selection method there are two options: My subscriptions and Access key. My subscriptions is selected by default. Below it there is a field for Select a Storage account. An input box for Container is also present. Its default value is hdinsightcluster 172-2019-03-14t11-47-2. Below it, there are fields for Additional storage accounts and Data Lake Storage Gen1 access. At the bottom, a Next button is present. [Video description ends]

Next, for the primary account storage type, I'm going to choose Azure Storage as opposed to Data Lake variations. This is going to be for data that is used by HDInsight as well as for logs that get generated. And I'll leave it on My subscriptions for access to that account. So, then I have to go through and choose a Storage account. So I'll choose one of my storage accounts.

[Video description begins] He clicks on Select a Storage account. A page titled Storage accounts appears. It has two options. He selects stor14567. The Storage account page closes. [Video description ends]

And then it'll make a storage container with the name listed down below here. And at this point, I'm going to click Next.

[Video description begins] He clicks the Next button. In the HDInsight page, step 3: Summary is selected. A page titled Cluster summary is displayed. It includes the following details: Basics, Security + networking, Storage, etc. [Video description ends]

So once the validation has passed, I'll be able to click Create to initiate my HDinsight Cluster, which in this case, is configured in the back end to use Apache Hadoop. So I'll go ahead and click on Create to start the process.

[Video description begins] He clicks the Create button. The HDInsight page closes. The Azure home page is open. A notification appears which reads: Submitting deployment. [Video description ends]

While that's happening, understand that the next couple of steps would really be for developers, where they would use some kind of a tool to interface with Hadoop to work with the data and workloads related to that data. Tools like Microsoft Visual Studio, the Azure storage explorer, or you could even, for example, use SSH to connect to the cluster and start actually issuing commands based on the Hadoop command syntax. So now I'll click on the All resources view on the left, and I'll filter it by hd as a prefix.

[Video description begins] In the navigation pane, he clicks on All resources. The All resources page opens. In the name input box, he types hd. One item is displayed in the table: hdinsightcluster172. [Video description ends]

And there's our HDInsight cluster, which I will click on.

[Video description begins] A page titled hdinsightcluster172 appears. At the top, the following buttons are present: Move, Delete, and Refresh. The page has a navigation pane with options such as: Overview, Activity log, Tags, Settings, etc. The main body has various details about the resource, such as Resource group, Status, Location, URL, etc. [Video description ends]

The first thing I'm interested in, in the Overview part of the properties blade is the URL, which I will copy to my clipboard, and I'm going to go ahead and open that up in another tab here in my web browser.

[Video description begins] He copies the URL: https: // hdinsightcluster172.azurehdinsight.net. [Video description ends]

I am then prompted to specify the Username and Password that I configured when I can set up this cluster in the first place. So we're going to go ahead and pop in those credentials.

[Video description begins] In the new tab, a Sign in box appears. He types cirving in the Username input box. He types the password in the Password input box. He presses Enter. [Video description ends]

And that's going to give me the cluster website page where I can start viewing a bunch of details. For example, from here I can go to Hosts, where I can get a list of a lot of the hosts that are being used here within my cluster for Apache Hadoop.

[Video description begins] An Ambari web page opens in the new tab. Five tabs are present at the top: Dashboard, Services, Hosts, Alerts, and Admin. Currently, the Dashboard is open. A navigation pane is present on the left. It contains the following options: HDFS, YARN, MapReduce2, etc. In the center pane, three tabs are present: Metrics, Heatmaps, and Config History. Currently, the Metrics tab is open. Two drop-down lists are present. In the first drop-down, Metric Actions is selected and in the second drop-down, Last 1 hour is selected. Beneath them, various details are displayed, such as HDFS Disk Usage, HDFS Links, Memory Usage, etc. [Video description ends]

[Video description begins] He clicks the Hosts tab at the top. The Hosts tab opens. An Actions drop-down list is present. A search input box is present to Filter by host and component attributes or search by keyword. Beneath it, a table is displayed with 9 columns: Name, IP Address, Rack, Cores, RAM, Disk Usage, Load Avg, Versions, and Components. [Video description ends]

If there are any alerts, as we can see it listed up here at the top in red, and also by a specific host here, then I can click to read any of those specific ideas.

[Video description begins] He points to the notification of 5 alerts displayed at the top of the screen. [Video description ends]

[Video description begins] In the 5th row under the Name column, he clicks on number 3 displayed next to the Name: wn4-hdinsi.e4hiqroou53uhf15yranlxhfmb.vx.internal.cloudapp.net. A new page opens by the same name. A table is displayed with four columns: Service, Alert Definition Name, Status, and Response. He points to the 3 items in red. Their status is CRIT. [Video description ends]

So we could see here that some of these alerts are related to connectivity issues because nothing has been actually done in this cluster at all thus far. So if I go back to the Dashboard, we'll see how we can get an overall usage of the data nodes that are available.

[Video description begins] He clicks the Dashboard tab at the top. The Dashboard opens. [Video description ends]

The Hadoop distributed file system, or HDFS disk usage among the nodes in the cluster.

[Video description begins] He clicks the first item in the Dashboard: HDFS Disk Usage. The following information is displayed: DFS used 1.6 MB (0.00%), non-DFS used 24.4 GB (1.55%), and remaining 1.4 TB (93.35%). [Video description ends]

Now you will use a variety of different tools to start loading data into Apache Hadoop as we mentioned. So this is what we would do at the administrative level. And from this point forward, it would be up to developers to interface with the Hadoop cluster to present data and workloads to be processed.

Azure Data Lake Analytics

[Video description begins] Topic title: Azure Data Lake Analytics. Your host for this session is Dan Lachance. [Video description ends]

Microsoft Azure Data Lake Analytics is a managed service offering in the Azure Cloud. It's designed for large scale data storage. We are talking about at the petabyte level. Now bear in mind, one petabyte equals approximately one million gigabytes. We're talking about potentially working with trillions of files. We can even take data, for example, that we might have stored in Azure storage account as blobs.

And we can actually copy that over into an Azure Data Lake store. For data analysis, we have to think about the kind of work-load power that we're going to need to work against these large types of data so that we can gain insights. And one consideration is configuring the Data Lake Analytic Unit, the DLAU. So this is a unit of measurement that's used to determine the underlying horsepower that's going to run our jobs where we can start to extract insights from this data.

So for example, each analytic unit contains a number of CPU course that are allocated to process data and also a chunk of memory. So at the time of this recording, one AU, one data lake analytic unit is two CPU cores and six gigabytes of RAM. So making a change to the data lake analytic unit really depends on the type of workload you envision will be handled through Azure data lake analytics. So this tells us then that we're talking about a large-scale parallel processing solution that uses node clusters.
We can use the Microsoft Visual Studio IDE, the integrated development environment, as a way to gain access to our Azure data lake and to begin running queries. We can also use the Eclipse IDE. We can use the IntelliJ IDE. All of these different integrated developer environments allow you to write code in a variety of different languages.
It really boils down to using whatever you are most familiar with, however, it's important to understand that these three IDEs are supported to hook into Microsoft Azure. And so in other words, there's an Azure toolkit that keeps getting updates for each and every one of these three items.
And these three items, these three IDEs also have plugins, even give them extended capabilities. So, Azure data lake storage then can be used to feed data into an Apache Hadoop cluster for parallel processing as part of data analysis. The Apache Hadoop cluster uses the Hadoop Distributed File System or HDFS. The jobs that we submit against that use what's called U-SQL.
This is even a type of project that you can launch if you're using GUI IDE tools like Microsoft Visual Studio. So U-SQL then, is just a simple language that you'll learn very quickly if you are already familiar with structured query language or just SQL.


Create a Data Lake Analytics Account
  - Just like a lake in the real world can have many incoming streams or tributaries to result in the water collected in the lake
    - Azure data lake in the Azure cloud allows us to specify a multitude of data sources to allow data to be fed into data lake.
  - Not only is it data storage, but we're talking about analysis of that data. So to get started here, I'm going to go into the Azure portal and click Create a resource in the upper left.

[Video description begins] He clicks on Create a resource. A page titled New appears. It contains a search bar at the top. The page has two columns: the first column is named Azure Marketplace. It has the following options: Get Started, Recently created, Compute, Networking, Analytics, etc. The second column is named Popular. It has the following options: Windows Server 2016 Datacenter, Ubuntu Server 18.04 LTS, Web App, SQL Database, etc. At the top, there is a search bar. [Video description ends]

Now because we're talking about analytics, I'm going to choose the Analytics category. And you'll see over on the right that we have Data Lake Analytics, which I will click.

[Video description begins] In the first column, he clicks on Analytics. A column titled Featured appears. It has the following options: Azure Data Explorer, HDInsight, Data Lake Analytics, etc. [Video description ends]

[Video description begins] He selects Data Lake Analytics. A new page titled New Data Lake Analytics opens up. An input box is displayed for Name. Drop-down lists are present for Subscription, Resource group, and Location. By default, the Resource group is cloud-shell-storage-eastus, The Subscription is Pay-As-You-Go and the Location is East US 2. A field for Data Lake Storage Gen1 is also present here. There are two options for Pricing packages: Pay-as-You-Go and Monthly commitment. Pay-as-You-Go is selected by default. A Create button is present at the bottom. [Video description ends]

So, what we can do is feed data into our Azure data lake. And then that data can be processed and transformed and manipulated for the purposes of gaining insights as to all of that collection of raw data, it can even be used for things like machine learning. So, I have to create a new data lake analytics account. I'm going to call this datalake172, and notice it's going to add the .azuredatalakeanalytics.net DNS suffix at the end.

[Video description begins] In the Name input box, he types: datalake172. [Video description ends]

I will deploy this into an existing resource group and choose a location that makes sense for me, and then down below, I've got to also create a data lake storage account.

[Video description begins] He clicks the drop-down menu for Resource group. A list of options appears. He selects Rg1. He clicks the drop-down menu for Location. A list of options appears. He selects Central US. [Video description ends]

[Video description begins] He clicks on Data Lake Storage Gen1. A page titled Select Data Lake Storage appears. There is an input box for name. A button titled Create new Data Lake Storage Gen1 is also present. Beneath it, the following text is displayed: 0 accounts found and No existing Data Lake Storage Gen1. [Video description ends]

So I'm going to click Create new Data Lake Storage Gen1, it's already got a name for it, that's fine, let's go with that. I'll leave it on Pay-as-You-Go and Encryption as enabled, so I'll click OK for that, and then I'll click Create to actually create this resource.

[Video description begins] A page titled New Data Lake Storage Gen1 appears. It has an input box for Name. The value here is datalake172adls. For Pricing package, there are two options with radio buttons: Pay-as-You-Go and Monthly commitment. Pay-as-You-Go is selected by default. The default value for Encryption settings is Enabled. An OK button is present at the bottom. [Video description ends]

[Video description begins] He clicks the OK button. The New Data Lake Storage Gen1 page and the Select Data Lake Storage Gen1 page disappear. [Video description ends]

[Video description begins] In the New Data Lake Analytics page, he clicks the Create button. [Video description ends]

Okay, so now I'm gonna go to the All resources view on the left and I'll filter it for things that start with the data.

[Video description begins] The Azure home page opens. In the navigation pane, he clicks on All resources. A new page titled All resources opens. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these options, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. [Video description ends]

[Video description begins] In the name input box, he types data. Two items are displayed in the table: datalake172 and datalake172adls. [Video description ends]

We can see the two resources that resulted from our configuration, the data lake storage and the data lake analytics resource, which I'm going to click on to pop into the properties.

[Video description begins] He clicks on datalake172. A page titled datalake172 appears. At the top, the following buttons are present: New job, Sample scripts, Data explorer, etc. The page has a navigation pane on the left with the following options: Overview, Activity log, Tags, Settings, etc. The main body has details about the resource. Some of these are: Pricing tier info, AU-hours used, Estimated cost, etc. [Video description ends]

So when we're in here, notice right away that we have the option of submitting a job. So what we're talking about doing here is, submitting a job for processing for data lake analytics. Now of course, that could be fed data that we've configured into our data lake configuration. And if I were to scroll down, you'll see in the properties blade here indeed we do have data sources.

[Video description begins] In the navigation pane, under Settings, he clicks on Data sources. A new page titled datalake172- Data sources appears. At the top, a button titled Add data source is present. A table is displayed with two columns: Name and Type. A data source named datalake172adls (default) is listed in the table. [Video description ends]

Currently, for our data lake analytic configuration, we've got our data lake account that we specified for storage upon creation, but notice that we could add additional data sources. We also have some other configuration items, like for example, the maximum number of concurrent running jobs.

[Video description begins] In the navigation pane, under Settings, he clicks on Limits and policies. A new page titled datalake172- Limits and policies appears. At the top, two buttons are present: Save and Discard. Scales with sliders are present for the following criteria: Days to retain job queries, Maximum AUs, Maximum number of running jobs, Maximum AUs per job, Priority per job, etc. [Video description ends]

We've got a slider here to draw that up or down, depending upon what our specific needs hour, our processing might entail. If I were to click Tools in the properties blade, we then have a variety of tools that we can work with from a developer perspective to feed data into Data Lake Analytics, and then to determine which job should process that data, so there are Data Lake Tools for Visual Studio, and as we scroll down, it's also available for Azure PowerShell, and Azure CLI.

[Video description begins] In the navigation pane, under Getting started, he clicks on Tools. A new page titled datalake172- Tools appears. Some of the options listed here are: Data Lake Tools for Visual Studio, Azure PowerShell, Azure CLI, etc. [Video description ends]


Add a Data Lake Data Source
  - You can feed data into Azure Data Lake Analytics programmatically, through command line tools and also through the GUI here in the portal.
  - Here in the Azure portal, I'm already looking at my Azure data lake analytics resource which I will click on to open up its properties blade.
  - Scroll down, I have an option here called Data sources where I'll see the data lake account that's already available for data lake analytics.
  - Click on that, I can see some details, the name and the type. This is Azure Data Lake Storage Gen1.
    - If I wish, I can also go down and start exploring the data by clicking Data explorer.
  - Now, this will be based on what we've added as data sources, as we can see. And I can start browsing through all of the files in the file system related to that storage.
So to add additional storage, I'm going to scroll back up in the properties blade and choose Data sources and then I'll click Add data source.

[Video description begins] In the navigation pane, under Settings, he clicks on Properties. A page for Properties opens. It has a navigation pane. He clicks on Data sources from the navigation pane. A page titleddatalake172- Data sources page appears. He clicks the Add data source button at the top. A new page titled Add data source appears. Drop-down menus are present for Storage type, Selection method, and Azure storage. There is an Add button at the bottom. [Video description ends]

And in this case, I'm interested in Azure storage and what I'm going to do is specify the Select account option or I can choose an Azure storage account.

[Video description begins] He clicks the drop down menu for Storage type. Two options appear: Azure Data Lake Storage Gen 1 and Azure Storage. He selects Azure Storage. [Video description ends]

[Video description begins] He clicks the drop down menu for Storage method. Two options appear: Select account and Account name. He selects Select account. He clicks the drop-down menu for Azure Storage. A list of options appears. He selectsstor14567. [Video description ends]

So I'm going to select an existing Azure storage account that has data that I would like to feed into Azure data lake analytics for further processing. So, I'm gonna go ahead and click Add.

[Video description begins] The Add data source page closes. The datalake172- Data sources page is open. A notification appears at the top right corner. It reads: Data source operation complete. Another Data source named stor14567/ is added to the table. [Video description ends]

And after a moment, we can see that our storage has been added, and, if I click on it, notice here it's not data lake storage, but rather, just simple Azure storage, as in a storage account.

[Video description begins] He clicks on stor14567/. A page titled stor14567/ appears. It contains details about the Name and Type. The Name is stor14567/ and the type is Azure Storage. He clicks the Close button at the top right corner of the page. The page closes. The datalake172- Data sources page is displayed. [Video description ends]

And so now that I've done that, if I scroll down for instance and go to Data explorer, now I may have to refresh this.

[Video description begins] In the navigation pane, under Data Lake Analytics, he clicks on Data Explorer. The datalake172adls page appears. [Video description ends]

So I'll click Refresh, and of course, I'll close what I was looking at previously because now I can see besides my data lake storage, I've also got my storage account here, my Azure storage account stor14567, it was called.

[Video description begins] He clicks the More button. A list of options appears. He clicks on Refresh. [Video description ends]

[Video description begins] He closes the datalake172adls page. 2 pages are simultaneously open: All resources and datalake172- Data explorer. A page titled All resources is open. It has two options: datalake 172 and datalake172adls . datalake172 is selected. A page titled datalake172-Data explorer is open. It has a navigation pane and a list of folders.These folders are: Storage accounts, datalake172adls (default), catalog, system, stor14567, Catalog and datalake172. [Video description ends]

[Video description begins] He expands the stor14567 folder. It contains 3 folders. He points to the folder named pics. [Video description ends]

I can even start browsing through folders in that Azure storage account to expose content. In this case, I've got a jpeg image.

[Video description begins] He clicks on the pics folder. A new page titled stor14567 opens. The following three buttons are present at the top: New folder, Upload, and Properties. A table with the following four column is displayed: Name, Type, Size, and Last Modified. A file named dog.jpg is listed in the table. [Video description ends]

Now, notice here, if I select that, I can get a preview of what is in that specific file.

[Video description begins] He clicks on dog.jpg. A page titled File Preview opens up. The following four buttons are present at the top: Format, Download, Properties, and Delete file. [Video description ends]

Normally, you'll have to download it to do that, as the built in filters often will not show you anything that makes any sense, it really depends on the file type, but notice we can also upload content even from this interface instead of go out to the storage account in Azure, including managing the hierarchy by creating folders and so on.

[Video description begins] He closes the File Preview page. The stor14567 page is displayed. [Video description ends]

And so it's important then to add the appropriate data sources to Azure data lake analytics so that you can begin to submit jobs that will process that data, and we'll see how to do that in another demo.

[Video description begins] In the navigation pane, under Settings, he clicks on Data sources. The datalake172- Data sources page opens. [Video description ends]

Work with Data Lake Datasets

[Video description begins] Topic title: Work with Data Lake Datasets. Your host for this session is Dan Lachance. [Video description ends]

Azure Data Lake Analytics is designed to be used as a large scale centralized data storage repository where data can come from many different sources. But it's also used for submitting jobs, so that we can process that data and gain insights from that data.

[Video description begins] A Microsoft Azure web page titled All resources opens. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present with the following options: Create a resource, Home, Dashboard, All Services, Favorites, etc. There are five buttons at the top: Add, Edit columns, Refresh, Export to CSV and Try preview. Below these buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. The name input box contains the following text: data. A table is displayed with six columns: NAME, TYPE, RESOURCE GROUP, LOCATION, SUBSCRIPTION, and TAGS. The table has two rows with NAME: datalake172 and datalake172adls. [Video description ends]

So, here in the portal, I've gone to the All resources view, I've filtered by data, because I know that my data lake analytics configuration is called datalake172.

[Video description begins] He highlights data in the name input box. [Video description ends]

So I'm going to go ahead and click to open that up. And what I'm interested in doing is submitting a job.

[Video description begins] He clicks on datalake172. A page with the same name opens. It has a search bar followed by a navigation pane with the following options: Overview, Activity log, Access control (IAM), etc. At the top, the following buttons are present: New job, Sample scripts, Data explorer, etc. The main body has details about the resource. Some of the options here are: Pricing tier info, AU-hours used, Estimated cost, etc. [Video description ends]

Now I have a New job button right here at the top in the overview part of the Properties blade. I could also scroll down under the data lake analytics section, and here I would also see New job.

[Video description begins] In the navigation pane under the Data Lake Analytics section, he clicks on the New job option. A new page titled datalake172 - New job appears. At the top, the following buttons are present: Data Explore, Open file, and Save as. There is an input box for Job name. It has the following text: New job. There is a horizontal bar with a pointer for AUs, where the pointer lies at 1. The following details are also present here: Account: datalake172, Estimated cost: USD 0.03/minute, etc. There is a Submit button. A code editor area is also present here. [Video description ends]

So I can give a name to the job, and I'm going to go ahead and specify the code for it down below, this syntax is called U-SQL.

[Video description begins] 10 lines of code appear in the code editor area. Code line 1 reads: @a =. Code line 2 reads: SELECT * FROM. Code line 3 reads: (VALUES. Code line 4 reads: ("Customer1", 190.0),. Code line 5 reads: ("Customer2", 100.0). Code line 6 reads: ) AS. Code line 7 reads: D(customerID, amount );. Code line 8 reads: OUTPUT @a. Code line 9 reads: To "/customerdata.csv". Code line 10 reads: USING Outputters.Csv();. [Video description ends]

So it's kind of a combination of the C# programming language along with structured query language, or SQL to give it a bit more power. And the reason it exists is because structured query language under itself is really not designed to handle Big Data, whereas this is designed to work with that through, in this case Azure Data Lake Analytics. So, what we're doing here is creating a, I'm going to be creating a file here, I'm creating a tiny dataset. Now, of course, we can bring this dataset in from many other ways. But all I'm doing is creating a file here called customerdata.csv, and I'm going to have a CustomerID column, or field definition along with amount, and I can see I'm feeding it a couple of sample rows here, Customer1, with a numeric amount of 190, Customer2, with numeric amount of 100.

[Video description begins] In the code line 9, he highlights: customerdata.csv. [Video description ends]

[Video description begins] He points at code line 7. [Video description ends]

Now, your U-SQL jobs can be much more complex, and they can actually deal with processing of data.

[Video description begins] He highlights code lines 4 and 5. [Video description ends]

All I'm doing here is trying to illustrate a very basic simple example, so you get the sense of the construct. The overall skeletal framework that is used to work with Data Lake Analytics and start to process information. So once this has been done, I'm going to go ahead and click Submit. Now before I do that actually, before I submit I can also adjust the performance, the AUs because what I'm doing here is determining how many things can be processed parallel at once.

[Video description begins] He moves the pointer of the AUs horizontal bar to 13. [Video description ends]

And so depending on the nature of your U-SQL, we'll determine if you need to do this. And because this is very simple, I'm not gonna need to adjust that. So I'm going to go ahead and submit this.

[Video description begins] He moves the pointer back to 1. He then clicks the Submit button. [Video description ends]

So the job is submitted, it's going to take me to a new dashboard where we can see it's currently in the preparation phase, after which it'll be queued for processing, it'll be run, and then we'll be able to examine the result. In this case, the result should be that we've got that customer data file with the data in it.

[Video description begins] A page titled New job appears. It has four buttons: Refresh, Resubmit, Reuse script, and Cancel job. There is a section titled Status: Preparing. It has four steps: Preparing , Queued, Running, and Done, where Preparing is currently active. The following details are also present here: Progress: 0%, AUs: 1, Consumed AU-hours: 0, etc. The other side of the page has the following tabs: Job graph, Script, Data, AU analysis, and Diagnostics. Currently, the Job graph tab is open. It has a drop-down menu for Display and a button for Playback. [Video description ends]

And we can now see that the status of our job is such that it has succeeded.

[Video description begins] The Status changes to Succeeded and Progress shows 100%. [Video description ends]

And so if we go, let's say to the Data tab here, look at any Outputs. We can see indeed we've got customerdata.csv file, but let's back out of here.

[Video description begins] He clicks on the Data tab. The following two tabs are present here: Inputs and Outputs. He clicks on Outputs. There is a table with two columns: Name and Size. It has one item with the name: customerdata.csv. He then closes the page. The screen shifts back to the datalake172-New job page. [Video description ends]

And, why don't we run the Data explorer option here, just to go through our data, and sure enough notice there it is, customerdata.csv, it's in our data lake storage.

[Video description begins] He clicks on the Data Explorer option from the navigation pane. The datalake172adls page opens. It has the following buttons: Filter, New folder, Upload, Access, Folder properties, etc. A table is displayed with three columns: Name, Size, and Last Modified. It has three items with names: catalog, system, and customerdata.csv. [Video description ends]

And, if I we're to actually open that up and preview, we can see our two customers along with the amounts that were specified in our U-SQL script.


IoT Overview
  - The Internet of Things, otherwise called IoT, is really just a general umbrella term that refers to a large variety of devices that communicate over the Internet. Now that relates to Microsoft Azure in the sense that we can register devices with this central location in the Azure Cloud, and we can receive data from these IoT devices and monitor them through the Azure IoT Hub.But we'll talk to that effect later on in more detail. There were plenty of examples of IoT devices.
  - Things like water pressure valves and gauges and their current settings, baby monitors, smart cars that allow their details about their internal systems and their location to be made available over the Internet in a secured manner, medical equipment that can be controlled through the Internet, as well as home automation features, things like environmental control and turning on lights, and so on. This is just but a subset of examples of IoT types of devices that have Internet connectivity.
The thing to be careful of with this is with consumer grade IoT devices. Often, security is just not a priority. In many cases, you'll find that firmware might not even be updatable when there are security holes that are revealed about a specific type of consumer grade IoT product, like a home automation device. As with all security hardening in IT, when it comes to IoT devices we should always take care to make sure that default settings, like credentials to access a web interface on the IoT device are changed.
AlsoIoT devices should be placed on an isolated and secured network. The reason for this is because if an IoT device is compromised, we want to make it as difficult as possible for the attacker to connect to other devices on the network where the IoT device resides. So by putting it on its own protected network, we're adding that extra layer of security.
Pictured on the screen, we have an example of the Shodan website, which is essentially an IoT search engine, where we can search for items, as I have done here, such as home automation, and it will index any discovered devices that might appear to be vulnerable out there on the Internet.

[Video description begins] A screenshot of SHODAN website is displayed on the screen. On the left, there is a navigation pane. It has the following headers: Total Results, Platform, Type, and Author. At the top, there is a search box for Exploits. Home automation is entered in the search box. In the center pane, the following results display: keware technologies homeseer 1.4 - Directory Traversal, Schneider Electric SBO / AS - Multiple Vulnerabilities, etc. [Video description ends]

And so when we work with the Azure IoT services, we have a centralized way to securely receive this information from IoT devices. And from there, we might even feed that data into things like Azure machine learning, to determine if vulnerabilities might exist or if there's suspicious activity related to those IoT devices that needs to be addressed.


IoT Central
  - Azure IoT Central is an Azure managed service. This means the underlying complexities of setting up the infrastructure to support the IoT central service, whereby we can work with our IoT devices, those complexities are hidden from us so we can focus on actually doing what the service offers, which is to centrally manage IoT devices.So it is a separate Azure resource that we deploy, and we have a URL that would use the DNS suffix of .azureiotcentral.com for the IoT central website. So it provides us the ability to centrally manage IoT devices that have been registered through the IoT hub.

It also allows us to monitor them, and we can even build triggers that look at some of the data that we're monitoring and can take specific actions, such as the pressure in a valve in a remote planned exceeding a given threshold value that is considered safe and acceptable. Pictured on the screen, we see an example of the Azure IoT Central Management Portal.

[Video description begins] A screenshot of the IoT 172 portal appears. The page URL: https://iot172.azureiotcentral.com has been highlighted. On the left, there is a navigation pane with the following tabs: Dashboard, Device Explorer, Device sets, etc. The Dashboard is currently open, and it has the following title: CONTOSO. Some of the options here are: Quick Start Demo, Tutorials, Add Device Set, etc. [Video description ends]

Notice that the URL uses the DNS suffix as we've mentioned of .azureiotcentral.com. This one was created using a template and you can see here the page lists CONTOSO, but notice on the left in the navigator we can also explore IoT devices that are registered. As we drill deeper into this sample Azure IoT central management portal, we can start exploring devices.

[Video description begins] A similar screenshot for IoT 172 portal appears. Here the center pane has the title: Refrigerator 1. Below the title, the following tabs are present: Measurements, Settings, Properties, Commands, Rules, and Dashboard. The Measurements tab is currently active. It has a list of Telemetry items. [Video description ends]

In this example, we are exploring a refrigerator IoT enabled device, where we can see some telemetry items such as items related to gyroscopes and pressure, and so on. So depending on the nature of the IoT device will determine what is seen here. But, again, we can configure actions that would look at thresholds that might be exceeded, in this case, maybe a temperature for a refrigerator getting too low or too high. And that could trigger the sending of an email to administrators to do something about this.


IoT Hub
Azure IoT Hub is a separate type of Azure resource that you can deploy much like you might deploy an Azure Virtual Machine. Azure Io Central uses an IoT Hub, but the IoT Hub isn't directly manageable in this particular case. But you might wonder, what does the IoT Hub exactly do? The purpose of the IoT Hub, as the name implies, hub meaning some kind of a centralized repository where we have IoT devices that are connected.

And from there, we can receive messages from IoT devices. So details about the statistics related to what that IoT device does, such as monitoring temperature controls in a building. But we can also configure it so that we send commands to control those remote IoT devices, such as to adjust the temperature. And developers can choose a wide variety of programming languages to do that in. But before all of this can happen, IoT devices need to be connected to the IoT Hub.

And that's done through connection strings that will show up after you've built your IoT Hub resource. So there's a device registration connection string to initially get a device connected to IoT Hub. When you deploy your IoT Hub, one of the things you'll get to deal with is the IoT sizing which really deals with the number of messages for throughput that you want your IoT Hub to be able to handle.

Now, not only device registration is of interest here, but also device message transmission, either from the device to the IoT Hub or command sent from the IoT Hub to devices to control them. So what might we use Azure IoT Hub for? Well, because there's a wide variety of IoT devices out there, the uses are many as well.

We could use it for medical device tracking, not only to track the device itself and where it is, but also, of course, to track all of the detailed statistics provided by that IoT device, which could include things like vital signs of the patient to which that medical device is connected. IoT Hubs can also be used to register and track information related to industrial machinery controls, or remote building, heating ventilation, and air conditioning control.
IoT devices will make a connection to IoT Hub and transmit data using a number of different protocols, depending on the configuration, one of which is HTTPS over TCP port 443. However, we've also got AMQP. This is the Advanced Message Queuing Protocol. This is a standard for IoT device transmission of data that uses port 5672, and it's designed to work on a number of different platforms not, for example, just Windows.

MQTT is the Message Queuing Telemetry Transport. This is another type of protocol used by IoT devices that uses TCP port 1883. Now, which one should you use? Well, for example, AMQP is a mature standardized protocol that provides more potential functionality than MQTT does, but it does so at a cost of higher overhead.


Configure IoT Hub
The Azure IoT Hub is a centralized Azure resource that's deployed in the Azure cloud that allows us to connect a multitude of IoT devices for the purposes of managing those devices and monitoring any data that they might send into Azure IoT Hub.

[Video description begins] A Microsoft Azure webpage opens. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present with the following options: Create a resource, Home, Dashboard, All services, and Favorites. The main body of the page has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

To get started here in the portal, I'm going to click Create a resource over on the left, and I'm going to search for IoT.

[Video description begins] He clicks on Create a resource from the navigation pane. A screen titled New appears. It has a search bar. The presenter types iot in the search bar. A list of options appears. [Video description ends]

And I'm going to choose IoT Hub.

[Video description begins] He selects IoT Hub from the list of options. A screen titled IoT Hub appears. It has a drop-down menu for the field Select a Software plan. IoT Hub is the default selection. There is a Create button at the bottom of the page. [Video description ends]

From here, I'll click Create, and I'll start by tying this into an existing resource group I've created.

[Video description begins] He clicks the Create button. A screen titled IoT opens. There are three tabs on this screen. These are: Basics, Size and scale, and Review + create. The Basics tab is currently active. It has a section titled Project Details. There are drop-down menus for Subscription, Resource Group, and Region. An input box for IoT Hub Name is also present. The default value for Subscription is Pay-As-You-Go. The default value for Resource Group is cloud-shell-storage-eastus. The default value for Region is West US. At the bottom there are two buttons: Review + create and Next: Size and scale. He clicks the drop-down menu for Resource Group. A list of options appears. He selects Rg1 from the list. [Video description ends]

And like pretty much deploying any resource in Azure, I'll select an appropriate region or location. And I'm going to give a name to this.

[Video description begins] He clicks the drop-down menu for Region. A list of options appears. He selects Canada East from the list. [Video description ends]

This I'm going to call iothubcentralapp.

[Video description begins] In the input box for IoT Hub Name, he types iothubcentralapp. [Video description ends]

Okay, after I've done that, I'm then going to click Next.

[Video description begins] He clicks the Next: Size and scale button. The screen shifts to the tab titled Size and scale. It has a drop-down menu for Pricing and scale tier. The default value is S1: Standard tier. A scale for Number of S1 IoT Hub units is also present. The pointer is currently on 1. On the page, there is a section with the following details: Pricing and scale tier, Messages per day, and Cost per month. The Pricing and scale tier is S1, Messages per day is 400,000, and Cost per month is 25.00 USD. The following features are enabled: Device-to-cloud-messages, Message routing, Cloud-to-device-commands, and IoT Edge. At the bottom there are two buttons: Review + create, and Previous: Basics. [Video description ends]

Here I can specify the pricing and scale tier, so that we can determine how many messages can be handled by this IoT Hub. These are called IoT Hub units, so this is the scale capacity, and as we need more IoT capacity units, then we can increase them. Now we have to choose the appropriate tier before that even becomes an option.

And notice that what we're looking at here is a number of messages per day that can be processed. And what goes along with that, of course, is the cost increase or decrease, as you increase or decrease the maximum messages per day that you want to be able to process.

[Video description begins] He clicks the drop-down menu for Pricing and scale tier. A list of options appears. He selects S3: Standard tier from the list. The name of the next criterion changes from Number of S1 IoT Hub units to Number of S3 IoT Hub units. The value of Pricing and scale tier changes to S3 and Messages per day changes to 300,000,000. The Cost per month changes to 2500.00 USD. He then changes the value of Number of S3 IoT Hub units to 3. The value of Messages per day changes to 900,000,000 and Cost per month changes to 7500.00 USD. He changes the value of Number of S3 IoT Hub units to 1. The value of Messages per day changes back to 300,000,000 and Cost per month changes back to 2500.00 USD. [Video description ends]

These are messages from IoT devices. Next, I'll click Review and Create, and then I'll just click the Create button.

[Video description begins] He clicks the Review + create button. The screen shifts to the tab titled Review + create. It has information on the basics and size and scale for the IoT hub . At the bottom, there are two buttons: Create and Previous: Size and scale. He clicks the Create button. A page titled All resources appears. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for Filter by name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. A few rows of data are present in this table. [Video description ends]

Now, I'm going to go to the All resources view here in the portal, and I'm going to filter it by IoT, since I know that's the prefix used to name my IoT Hub.

[Video description begins] In the Filter by name input box, he types iot. A resource named iothubcentralappappears in the table. [Video description ends]

And now we can see that it's listed here in the view. I'm going to click to open up its Properties blade.

[Video description begins] He clicks on iothubcentralapp in the table. A page titled iothubcentralappappears. It has a navigation pane. The main body has the following buttons: Move, Delete, and Refresh. Below the buttons, a few details are listed. These include: Resource group, Status, Location, Subscription, Hostname, etc. [Video description ends]

The first thing that we want to bear in mind is the hostname that's been assigned to our IoT Hub because we're talking about connectivity from IoT devices over the Internet to the IoT Hub defined in the cloud, which is what we're looking at here.

[Video description begins] The hostname is iothubcentralapp.azure-devices.net. [Video description ends]

Also, if we take a look further down, we can also see we have an IoT devices view.

[Video description begins] He clicks on IoT devices present in the navigation pane. A page for IoT devices appears. At the top, the following buttons are present: Add, Refresh, and Delete. Below the buttons, there is a table with the following columns: Device ID, Status, Last Activity, Last Status Update, etc. The table is currently empty. [Video description ends]

If I click on that, we don't have any devices of course yet, but we can click to add IoT devices by specifying the Device ID.

[Video description begins] He clicks the Add button. A page titled Create a device opens. It has an input box for Device ID, Primary key, and Secondary key. For Authentication type, there are three options: Symmetric key, X.509 Self-Signed, and X.509 CA Signed. Symmetric key is selected by default. A check box for Auto generate keys is also present. This box is checked. For Connect this device to an IoT hub, there are two buttons: Enable and Disable. Enable is selected by default. [Video description ends]

And whether we have a certificate or a symmetric key that's used to authenticate the device to the IoT Hub.

[Video description begins] He closes the Create a device page. The IoT devices page is open. [Video description ends]

Then we've got IoT Edge listed over here on the left-hand side, where we can add an IoT Edge device.

[Video description begins] From the navigation pane, he clicks on IoT Edge. An IoT Edge page opens. It has the following buttons on top: Add an IoT Edge device, Add an IoT Edge deployment, and Refresh. This page has two tabs: IoT Edge devices and IoT Edge deployments. The IoT Edge devices tab is currently open. It has a table with the following columns: Device ID, Runtime Response, Deployment Count, etc. [Video description ends]

[Video description begins] He clicks the Add an IoT Edge device button. A page titled Create a device opens. At the top, an information box is present, which has the following text: Find Certified for Azure IoT devices in the Device Catalog. This page has input boxes for Device ID, Primary key, and Secondary key. The Authentication type is Symmetric key. A check box for Auto generate keys is also present. This box is checked. For Connect this device to an IoT hub, there are two buttons: Enable and Disable. Enable is selected by default. [Video description ends]

Now from here we can look at the supported Azure IoT devices in the Device Catalog.

[Video description begins] He clicks the information box. A new tab opens in the browser. The url is https://catalog.azureiotsolutions.com. A page titled Find your IoT device appears. It has a search bar and a button named See all devices. A section titled Azure IoT Edge Certified is also present here. Some of the devices listed here are: Cloudian AI Box, ARTiGO A1250, OpenBlocks IoT VX2, etc. [Video description ends]

And, for example, if I'm interested in looking at power, some kind of IoT device that tracks power. I might start selecting these devices and reading about them in their support for Azure.

[Video description begins] In the search bar, he types power. A list of devices appears on the screen. He clicks on the device named PMC-5231. A page with the information of this device opens. It has three tabs: Device Specifications, Kit Specifications, and Get Started. The Kit Specifications tab is currently open. The kit is called ICP DAS- Power management IoT Kit. Below the name of the kit, there is a Request Demo button. [Video description ends]

So the idea is that we need to be able to determine which IoT devices in this particular case would support IoT Edge which allows us to write custom code modules that will actually run directly on that device.

[Video description begins] He shifts to the Microsoft Azure tab. He closes the Create a Device page. The IoT Edge page is open. [Video description ends]

And then we can add an IoT Edge deployment to push out the IoT Edge agent and custom modules, code modules that we want to do.

[Video description begins] He clicks on the Add an IoT Edge deployment button. A page titled Create Deployment appears. It has six tabs. The first tab is titled Name and Label is open. It has an input box for Name. At the bottom, there is a Next button. In the input box for Name, he types aa. [Video description ends]

Now these code modules, of course, are docker compatible containers that we want to push out. We can specify the container registry settings to point to those specific items.

[Video description begins] He clicks the Next button. The page shifts to the second tab, titled Add Modules (optional). It has input boxes for Name, Address, User Name, and Password. At the bottom there are two buttons: Previous and Next. [Video description ends]

So we have a number of things that we can do then through the specific IoT Hub.

[Video description begins] He closes the Create Deployment page. The IoT Edge page is open. [Video description ends]

It serves as a central point to manage and monitor IoT devices.


IoT Edge
Azure IoT Edge is an IoT-based solution for the Azure cloud that allows us to have custom code running on IoT devices. So this custom IoT software can run on the device and can even perform processing data functions on the device before even sending data back to the cloud, and specifically, back to an Azure IoT Hub. So the way that this works, generally speaking, is developers can build these custom modules, which really run as docker containers on Azure IoT Edge devices.

And those code modules or containers are then deployed to IoT devices. This also means that if there's a network outage because these IoT devices ideally would be on-premises elsewhere and not in the Azure cloud, if there's a network outage, they can still work with their code logic and process data, and when the network link is re-established, send that to the cloud specifically to the Azure IoT Hub for further processing and storage.

Azure IoT Edge has a number of components that work together, such as the Azure IoT Hub, which is an Azure resource that is used to centrally register IoT devices and manage and monitor them in the Azure cloud. Of course, the Azure IoT devices themselves are components that are used. These could be devices built by any manufacturer out there such as small devices that are used with sensors to determine temperature or power readings or pressure and pump readings or anything like that.

And that IoT device then could be registered with the IoT Hub and it can send data to the IoT Hub. But remember, with Azure IoT Edge, a lot of that data processing and manipulation can happen directly on customized code modules we place or push out to IoT devices before being sent into the Azure cloud. And so the next component is IoT Edge runtime. The Azure IoT Edge runtime needs to be supported on the IoT device.

And essentially, this is what allows us to push out. It's an agent that allows us to push out our code modules or docker compatible containers that have our custom code onto IoT devices. So when you configure an Azure IoT Hub, you can choose to add an IoT Edge device. And when you do, you'll see that there's a web page here where you can search for specific IoT device types that are supported to work with Azure IoT Hub as an IoT Edge device running that agent.

[Video description begins] A screenshot of Microsoft Azure IoT Device Catalog is displayed on the screen. It is titled: Find your IoT device. Below the title, there is a search box. The central pane shows the options for Azure IoT Edge Certified devices. Two devices have been listed here. [Video description ends]

So the process looks like this: We first create an IoT Hub.

[Video description begins] Screen title: IoT Edge Process. [Video description ends]

This is an Azure resource and we might even do it using the portal, let's say, after which we can then look at the connection strings in the IoT Hub to determine how to register our IoT device or devices with that IoT Hub. Next, we would add, as we saw on the previous screen an IoT Edge runtime device.

Essentially, we're pushing the agent out to that device, so it has to support this connectivity to Azure IoT Hub after it's registered. And then as developers build these custom modules or docker compatible containers, we can then create deployments. Really, it's called creating an IoT Edge deployment, where we specify the modules that we want to push out to specific IoT devices connected to IoT Edge that are running IoT Edge runtime.

IoT Solution Accelerators

[Video description begins] Topic title: IoT Solution Accelerators. Your host for this session is Dan Lachance. [Video description ends]

Microsoft Azure IoT solution accelerators are essentially pre-created IoT cloud solutions, where code is already written. However, you can customize it as you see fit. Also, it's got built-in support for IoT device monitoring. And, it also means that required cloud IoT services like IoT Hub get created automatically from this essentially prefab IoT cloud-based solution. So we could use accelerators so that we have a complete IoT cloud solution out of the box, but rarely is that the case.

Often, we will use one of these prefabricated IoT cloud solutions in Azure as a starting point, where we then go back and tweak it and make changes certainly to things like code, especially if we're going to be using IoT edge devices, where we run custom code modules directly on those IoT devices on another network. Pictured on the screen, we can see the Azure IoT solution accelerators website.

[Video description begins] A screenshot of the Azure IoT solution accelerators website is displayed on the screen. The URL of the website https://www.azureiotsolutions.com/Accelerators is highlighted. The page has two sections: Deploy a Microsoft solution accelerator and Explore partner solution accelerators. The Deploy a Microsoft solution accelerator section has the following options: Remote Monitoring, Connected Factory, Predictive Maintenance, and Device Simulation. [Video description ends]

Now, by going to this solution accelerators website, we can browse the variety of prefabricated solutions that could serve as either a complete solution, out of the box, or as we mentioned, as a starting point.

[Video description begins] Screen title: Deploying Azure IoT Solutions Accelerators. [Video description ends]

Once you've located a solutions accelerator that you're interested in from the website, you can select it. And you do that by clicking the Try Now button, at which point you're then going to be asked to specify an Azure subscription and region for the deployment. Next thing is that after it's deployed, which could take a few minutes, it might include some IoT device simulators, so that you can immediately be up and running and start working with the tool.

It might even use backend Azure Cosmos DB storage, but remember that these Azure IoT solutions accelerators are all a little bit different. In the end, one commonality is that they will often have a monitoring dashboard, if not more than one that you will use to navigate through the IoT solutions accelerator.

Azure Cognitive Services

[Video description begins] Topic title: Azure Cognitive Services. Your host for this session is Dan Lachance. [Video description ends]

Artificial intelligence, otherwise called AI, is essentially the imitation of human behavior by technology. In Azure, that could be done using Azure Cognitive Services, which provides a series of developer artificial intelligence tools and also an endpoint URL for making API calls to use artificial intelligence. AI usage is many-factored, including for speech purposes. This would allow developers to add speech-enabled features to their applications, such as voice to text.

There are APIs related to vision metadata tagging for processing of images, language analysis APIs, and intelligence search APIs. So, you get to learn about each of these API calls when you deploy cognitive services in Azure as a resource. The documentation is built in to the Properties blade of cognitive services. And bear in mind that in order for developers to make API calls to the API of their choosing, depending on the need, will require access to a key for the code to authenticate.

Deploy Azure Cognitive Services

[Video description begins] Topic Title: Deploy Azure Cognitive Services. Your host for this session is Dan Lachance. [Video description ends]

In this demonstration, I will deploy Azure Cognitive Services in the portal. This is really more of a developer thing; however, as IT administrators for Azure, we can deploy Azure Cognitive Services, which really serves as an entry point for developers to hook into APIs of their choosing.

[Video description begins] A Microsoft Azure webpage opens. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is present on this screen with the following options: Create a resource, Home, Dashboard, All services, and Favorites. The center pane has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

To get started here in the portal in the upper left, I'm gonna click Create a resource.

[Video description begins] He clicks the Create a resource option from the navigation pane. A page titled New opens. At the top, a search bar is present. [Video description ends]

And I'll just search for C-O-G, for cog, and I can see Cognitive Services listed, so I'll go ahead and search that.

[Video description begins] In the search bar, he types cog. The following list of options appears: Azure Search, Cognitive Services, Spatial Anchors, etc. He clicks Cognitive Services. A new page titled Cognitive Services opens. It has a drop-down menu for Select a software plan. The default value here is Cognitive Services. Below it, a Create button is present. [Video description ends]

Then, I'll choose Create.

[Video description begins] He clicks the Create button. A page titled Create appears. It has an input box for Name. There are drop-down menus for Subscription, Location, Pricing tier, and Resource group. A check box with the following text is present: I confirm I have read and understood the notice below. At the bottom of the page, a Create button is present. [Video description ends]

I need a name for this, so I'm gonna call this cogservice1.

[Video description begins] In the input box, he types cogservice1. [Video description ends]

And I'm gonna deploy this into a location that makes sense, that's nearest to me geographically where I'll be accessing it.

[Video description begins] The default value for Subscription is Pay-As-You-Go. He clicks the drop-down menu for Location. A list of options appears. These are: Central US, East Asia, Canada Central, etc. He selects Canada Central. [Video description ends]

And I'm gonna choose the only available pricing tier, and I'll deploy this into an existing storage group.

[Video description begins] He clicks the drop-down menu for Pricing tier. S0 appears in the options. He selects it. [Video description ends]

Notice I have to check off this confirmation about Microsoft using data that we send to Bing Search Services, if we talk to Bing-related APIs. So I'm going to go ahead and do that, and just go ahead and create this resource.

[Video description begins] He clicks the drop-down menu for Resource group. The following options appear: Rg1, testwebapp1, testwebapp2, etc. He selects Rg1. He checks the box for I confirm I have read and understood the notice below. [Video description ends]

[Video description begins] He clicks the Create button. The Microsoft Azure Home page appears on the screen. [Video description ends]

Once it's completed, it'll show up like any other resource does. So if I go to All resources and filter with a prefix of cog, there's cogservice1.

[Video description begins] He clicks the All resources option from the navigation pane. A new page titled All resources is displayed. The following buttons are shown below the title: Add, Edit Columns, Refresh, etc. Below the buttons, there is an input box for name. There are drop-down menus for resource groups, types, location, etc. A table is present below these input boxes. It has the following columns: Name, Type, Resource Group, etc. [Video description ends]

And if I click on and open it up, the first thing that's going to be important is the Keys in the Properties blade.

[Video description begins] In the input box for name, he types cog. A resource named cogservice1 appears in the table. He clicks on it. On the next screen, a new page titled: cogservice1  Quick start is displayed. It has a navigation pane with the following options: Overview, Keys, Quick start, etc. Quick start is currently active. He clicks the Keys option from the navigation pane. [Video description ends]

[Video description begins] A new page titled cogservice1  Keys appears. At the top, the following buttons are present: Regenerate Key1 and Regenerate Key2. Below it, there are input boxes for Name, Key 1, and Key 2. [Video description ends]

So you've got two Keys here, and you can regenerate one or the other. So you have two so that you can keep one in use for a while as you regenerate the other and over time, vice versa.

[Video description begins] He highlights the values in Key 1 and Key 2. [Video description ends]

So there is more security achieved by rotating keys periodically instead of sticking with the exact same keys. But when developers are making API calls, they're going to need access to one of these keys. Now, if I go to Quick start in the Properties blade.

I can also see reference documentation links for making API calls to the API of the developers choosing, whether it's the face API reference for facial recognition or whether it's translator text API references.

[Video description begins] He clicks on Quick start from the navigation pane. Three guidance steps for Quickstart are written on the screen. The first step is Grab your keys. The second step is Make an API call to this endpoint: https://canadacentral.api.cognitive.microsoft.com/ and the third step is Enjoy coding. The second step has the following built-in testing consoles: Face API reference, Translator Text API reference, Logs, etc. He hovers over a few of them. [Video description ends]

So when I click on any one of these, let's say we choose the face API reference, that's gonna open up a new web browser where we can see the regions in which that specific API is available through Cognitive Services.

[Video description begins] He clicks the Face API reference. A new tab titled Microsoft Cognitive Services opens in the browser. A navigation pane is shown with the following options with drop-down menus: Face, FaceList, LargeFaceList, etc. The Face option is expanded to show the following options: Detect, Find Similar, Group, etc. Detect is currently active. In the center pane, Face API - V1.0 heading is shown with a list of available regions. Next to it, an API definition button is present. [Video description ends]

And then we can see the API definition can then be downloaded either as a Swagger or a WADL file. The developers can use to learn about how to hook in to the API.

[Video description begins] He clicks the API definition button. It expands to show the following options: Swagger and WADL. [Video description ends]

And, as we go further down it has more of an explanation about how this works and how to formulate the request URL.


Azure Machine Learning Studio
  - You can use the Azure portal to create an Azure Machine Learning Studio workspace. 
    - The purpose of Machine Learning Studio, it being a web-based tool, is essentially data analysis, but it runs deeper than that. 
    - Always bear in mind that the source data that we use, that we're going to analyze needs to be trustworthy, and it needs to be accurate.
  - Although we do have some built-in functions that allow us to manipulate data, in other words, to transform the data
    - It's also important to note that there are sample data sets that we can use to learn how to use the Machine Learning Studio interface. 
      - Of course, we can also import our own data sets.
  - The purpose of machine learning in this context is to take vast amounts of data, and based on the factors that we define as being relevant and the training model that we apply to that data, we can then predict future trends or some kind of outcome as it might relate to financial credit risks. Or, as another example, the most likely income to be expected based on marital status, education, city, and many other potential factors, whatever happens to be in your data set that you specify as being relevant.

It might even relate to the healthcare side of things, such as heart disease prediction, given a number of factors. The process of working with a data experiment in Azure Machine Learning Studio begins with working with data. Whether it's sample data that's provided, or whether you import your own custom data. Bear in mind that there are also plenty of pre-defined templates.

There's a gallery that you can select from, that you can open up directly into Machine Learning Studio, so that you can begin working with these items and start to learn how to use the tool. The next thing to do once you've acquired data, or you decide you're going to use sample data, is to start applying functions such as maybe to transform the data into a specific manner, or maybe to exclude data that is not relevant, perhaps values that fall below a certain range.

You can also then apply learning algorithms based on what it is you're looking for in terms of an outcome. Finally, the last thing you would do is to run the data experiment and then visualize the outputs. Pictured on the screen, we can see the result of having created a Machine Learning Studio workspace object in Azure and then launching the Learning Studio.

[Video description begins] A screenshot of the Microsoft Azure Machine Learning Studio webpage is displayed on the screen. There is a side pane and a navigation pane. The navigation pane has a search bar for searching experiment items. It also has various other options, such as Saved Datasets, Data Format Conversions, Data Transformation, etc. The Data Transformation field is expanded to show the following options: Filter, Learning with Counts, Manipulation, Sample and Split, and Scale and Reduce. The Scale and Reduce field is expanded to show the following options: Clip Values, Group Data into Bins, and Normalize Data. The items in the experiment are shown in the center pane. A right pane is also present. It has two tabs: Properties and Project. Currently, the Properties tab is open. Under the option Clip Values, drop-down menus are present for the following fields: Set of thresholds, Upper threshold, Upper substitute value, etc. [Video description ends]

What you end up getting in the middle is a blank canvas. And then you can start dragging items from the left, such as data sets and you can add them into the canvas, but you can also then expand things like functions to manipulate your data. And, in this screenshot, the Data Transformation category has been opened up and the Clip Values item has been dragged over.

Now, when you drag something over and select it on the far right in the panel, you'll see details related to what's selected. In this case, for clipping peak values of a specific piece of data. Now, once you've done this, in the left hand-side of the screen in the navigator, you'll also be able to select different types of training models. And at the very bottom center, which you can't see in this screenshot, you'll have a Run Experiment button that you can use to actually run your experiment and then end up with some kind of predictive analysis as an outcome.

                    
Azure Firewall
The Azure Firewall is a managed service that, as the name implies, is used to control inbound and outbound traffic to and from Microsoft Azure. So it's set to block everything by default. But besides controlling in and outbound traffic to and from Azure, it gets associated with one or more subnets within an Azure VNet.

And we can even use other VNets besides the one where we deployed the Azure Firewall that connect in a hub and spoke fashion. Now when you deploy the Azure Firewall, you need to have a subnet called AzureFirewallSubnet within the VNet that you're deploying Azure Firewall into. Now you don't have to worry about having that done ahead of time. You can have it done ahead of time, or you can do that as you deploy the Azure Firewall.

The Azure Firewall has a static public IP address. This is unlike a network security group, or NSG, which can also be used in Azure to control in and outbound network traffic. So because the Azure Firewall has a static public IP address, then you could use that in conjunction with other firewalls elsewhere as a source, perhaps as a trusted location to receive traffic from.

Also we use rules of different types that we'll talk about to control the traffic flow. And again, something that makes the Azure Firewall different than a standard Azure network security group is that in an outbound direction it supports rules related to fully qualified domain names. So if I want to specifically allow a certain subset of URLs within a DNS domain, I can do that using the Azure Firewall.

The Azure Firewall also includes some threat intelligence capabilities that can not only alert on potential threats but also start denying traffic based on what's currently happening. Azure Firewall supports three different types of rules, one of which is called a NAT Rule to allow inbound access to resources deployed in Azure, either traffic stemming from your on-premises network or from somewhere else on the Internet.

So this is supported through TCP and UDP transport protocols. And it's referred to as Destination Network Address Translation, or DNAT. Where we've got a public IP address and port that is configured to map to an internal or private IP address import to allow traffic initiated from the outside in to Microsoft Azure. Each of the rules that we create within a collection has a priority value that determines the order of rule execution. And once there's a match with a rule then processing stops after that.

So, as I've mentioned, rules get placed into what's called a collection, so you can have more than one rule grouped together, for example, for Destination Network Address Translation, or DNAT. So pictured here, we can see a DNAT rule collection with the name of incoming, a priority of 100. And we've got one rule configured down below. Notice that the destination is the public IP address of the Azure Firewall.

And then further on the right, we can see the translated address and port which are what are used internally. Remember we've got a public IP address and port mapping to private IP address and port.

[Video description begins] A window titled Add NAT rule collection appears on the screen with certain data and Rules. The data displays: Name as Incoming, Priority as 100, Action as Destination Network Address Translation, which is abbreviated to DNAT. The Rules display: Name as Incoming HTTP, PROTOCOL as TCP , SOURCE ADDRESS as *, DESTINATION ADDRESS as 40.80.251.142, which is public IP of Azure Firewall, DESTINATION PORTS as 80, TRANSLATED ADDRESS as 10.1.1.1, and TRANSLATED PORT as 80. [Video description ends]

Next, we've got Azure Firewall network rules, which support TCP, UDP, ICMP, as well as any type of protocol, where we can specify the source and destination IP address, the destination port. And this is what you would normally use to allow communication or to control traffic flow between subnets. And it allows us to either configure an action of allowing the traffic or denying it.

Azure Firewall application rules are for outbound connectivity, which means from within Azure going out. And so we can specify Fully Qualified Domian Names, or FQDNs, including using wildcards. So we could specify star or asterisk dot somednsdomain.com or we can simply refer to everything with an asterisk. And we can specify the protocol and port, such as HTTPS:443, and we can either allow or deny.

Now bear in mind that the default configuration with Azure Firewall is things are denied. So if you want to allow specific access, if you want to make a white list of FQDNs, then you can certainly do that very easily. The last thing to mention is that you'll also need to build a route table Azure object that has the default route for a subnet going through the Azure firewall's private IP address for an outbound direction in the case of configuring application rules.


Configure Azure Firewall
In this demonstration, I'll be using the Azure portal to configure the Azure Firewall. The first thing we'll do is take a look at our existing configuration for virtual machines that will be affected by the Azure Firewall.

[Video description begins] The Homepage of Azure portal opens. The address bar shows: https://portal.azure.com/#home. The left navigation pane of the Homepage displays various links to resources and services, and the right pane of the Homepage displays icons to access various Azure services. [Video description ends]

So here in the portal, I'm going to click on the Virtual Machines view over on the left. Here I've got a virtual machine running, it's called eastwindowsvm1. And if we take a look at the networking for this, it's in a network called EastVnet1 and more specifically in a subnet within that vnet called EastSubnet1.

[Video description begins] He clicks Virtual machines on the left navigation pane of the Azure portal. A window titled Virtual machines default directory appears on the right pane. Virtual networks displays three networks in three rows. The details of the second row display: NAME as eastwindowsvm1, TYPE as Virtual Machine, STATUS as Running, RESOURCE GROUP as Rg1, LOCATION as Canada East, SUBSCRIPTION as Pay-As-You-Go. He clicks the second row. A window titled eastwindowsvm1 Virtual machines opens on the right pane. He clicks Networking under the Settings. The Network Interface and port rules display. Network interface displays as eastwindowsvm1758 and Virtual network/subnet displays as EastVnet1/EastSubnet1. He closes the window on the right pane. [Video description ends]

Now having said that, if I go to my jumpbox virtual machine, which is running, and click on it and look at the networking. It's in the same virtual network, EastVnet1, but in a different subnet, in this case EastSubnet2. Now a jumpbox is normally used as a point for remote administration from the outside. So I can make a connection from the Internet into the jumpbox, and from the jumpbox to other virtual machines on private networks.

[Video description begins] The window titled Virtual machines default directory appears on the right pane. Virtual networks displays three networks in three rows. The details of the third row display: NAME as JumpBox, TYPE as Virtual Machine, STATUS as Running, RESOURCE GROUP as Rg1, LOCATION as Canada East, SUBSCRIPTION as Pay-As-You-Go. He clicks the third row. A window titled JumpBox - Networking Virtual machines opens on the right pane. He clicks Networking under the Settings. The Network Interface details display: Network Interface as jumpbox568 and Virtual network/subnet as EastVnet1/EastSubnet2. [Video description ends]

So what I'm going to do then is take a look at my virtual network definition, because I've prepared something ahead of time. If I go into virtual networks on the left. And then if I open up one of my virtual networks here on the right, called EastVnet1. I've already created a subnet called AzureFirewallSubnet.

All one word, no spaces, and I've allocated it some address range that falls under the vnet range. Now you can either have this done ahead of time or you are prompted to create a new virtual network and a subnet with this name when you build the Azure Firewall, as you'll see pretty much now.

[Video description begins] He closes the window JumpBox - Networking. He clicks Virtual networks on the left navigation pane of the Azure portal. A window titled Virtual networks Default Directory appears on the right pane. Virtual networks displays four networks in four rows. The details of the first row are: NAME as EastVnet1, RESOURCE GROUP as Rg1, LOCATION as Canada East, SUBSCRIPTION as Pay-As-You-Go. He clicks the first row. A window titled EastVnet1 Virtual network opens on the right pane. He clicks Subnets under the Settings. Three subnets display in three rows on the right pane. He highlights the second row with the following details: NAME as AzureFirewallSubnet, ADDRESS RANGE as 10.1.5.0/24, and AVAILABLE ADDRESS as 251. [Video description ends]

So I'm going to click Create a resource in the upper left to begin building the firewall. I'm going to search for firewall. I'll select it from the list and I'll click Create. So I want to put this in an existing resource group I've already got created. And I'm going to call this Fw1 for firewall1, and in this case I'll put in the Canada East region and here's where you have the option to create a new virtual network or use an existing one.

Notice it wants to call it, the subnet at least within the Vnet, AzureFirewallSubnet. We've already done that. So if I were to choose Use existing, if I use existing Vnet, let's say I chose Vnet2 here. Notice it says you need to have a subnet called AzureFirewallSubnet. Well that Vnet doesn't but EastVnet1 does, and so I don't get that message any longer. Now remember that an Azure Firewall has a public IP address so it needs to create that resource. I'm going to call this Fw1PubIP and I'll click Review and create, it'll check.

[Video description begins] He clicks Create a resource on the left navigation pane of the Azure portal. A window titled New appears on the right pane. He types firewall in the search bar and clicks Firewall, which appears as the search result. A window titled Firewall Microsoft appears on the right pane. A section appears at the bottom of the window, which is titled Select a software plan, Firewall, Azure firewall is a managed cloud-based network security service that protects your Azure Virtual Network resources. He clicks the Create tab, below the section. A window titled Create a firewall appears on the right pane. It displays four tabs, Basic, Tags, review + create and requires certain details to be populated under each tab. Under the Basics tab, he enters the following details: Subscription as Pay-As-You-Go, Resource group as Rg1, Name as Fw1, Region as Canada East, Choose a virtual network as Use existing, Virtual network as EastVnet1 (Rg1), Public IP address as Fw1PubIP. He clicks Review + create. [Video description ends]

And once the validation has passed, I will click Create. So I'm in the midst of creating the firewall, and then we can see that the deployment is underway.

[Video description begins] A window appears on the right pane. It displays Create a firewall is in progress and then updates as Validation passed. The window also shows the summary of the data populated under Basics tab. He clicks the Create tab at the bottom of the window. A pop-up window appears on the top-right corner and displays: Submitting deployment. The pop-up updates that deployment is in progress. The window also shows: Your deployment is underway. [Video description ends]

While that's happening, I'm going to click Create a resource because what we need to create is a route table. Now we have to do this so we can direct any subnets that have resources that we want to go through our Azure Firewall, we need to define a route so that they are forced to so before traffic gets to the Internet.

Now that's going to be our example, the Azure Firewall also controls inbound traffic from the Internet. So I'm going to choose Route table and I'm going to click Create. And I'm going to call Fw1Rt1, firewall 1, router table 1. And I'll place this in an existing resource group. Same region or location, Canada East, and Create.

[Video description begins] He clicks Create a resource on the left navigation pane of the Azure portal. A window titled New appears on the right pane. He types route in the search bar and clicks Route table, which appears as the search result. A window titled Route table appears and he clicks the Create tab at the bottom of the window. A window titled Create route table appears on the right and requires certain details to be populated. He enters the following details: Name as Fw1Rt1, Subscription as Pay-As-You-Go, Resource group as Rg1, Location as Canada East, Virtual network gateway route propagation as Enabled. He clicks the Create tab at the bottom of the window. [Video description ends]

So we're going to have to do two things here. Number one, I'm going to have to create a route to the private IP address of my Azure Firewall. And I'm also going to have to associate the routing table with the subnet in question. Okay, looks like that resource deployment has succeeded. So let's just go to all resources here, I'll type rt and there it is, Firewall 1 Rt1, my routing table.

[Video description begins] A pop-up window appears on the top-right corner of the Homepage of the Azure portal. It displays that the deployment was successful. He closes the pop-up window. He clicks All resources on the left navigation pane of the Azure portal. A window titled All resources Default Directory appears on the right pane. He types rt in the search bar and a row displays as a search result. The details on the row display: NAME as Fw1Rt1, TYPE as Route table, RESOURCE GROUP as Rg1, LOCATION as Canada East, and SUBSCRIPTION as Pay-As-You-Go. He clicks the row and a window titled Fw1Rt1 Route table displays on the right pane. [Video description ends]

First thing that I'll do here is go to subnets and click Associate. I'm going to choose EastVnet1 and I'm interested in EastSubnet1. That's got virtual machines on it and my goal is to limit their access to specific Internet locations based on the FQDN. And those virtual machines are in EastSubnet1. So I want them affected by this routing table. So therefore I'm going to go ahead and click OK.

[Video description begins] He clicks Subnet under the Settings of Fw1Rt1 Route table window. He clicks the Associate Tab on the top of the window. The Associate subnet window displays two options to select from. The first is Virtual network and the second is Subnet. He clicks the first option. A list of four resources displays on the right. He clicks the first resource EastVnet1 canadaeast. A list of three subnets displays on the far right. He clicks the second subnet EastSubnet1 Rg1. He clicks OK on the bottom of the window. A pop-up window displays on the top-right corner of the right pane. It shows that route table is being saved for the subnet. [Video description ends]

Then, I need to create a route. Now, to do that, I need a private IP at the firewall. Let's see if the firewall is ready yet. So if I go to all resources and filter by fw, there is Fw1, but we don't have the private IP address yet. So let's give it a moment until it's completely initialized, then we'll copy the private IP because that needs to be in the routing table entry, as you will see in a moment. And after a minute, we have now have a private IP address for this firewall. So we're going to go ahead and copy that.

[Video description begins] He clicks Routes under the Settings of Fw1Rt1 - Routes window. He clicks All resources on the left navigation pane of the Azure portal. A window titled All resources Default Directory appears on the right pane. He types fw in the search bar and a list of three resources display in three rows. He clicks the first row with details: NAME as Fw1, TYPE as Firewall, RESOURCE GROUP as Rg1, LOCATION as Canada East, and SUBSCRIPTION as Pay-As-You-Go. A window titled Fw1 Firewall displays. The Private IP address 10.1.5.4 updates on the window. He clicks and copies the IP address. [Video description ends]

Now just for fun, let's go back to virtual networks for a moment and let's open up EastVnet1, and let's click Connected devices.

[Video description begins] He clicks Virtual networks on the left navigation pane of the Azure portal. A window titled Virtual Networks Default Directory appears on the right pane. A list of four virtual networks appear in four rows. He clicks the first row, which displays virtual network as EastVnet1. He clicks Connected devices under the Settings. [Video description ends]

So we can see that our firewall device, firewall 1 is connected to a subnet called AzureFirewallSubnet. We've got our jumpbox connected to EastSubnet2, we are going to reach into that jumpbox. And then from it we will connect to the private IP address for our Windows virtual machine running in EastSubnet2. So let's get back to our routing table and get this all figured out and working.

[Video description begins] A window titled EastVnet 1 - Connected devices opens with four devices displayed in four rows. He highlights the details of the first row: DEVICE as jumpbox568, TYPE as Network interface, IPADDRESS as 10.1.3.4, and SUBNET as EastSubnet2. He highlights the details of the second row: DEVICE as Fw1, TYPE as Firewall, IP ADDRESS as 10.1.5.4, and SUBNET as AzureFirewallSubnet. He highlights the details of the third row: DEVICE as eastwindowsvm1758, TYPE as Network interface, IP ADDRESS as 10.1.1.4, and SUBNET as EastSubnet1. He highlights the details of the first row: DEVICE as eastlinuxvm1764, TYPE as Network interface, IP ADDRESS as 10.1.1.5, and SUBNET as EastSubnet1. He closes the right pane. [Video description ends]

So I need to go to All resources. Filter it for rt, there's our routing table. We've already associated with EastSubnet1. And now I'm going to go to Routes and Add a route. I'm going to call this firewall1 default and the address prefix here for the default route is 0.0.0.0/0. The actual firewall is considered a virtual appliance in here, we're going to give it the private IP address. Then I'll click OK.

[Video description begins] He clicks All resources on the left navigation pane of the Azure portal. A window titled All resources Default Directory appears on the right pane. He types rt in the search bar and a resource Fw1Rt1 displays in a row. He clicks the row. A window titled Fw1Rt1 Route table displays. He clicks Subnets under the Settings. The subnet EastSubnet1 displays on the right pane. He clicks Routes under the Settings. A window titled Add route opens on the right pane. He clicks Add tab on the top of the window. A window titled Add route displays on the right pane and requires data to be populated. He enters the following details: Route name as Fw1Default, Address prefix as 0.0.0.0/0, Next hop type as Virtual appliance, and Next hop address as 10.1.5.4. He clicks OK at the bottom of the window. [Video description ends]

So now I've used remote desktop to RDP into my jumpbox and through it RDP to the private IP address of a Windows computer that is on a subnet affected by our default route to our firewall. And so what you are going to notice then on those machines, like if you go to the command prompt and if you try to ping something on the Internet, let's say www.google.com, you are not going to get a response back.

But you would from your jumpbox, of course, because it's reachable from the Internet. And so if I were to open a web browser here on this computer, and let's say I just try to go to cnn.com. Notice, I get an action of deny being shown here. No rule matched. And the default rule blocks connectivity. Okay, well, let's say I want to allow access to cnn.com. So I'm going to make an application rule that will allow that.

[Video description begins] He types the following command in the command prompt: ping www.google.com. No data displays as a result. He closes the command prompt. He opens the web browser Internet Explorer and types the following in the address bar: http://www.cnn.com/. He presses enter and the web page displays: Action Deny. No rules matched. Proceeding with default action. [Video description ends]

Back here in the Azure portal, in the All resources view, I'm going to filter for things that have fw in the name. And let see, firewall 1, Rules, Application rule collection, Add application rule collection. I'm going to call this AllowedEntertainment. If I can spell that correctly. I'm going to give it a rule priority. In this case, it's the only one I have, so 100. I want to allow, and the name here will be AllowHBO or CNN or whatever it is, in this case CNN. And let's say the source address is any, protocols and ports http,https, and the target FQDN will be star dot cnn.com and I'll click Add.

[Video description begins] He opens the Azure portal and clicks All resources on the left navigation pane. He types fw in the search bar on the right pane of the All resources window. Three resources display in three rows. He clicks Fw1 in the first row. A window titled Fw1 Firewall opens on the right pane. He clicks Rules under the Settings. Three tabs display on the right pane. He clicks the third tab Application rule collection. He clicks Add application rule collection, which displays below the three tabs. Add application rule collection window displays on the right pane, which requires some details. He enters the following details: Name as AllowedEntertainment, Priority as 100, Action as, Allow. He enters the following Target FQDNs details: NAME as AllowCNN, SOURCE ADDRESS as *, PROTOCOL PORT as http, https, Target FQDNS as *.cnn.com. He clicks Add tab at the bottom of the window. [Video description ends]

So once it's updated that firewall rule, I'm going to go back to that client station and retry the connection to cnn.com.

[Video description begins] The window titled Fw1 - Rules opens on the right pane of the Azure portal. A pop-up window displays on the top-right corner of the window. It displays that the firewall is being updated. [Video description ends]

And after a moment we can see we're able to pop up the web page because now that is listed as an allowed FQDN through our Azure Firewall. Although if I try to go to other sites here, like I've tried to go to google.com, again, I get an action of deny and I don't get access to the webpage.

[Video description begins] He opens the CNN website http://www.cnn.com/ on Internet Explorer. The web page opens successfully. He opens the Google website http://www.google.com/ The web page displays: Action Deny. No rules matched. Proceeding with default action. [Video description ends]

Azure DDoS Mitigation

[Video description begins] Topic Title: Azure DDoS Mitigation. Your host for the session is Dan Lachance. Screen Title: Azure DDoS Mitigation Distributed Denial of Service is abbreviated to: DDoS. [Video description ends]

A distributed denial of service attack is executed by an attacker, pictured here at the top of the diagram, who has control of a multitude of infected machines. Now, these machines would have been infected perhaps by tricking users into following links to websites that contain malicious code. Or email messages that have infected file attachments, and the like. Now the idea is that the attacker has control of all of these machines. These machines are called zombies or bots.

And they are organized into what is referred to as a botnet, a collection of computers under the control of an attacker. And often, if you actually search around the dark web, you will come across sites where these are for sale. You can rent the use of a botnet to execute a DDoS attack against, for example, a website or even a competitor to make their web application unavailable. Or even if you're a malicious person, to demand ransom. So highly illegal. However, it does exist and it's a reality.

And so we need to be able to mitigate this. So the attacker controls all of these bots organized into a botnet, which can render a website or an application useless for legitimate traffic. Now what can we do about this? Well, with a distributed denial of service attack, basic protection is automatically enabled for you in Microsoft Azure. And there's no additional cost, but what does that mean?

Well, why don't we compare basic with standard, which does have a cost associated with it. You configure standard DDoS mitigation protection in the properties of an Azure virtual network, when you're in the properties blade.

[Video description begins] Virtual network is abbreviated to: VNet. [Video description ends]

So what happens then, is that based on the resources deployed in that Azure VNet, Microsoft Azure will tune protection against DDoS attacks against those resources. And you also get alerts when DDoS attacks appear to be occurring against some of your deployed resources In those VNets.

Network Security Groups

[Video description begins] Topic Title: Network Security Groups. Your host for the session is Dan Lachance. [Video description ends]

Azure network security groups, or NSGs, are resources in Azure that get associated with other resources like NICs, network interface cards, used by virtual machines, or subnets.

[Video description begins] Network Interface Cards is abbreviated to: NICs. [Video description ends]

And so we're talking about inbound network security rules to control traffic coming into Azure, or even traffic leaving Azure in an outbound direction. But that inbound and outbound protection is associated at the NIC level for a specific virtual machine or, a little bit more generally, at the subnet level. So certainly, if you've got a subnet with a bunch of Linux machines that you want to be able to administer, you might allow inbound SSH, either to one jump box or to all of them.

And so you could do that through a network security group associated with the subnet. However, when it comes to associating network security groups with things like network interface cards used by DMs, bear in mind that only one network security group can be associated with a network interface card.

[Video description begins] Network Security Groups is abbreviated to: NSGs. [Video description ends]

Azure network security groups support Allow as well as Deny actions, depending on what your requirements are. There are also a series of default rules to allow things like load balancing, to allow Inter-VNet communication. And of course, incoming Internet traffic initiated from the Internet is blocked by default. Outbound Internet traffic, however, is allowed by default.

When you use the portal to create a network security group, or an NSG, it's going to look something like this. Specifically, this is a rule being created within the NSG, where at the top we specify the Source, in this case it's IP Addresses. We can control either a specific IP address or a range of IP addresses. We can specify a source port range or just a single port from which the traffic is initiated from. And then we have to specify the Destination, because this is an inbound rule. In this case, it could be a virtual network, it could be a specific virtual machine IP address. And, of course, we can see here the Destination port of 80.

We can specify the Protocol as being TCP, UDP, or Any. And then, of course, we determine whether we want to Allow or Deny this traffic, in this case we are allowing it. The Priority value is relative to other items. Here we've got a Priority for 100 in this rule. If we have another rule with a priority of 300, well this rule will get checked first, and if there's a match with the incoming traffic, rule processing stops. Otherwise, it would continue on to the next rule with a priority of 300. And then, of course, we have a name that we can assign to the rule.

[Video description begins] A window titled Add inbound security rule NSG1 appears. It shows Basic information that needs to be populated. The data shows: Source as IP Addresses, Source IP addresses/CIDR ranges as 199.126.129.55, Source port ranges as *, Destination as VirtualNetwork, Destination port ranges as 80, Protocol as TCP, Action as Allow, Priority as 100 and Name as Port_80. [Video description ends]

Here we can see a number of inbound security rules listed together for a network security group. We can see the first rule, PRIORITY 100, is the rule we just looked at a moment ago for port 80. So because that has the smallest priority number, at least value-wise numerically, it gets checked first. And on the far right, you can see the ACTION is to Allow it if incoming traffic matches those conditions.

The next three, the last three also, are default rules, and I can click the Default rules button pictured here in the screenshot to hide them if I don't want to see them. But allowing inbound VNet traffic and load balancing is allowed by default. But after that, notice the last rule at the bottom is to DenyAllInbound traffic if there is not a match from above.

[Video description begins] The screen displays a screenshot of inbound security rules. The screenshot shows a table with seven columns and five rows. Above the table, two tabs display: Add and Default rules. The first row of the table displays the title of seven columns as: PRIORITY, NAME, PORT, PROTOCOL, SOURCE, DESTINATION, and ACTION. The second row displays 100, Port_80, 80, TCP, 199.126.129.55, VirtualNetwork, Allow as values for each column. The third row displays 65000, AllowVnetInBound, Any, Any, VirtualNetwork, VirtualNetwork, Allow as values for each column. The fourth row displays 65001, AllowAzureLoadBalancerInBound, Any, Any, AzureLoadBalancer, Any, Allow as values for each column. The fifth row displays 65500, DenyAllInBound, Any, Any, Any, Any, Deny as values for each column. [Video description ends]

Network security groups in Azure can be managed using the Azure portal GUI, or using PowerShell cmdlets such as New-AzNetworkSecurityGroup, Get-AzNetworkSecurityGroup to retrieve a list of them. We can remove a security group with Remove-AzNetworkSecurityGroup.

However, there are also PowerShell cmdlets to manage the rules within the network security group. At the CLI level, we can use az network nsg create, naturally to create the network security group. We can list them, and of course we can delete them using the appropriate syntax.

Network Security Group GUI Management

[Video description begins] Topic Title: Network Security Group GUI Management. Your host for the session is Dan Lachance. [Video description ends]

In this demonstration, I will use the Azure portal to create and configure a network security group. In Azure, network security groups are often simply referred to as NSGs and they are used to control traffic into and out of VNet subnets.

[Video description begins] The Homepage of Azure portal opens. The address bar shows: https://portal.azure.com/#home. The left navigation pane of the Homepage displays various links to resources and services, and the right pane of the Homepage displays icons to access various Azure services. [Video description ends]

So to go ahead and get started here, let's take a look at an existing configuration and then we'll build a new one. So here in the portal, I'll start by clicking on Virtual networks over on the left, and I'm going to click on one of my existing virtual networks to pull up its properties blade. Now the first thing I want to do here is look at the subnet affiliation or

[Video description begins] He clicks Virtual networks on the left navigation pane of the Azure portal. A window titled Virtual networks appear on the right pane. Virtual networks displays two networks in two rows. The details of the first row display: Name as EastVnet1, Resource GROUP as RG1, LOCATION as Canada East, and SUBSCRIPTION as Pay-As-You-Go. The details of the second row display: Name as EastVnet2, Resource GROUP as Rg1, LOCATION as Canada East, and SUBSCRIPTION as Pay-As-You-Go. He clicks the first row. [Video description ends]

association to the selected VNet. And on the right, we can see that we've got a number of subnets such as EastSubnet1, for example, that is associated with this virtual network. And notice under the SECURITY GROUP column, we can see the network security group associated with that particular subnet, in this case, NSG1. So therefore, if I go to All resources and

[Video description begins] He clicks Subnets on the left navigation pane of the Azure portal. A window titled EastVnet1 - Subnets Virtual network appears on the right pane. Three rows display three subnets. He highlights the last row. The data displays: NAME as EastSubnet1, ADDRESS NAME as 10.1.1.0/24, AVAILABLE ADDRESS as 249, DEDICATED TO as blank, and SECURITY GROUP as NSG1. [Video description ends]

if I were to filter by NSG, among other things, we will certainly see NSG1, the network security group we were just talking about.

[Video description begins] He clicks All resources on the left navigation pane of Azure portal. A window titled All resources appears on the right pane with various links. He types nsg in the search bar placed above the links of all the resources. Three resources display in three rows as the result of the search. The third row displays data: NAME as NSG1, TYPE as Network security group, RESOURCE GROUP as Rg1, LOCATION as Canada East, and SUBSCRIPTION as Pay-As-You-Go. He clicks the last row. [Video description ends]

And if I go ahead and click on that to pull up its properties blade, it has a set of inbound security rules to control traffic into, in this particular case, the way it's being used, the subnet, and also outbound security rules. Now when I go to both inbound and outbound security rules, I can hide the built in default rules, which, if you look at their priority values fall towards the bottom of the list of rules.

The rules are matched against, in this case, incoming traffic starting at the very top based on the priority, and then going further down to the next priority value and so on and so forth. When there is a match, rule processing starts. And so that is also true when it comes to outbound security rules.

[Video description begins] The screen displays NSG1 network security group on the right pane of the portal. The right pane displays NSG1 properties and other links. He clicks Inbound security rules under Settings. A table with seven columns and six rows displays on the right. He clicks Outbound security rules under Settings. A table with seven columns and four rows displays on the right. He clicks Inbound security rules again. He clicks Default rules tab placed above the rows. This hides the default value rules and displays only three rows. He clicks the Default rules tab again and all the seven rows display. He highlights the first column of the table, which shows the PRIORITY as 1000, 1010, 65000, 65001, and 65500. He clicks Outbound security rules and closes the window. [Video description ends]

Now let's just go look at our virtual machines. If I were to pop up the properties blade of a virtual machine, and if we were to click on Networking, we would also see the VNet and the subnet association, but also the network security group. So notice here that we've got NSG1, that's network security group 1, attached to a subnet, and we can see that the rules are showing up in here. But also notice that if the virtual machine were running, we'd be able to click Effective Security Rules so that we would be able to see all of the rules in effect if we've got more than one particular security group. Because you might have a network security group associated to a virtual machine specifically.

[Video description begins] He clicks Virtual machines on the left navigation pane of the Azure portal. A window titled Virtual machines Default Directory displays on the right pane. The window displays three rows with three virtual machines. He clicks the second row, which displays: NAME as eastwindowsvm1, TYPE as Virtual machine, STATUS as Stopped, LOCATION as Canada East, and Subscription as Pay-As-You-Go. A window titled eastwindowsvm1 virtual machine opens on the right pane. He clicks Networking under Settings. The right pane displays: Network Interface as eastwindowsvm1758, Virtual network/subnet as Eastvnet1/EastSubnet1, and network security group as NSG1 (attached to subnet: EastSubnet1). A table also displays inbound and outbound port rules on the same window. He clicks Effective security rules on the top of the window. A window titled eastwindowsvn1758 - Effective security rules opens on the right pane, which displays all the effective inbound and outbound rules. [Video description ends]

So I'm going to go to the Create a resource button in the upper left, and here under the Networking section, I'm actually going to create a network security group. Now when I do that, I have to come up with a name for it. So if this is going to be, let's say for the Windows environment for an application, specifically, that has many resources like a back end database, some virtual machines, a load balancer and what not, maybe I would call this, WebApp1_ NSG, if it's for that purpose. Then I have to deploy it into either an existing resource group or create new resource group, specify the location, and then I simply click Create.

[Video description begins] He clicks Create a resource on the left navigation pane of the Azure portal. A window titled New appears on the right pane. Under the Azure Marketplace section, he clicks Networking and then clicks Network security group. A window titled Create network security group opens. He populates the required data: Name as WebApp1_NSG, Subscription as Pay-As-You-Go, Resource group as Rg1, and Location as Canada East. He clicks the Create tab at the bottom of the window. [Video description ends]

But that's not the end of the story with network security groups, though of course, because they need in and outbound rules configured appropriately so that they can be used. And then, of course, they need to be associated with things like subnets so they're actually effective.

So if I go to All resources here, let's just look or filter for NSG, here's WebApp1 NSG, so I'm just going to go ahead and click on that. So for inbound security rules, we've got the default rules, because if I hide them we see nothing. Same with the outbound rules, we've got the default rules.

[Video description begins] He clicks All resources on the left navigation pane of the Azure portal. A window titled All resources appears on the right pane. He types nsg in the search bar and four network security groups display in four rows, as a search result. He clicks the last row WebApp1_NSG. A window titled WebApp1_NSG Network security group opens on the right pane. He clicks Inbound security rules under Settings and a list of three rules displays in three rows. He clicks Default rules tab placed above the rows. This hides the default value rules and it does not display any row. He clicks Outbound security rules under Settings and a list of three rules displays in three rules. He clicks Default rules tab placed above the rows. This hides the default value rules and it does not display any row. [Video description ends]

However, I want to add a rule to allow inbound traffic. So because this is for a web app, I'm going to click Add to add a rule. The source will be Any. I can specify Source port range on the request, and I can also specify a destination of Any. Or I could specify an IP Address if I know, for instance, I've got a fixed IP address, a static, unchanging IP address, that I'm using for a virtual machine, that I can pop that in here.

If I know that the destination port is 443, it's an HTTPS connection type of application only, I know that's happening over TCP port 443, and I want to allow it. And again, I've got a priority value here and I need to give it a name. How about we call this AllowinboundHTTPS, and then I'll click Add.

[Video description begins] He clicks Inbound security rules under the Settings of WebApp1_NSG - Inbound security rules window. He clicks Add on the right pane of the window. A window titled Add inbound security rule opens on the right. He enters the following details: Source as Any, Source port ranges as *, Destination as IP Addresses, Destination IP addresses/CIDR ranges as 10.1.1.5, Destination port ranges as 443, Protocol as TCP, Action as Allow, Priority as 100, and Name as AllowInboundHTTPS. He clicks the Add tab at the bottom of the window. [Video description ends]

So once we've added the security rule or security rules to our liking, we're then ready to make this effective by associating this network security group with something, and those somethings could include, as we know, a subnet. If I go to Subnets, I can click Associate and I can choose, first, a virtual network and then choose the appropriate subnet to which I want that applied.

[Video description begins] He clicks Subnets under the Settings of WebApp1_NSG - Subnets window. He clicks the Associate tab on the right pane. A window titled Associate subnet WebApp1_NSG opens and displays two options to choose from: Virtual network and Subnet. He clicks the Virtual network option. A window titled Choose virtual network opens on the right. It displays EastVnet1 Rg1 and EastVnet2 rg1. He clicks EastVnet1. It displays three options under Choose subnet on far right. He clicks the second option EastSubnet 2 Rg1. A window titled Associate WebApp1_NSG opens with two options: Virtual network EastVnet1 and Subnet EastSubnet2. He clicks OK at the bottom of the window. [Video description ends]

However, I'm going to exit out of there because we can also associate this with a network interface that's tied to a virtual machine. So we could have a network security group for an entire subnet, but there are times when you might have a single virtual machine which is linked to a network interface that has specific in or outbound network traffic security rule requirements. And so in that case, you could associate your network security group with a specific network interface.

[Video description begins] He closes the Associate subnet window. He clicks Network interfaces under the Settings of WebApp1_NSG - Network interfaces window. He clicks the Associate tab on the right pane of the window. Associate network interface window opens on the right pane and displays jumpbox568 Rg1 network interface. He clicks jumpbox568 Rg1 and a pop-up window appears on the top-right corner of the right pane. It displays that the network interface is being saved. [Video description ends]

Network Security Group CLI Management

[Video description begins] Topic Title: Network Security Group CLI Management. Your host for the session is Dan Lachance. [Video description ends]

In this demonstration, I will create a network security group using the Azure CLI. I've downloaded and installed the Azure CLI and I've already run the az login command to authenticate to Azure. So at this point, I'm going to run az space network space nsg, for network security group, create. And from here, if I do --help, I'll learn about the syntax related to the creation of a network security group.

[Video description begins] A Command Prompt opens. He types and executes the following command in Command Prompt: az network nsg create --help. He presses enter and the screen displays various commands. He types and executes the following command: cls. A clear screen displays. [Video description ends]

However, I'm going to go ahead and bring up that command using my up arrow key and just modify it by removing --help. I'm going to use -g, I'm going to tie this network security group or deploy it into a resource group, and I'm going to call it, with -n for name, Windows_NSG. So assuming I need a network security group to control traffic into and out of Windows virtual machines, this will be a good name.

I'm going to go ahead and just do that. Once that's finished, of course, I can also get a list of virtual networks. So we can see it looks like it created our Windows_NSG, network security group.

[Video description begins] He types and executes the following command in Command Prompt: az network nsg create -g Rg1 -n Windows_NSG. He presses enter and the screen displays various commands. [Video description ends]

And at any point in time I could run az space network space nsg space list. Now I get the same kind of thing back.

[Video description begins] He types and executes the following command: cls. A clear screen displays. He types and executes the following command in Command Prompt: az network nsg list. He presses enter and the screen displays various commands. [Video description ends]

What I could do is also run that command, but pipe the result to the find command and tell it to look for name. Now I'm also going to get the names of rules within the network security groups. But at least we can see we have less to look at, and indeed, our Windows Network Security Group lives on.

[Video description begins] He types and executes the following command: cls. A clear screen displays. He types and executes the following command in Command Prompt: az network nsg list | find "name". He presses enter and the screen displays various commands. He highlights the following command: "name" "Windows_NSG" in the last command line of the Command Prompt. [Video description ends]

So, the next thing we're going to do is create a rule within that network security group to control traffic. So I'm going to run az space network space nsg space rule space create. And this is going to be for a resource group of Rg1 --nsg-name, in this case is Windows_NSG. I'll set the priority, let's say, for this rule to value of 200, which is relative to the other rules to control the execution.

And I'll use --source-address-prefixes anywhere, so asterisk, --destination-address-prefixes, same thing, going anywhere. And then I can specify also the destination port information. So, --destination-port-ranges. And in this case I want to make an allowance for port 443 --direction is going to be inbound because network security groups can also control traffic going out. -- access, we can either allow or deny, in this case, allow, the protocol, -- protocol, is tcp. And finally, let's give this thing a name.

How about AllowInboundHTTPS. And then I'll go ahead and press Enter on the assumption that everything was typed in correctly. Okay, it looks good.

[Video description begins] He types and executes the following command: cls. A clear screen displays. He types and executes the following command in Command Prompt: az network nsg rule create -g Rg1 -- nsg-name Windows_NSG --priority 200 --source-address-prefixes * --destination-address-prefixes * --destination-port-ranges 443 --direction inbound --access Allow --protocol tcp --name "AllowInboundHTTPS" . He presses enter and the screen displays various commands. [Video description ends]

Let's just do this, let's clear the screen. az space network nsg rule space list and --resource-group Rg1, and what's the name of our security group? --nsg-name, it's Windows_NSG, and we can press Enter, and we have a typo. Well, that's because we have az newtork when really it should be az network. A little dyslexic here, there we go.

[Video description begins] He types and executes the following command: cls. A clear screen displays. He types and executes the following command in Command Prompt: az network nsg rule list --resource-group Rg1 --nsg - name Windows_NSG. He presses enter and the screen displays various commands. [Video description ends]

So we got the same kind of output that we got when we created that rule. And we can see the destinationPortRange indeed is for port 443, and that this is for an Inbound direction and we're allowing that traffic.

[Video description begins] He highlights the following commands: "destinationPortRange": "443", "direction": "Inbound", "access": "Allow",. [Video description ends]

Network Security Group PowerShell Management

[Video description begins] Topic Title: Network Security Group PowerShell Management. Your host for the session is Dan Lachance. [Video description ends]

You can also use PowerShell to create and manage network security groups in Azure. Here I've already got a PowerShell script that I've opened up in the PowerShell ISE, the integrated scripting environment. The first command is Get-AzNetworkSecurityGroup. So having my cursor blinking on line 1 where that command exists, I'm going to click the Run Selection button. And this is going to list back, of course, the Azure network security groups and the details that go along with each of them as we can see.

[Video description begins] A window titled Windows PowerShell ISE displays. The window is divided into two sections. The first section displays commands and the second section below that displays codes. He highlights and executes the following command in the first line of command: Get-AzNetworkSecurityGroup. The cursor blinks after the command. He clicks the Run Selection button on the toolbar. The second section of the window displays various codes. [Video description ends]

However, in line 3 I'm filtering it out and only showing the name. So I'm piping it to the select alias in PowerShell, and telling it that the only prop I'm interested in is name. So let's go ahead and run that line, and see how the output differs. That is much cleaner looking, because now we see only the names of the network security groups as opposed to all of the details for each and every one of those network security groups.

[Video description begins] He highlights and executes the following command in the third line of command: Get-AzNetworkSecurityGroup | select name. The cursor blinks after the command. He clicks the Run Selection button on the toolbar. The second section of the windows displays: Name, eastlinuxvml-nsg, eastwindowsvml-nsg, NSG1, WebApp1_NSG, Windows_NSG. The section also displays other details of network security groups. [Video description ends]

So to build a new network security group we would use the New-AzNetworkSecurityGroup cmdlet. Where we have to specify a name,- name, we deploy it into a resource group, so I use -resourcegroupname for that, and then we specify the Azure region. Now I'm going to go ahead and run that line, so I'm going to select it and I'm going to run the selection. So after a moment we'll see that we've got a new network security group here.

[Video description begins] He types and executes the following command in the second section of the window: cls. He highlights and executes the following command in the fifth line of command in the first section: New-AzNetworkSecurityGroup - name Linux_NSG -resourcegroupname RG1 -location canadaeast. He selects the fifth line of command and clicks the Run Selection button on the toolbar. The second section of the windows displays data associated with new network security group. [Video description ends]

Let's clear the screen down here in PowerShell, why don't we run that command again where we just select by name. So how about we do that, let's just clear this up and let's see what we get returned here. What we're looking for is that we've got our Linux NSG or network security group that exist. And indeed it is returned from that PowerShell cmdlet,

[Video description begins] He types and executes the following command in the second section of the window: cls. He highlights and executes the following command in the third line of command in the first section: Get-AzNetworkSecurityGroup | select name. He clicks the Run Selection button on the toolbar. The second section of the windows displays: Name, eastlinuxvml-nsg, eastwindowsvml-nsg, Linux_NSG, NSG1, WebApp1_NSG, Windows_NSG. [Video description ends]

so, what are we doing in line 7? Well, I'm using the back tick character so that I can have this wrap across three lines, it's really one big statement. What we're doing here is we're running Get-AzNetworkSecurityGroup and I'm calling it by name. I want to get the Linux network security group, and here's the resource group it's in.

And then, once we have a handle on that object, we are piping that output to the Add-AzNetworkSecurityRuleConfig cmdlet. And we're adding a rule that's called AllowSSH, so we're allowing access that's destined from an inbound direction for TCP port 22, as we see way down here. We can see all the other details like the priority, the sourceaddressprefix, and in this case from anywhere, *the sourceportrange*, destinationaddressprefix*.

Having done that, that's the middle command as we can see selected here. Then we take the result of that and we pipe it to Set-AzNetworkSecurityGroup, so we can write the settings to the security group that we got from the beginning of the command. Does that make sense? We get the network security group, get a handle on it, add a rule and then write it using the Set-AzNetworkSecurityGroup cmdlet.

[Video description begins] He highlights and executes the following command in the seventh line of command: Get-AzNetworkSecurityGroup -name linux_nsg -resourcegroupname rg1 | Add-AzNetworkSecurityRuleConfig `. He highlights and executes the following command in the eighth line of command: -name AllowSSH -access allow -protocol tcp -direction inbound -priority 220 -sourceaddressprefix * `. He highlights and executes the following command in the ninth line of command: -sourceportrange * -destinationaddressprefix * -destinationportrange 22 | Set-AzNetworkSecurityGroup. [Video description ends]

So, let's make sure we execute lines 7, 8, 9 here as one expression. So I'm going to select them and I will click the Run Selection button. And after a moment, it looks like it ran. Why don't we do this? Why don't we go into the Azure portal and check our work in this particular example just for fun.

[Video description begins] He selects the seventh, eighth, and ninth line of command and clicks the Run Selection button on the toolbar. The second section of the windows displays various codes. [Video description ends]

So here in the portal I'm in the All resources view, why don't we filter it for things that have NSG in the name. There's the Linux network security group, and if you look at our inbound security rules, there is the AllowSSH with the priority of 220, port 22, and so on, and of course it is allowed. So there you have it, it's pretty easy to work with network security groups using Microsoft PowerShell.

[Video description begins] The Azure portal displays. He clicks All resources on the left navigation pane. The links to All resources display on the right pane. He types nsg in the search bar placed above the links of all the resources. Six resources display in six rows, as the search result. He clicks Linux_NSG on the third row. Linux_NSG network security group opens on the right pane. He clicks Inbound security rules under Settings. A table with five rows and seven columns displays. He highlights the first row, which shows the following data: PRIORITY as 220, NAME as AllowSSH, Port as 22, PROTOCOL as TCP, SOURCE as Any, DESTINATION as Any, and ACTION as Allow. [Video description ends]

Configure a VM Jump Box

[Video description begins] Topic Title: Configure a VM Jump Box. Your host for the session is Dan Lachance. [Video description ends]

In this demonstration, I'm going to create a jump box. A jump box is a machine that you can connect to. For example, from the Internet if you're working on premises, so that you have access into the Azure cloud. And from the jump box you can then make remote connections to other internal Azure resources. Like other virtual machines that might not be publicly accessible directly.

[Video description begins] The Homepage of Azure portal displays. The address bar shows: https://portal.azure.com/#home. The left navigation pane of the Homepage displays various links to resources and services, and the right pane of the Homepage displays icons to access various Azure services. [Video description ends]

And so to get started, really we're talking about creating a virtual machine. So I'm going to click Create a resource in the upper left here in the portal, it's going to be Windows Server 2016 Datacenter. And I will deploy this into an existing resource group. We're going to call this JumpBox, and I'm going to go ahead and deploy this into a specific Azure region of my choosing.

And I'll fill in the Username and Password information. And then I'll click Next, I'm going to accept the disks. And for networking this is going to go and do a virtual network called EastVnet. And specifically I'm going to put this in a subnet, let's say, called EastSubnet1, and it's going to make a new public IP.

So that's fine, let's let it create that, because I need a public IP to get to the jump box. And from the jump box we get to other internal resources that might not have a public IP. So I'm okay with this. I'm just going to basically go through the wizard. I'm okay with everything here. Let's make sure validation is passed.

[Video description begins] He clicks Create a resource on the left navigation pane of the Azure portal. A window titled New displays on the right pane. It displays various links. He clicks Windows Server 2016 Datacenter Quickstart tutorial. A window titled Create a virtual machine displays on the right pane. It displays seven tabs: Basics, Disks, Networking, Management Advanced, Tags, and Review + create. He clicks the Basics tab. The tab displays various details, which need to be populated to create a virtual machine. He selects and types the following details: Subscription as Pay-As-You-Go, Resource group as Rg1, Virtual machine group as JumpBox, Region as Canada East, Availability options as No infrastructure redundancy required, Image as Windows Server 2016 Datacenter, and size as Standard DS1 v2. He types his username and password and clicks the Next: Disks > tab at the bottom of the window. The Disks tab displays. The OS disk type displays as Premium SSD. He clicks Next: Networking > tab at the bottom of the window. The Networking tab displays. He enters the following data: Virtual network as EastVnet1, Subnet as EastSubnet1 (10.1.1.0/24), Public IP as (new) JumpBox-ip, NIC network security group as None, and Accelerated networking as Off. He clicks Next: Management > tab at the bottom of the window. He clicks the Advanced, Tags and Review + Create tabs also. [Video description ends]

And it is, so I'm going to create this virtual machine. Now, while that's happening, if I go look at my other virtual machines. I've got one here called eastwindowsvm1, and it's got a private IP allocated but not a public IP. And this virtual machine is actually in the midst of being started. Let's just go back here and do a refresh now. And in a moment, we'll see that it's actually up and running.

[Video description begins] The Create a virtual machine window on the right pane displays Validation passed. He clicks the Create tab at the bottom of the window. A pop-up window shows that the deployment is in progress. He clicks Virtual machine on the left navigation pane of the Azure portal. A window titled Virtual machine opens on the right pane and displays three virtual machines in three rows. He clicks the second virtual machine eastwindowsvm1 on the second row. A window titled eastwindowsvm1 Virtual machine opens on the right pane. The window displays Private IP Public Address but not the Public IP address. He clicks Virtual machine on the left navigation pane of the Azure portal. A window titled Virtual machine opens on the right pane and displays three virtual machines in three rows. He clicks Refresh tab displayed above the rows. The Status of the virtual machines eastwindowsvm1 and JumpBox, displayed on the second and third row gets updated to Running. [Video description ends]

And after a few moments, we can see that the two virtual machines are up and running. Again, we've got a virtual machine here that does not have a public IP, but it does have a private one. But that's not our JumpBox. Our JumpBox, if I click on it, in fact does have a public IP address.

Let's start by using the Remote Desktop client here on premises to connect into the jump box. Okay, so I've popped in the public IP address that I copied from the jump box virtual machine in Azure. So I'll paste that in here, I'm going to click on Connect. And when I put in the credentials and click OK, I'll just get this certificate message. I'm going to trust this certificate and tell it not to ask me again every time I connect, and I'll choose Yes. So we're making an inbound connection from on-premises through

[Video description begins] The window titled Virtual machines displays on the right pane. He clicks the second virtual machine eastwindowsvm1 on the second row. The Public IP address is still not displayed. He clicks the third virtual machine JumpBox on the third row. The window tilted JumpBox displays the Public IP address as 52.235.38.242. He clicks and copies the Public IP address. A pop-up window titled Remote Desktop Connection displays. He types Computer as 52.235.38.242 and clicks Connect. Another pop-up window titled Windows Security displays. He enters the credentials and clicks OK. A security warning displays on the window. He clicks the Yes tab. A pop-up titled Remote Desktop Connection displays, which shows the connection is being established to 52.235.38.242. [Video description ends]

the Internet into our jump box Windows virtual machine in the Azure cloud. Now, let me just go ahead and minimize that Remote Desktop window. Because what we want to do is now make a connection to this virtual machine eastwindowsvm1. Which, of course, as we know, if we go to overview, let's say, it does not have a public IP but it does have a private one. So I'm going to copy that private address, 10.1.1.4. Let's go back to our Remote Desktop session in our jump box.

[Video description begins] A window titled Virtual machines displays on the right pane of the Azure portal. The window displays three virtual machines in three rows. He clicks the second row: eastwindowsvm1. A window titled eastwindowsvm1- Networking displays on the pane. He clicks Overview. The right pane displays the Private IP address as 10.1.1.4, however, does not display the Public IP address. He clicks and copies the Private IP address. [Video description ends]

So now within here, I'm just going to go to my Start Menu and we're going to go ahead and fire up the Remote Desktop client. So from the jump box we're making a connection to other Azure host. In this case, using the private IP, in this case 10.1.1.4, which was our example, 1.1.4. And I'll click Connect. And of course it wants the credentials so I'll go ahead and supply that including the password.

And then after a moment we'll be prompted to trust a certificate for that connection to secure that network transmission. And now we can see that we are one level deeper, we are now connected to an internal Azure virtual machine, that itself, does not have a public IP. But rather, we got to it by going through a jump box. Now, the jump box itself does not have to be on the same subnet.

[Video description begins] He clicks Start menu on his computer and opens the Remote Desktop Connection. A pop-up window titled Remote Desktop Connection displays. He types the Private IP address as 10.1.1.4 and clicks the Connect tab on the pop-up window. Another pop-up window displays, which requires credentials to connect. He types the credentials and clicks the OK tab on the pop-up window. A security certificate appears and he clicks the Yes tab. The connection gets established. [Video description ends]

Back here in the Azure portal, if I open up EastVnet1 and look at the connected devices, we can see our Windows virtual machine and our jump box which are both on the same subnet. Now, that may or may not meet your security needs, we easily could have put our jump box on a different subnet in a different range.

And it would still be able to make a connection to the private IP of our Windows virtual machine. And sometimes because the jump box is publicly accessible, you might want to put it on its own subnet for isolation purposes, but it's not a requirement.

[Video description begins] A window titled eastwindowsvm1 Virtual machines displays on the right pane of the Azure portal. He clicks Activity log and a window titled Virtual networks displays on the right pane. The window displays two virtual machines in two rows. He clicks EastVnet1 on the first row. A window titled EastVnet1 Virtual network displays on the right pane. He clicks Connected devices under Settings and the right pane displays the following three network interfaces in three rows: eastwindowsvm1758 with IP address 10.1.1.4 , eastlinuxvm1764 with IP address 10.1.1.5, and jumpbox240 with IP address 10.1.1.6. [Video description ends]

Just-in-Time VM Access

[Video description begins] Topic Title: Just-in-Time VM Access. Your host for the session is Dan Lachance. [Video description ends]

Configuring a virtual machine in Azure with just in time access can further harden virtual machines. This is because instead of always allowing, for instance, inbound remote management traffic, then what we could do is only enable that as it's needed and then turn it off when remote management is complete. Instead of always leaving a port open, for example, through an inbound rule in a network security group. So here in the portal, I've got a list of virtual machines, one of which I will click on, it's called JumpBox.

[Video description begins] The Virtual Machines page of the Azure portal opens. The left navigation pane of the portal displays various links to resources and services, and the right pane displays details of three virtual machines in three rows. He clicks the last row. The details of the virtual machine are: NAME as JumpBox, TYPE as Virtual machine, STATUS as Running, RESOURCE GROUP as Rg1, LOCATION as Canada East, SUBSCRIPTION as Pay-As-You-Go. A window titled JumpBox opens on the right pane. [Video description ends]

And in here I am going to go to the configuration part of the properties blade, where I can enable just-in-time-access, so I'm going to go ahead and do that. Now when you enable that on a virtual machine, you can then open the Azure Security Center from that provided link or just by clicking Security Center here in the bottom left of the navigator, same thing, same place.

But when I do that, what happens is I can select virtual machines that are enabled for this and request access. Now before we do that, why don't we go back to our virtual machines here, and I'm going to copy the public IP address of this virtual machine and attempt to connect using the remote desktop protocol client on my station.

[Video description begins] He clicks Configuration under Settings displayed on the JumpBox window, A window titled JumpBox - Configuration opens on the right pane. The window displays: Just-in-time access with Enable just-in-time policy tab and Azure hybrid benefit with Yes and No tabs. He clicks the Enable just-in-time policy tab. A pop-up window appears on the top-right corner of the screen. It displays that just-in-time access policy is successfully enabled. The JumpBox - Configuration window displays Open Azure Security Center link under Just-in-time access. He clicks the link and a window titled Just in time VM access opens on the right pane. The window displays a row, which shows a configured JumpBox virtual machine with a checkbox. He clicks and enables the checkbox. He clicks Virtual machines on the left navigation pane of the Azure portal. The right pane displays a list of three virtual machines in three rows. He clicks the last row, which displays JumpBox. A window titled JumpBox opens on the right pane. He clicks and copies the Public IP address 52.235.38.242. [Video description ends]

So I'm trying to make a remote desktop connection to the public IP of this virtual machine. But notice it seems to be taking an awful long time, and that's because it's going to time out. When you enable just-in-time-access, this is what the desired outcome is.

[Video description begins] A Remote Desktop Connection pop-up window displays. It attempts to establish the remote desktop connection to the Public IP address 52.235.38.242. Another pop-up window shows that the connection could not be established. He clicked the OK tab on the pop-up window. He closes the Remote Desktop Connection pop-up window. [Video description ends]

And so, when we go to the Azure Security Center or we can do that through the configuration, then we can request access as we need it. So I'm going to select that JumpBox virtual machine, it could be any virtual machine, and then I'll click Request access. So I want access to port 3389 because it's running Windows, I want that on,

[Video description begins] He clicks Configuration under Settings of the JumpBox window. The JumpBox - Configuration window opens on the right pane. The window displays Just-in-time access with Enable just-in-time policy link. He clicks the link and the window titled Just in time VM access opens on the right pane. The window displays a row, which shows a configured JumpBox virtual machine with a checkbox. He clicks and enables the checkbox. He clicks the Request access tab displayed above the row. [Video description ends]

I want to allow it from my current IP address as it's known on the Internet. And it's set here for three hours, that's fine, although I do have the slider I could control. But I will leave it on 3, and I am going to click the Open ports button.

[Video description begins] A window titled Request Access opens on the right pane. A row displays the port details that need to be selected for JumpBox virtual machine. He selects the following details: PORT as 3399, TOGGLE as On, ALLOWED SOURCE IP as My IP, and TIME RANGE as 3 hours. He clicks the Open ports tab at the bottom of the window. [Video description ends]

And after a moment we can see in the upper right that it's enabling just-in-time or JIT access to that virtual machine. So now if I go back to my remote desktop connection for the public IP of that virtual machine and click Connect, we know it's working because it's prompting us for credentials right away. And if I pop those credentials in, then we will successfully have made a remote desktop connection through just-in-time-access to that virtual machine.

[Video description begins] The window titled Just in time VM access opens on the right pane. A pop-up window displays on the top-right corner of the window. It displays: JIT or Just-in-time network access request initiated. A Remote Desktop Connection pop-up window displays. He clicks the Connect tab displayed on the pop-up window. Another pop-up window titled Windows Security displays. He types the required credentials and the remote desktop connection gets established. [Video description ends]

VM Antimalware

[Video description begins] Topic Title: VM Antimalware. Your host for the session is Dan Lachance. [Video description ends]

There are a few ways, using the Azure Portal, that we can install anti-malware agents within virtual machines.

[Video description begins] The Virtual Machines page of the Azure portal opens. The left navigation pane of the portal displays various links to resources and services, and the right pane displays details of three virtual machines in three rows. [Video description ends]

One is to go to the Azure Security Center. When I go to the Azure Security Center, we can start to take a look at any of the recommendations that might apply to things like Compute, which would be virtual machines.

[Video description begins] He clicks Security Center on the left navigation pane of the Azure portal. A window titled Security Center - Overview opens on the right pane. The window displays three sections: Policy & compliance, Resource security hygiene, and Threat protection. These sections display certain data and various details. The Resource security hygiene section further displays two sections: Recommendations and Resource health monitoring. The Resource health monitoring section display: 3 Compute & apps, 3 Data & storage, 3 Networking, and 1 Identity access. He clicks 3 Compute & apps. [Video description ends]

And I can see here that it talks about installing endpoint protection on virtual machines. And if I click that, it'll have some recommendations for virtual machines that need it and I could select some or all of them and choose Install. But we can also do this manually.

[Video description begins] A window titled Compute opens on the right pane. The window displays four tabs: Overview, VMs and Computers, VM scale sets, Cloud services, and App services. The Overview tab displays four rows. He clicks the first row, which displays the following data: Recommendation as Install endpoint protection solution on virtual machines, Secure Score as +15, and Failed resources as 2 of 3 virtual machines. A window titled Endpoint Protection not installed on Azure VMs displays on the right pane. The window displays Virtual Machine row with no recommendations. [Video description ends]

So if I go to my Virtual machines view, and if I click on a virtual machine to pull up its property sheet, one of the things I can look at are its Extensions. And extensions are add-on items that run as agents within the virtual machine to give it additional functionality.

And so I have no extensions listed here, but I could click Add. And then it's a matter of choosing from the list. For example, I'll choose Microsoft Antimalware. And I'm going to go ahead and click on Create.

[Video description begins] He clicks Virtual machines on the left navigation pane of the Azure portal. The right pane displays details of three virtual machines in three rows. He clicks the second row, which displays the following data: NAME as eastwindowsvm1, TYPE as Virtual machine, STATUS as Running, RESOURCE GROUP as Rg1, LOCATION as Canada East, and SUBSCRIPTION as Pay-As-You-Go. A window titled eastwindowsvm1 opens on the right pane. He clicks Extensions under Settings and clicks the Add tab. A window titled New resource opens on the right pane. The window displays a list of resources and he clicks Microsoft Antimalware from the list. The details on Microsoft Antimalware display on the right. He clicks the Create tab at the bottom of the window. [Video description ends]

Now a lot of these extensions will give you some configuration settings, as we see here, that are specific to that extension. Such as whether I want to configure excluded files or locations from my anti-malware solution that might normally trigger false positives. Or files extensions I want to exclude, or processes that are running that I want to exclude.

So I'm going to leave Real-time protection enabled, and we're going to turn on Run a scheduled scan. That's enabled. And the Scan type will be a full scan. And the Scan day, let's say, will be Sundays. And we can also determine the maximum amount of Scan time from midnight, so this is the starting time. So this is 120 minutes from midnight, so in other words, at 2 o'clock in the morning we want to begin doing a scan. So I'm going to go ahead and click OK.

[Video description begins] A window titled Install extension displays on the right pane. He enters the following data: Excluded files and locations, Excluded file extensions, and Excluded processes as blank, Real-time protection as Enable, Run a scheduled scan as Enable, Scan type as Full, Scan day as Sunday, and Scan time as 120. He clicks the OK tab at the bottom of the window. [Video description ends]

And we can now see it's submitted that deployment to install that extension within that virtual machine. And after a moment, we can see that the provisioning succeeded for the installation of that anti-malware extension.

[Video description begins] The window titled New resource opens. A pop-up window titled Submitting deployment displays on the top-right corner of the right pane. A window titled eastwindowsvm1 - Extensions opens on the right pane. The window displays a row, which shows the following details: NAME as IaaSAntimalware, TYPE as Microsoft.Azure.Security.IaaSAntimalware, VERSION as 1.*, and STATUS as Provisioning succeeded. [Video description ends]

Storage Account Access

[Video description begins] Topic Title: Storage Account Access. Your host for the session is Dan Lachance. [Video description ends]

When you are planning your Azure resource deployment, one thing to consider is from where you want to allow access to that resource. And that also applies to storage accounts, which we'll focus on here.

[Video description begins] The Homepage of Azure portal opens. The address bar shows: https://portal.azure.com/#home. The left navigation pane of the Homepage displays various links to resources and services, and the right pane of the Homepage displays icons to access various Azure services. [Video description ends]

So, here in the Azure Portal, I'm going to start in the left-hand navigator by clicking on Storage accounts, where I will click on an existing one to pull up its properties blade. I'm interested in scrolling down in the properties blade until I see Firewalls and virtual networks.

[Video description begins] He clicks Storage accounts on the left navigation pane of the Azure portal. Three Storage accounts appear on the right pane. He clicks an existing storage account stor14567. The right pane displays the properties of stor14567. He scrolls through the list of properties and clicks Firewalls and virtual networks. The right pane of Firewalls and virtual networks displays two radio buttons under Allow access from. The first radio button is All network and the second radio button is Selected network. [Video description ends]

Notice that this is configured to allow access from all networks. Now we can limit that. If I click Selected networks, I can choose to add an existing VNet, or virtual network, or add a brand new virtual network that will have access to the storage account. So I'm going to choose Add existing virtual network. From here, I can select all my VNETs, or specifically cherry pick the ones I'm interested in. And then I can also choose subnets, any variation thereof, that should have access, I'll choose a specific subnet, and I'll click Add.

[Video description begins] The first radio button All network is selected, by default on the right pane of Firewalls and virtual networks. He clicks the second radio button: Selected networks. After the selection, Under Virtual networks displays: Secure your storage account with virtual networks. It also displays two options to select from: Add existing virtual network and Add new virtual network with a + sign in front of both the options. He clicks Add existing virtual network. Another window titled Add networks displays on further right of the pane. The window displays: Subscription, Virtual networks, and Subnets, each having a drop-down menu. From all the three drop-down menus, he selects Subscription as Pay-As-You-Go, Virtual networks as EastVnet1 displayed under Rg1, and Subnets as EastSubnet1. He clicks the Add at the bottom of the window. [Video description ends]

And we can see here that we've got an entry here for the EastVnet1 with EastSubnet1 having access to this storage account. But as we go further down below, we can also even add our client IP address. This IP address is my current IP as it's known on the Internet. And so conveniently, I can set that on. But bear in mind, if my public IP address for my Internet connection changes, then this will no longer work, but I can just come in and change it again.

I can also specify specific IP addresses or CIDR ranges. I can determine if I want to allow read access to logging or metrics related to this storage account from any network, I don't. And if I want to allow other trusted Microsoft services to access this storage account. But be careful with this one. Notice it's checked on by default, which it allows some other services like Azure Backup or Recovery services to be able to talk to the storage account. And so I'm going to go ahead and leave that on then because of that, and I'm going to click Save.

[Video description begins] The Firewalls and virtual networks pane of the storage account stor14567 displays the added virtual network. Virtual network displays: VIRTUAL NETWORK as EastVnet1, SUBNET as 1, RESOURCE GROUP as Rg1, and SUBSCRIPTION as Pay-As-You-Go. He clicks the arrow placed before EastVnet1. Under EastVnet1, the details display: SUBNET as EastSubnet1, ADDRESS RANGE as 10.11.0/24, ENDPOINT STATUS as Enabled, RESOURCE GROUP as Rg1, and SUBSCRIPTION as Pay-As-You-Go. He scrolls through the window. Under the Virtual networks, two more sections display: Firewall and Exceptions. Firewall displays Add IP ranges to allow access from the internet on your on-premises networks. He checks the checkbox: Add your IP address ('71.7.176.108'). He moves his cursor to Address Range, which displays under IP address checkbox. There are three check boxes under Exceptions: Allow trusted Microsoft services to access this storage account, Allow read access to storage logging from any network, and Allow read access to storage metrics from any network. The first checkbox is checked by default. He clicks Save, which displays on the top of the pane. [Video description ends]

After a moment, we can see it successfully wrote the changes here. So now we have limited access to our storage account from a specific VNet subnet, and from a specific on-premises client IP address.

[Video description begins] A pop-up window titled Saving firewall and virtual network settings, displays on the top-right corner of the Firewalls and virtual networks pane of the stor14567 storage account. The window displays : Saving firewall and virtual network settings for storage account 'stor14567'. The pop-window updates and displays: Successfully saved firewall and virtual network settings for storage account 'stor14567'. [Video description ends]

Azure Advanced Threat Protection

[Video description begins] Topic Title: Azure Advanced Threat Protection. Your host for the session is Dan Lachance. [Video description ends]

Azure Advanced Threat Protection, or ATP, provides protection against security threats to your Azure resources. There is built-in monitoring to monitor for suspicious activity and then to send alerts about that activity.

So it identifies anomalies based on what is not within the profile of being normal in your Azure usage environment. In other words, beyond a standard normal usage baseline, anything outside of that is considered abnormal. Also, Advanced Threat Protection reports are available to be generated.

[Video description begins] A diagram displays. It shows four elements: Monitoring and alerts, Protection, Azure ATP reports, and Identify anomalies. Advanced Threat Protection is abbreviated to: ATP. [Video description ends]

Specifically, the type of protection that ATP gives us is against attacks related to things such as pass the hash. Pass the hash is a type of attack that given access to a virtual machine where we've got, for example, an administrator logged on. Doesn't have to be an administrator, but that's in our example. Then, if an attacker can gain access to that host during that session, then the attacker can look at the hash values stored in memory and use that hash value to connect to other network resources as that user, without having to figure out what the password is.

Another protected item would be against enumeration of SMB, or Server Message Block, sessions. Protection against the enumeration of items in Active Directory. Protection against encryption downgrades, which is applicable when two machines begin to communicate, they negotiate how they will communicate. And in the attackers sense of realm, of what would happen is that they would try to use a lower level of encryption. Ideally, one that is known to have weaknesses.

And that's called an encryption downgrade attack. Advanced Threat Protection can also detect DNS reconnaissance attempts. Reconnaissance essentially is information gathering. The more that a malicious user knows about your Azure environment, including DNS names, IP addresses, deployed resources, which resources talk to each others, then the better off they are in finding some kind of a vulnerability and attempted to compromise something you've got deployed in Azure.

In order to use Advanced Threat Protection in Azure, you need an ATP license. And you manage this through the ATP portal, it's a separate portal that has a URL of portal.atp.azure.com.

[Video description begins] The ATP portal address typed is: https://portal.atp.azure.com. [Video description ends]

ATP is also designed to connect to and monitor Active Directory, there are Azure ATP sensors that are used to do that. And this is used to detect things like Active Directory enumeration type of reconnaissance attacks.                    
