                    AZ900 Microsoft Azure Cloud Fundamentals 2021
                    Course Notes Part 29
                    

Deploy an Azure Virtual Machine Scale Set (Cont)
  - Because with an Azure load balancer, as opposed to specifying the operating system image and the credentials here
    - The load balancer can reference existing virtual machines that are already out there
    - They don't even all have to be identical which is a little bit different than what we're doing here with the virtual machine scale set.
  - Here's the Instance count property, where it defaults to having 2, but that can be adjusted
    - You can also set the instant size, which determines things like the amount of CPU power and the amount of memory
    - Click Change size, I'll just choose something very basic, let's say 1 VCPU and 1 GB of RAM.
  - Go ahead and select that and scroll further down
    - Let it use managed disks, which is by default
    - Under advanced settings, I can determine whether I want to allow scaling beyond 100 instances
    - We shouldn't need that, so don't turn that on.
  - Autoscaling can also be enabled
    - Autoscaling changes the number of backend instances automatically based on things like CPU busyness or threshold.
    - We can see that if we've got a CPU threshold above 75%, then we can increase by a virtual machine
    - One VM based on the image that we specified when we were creating this.
  - That's for scaling out, adding virtual machines to support a busy workload
    - The opposite is scaling in, so both of them are horizontal scaling
    - But scaling it reduces the virtual machines based on a CPU threshold, this is a good setting
    - It's important because we don't want to have virtual machines running we don't need, because we're paying for that
  - Decide whether  to use an application gateway for load balancing, although there are none any already defined
    - Choose load balancing as a solution, while defining the scale sets, so we are doing two things at once.
  - Give a public IP address name for the load balancer IP address
    - If we scroll back up at the top here, the name of this scale set is webapp3vmss
    - Copy that, and I'm just going to go ahead and use that as part of the name here, call it pubIP at the end
    - Then we can use a domain name label to which the following suffix listed down here, foe example a region, .cloudapp.azure.com will be added.
  - That can be customized, but I'll accept that default, finally choose a virtual network
    - For example choose EastVNet1, and there is 1 subnet, that's important because that's where we will be deploying these virtual machines
    - They're going to assume IP addresses from that subnet address range.
  - It's important to make the correct selection. Do we need a public IP address for each and every instance, it's set to off?
    - Choose no, because these are running in the backend to support an app
    - You might wonder, how do I gain access to them if I need to manage them?
    - You might have another virtual machine outside of the scales set running in that subnet that does have a public IP address.
  - You can connect to it, for example, from on-premises, and once you're connected to it, you would be on the private network
    - You could then manage these additional virtual machines from this scale set
    - It means having less public IP addresses, which saves on cost
    - The next thing we're going to do is just click Create
    - Then go to the All resources view, and let's take a look at our newly created scale set.
  - Filter this view for vmss, and here we can see we've got our webapp3vmss virtual machine scale set
    -We can also see the load balancer and the public IP address resources.
  - Click on the virtual machine scale set to open up its Properties blade
    - In the Overview section on the right, we can see the public IP address here, that's actually for the load balancer component.
  - Click on Instances on the left, we can see the virtual machine instances here in their current state.
    - Click, for example, on Scaling, this is where during the creation we had the option of configuring autoscaling
    - This is for scaling out and also for scaling in.
  - Click Operating system, we can see here that it's the Windows Operating System, based on the image we selected
    - Same with the sizing, we can see the size of the virtual machine
    - Which determines the underlying horse power, like the number of VCPUs and the amount of RAM
    - Close out of that, and I'm going to click on our load balancer that was created for the scale set.
    - Notice that we've got the public IP address here, that's the frontend for client connectivity to the backend configuration.
  - Notice that if the Backend pools were clicked here, we can see that we've got a backend pool that was created for us automatically
    - And here are the virtual machine instances. And, of course, we can see the private IP addresses that they've been assigned.
  - While we've got virtual machines instances listed here, click on the Virtual machines view over on the left
  - There aren't virtual machines here that result from the use of a scale set.


Azure Load Balancing
  - The Azure Load Balancer is used to take incoming client requests and spread them out amongst backend virtual machines that support an application. 
    - This means we have a result of increased performance because we've got more virtual machines to service client requests
    - It also supports high availability which allows client requests to bypass unresponsive VMs.
  - This means is that the load balancer is configured to periodically probe backend virtual machines to make sure they respond
    - For those that do not respond, client requests will not rerouted to those specific instances
    - We can configure a public load balancer which means that the load balancer is Internet-facing and it will be assigned a public IP address.
  - When clients enter the URL for a web app, it needs to resolve to that load balancer public IP address
    - That's for inbound Internet traffic
    - We can also define an internal load balancer that would be used not over the Internet
    - But instead within an Azure VNet, maybe for some kind of internal line of business application running in the cloud.
  - It can also be used for on-premises traffic that's coming into Azure, for example, through a VPN in a hybrid cloud configuration scenario
    - With the Azure Public Load Balancer, we have health probes that verify the backend virtual machine responsiveness
    - That actually gets configured within what's called a load balancer rule
    - You'll see that when opening up a load balancer in Azure and take a look at its properties blade
  - Load balancers in Azure can be managed like most resources in a number of ways, such as through the Azure Portal, the web GUI, or the Azure CLI.
  - So for example, to create a load balancer in the CLI, we could issue the az network lb, for load balancer, create
    - In PowerShell, the equivalent would be the New-AzLoadBalancer cmdlet
    - If you're using an ARM template to deploy load balancer resources, then you would refer to the Microsoft.Network/LoadBalancers resource type.


Azure Serverless Computing
  - Microsoft Azure has a number of service offerings that are under the classification of serverless computing, but what does this mean? 
    - Because in the end, there's always an underlying server that's used, for example, to support a database application and code that's running
    - However, we're talking here about automated server deployment and management, what this means is a managed service
    - That we don't have to worry about actually deploying a virtual machine and the operating system and the tools within it that will run our code.
  - Really we're talking about focusing more on code and applications that result from that
    - This is of primary interest to developers, an example would be working with what are called Azure functions
      - Azure functions allow you to create and run code on-demand in the cloud 
      - Without having to worry about provisioning a server that has the appropriate engine that can run that code, it's taken care of for you.
  - We can implement Azure functions in a number of different ways
    - It could be used for a web application, it could be a mobile device app that we're developing
    - That is configured to talk to Azure resources through our functions
    - We could look at Internet of Things, or IoT, received data, such as through the Azure IoT Hub
    - In Azure, that could trigger a function that we've created as an Azure function.
  - The key is here, we've got a container, so to speak, in which we can run our code 
    - Without having to define the underlying server operating system details to support the running of that code
    - You might even have an Azure function through serverless computing that takes a look at files that people might upload to an Azure storage account
    - When that file is uploaded, that is a trigger that fires off the Azure function 
    - That maybe categorizes or adds metadata to that file or does something specific with it.

