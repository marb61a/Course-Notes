                    AZ900 Microsoft Azure Cloud Fundamentals 2021
                    Course Notes Part 33


Azure SQL Database PowerShell Deployment (Cont)
  - What we are doing is then running new object of type System.Management.Automation.PowerShell or PSCredential
    - The argument list is going to have the username, in this case cirving
    - Then convert to a secure string, a password that is being specified here, within double quotes.
  - Then what's happening is we're building our new Azure SQL database and tying it to our SQL server instance that we've created above
    - We can then call this database db112
  - Add a new Azure SQL Server firewall rule to allow incoming SQL traffic from the appropriate IP address
    - Which happens to be the public IP address for our on-premises environment.
    - Go ahead and run this script by clicking the Run Script button up at the top.
    - After a moment or two, we can see it looks like the script has completed running
    - Check the work in the portal, take a look for sqlsrv3362 and db112.
    - In the portal, I've gone to the All resources view and filtered for anything that starts with SQL, S-Q-L, and we can see indeed, we've got sqlsrv3362.
    - Open that Properties blade up, and go down under Firewalls and virtual networks, we can see our Allow incoming SQL firewall rule that was created.
    - We can also see that we've got DB or database 112 that was created as the result of our PowerShell script.
  - The only other thing to bear in mind is don't leave these database resources running in Azure if you're not using them
    - This because you will pay for using them even if they're running, and you're not actually using them
    - So remove these resources when you no longer need them immediately


Connect to Azure SQL Database
  - Once you've deployed Azure SQL database in the Azure cloud, how do you connect to it?
    - In the Azure portal, we've already deployed Azure SQL database, so there is a SQL server instance and a database already up and running.
  - Go ahead and click on the link to open up the Properties blade for the SQL server instance.   
    - The first thing to do is scroll all the way down under Security and look at Firewalls and virtual networks.
    - We've already added a firewall exception to allow my current client IP address, my public IP.
    - We've also made a firewall rule to allow traffic from this address
    - This is our on-premises public IP as it's known out on the Internet.
    - The other thing that we can do here, is open up the Properties blade for our deployed SQL database in the cloud.
    - From here, we can see the server name that we can simply copy.
  - Go to the on-premises environment and launch the SQL Server Management Studio tool
    - Specifically, this is the Microsoft SQL Server Management Studio tool for SQL Server 2014
    - Click Connect over on the left.
    - What we want to do is connect to a database engine.
    - We want to make sure that I've got the SQL Server name that I copied from Azure listed here, and I do.
  - When we deployed that SQL Server, we specified an admin name of cirving, so that is there
    - We just have to supply the password that I specified when I deployed that SQL server instance
    - Once we've done that, I can go ahead and click on the Connect button.
  - Because the firewall allows connectivity from this host behind a NAT firewall
    - We can see now that we are indeed connected to our Azure SQL database instance
    - Go down under Databases to take a peek, here's db112 or database 112
    - If we flip back to the portal, we can see indeed that is the name of our Azure deployed SQL database.


Azure Database Migration Service
  - The Azure Database Migration Service allows you to keep your existing data and simply move it into the cloud
    - We're talking about moving database workloads from an on-premises IT environment into Microsoft Azure
    - The movement of that data can happen through a site-to-site VPN tunnel that you would have first defined 
    - Between your on-premises network and an Azure virtual network or you might do that movement of data through an ExpressRoute circuit.
  - ExpressRoute does not go through the Internet
    - Instead, it is a dedicated network circuit from your on-premises network directly into the Azure cloud
    - Depending on where you are in the world, this may not be an option
    - Generally, it is conceptually a choice that we at least have to examine when we're going to be moving or migrating data from on-premises into Azure.
  - The Azure database migration process begins with discovery
    - What we're talking about discovering are database items available on-premises
    - The next thing is assessing the workloads that use those databases to determine whether or not they can be migrated into Azure.
  - The convert part of the process means that we want to take a look at the database schema on-premises
    - The schema is the blueprint of what type of data is allowed to be stored
    - We want to make sure that, that schema will function correctly in the Azure environment
    - This is normally not an issue unless, on-premises, you've customized your database schema to support non-standard data types, for example.
  - That's all considered pre-migration in terms of tasks. The next thing that we have is to actually migrate the schema and data objects. Depending on the amount of data you're talking about and the speed of your network link to the Azure cloud, we'll determine how long it will take to bring across very large data sets.
Next, we've got data synchronization, so the data that's migrated into Azure is kept in sync with on-premises data during this transitory process. Finally, at the cutover stage, we actually cut ties with the on-premises data source. And so there is no longer synchronization between on-premises and Azure cloud hosted data.
As we'll see in a different demonstration, we start the process of working with Azure Database Migration by actually creating a database migration instance. And we can do that, for example, through the Azure portal. From there, it will take us through all of these steps in the database migration process.


SQL Server Migration Assessment
The SQL Server Migration Assessment tool allows you to run this on-premises, so you can assess what you currently have running and which are likely candidates for being migrated into the Azure cloud.
So here, I've gone to the Microsoft.com website, and I've searched the downloads for the Migration Assistant. So we can see here, Data Migration Assistant v4.2, at least at the time of this recording. So I have to go ahead and download that tool.
Once it's downloaded, I'm going to go ahead and run the installer, so it's called the DataMigrationAssistant.msi. So I'm just going to right-click on that and choose Install.
I'll choose Next, I will accept the terms of the license agreement, I'll click Next again, and it'll just go ahead and run the installation.
Before you know it, it's done. So, there's a check box here on the installation screen to launch the Microsoft Data Migration Assistant. Of course, I could launch it after through my Start menu, but I'm going to go ahead and turn that check mark on, and I'm going to click Finish.
Now it's loading the Microsoft Data Migration Assistant.
So the first thing I'll do here is click the new button, the plus sign, to create a new migration project.
Notice, we can build in assessment project, which is what we're going to do, to assess our on-premises SQL databases to test their suitability to be migrated to Azure. However, we can also actually perform a migration. However, we're not going to build a migration project here, just assessment. So the project name here is going to be HfxProj1 because my city, where this is happening on-premises, is Halifax.
And the source server will be SQL, the target will be Azure SQL database. I'll click create, then I'm going to click Next.
I'm going to give it some details, such as the name of the on-premises server that I want to use.
So I'll fill that in, that's my on-premises SQL server. It uses Windows Authentication, but I could choose the appropriate authentication type. If you're not sure what to choose here, talk to your on-prem SQL people and I'm going to click Connect. We're not going to change anything else here.
So I know it's made a good connection because I have a list of valid databases that are being hosted on that SQL server instance. So I'm just going to choose one of the databases in question that I'm thinking about migrating to Azure, and I'm going to click Add.
So we can see it's been added here. And we can add and remove sources at will here to determine what we want our assessment to be run against. So I'm going to go ahead and click Start Assessment in the bottom right.
Once the assessment is complete, we can see that we are in step 3, where we're reviewing the results. And so we can see our SQL server on-premises listed over here on the left. And then we can see our listed items of unsupported features.
So the service broker feature not being supported in the Azure cloud and when we select that unsupported feature, we get some details listed over here on the right.
Then we also get some recommendations about what we might be able to do to resolve this issue once the database has actually been migrated into the Azure Cloud.
Now, also remember that once you're happy with this, you can actually add an actual migration project,
where you can actually start moving data into the cloud. So this migration assistant is a great tool then for you to evaluate your on-premises SQL databases and how likely they are as candidates for running in the Azure cloud.


Azure SQL Geo-Replication
To increase fault tolerance and availability for Azure SQL, we have the option of enabling Geo-Replication.
Here in the portal, I've already got Azure SQL deployed. So if I go to the All resources view, and if I filter that view for anything that has a prefix of SQL, we can see both.
We've got a SQL Server and a single SQL database instance hosted on that server.
If I click on the server to open up its Properties blade, you'll notice that we don't have any options related to Geo-Replication, at least not at the server level.
However, if I get back out of that, if I go into my database property sheet, notice that Geo-Replication is an option.
Now currently, we can see that we've got an area on the map here in Eastern Canada where we've currently got our current SQL database deployed. That's the Azure region or location.
Now if you're not so great with your geography, don't worry if you don't know what you're looking at on the map. Because when I scroll down a little bit, I can see indeed Canada East is that current region.
And I can see the status of that replica is that it's online. Down below, it says for secondaries, Geo-Replication is not configured, and we can see here the list of target regions.
So let's say, for example, I want this to be replicated to Canada Central as a different region.
Now the secondary type is by default set to a readable replica of our Azure SQL database. Then for the target server, I have to configure settings. Now, what that means is I need another Azure SQL server instance.
Now if I don't have one, I have to create one here. So I'm going to call this sqlsvr172_central. You'll notice that it's going to tell me over here if it likes underscores, upper case letters, lower case letters. So notice here, it doesn't like a lot of the items that are specified here in the name.
So I'm just going to call it sqlsvr172central. And I'm going to specify the credentials and password here which do not have to be the same as they are for the primary server holding the master writable replica.
Once that's been filled in, I'm just going to go ahead and click Select.
So really we're creating a new SQL Server instance to accommodate our Geo-Replication to a different Azure region. I'm going to leave the standard pricing tier as it is, and I'm going to click OK.
Now currently, we have a message about the deployment being in progress up here in the upper right in the Azure portal.
And if I kind of scroll up here, and take a look here, after a moment, we'll see that it will reflect that we've got Geo-Replication from the Canada East region to the Canada Central region.
And before you know it, you'll have this little check mark in these regions that are filled in with the solid color. You can see the other regions that are not filled in, and they do not have a check mark. So therefore, we don't have a replica of this SQL database in those locations.
And if we scroll down, we can see that represented in textual form. So, not only do we have our original online master replica in Canada East listed here at the top, but we can also see we've got a secondary now in the Canada Central region, and it's currently listed as being readable.
Now if you click the ellipsis button, the three dots with the context menu next to the word readable, you'll have the option to force a failover which essentially promotes this to be the primary replica, and the other current primary would then become a secondary. It does say that this can cause some data loss while you're doing this.
Also notice that we do have the option also of stopping replication, so, for instance, if there's a failure or a disaster in our primary region.


NoSQL Overview
In the Microsoft Azure Environment, you can choose to deploy a SQL compliant type of database or a NoSQL database, so it's important to know the difference between the two. With NoSQL databases, we have a less rigid schema than with a traditional, relational database, such as MySQL or Microsoft SQL Server.

The schema, remember, is the blueprint of what type of data is allowed to be stored. And, so, with NoSQL, it's really designed to be much less structured to allow or accommodate for the storage of many different types of data. NoSQL is also designed for high scalability because it's really what is often used to work with very large data sets.

[Video description begins] Screen title : NoSQL Database Characteristics. [Video description ends]

So high performance and availability are a big part of NoSQL. Essentially, the manipulation and analysis of big data. With NoSQL, each stored row can actually store different types of data. That's unlike a relational database structure that has a blueprint or schema that defines exactly what can be stored in each row within a table.

We don't have that kind of structured limitation with a NoSQL database. There are a number of different types of storage configurations for NoSQL databases, such as key and value pairs, or NoSQL document stores, or graph database stores, but in the end, a NoSQL database is not relational.

[Video description begins] Screen title: NoSQL Horizontal Scaling. [Video description ends]

NoSQL uses horizontal scaling extensively as a traditional relational database system can as well.

[Video description begins] A diagram appears on the screen. It has a box with four blocks placed side by side. Below the box, there is a forward arrow. [Video description ends]

What this means is scaling out, as we see pictured in the diagram by adding database servers to handle the workload. Now this can be done for clustering purposes, for load balancing, and for replication of data.

[Video description begins] Screen title: Common NoSQL Database Products. [Video description ends]

Common NoSQL products include Azure CosmosDB, Azure Redis memory caching, which allows us to take data and cache it in memory. Data that is accessed frequently, so that subsequent requests are a service from the cache, which is much quicker than reading it from disk.

There are also numerous database options, including for NoSQL available to the Azure marketplace. So you can choose to deploy a new Virtual Machine instance that has a variety of different NoSQL products installed and configured for you already.


CosmosDB
  - Azure CosmosDB is a NoSQL database option available in Microsoft Azure. So it's a NoSQL solution that is globally distributed across Azure regions. 
    - This global distribution means that users can contact the nearest replica of CosmosDB to work with the data. 
    - That way, there's a better user experience instead of accessing it across multiple Azure regions.
  - Azure CosmosDB supports default encryption of data at rest, and it's used by a lot of popular services that you've probably heard of, like Xbox, Office 365, and Skype. When you start to deploy Azure CosmosDB, you begin by creating an Azure CosmosDB account, as we'll see in another demonstration. You also get to select the appropriate API for the account type.

Now, we might choose, for example, a certain type of account type like Gremlin if we want to use graph databases, or MongoDB if we're using a document type of database, and so on. So we'll see that as well when we configure Azure CosmosDB in a demonstration.

We can import data into CosmosDB from a number of different sources, including SQL databases. Now, even though CosmosDB is generally considered NoSQL, we still have the option of bringing in SQL data to store it in here. We also can specify CSV or comma separated value files as a data source or JSON files, and even standard NoSQL compliant databases like MongoDB.


Deploy CosmosDB
  - Microsoft Azure CosmosDB is a great choice when you have vast amounts of unstructured data that you want to store and manage in the cloud. I'm going to start here in the left-hand navigator in the Azure Portal by clicking Create a resource, and I'll search for cosmos.
  - From here, I'll choose Azure Cosmos DB, and then I'll click Create.
The first thing I'll do is place this into a resource group, and then, down below I need to create a Cosmos DB account name.
So I'm going to call this cosmosdb-acct172. Now, be careful because in some cases in Azure if you start to use weird symbols like underscores, it'll tell you. So luckily we have this kind of easy notification that there's something wrong with the name, so, just be aware of that.

[Video description begins] In the input box for Account Name, he types cosmosdb_acct172. An error message pops up. It reads: The name can contain only lowercase letters, numbers, and the '-' character, and must be between 3 and 31 characters. Name is invalid. He then types cosmosdb-acct172. [Video description ends]

Now for the API, I can determine exactly what it is I want to configure Cosmos DB as because really it's kind of like a multi-model type of solution. So, do we want to treat it as a core SQL solution?

Or do we want it to adhere to the MongoDB API standard, or Cassandra, or is it a table type of data store or a graph type of NoSQL data store? So in this example, I'll choose Azure Cosmos DB for Mongo DB API.

[Video description begins] He clicks the drop-down menu for API. A list of options appears. He selects Azure Cosmos DB for MongoDB API. [Video description ends]

Now, I would do that if I knew that I had perhaps an application or some code that was already written that needs to talk to the MongoDB API to access data. I'm going to specify an appropriate location.

[Video description begins] He clicks the drop-down menu for Location. A list of options appears. He selects Canada East from the list. [Video description ends]

I'm going to disable geo-redundancy. Notice, that was enabled by default for Cosmos DB. I also, of course, want to leave multi-region writes disabled since I've disabled geo-redundancy. When I click Next, I then have to place this into an Azure Vnet. So I'll choose a Vnet and a subnet.

[Video description begins] He clicks the Next: Network button. The screen shifts to the next tab titled Network. It has drop-down menus for Virtual Network and Subnet. He clicks the drop-down menu for Virtual Network. A list of options appears. He selects EastVnet1 from the list. A section titled Configure Firewall appears. For Allow access from Azure Portal, there are two options: Allow and Deny. Allow is selected by default. For Allow access from my IP (71.7.176.108), there are two options: Allow and Deny. Deny is selected by default. He clicks the drop-down menu for Subnet. A list of options appears. He selects EastSubnet1 from the list. At the bottom, there are three buttons: Review + create, Previous, and Next: Tags. [Video description ends]

And right now it's set to allow access from the Azure Portal, which is great. So I can use this portal GUI interface to make a connection to my Cosmos DB and also to connect to it and look at performance metrics and things of that nature.

And conveniently, it also has my current public IP address listed here, and I can click Allow to add, essentially, a firewall exception for CosmosDB, so that if I need to get in from on-premises, maybe I'm using a MongoDB GUI management tool, for example, that I will be able to get in, or maybe I've got some code segments running on-premises on a server that need to talk in Azure to my Cosmos DB to work with that. So I'm going to turn on Allow for that, and I'm going to click Next for tagging.

[Video description begins] He clicks on the Allow button for Allow access from my IP (71.7.176.108). [Video description ends]

Well, there's no tags in here to assign here so I'll just go to Review and create, and once the validation says it succeeded, I will create my Cosmos DB deployment.
And after a moment we can see our deployment is complete, and we've even got a view over on the left here called Azure Cosmos DB, and I can see my deployed instance listed here.
I'm going to click it, and here we can see a number of interesting items.

[Video description begins] He clicks on cosmosdb-acct172. A page titled cosmosdb-acct172 appears. It has a navigation pane. The following buttons are present on this page: Add Collection, Refresh, Move, Delete Account, etc. Below the buttons, there is a list of details. These include: Status, Resource group, Read Location, Write Location, etc. [Video description ends]

For example, as I scroll down in the Overview part of the Properties blade, I can see the region into which it was deployed. This looks like Eastern Canada.

[Video description begins] He scrolls down the page. A section titled Regions appears. It has a world map. The East Canada region has a blue tick mark. [Video description ends]

And as I scroll down, I've also got this Data Explorer option, where I have buttons to create a new database or a new collection to begin working with data.

[Video description begins] From the navigation pane, he clicks on Data Explorer. A Data explorer page opens up. The following buttons are present here: New Database, New Collection, and Open Full Screen. [Video description ends]

Of course, you can do this programatically or using command line tools or even GUI tools that you might even run on-premises. You would just need to make sure you have a way to access Cosmos DB, and we're talking really here about adding a firewall exception, so here in the Properties blade, if I go to Firewall and virtual networks, notice here that my client IP, my public IP on the Internet, has been added here as being allowed in.
But you would also need to go to Connection String because you would have to have the correct Cosmos DB host name, the port number to connect to, as well as the Cosmos DB user name, and either the primary or secondary password.

[Video description begins] From the navigation pane, he clicks on Connection String. A page for Connection String opens up. It has two tabs: Read-write Keys and Read-only Keys. Read-write Keys is currently open. It has the following criteria listed: Host, Port, Username, Primary Password, Secondary Password, Primary Connection String , Secondary Connection String, etc. The presenter highlights the values for Host, Port, and Username. The Host is cosmosdb-acct172.documents.azure.com. Port is 10255, and Username is cosmosdb-acct172. [Video description ends]

So you would do that, for example, if you were using some kind of MongoDB type of GUI tool on-premises that you wanted to reach into the cloud to this instance to make changes to.
