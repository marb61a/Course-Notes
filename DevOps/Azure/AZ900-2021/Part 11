                    AZ900 Microsoft Azure Cloud Fundamentals 2021
                    Course Notes Part 11

Create a Storage Account (Cont)
  - The first thing we have to think about is the subscription to which this storage account will be tied. I only have one subscription so that's an easy choice. Then I have to associate this with a resource group. I could either create a new one or choose from an existing one in the drop down list, which I will do. I'll choose Rg1.
  - Further down below give a name to the storage account. 
    - Uppercase letters will not be allowed however Lowercase are fine. 
    - If I start using uppercase letters I get a little red error message here about the fact that the name can only contain lowercase letters and numbers
    - Notice if I back out of the capital letters here, that if I just put in a name that's already in use that isn't globally unique. 
    - It will tell me so go ahead and call it something, it'll determine whether or not that's a unique name. 
    - In this case it is because we've got the green check mark. We don't have the red error text. 
    - Of course, we always need to make sure we adhere to organizational naming standards as it applies to the creation of Azure resources. 
    - For the location, I'm going to specify a region and the performance will be either Standard or Premium.
  - In other words, with Standard, do we want to use older hard disk technology like magnetic hard disks that spin. Or the newer solid-state storage which provides better performance? Of course, it also means an increased cost. Now, depending on what we're planning on doing with the stuff that we put in the storage account really determines the next couple of selections. So if we're not going to have frequent access to what we're going to store in the cloud, we might want to just stick with standard performance.

But if we're going to have frequent access and we want it to be speedy, maybe we should look at using Premium. Down below I've also got to specify the account kind, whether it's StorageV2, general purpose storage. Or general purpose version one storage, or BlobStorage. Now with general purpose version two type of storage, we have an access tier, Cool or Hot. Similar to Standard and Premium, for frequently access data and the speediest access we should be choosing the Hot access tier. If this is more of an archive type of usage scenario, we would look at using a Cool access tier.

Now, if I were to switch this to Storage general purpose v1, notice that we lose the option of selecting the storage tier. And if I were to choose BlobStorage, binary large object, we then get a couple of additional options for replication. So the first option is locally redundant storage or LRS. Now, this means that we've got some replication that will occur within the Azure environment but at a very small level. Not, for example, across regions. Whereas Geo-redundant storage, if we were to select that, does provide replication across Azure regions geographically. And the benefit of doing this is that if there's some kind of a large-scale disaster or outage within an entire geographical region.

Well, your data's already been replicated elsewhere, and you can access it that way. Then we've got another variation called Read-ahead geo-redundant storage, RA-GRS. So essentially, this is similar to replicating across Azure regions, the difference being that we would have read-access only to a replica. So depending on what your storage requirements are will determine what you select here. It's important to realize that if we were to choose StorageV2 general purpose v2.

That we can change it later on if we want to for example, BlobStorage. If we're going to be working with storage, let's say of virtual machine hard disks. So we can always change our mind later. So generally speaking, the general purpose v2 account kind is what you'll see used more often than not in Azure. So I'm going to go ahead and click Next.

[Video description begins] He clicks the Next button and the Advanced tab gets active. The page has 3 sections- Security, Virtual Networks, and Data lake storage gen2. [Video description ends]

Here we have a couple of options such as whether we want to enable secure transfer. This would mean only allowing connections over HTTPS or newer versions of SMB, the Server Message Block protocol. As opposed to older, less secure standards. So I'm going to leave that on Enabled.

[Video description begins] In the security section, there is a field named secure transfer required with 2 radio options- Disabled and Enabled. He selects the Enabled option. [Video description ends]

Then we can determine where we want to allow access from in terms of virtual networks. And currently, it says All networks. If I were to click Selected network, then from the drop-down list, I could choose an existing Azure virtual network that I previously have defined. However, I'm going to leave it on All networks for now.

[Video description begins] The virtual networks section has a field allow access from. This field has 2 radio options- all networks and selected network. He selects the all networks option. [Video description ends]

We're going to talk about data lake storage later on, so I'm going to leave that disabled as a default setting, and then I'll click Next.

[Video description begins] The Data lake storage gen2 section has a field named hierarchical namespace. This field has 2 radio options- Disabled, the Default Option, and Enabled. He leaves the field with the default option. Then, he clicks the Next button. [Video description ends]

So we then get to decide whether we want to assign a tag to this storage account. And remember, tagging is just metadata, it's extra information that you might use here. So you can search, or sort, or assign costs to a department or a project. And from the name drop-down list, if I've already defined a tag before which I have, it'll show up. I've already used a tag called project. So go ahead specify that.

[Video description begins] The third tab- Tags- gets active now. A brief description displays. It reads: tags are name/value pairs that enable you to categorize resources and view consolidated billing by applying the same tag to multiple resources and resource groups. A note displays: Note that if you create tags and then change resource settings on other tabs, your tags will be automatically updated. There are 3 fields in this tab- name, value, and resource. [Video description ends]

Then I can give it a value, and I can also see any existing values I might have used for tagging. In this case, ProjectA. I'm going to go with it. I could add a multitude of tags but I'm just going to leave it that way for now. Technically, I don't have to add tags at all.

[Video description begins] He selects project in the name field, project A in the Value field and Resource Account in the Resource field. [Video description ends]

Then I'll click Next to review my settings.

[Video description begins] He clicks next and the tab Review+Create gets active. All the storage account settings display. The message validation passed displays on the top. A link captioned download a template for automation displays at the window bottom. [Video description ends]

Now notice it says the validation has passed based on my selection. We have a little summary here of what's going to be created. I also have the option to download a template for automation. That is an ARM template that uses JSON file syntax. And why would I do that?

Well, I might download it if I want to be able to deploy a storage account with all these settings from the template in the future. Maybe even using the Azure CLI or PowerShell, which is way quicker than doing it here and clicking on all these things in the screen. So it allows for repetition, automation, that type of thing. However, I'm okay with this. I'm going to click on the Create button to create the storage account.

[Video description begins] A message window displays on the top-right corner and it says: initializing deployment. A progress bar displays there. [Video description ends]

And it's taking us into an overview screen for the deployment of our new storage account.

[Video description begins] Once the deployment is complete, an overview screen displays. It has a navigator with options-overview, inputs, outputs, and template on the left. 4 buttons display on the right, namely Delete, Cancel, Redeploy, and Refresh. The text- Your deployment is underway- displays on the screen in large font. [Video description ends]

We can see some information related to it down below. But at the same time, I can simply go over to All resources on the left. And after I refresh it, we'll see that we do have our new storage account listed.

[Video description begins] He clicks the all resources option in the main window navigator and its page displays. It has buttons- add, edit columns, refresh, assign tags, delete, export to CSV, and try preview. Below the buttons the subscription mode displays. Then, filter options display, namely filter by name, resource groups, types, locations, tags, and grouping. According to the filter options selected, search results display in a table format. Its columns are name, type, resource group, location, subscription, and tags. The eaststorageaccount 1 displays in the table and the value under tags column is 1. [Video description ends]

And like always, we can see the resource group, it was deployed into the region or location. And in this case, if you've added the Tags column, you'll see that here too. The Tags column is not normally here by default unless you go to Edit columns,

[Video description begins] He clicks the Edit Columns button and its window opens on the right. All the available columns are listed on the left side and the selected columns on the right. Between the two column types are right and left arrow buttons for adding and removing columns. 5 column names display under selected columns, namely- type, resource group, location, subscription, and tags. [Video description ends]

select it on the left. And then click the arrow to move it on the right, which I've already done. So therefore, I can see some tag information. If I were to click on that storage account, it opens up the properties blade for it.

[Video description begins] He closes the edit columns window and returns to the storage account window. Here, he clicks eaststorageaccount 1 and its detailed page opens. There are 4 buttons here, namely Open in Explorer, Move, Delete, and Refresh. A navigator on the left shows menus such as Tags, Diagnose And Solve Problems, Events and Settings. [Video description ends]

And I could go back and take a look at the tags and make changes to it. Or I could go through and look at the settings specific, in this case to a storage account. Such as geo-replication options, if I want to enable that type of item.

[Video description begins] He clicks geo-replication in the settings menu group. A world map displays on the right. [Video description ends]

Also, I can see if I want to configure blob service settings and so on.

[Video description begins] He clicks blobs in the blob service menu group. Its page displays on the right. There are 4 buttons on the top- Container, Refresh, Delete, and Change Account level. A Search field is also present and a table with columns name, last modified, public access, and lease state. [Video description ends]

So we have a number of properties available then after we've configured an Azure storage account. But there you have it, that's how you can initially create the storage account here in the Azure portal.


Azure Blob Storage GUI Management
In this demonstration I'm going to use the Azure portal to create a new Azure storage account, and then we'll configure to be used for Blob storage. To get started here in the portal, I'm going to click Create a resource over on the left.
[Video description begins] The Microsoft Azure portal home page displays in a browser window. The address bar contains the URL: https://portal. azure.com /#home. The page is divided into 2 sections. In the left section, is a menu bar with menus such as Create a resource, Home, Dashboard, All services and Favorites. The right section shows the page linked to the menu item clicked on the left. He clicks the Create a resource menu. [Video description ends]
I want to create a storage account, so one way for me to do that, is to go under the Storage category here and then on the right to choose Storage accounts. I'm going to go ahead and do that.
[Video description begins] A dialog box titled New appears. It has a search field at the top. Below that are two columns-one titled Azure Marketplace and the other Featured. Under Azure Marketplace are various menu items such as Get started, Recently created, Compute, Networking, Storage, and others. In the featured column, detailed contents of the selected menu displays. The host clicks the Storage menu and its contents display on the right. He clicks the Storage account tutorial from here. [Video description ends]
So, now I have to tie it to a resource group. So I've already got one called Rg1, and down below I have to give it a name.
[Video description begins] A Create storage account window displays. It has 4 tabs- Basics, Advanced, Tags, and Review+create. The Basics tab is active now. It has a brief description about Azure storage and a section titled PROJECT DETAILS. He selects Rg 1 in the Resource group drop-down field. [Video description ends]
Now notice if I start typing in things like capital letters, it says here that the account name can use only lower case letters and, of course, numbers. And it needs to be between 3 and 24 characters, fine. No problem, because when we plan out how we're going to name our Azure resources, we should have a standard naming convention. So in this case, I'm going to call this stor, for storage account, S-T-O-R. And then I'm going to give it a number to make it unique.
[Video description begins] He scrolls down the window and reaches a section titled INSTANCE DETAILS. The first field in this section is the Storage account name. He types stor14567 here. [Video description ends]
Then, I'm going to choose a storage location that reflects where it might be used geographically. Then I get to choose between Standard and Premium types of storage, where I can determine, for example, whether or not I have access to these cool and hot access tiers. If it's standard, I do have access to that, and I could choose BlobStorage for the account kind, but I could also choose Premium for performance.
[Video description begins] He selects Canada East in the Location field. The Performance field has 2 radio options- Standard and Premium. He selects Standard and clicks the drop-down menu in the next field, Account kind. There are 3 options here- StorageV2, Storage , and Blob Storage. He selects StorageV2 option. When he clicks the Premium radio option, the Account kind field shows only the first 2 options. He finally clicks the Standard option and Blob storage option. [Video description ends]
Now, notice I don't get BlobStorage available when I do that. So it's important to understand the ramifications of the choices you make here and what features will follow down below. So I want to work with BlobStorage here, so I'm going to leave it on standard, and I'm going to choose BlobStorage. Then I get to determine if I want replication. So locally-redundant storage, geo-redundant storage, and read-access geo-redundant storage. Think of locally redundant storage as meaning that your data is replicated only within an Azure data center.
So therefore, if you've got a problem with an Azure data center, you could lose all your data if you don't have it stored elsewhere. Geo-redundant storage will replicate your data across multiple Azure regions. So, in the case of an Azure data center problem, even an Azure regional disaster, your data's still been replicated elsewhere. Then you've also got read-ahead geo-redundant storage, RA-GRS. And what this means is that you've got a primary replica that's writable, and then the replica itself from that is only allowable through read access. So in this case, I'm going to leave it on locally-redundant storage. I'm going to leave it on the hot access tier under the assumption that I'm going to be accessing the Blobs that I will populate the storage account with on a frequent basis.
[Video description begins] The next field is Replication. There are 3 options in its drop down menu- Locally-redundant storage, Geo-redundant storage, and Read-access geo-redundant storage. He selects Locally-redundant storage. The last field is Access tier and it has 2 radio options- Cool and Hot. He selects Hot. Then, he clicks the Next button. [Video description ends]
Now, I can click Next to view any advanced options. Do I want secure transfers enabled? Do I want to limit the virtual networks from which access is allowed to this storage account? I'm not going to change anything here.
[Video description begins] The Advanced tab gets activated. The page has 3 sections- SECURITY, VIRTUAL NETWORKS, and DATA LAKE STORAGE GEN2. [Video description ends]
I can click Next and then apply tags if applicable.
[Video description begins] The Tags tab gets activated. A brief description displays. There are 3 fields in this tab- NAME, VALUE, and RESOURCE. He doesn't update any of the fields and clicks Next. [Video description ends]

I'm just going to click Next to review my settings. So it's running a file validation based on my selection looks good, so at this point I'm just going to go ahead and create my BlobStorage account.

[Video description begins] The last tab, Review+create, gets activated. It contains all the options he chose. A progress bar on the top shows the review and validation progress. When the review completes, a message, Validation passed, displays at the top of the screen. He clicks the Create button and a progress bar displays in the top-right corner of the window. It is captioned- Submitting deployment. [Video description ends]

We can see clearly our deployment is underway, we have a link here to our new storage account down below. But, notice on the left also, we've got a view just for Storage accounts.

[Video description begins] A new page displays. It is titled- Microsoft.StorageAccount-2019030007131545- Overview. The page is divided into 2 sections-left and right. The left section has a search field and 4 menus- Overview, Inputs, Outputs, and Template. The right section has 4 buttons- Delete, Cancel, Redeploy, and Refresh. Below the buttons, the deployment progress status displays. A table with all newly-created resources display. There is just 1 resource here- stor14567- he just created. [Video description ends]

So if I click that, I'll see any storage accounts. And remember, if you don't see your new storage account here, you can always click Refresh until such time that it shows up and the deployment has completed. So ours is showing up here, I'm going to click on the link for

[Video description begins] There are 3 storage accounts here, including Stor14567, shown as links in a table. In the top-right corner the deployment status shows completed. He closes the window. [Video description ends]

the name of my storage account to go and do its properties blade. And there are a number of things that I can do here, for

[Video description begins] He clicks the stor14567 link and its page opens. There are 2 sections - a navigator on the left with menus. The right section shows contents of the menu clicked in the navigator. [Video description ends]

example, if I scroll all the way down, I can click on Blobs and it says, we don't have any containers yet. Well, remember, containers are kind of like folders used to organize Blobs. So what I'm going to do then is click Container. I'm going to call this one pics, for pictures.

[Video description begins] He clicks the Blobs menu in the Blob service group in the navigator. Its window opens on the right. There are 4 buttons here- Container, Refresh, Delete, and Change access level. He clicks the Container button. A section titled New container displays. It has 2 fields- Name and Public access level. Two buttons- OK and Cancel- display at the bottom of the page. [Video description ends]

And then down below I can determine whether it should be private, so no anonymous access allowed. Or anonymous read access for the blob only, or anonymous read access for containers and blobs. Why don't we start up here with Private (no anonymous access); OK, and

[Video description begins] He types pics in the Name field. He clicks the drop-down menu in the Public access level field. There are 3 options- Private ( no anonymous access), Blob (anonymous read access for blobs only), and Container ( anonymous read access for containers and blobs ). He selects Private. Then, he clicks the OK button. [Video description ends]

after a moment there's the pics container. So I'll click it to open it up. That gives me a new properties blade related to the container, and from here I can upload Blobs.

[Video description begins] The pics container appears in the contents as a link. He clicks the link and the pics page opens. The page is divided into 2 sections- a navigator on the left and the contents on the right. There is no content in the pics container. In the right section are buttons captioned Upload, Refresh, Change access level, Delete, Acquire lease, and Break lease. [Video description ends]

So I'm going to go ahead and upload Blobs. When I do that on the far right, I'll click the Select a file button.

[Video description begins] He clicks the Upload button. A new window titled Upload blob, appears in the far-right side of the screen. There is a files field where a file can be searched to be uploaded as a blob. A check box captioned Overwrite if files already exist is also present. An Upload button is present at the bottom of the window. [Video description ends]

After you've selected a local file, and you can have multiple files. At this point you can open up Advanced to specify details about the upload whether it should be treated as a block blob or an append blob. In this case it's going to be a block blob.

[Video description begins] He searches the file dog.jpg in the Files field. Then, he clicks the Advanced drop down arrow. The Advanced section displays. It has 4 fields and an Upload button. The Authentication type field has 2 options- OAuth and SAS. The Blob type field is a drop-down type with 2 options- Block blob and Append blob. The Blob size field has a default value of 4MB and the last field Upload to folder is blank. [Video description ends]

And I'm going to click Upload. And after a moment we can see it's uploaded this jpg. It's showing up right here in the list, and

[Video description begins] When he clicks the Upload button, a message box displays in the top-right corner of the window. It says: Upload completed for dog.jpg. Dog.jpg file now shows in the pics page, as a clickable link. [Video description ends]

if I actually click on it, I'll see some details, or properties related to it. Notice that by default server-side encryption is enabled for protection of data at rest. So what I'm going to do then for the URL is click the little copy icon, because I'm going to open a new web browser window, we're going to see if we can access this Blob data, over HTTP using a web browser.

[Video description begins] When he clicks the dog.jpg link, its page displays. The page has 4 tabs- Overview, Snapshots, Edit blob, and Generate SAS. The Overview tab is active now and the blob URL displays. He clicks the copy icon next to the URL. [Video description ends]

Now, when I paste that URL up here, by default, I get this kind of an error message, resource not found. Well, that's because we didn't allow anonymous access, if you recall.

[Video description begins] He opens another browser window and pastes the copied URL there. An error message displays that reads: This XML file does not appear to have any style information associated with it. [Video description ends]

So if I go back into Azure, and why don't we go back to the point, I'm just using my links here, my breadcrumb trail. Why don't we back to the point where we can actually go into our folder. So there's pics, and I'm going to click, I'm looking at the overview on

[Video description begins] He goes back to the Azure portal window and clicks the pics link. The pics container window opens. [Video description ends]

the left, I'm going to click the Change access level button at the top. And here it is, private (no anonymous access). Let's say we choose Blob (anonymous read access for blobs only).

[Video description begins] He clicks the Change access level button on the top of the window. The page opens and he clicks the Public access level drop-down field. He selects the Blob (anonymous read access for blobs only) option in the field. [Video description ends]

Okay, let's try that. So I'm going to click OK. It says it successfully applied the change. So, let's go back into our browser here where previously it failed, and let's refresh it. And sure enough, now we have access to the picture of the dog. So we can see how we can build a storage account and configure a variety of Blob Storage options, and then how we can start to work with content in the Blob Storage account.



Azure Blob Storage CLI Management
  - You can use the Azure CLI to manage Azure storage accounts and the contents within them.
  - To get started here, I'm going to build a new storage account in Azure. I've already run az login, and I've already authenticated to my Azure account. So the next thing I want to do here is I'm going to go ahead and run the az storage account create, command prefix. Where I'm going to use -n for name, and I'm going to call this store, let's say I'm just going to make up the name of the storage account. Although make sure you adhere to the naming standards for Azure resources in your organization.

[Video description begins] He types and executes the following command: az storage account create -n stor1988 - g rg1 -l canadaeast --sku "Standard_ LRS ". [Video description ends]

Then I'm going to use -g and specify I want this deployed in a resource group I've already created called rg1. And -l for location, or Azure region, in this case let's say canadaeast, and then --sku to determine the type of replication I want. In this case, I want "Standard_LRS". That's locally redundant storage replication, essentially within an Azure datacenter, as opposed to geo-redundancy across regions.

So I'm going to go ahead and do this and press Enter. So it's going to create my storage account, and it's going to be called, as you can see stor, in this case, 1988. And we can see it's returned a lot of information about what it's just done. But what we're looking for here is the provisioningState being set to Succeeded. So we're going to clear the screen and run az storage account list.

[Video description begins] Next, he types and executes the following command: az storage account list. [Video description ends]

Now again, I'm going to get a lot of information for each storage account, which is fine. But let's say I just want to see the names of the storage accounts. So I'm going use the up arrow key to go through my previous command history. And I'm going to use a vertical bar or pipe symbol, now you can shift your backslash key on your keyboard to get that. Which means I want to take the result of the command on the left and feed it into what I'm about to specify to the right of the pipe. Which is the Windows find command.

And I'm going to tell it in quotes I'm looking for "name", N-A-M-E. This is a little more digestible. For instance, here I can quickly determine that yes, our new storage account, stor1988, has been created. Now when you want to work with a storage account, let's say programmatically as a developer. Or like we are here in a command line environment, you need an access key. Well here in the portal, if I go to the Storage accounts view, I can see our storage account is there. If I click on it, there's access keys shown here in the Properties blade.

And we've got a couple of access keys, key1 and key2, and you can regenerate them independently of one another. So that one could still be used by code that might reference a specific connection string or a key. While the other one, you are changing, because from a security standpoint, it's pretty smart to change keys periodically to enhance security. Now I could copy the keys here.

So I'm going to copy, let's say, the first key. It doesn't matter which one you use when you are using command line tools or programmatic access. Back here at the CLI you might wonder, well how do I do that from the CLI? How do I list keys? Well you can if you really want to. You would run az storage account keys list, and then you'll see the same type of thing that we would have looked at. Now, of course, I get an error because I didn't tell it which storage account. Well, that might be useful.

So how about --account-name stor1988, and then the resource group we have to specify too, --resource-group, in this case, rg1. And maybe I'll tell it --output, in tabular format, so table. And then that way we'll be able to easily digest Key1 and Key2. So we can see it and we could highlight it and copy, but I've already copied it. But you might wonder, why do we care? Why do we have to copy it? Well because I want to create a container in my storage account and then upload an on-premises file into that container.

But you can't do that until you start working with the access key, one of them, either one, it doesn't matter. So here we go, I'm going to clear the screen, and what I want to do is I want to create a container, so az storage container create. Now if I don't know what to from here, I can use --help to get help on what follows next, along with examples.

[Video description begins] He types and executes the following command: az storage container create --help. [Video description ends]

However, I'm just going to bring that back up here and remove the --help. At the end to create my storage account container, I'm going to specify name, --name. Let's call it pics, for pictures, --account-name, with the two c's here. Is going to be stor, S-T-O-R 1988, but that's not all I need because I need the account keys. So --account-key and I'll just paste that key in there. You wouldn't want to memorize that, so you can also stuff that into a variable or work with it however you please. So I'm going ahead and press Enter to build that container,

[Video description begins] He types and executes the following command: az storage container create --name pics --account - name stor1988 --account -key. He types the account key and presses enter. The output displays: { " created " : true }. [Video description ends]

and it looks like it says "created": true. Well, that's good news. Here in the current directory on drive C called samplefiles, if I do a dir, I've got a file called dog.jpeg.

[Video description begins] He types and executes the following command: dir. The output displays: volume in drive C is OS. The contents of samplefiles display. There are 2 directories and one file- dog.jpg in samplefiles. [Video description ends]

Let's upload that. So do that, I'm going to run az storage blob upload, that makes sense, and then I'm going to use --container-name, which in this case is pics --name. What do you want to call the blob? How about I call it the same thing, dog.jpg --file. Where's the file? Well that would be c:\samplefiles\dog.jpg.

There's no spaces in my folder or filename so I don't need to put anything in quotes. But bear in mind, that could be an issue depending on how you're doing this. I have to tie this to my storage account, of course, --account-name is stor1988. Make sure we type that in correctly. It'll always give us errors if we don't spell things correctly, so it's not a problem to quickly fix them. Next thing is the account key, of course, --account-key. And I'll just go ahead and paste that in there. And assuming the syntax is correct, when I press Enter, it will upload that file. And we're just going to flip over in a moment to the Azure Portal to check that out.

[Video description begins] He types and executes the following command: az storage blob upload -- container - name dog . jpg -- file c: \ samplefiles \ dog . jpg -- account - name stor1988 -- account - key. He types the account key and presses enter. The output displays: finished 100%. [Video description ends]

Okay, it looks like it's finished. Let's go to the portal.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. The page is divided into 2 sections. In the left section, is a menu navigation pane. The right section shows the page linked to the menu item clicked on the left. He scrolls down the navigation pane. [Video description ends]

When we were last here in the portal, we were looking at our storage account properties blade and we had gone to the access keys. Well, let's drill down a bit further down, shall we? Let's go down into Blobs, and there's the pics container, and

[Video description begins] He reaches the Blob service menu group and clicks Blobs. Its window displays on the right. Storage account is stor1988 and a table shows all the contents of stor1988. There is only 1 item -the pics container he just created. He clicks it. [Video description ends]

there's the dog JPG file. So we can work with this if we need to using the Azure CLI.

[Video description begins] The contents of the pics container display on the right. It contains only 1 file- dog.jpg. Its Blob Type is Block blob and its Lease State is Available. [Video description ends]


Azure Blob Storage PowerShell Management
We can manage Azure Storage accounts using Windows PowerShell cmdlets, either in the Azure Cloud Shell, which is accessible in the portal, or in this case here, on-premises where I've already downloaded and installed Azure PowerShell. So I've already run the connect-az account cmdlets to connect to my Azure account.
[Video description begins] The Administrator Windows PowerShell window displays. The command prompt reads PS C:\. [Video description ends]
So to build a storage account, I'm going to run a new-azstorage account cmdlet. Now, what I need to specify is the resource group name into which I want this deployed. So -resourcegroupname, in this case rg1, I've already got it created. -name for the storage account, in this case will be stor, let's say, 1989, following naming conventions of my organization. -location, that's the Azure geographical region, is going to be canadaeast. The -skuname, for replication purposes here, will be standard locally-redundant storage, or lrs. So in other words, within the Azure data center. Let's go ahead and press Enter and see what happens.
[Video description begins] He types and executes the following command: new -azstorageaccount -resourcegroupname rg1 -name stor1989 -location canadaeast -skuname "standard _lrs". [Video description ends]
Well, what happened is our storage account was created. Now, I am hard wiring everything like the name of the resource group and the name and the location. Of course, this is just an example. When you are scripting with PowerShell, with the CLI, you can get very fancy with this and use parameter values that you might ask the user for when running a script, and so on.
[Video description begins] The output displays. It is a table with columns storageaccountname, resourcegroupname, location, skuname, kind, accesstier, ptcreationtime, and provisionstate. One row of data displays. It tells the details of stor1989. Its ResourceGroupName is rg1, Location is Canadaeast, skuname is standardLRS, Kind is Storage, and ProvisioningState is Succeeded. [Video description ends]
But let's move on. Because now, to verify our work, we could use the portal, but instead, why don't we just run get-azstorageaccount. So we should see our newly created one, stor1989, somewhere in the list, and here it is right here.
[Video description begins] He types and executes the following command: get -azstorageaccount. The output displays. It is a table with the same columns as of the previous command, minus the column ProvisioningState. There are 6 rows of data in the tabtle. Stor1989 is also present. [Video description ends]
So we know it's there, and we know that we're doing this correctly. Let's do more, because this is so much fun. So I'm going to make a variable here called $ctx, for context. And the idea here is I can attach a context to PowerShell commands that work with a storage account. And so then I don't have to always repeat the storage account name and stuff like that.
So I'm going to run this variable, or create this variable, I should say, $ctx. It can be called anything. And it will contain, or =, the result of running get-azstorageaccount and -r rg1, that's the resource group into which my newly created storage account was deployed. And the name of it, if you recall, was stor1989.
[Video description begins] He types and executes the following command: $ctx = get -azstorageaccount -r rg1 -name stor 1989. [Video description ends]
Okay, so I want to make a reference to that storage account, and it's going to be referenced through the $ctx variable. So if I were to type $ctx, I can see that it's returning back information about that account. Actually, if I run $ctx.context, it gives me endpoint or
[Video description begins] He types and executes the following command: $ctx. The output displays. It is a table with all the original columns. The table contains a single row with details about stor1989. [Video description ends]

connection information, and that's really what I need here. Okay, so now that we have that knowledge, let's work further with it.

[Video description begins] He types and executes the following command: $ctx.context. The output displays. It is detailed information about stor1989. [Video description ends]

What I want to do here, really, is I want to create a container in my storage account, but we had to do that stuff first to set it all up. So new-azStoragecontainer. And then -name, what would you like to call it? How about we call it pics, for pictures, to follow our examples in some of the other demos. And I'm going to use -context and just give it my variable. Now, if I just give it, I'll just put here $ctx, because it is a variable.

[Video description begins] He types and executes the following command: new -azstoratecontainer -name "pics" -context $ctx. The command contains a typo so the output is incomprehensible. [Video description ends]

If I put that in, it doesn't really know what I'm talking about. And that's because if I bring up the arrow key, I want to reference the context property of the storage account, so .context.

[Video description begins] He types and executes the following command: new -azstoratecontainer -name "pics" -context $ctx. context. The command contains a typo. [Video description ends]

Well, if you spell things incorrectly, like I've done here, I didn't spell storage correctly, it's never going to work anyway. Let's just go back to our original version. Just so we can demonstrate here. But we need spell the cmdlet correctly. So storage, okay, yeah, new azstoragecontainer, okay, so it still doesn't like it, that's fine.

[Video description begins] He corrects the typo and changes storatecontainer to storagecontainer. Then, he executes the command. [Video description ends]

And that's what we really wanted to see. But if we reference the context property of our variable, it just loves it. So it's created our pics folder.

[Video description begins] He types and executes the following command: new -azstoragecontainer -name "pics" -context $ctx.context. The output displays. It is a table with 3 columns- Name, PublicAccess, and LastModified. The pics folder details show in the table. [Video description ends]

So let's get some content up there. If I change directory into the sample files folder I've prepared here,

[Video description begins] He types and executes the following command: cd .\samplefiles\. The command prompt changes to PS C:\samplefiles. [Video description ends]

I've got a picture of my dog, and the file's called dog.jpg.

[Video description begins] He types and executes the following command: dir. The output displays. It shows the content of directory: C: \ samplefiles. There is a table with 3 columns- mode, lastwritetime, and length name. There is just 1 file dog.jpg in the samplefiles directory. [Video description ends]

Who doesn't like pictures of dogs? So I'm going to go ahead and upload that to the pics container in my newly created storage account. So to do that, I'm going to run the set-azstorage, spell storage correctly this time, blobcontent. And then -file is going to be c:\samplefiles. There's no spaces here around my file name or within my file name, I should say, or within my folder name. So I don't have to put this in quotes because of that reason. And now what I want to do is tell the container I want that to go in, so -container, which in this case is pics. And then what do you want to call the blob? Well, I want to call it dog.jpg, although it could have a different name. And then, of course, once again -context, when this time we know what we're going to do. It's going to be our variable ctx, which points to our storage account and then call upon the .context property of that storage account.

[Video description begins] He types and executes the following command: set -azstorageblobcontent -file c:\ samplefiles\dog.jpg -container pics -blob dog.jpg -context $ctx .context. [Video description ends]

And we can see it looks like it's in the midst of uploading our jpg. So once that completes, we'll just double-check our work by flipping over to the portal, I guess we'll do that right now.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. [Video description ends]

So here in the portal, in the Storage accounts view, indeed, there's the stor1989 storage account. If I click it, and if we scroll down to the Properties blade and

[Video description begins] He scrolls down the menu section and clicks the Storage accounts menu. The window opens on the right and all the storage accounts display there. Stor1989 is also shown here as a link. [Video description ends]

click on Blobs on the left, we can see pics on the right.

[Video description begins] He clicks the stor1989 link and its window opens on the right. This page is also divided into 2 sections- a navigator on the left and the detailed page on the right. He scrolls down the navigator to the Blob service menu group. Here he clicks the Blobs menu and its window display here. There is just one container, pics, shown as a link. [Video description ends]

And within it, we should see dog.jpg.

[Video description begins] She clicks the pics link and its window displays. Dog.jpg is listed in its contents. [Video description ends]


Azure Files
If you've performed IT network administrator duties over the years, you've probably at some point shared a folder on a computer. And then connected to it from other computers.
[Video description begins] Screen title: Azure Files. [Video description ends]
And that's exactly what's going to happen here with Azure files, except that the shared folder's hosted in the Cloud. So it's a cloud-based file share that allows access over the SMB protocol, Server Message Block. Which is really what is used with Windows file and print sharing. You can mount these shares in the Azure Cloud from virtual machines running in the cloud. Or you can do it from on-premises machines and reach into Azure to get to that shared folder, assuming that firewall rules allow that.
So the client devices might be running a Windows operating system, the Mac OS, or even a Linux variant. As long as it supports SMB, it doesn't matter. That also includes apps on smartphones. So let's say you've got an Android smartphone, you could install an app that supports SMB and map a drive into the Azure Cloud to do this. So to manage Azure files, we can use the Azure Portal GUI. We can also manage and work with Azure file shares using the Azure CLI, and also, using Azure PowerShell cmdlets.
[Video description begins] A process infographic displays. It has the three steps to be followed for Azure file management. The first step is Azure Portal. The second step is Azure CLI, and the last step is Azure PowerShell commandlets. [Video description ends]
In order to work with Azure files, what do you need? First, you need a storage account in Azure. Within the storage account you can then configure your Azure file share. So you have to give it a share name and a quota, which is really just a size limit. Now remember, access from SMB, the Server Message Block protocol needs access to TCP port 445. So depending on where the clients are coming from that need to map to this or mount this shared folder. You're going to have to make firewall provisions to allow this to happen.
So from Windows, we might map a drive letter either using the GUI or the net use command. Like we would normally to map to a file server on-premises that has a shared folder. You can connect directly to the UNC path. You could even use a mount point path. Which really just means it's more like the Unix and Linux world. Where you've got a folder that you connect to that points to the other shared folder out in the Azure Cloud, as opposed to a drive letter.


Configure Azure File Storage
  - Use the Azure portal to configure Azure file storage. Remember, Azure file storage is really just defining a shared folder in the Azure cloud, much like you might designate a shared folder on a file server on-premises. The concept is the same. So how do we get started?
  - The first thing you need is a Storage account, so let's first go to the Storage accounts view over on the left.

[Video description begins] He clicks the Storage accounts menu in the navigator. Its window opens on the right side. It has buttons Add, Edit columns, Refresh, Assign tags, and Delete. There are fields for filtering search results. 6 storage account items display in a table format. [Video description ends]

So I've got a Storage account here called stor1989. We're going to use that one. Within the Properties blade for that storage account, I'm going to scroll all the way down until I see Files.

[Video description begins] He clicks the stor1989 link and its window opens. The page has a navigator on the left that he scrolls down to the File service menu group. He clicks Files and its window displays on the right. There are no files in the stor1989 container. 2 buttons- File share and Refresh - display on the top. [Video description ends]

Now, when I click Files on the right, I can see I don't have any file shares yet. So I'm going to click the add File share button at the top. And this one, I'm going to call, let's say shared_files. Now notice if I put in an underscore, do you see what happened there? It doesn't like it. And if I hover over the little red block with the white exclamation mark, it tells me the rules for naming this. And bear in mind that in Azure, unfortunately, the rules for naming resources are not 100% consistent, but that's why the help is right in front of us, at least in the GUI.

[Video description begins] He clicks the File share button and a File share window opens on the far-right side of the screen. There are 2 fields in this section- Name and Quota. 2 buttons- Create and Discard are also present. He types file_ shared in the Name field. A red exclamation point appears, indicating an error. Naming convention rules pop up when he hovers the mouse on the exclamation point. He removes the underscore and the exclamation point disappears. [Video description ends]

So anyways, I'm going to call this sharedfiles, and let's say for the for the Quota, maybe I'll set it to 4 gigabytes. And then I'll go ahead and create it, so I'm going to click Create.

[Video description begins] The sharedfiles file appears in the storage account. [Video description ends]

So right away, we can see it's there, sharedfiles. And if I click on it, I can actually upload content to it.

[Video description begins] He clicks sharedfiles and its window displays. It has 6 buttons- Connect, Upload, Add directory, Refresh, Delete share, and Quota. He hovers over all the buttons on the page. [Video description ends]

And you can add directories within it as well, so you can make subordinate subdirectories to organize large amounts of files. How about I click Upload to upload some content here?

[Video description begins] An Upload files panel opens on the far-right side of the screen. It has a field named Files and a small folder icon. An Upload button displays at the panel bottom. [Video description ends]

Over on the right, it opens up an Upload files blade. So I'm going to click the little folder icon, the blue folder icon, to upload a file. So I'm going to choose an on-premises file.

[Video description begins] When he hovers over the folder icon, No file chosen alt text displays. [Video description ends]

And once I've done that, I'll just click the Upload button. So it's in the midst of uploading that content.

[Video description begins] He clicks the folder icon. Dog.jpg appears in the Files field. A section titled Current uploads appears in the panel. Dog.jpg is getting uploaded here and a circular progress bar shows that 4MB out of 6MB has been uploaded. [Video description ends]

Now, the next thing we're going to do is we're going to figure out how we can make a connection to the shared folder from a virtual machine running within the Azure cloud. But you just as well could do it from on-premises, as long as TCP port 445 is opened up.

[Video description begins] When the entire file is uploaded a green tick mark appears beside the file name and a message with text- Upload completed- displays in the panel. [Video description ends]

So let me just go ahead and close this. When you're looking at a Azure file share, like we are now, you're going to see this Connect button up at the top.

[Video description begins] Dog.jpg appears in the main page. Next, he clicks the Connect button. A panel titled Connect appears on the far-right side of the screen. It has 3 tabs- Windows, Linux, and MacOS. Windows tab is active now. Here is a field named Drive Letter. The letter Z appears in this field. Below are PowerShell commands that you can use to connect to this file share from a Windows computer. 2 Commands display. [Video description ends]

And here, you can see how you can make a connection to it. For example, using the net use command in Windows. So I'm going to go ahead and copy the net use command to the Windows Clipboard,

[Video description begins] He highlights the second command and clicks the copy button next to it. The alt text- Copied- appears. [Video description ends]

and let's just go see what we've got here for virtual machines. I'm going to click Virtual machines on the left.

[Video description begins] In the Azure portal page, he clicks the virtual machines link in the navigator. The virtual machines page displays on the right. The page has buttons captioned Add, Reservations, Edit columns, Refresh, Assign tags, Start, Restart, Stop, Delete, and Services. Below are filter options such as Name, Resource groups, Types, Locations, Tags, and Grouping. 2 items display below. They are virtual machines named eastlinuxvm1 and eastwindowsvm1. The first machine's status is stopped and the second is running. [Video description ends]

So I've got a Windows virtual machine here called eastwindowsvm1, and it says the status is it's running. Okay, so I'm going to open that up and take note of the public IP.

[Video description begins] He clicks eastwindowsvm1 and its window appear. There are 6 buttons at the top- Connect, Start, Restart, Stop, Capture, Delete, and Refresh. Below are details such as Resource group, Status, Location, Subscription, subscription ID, Computer name, Operating system, size, public IP address, Virtual network, and DNS name. [Video description ends]

And on my on-premises computer here, I'll use the remote desktop protocol client to connect to that IP with the appropriate name and password defined when this virtual machine was created. Okay, so I've popped in that public IP address for that virtual machine, I'm going to go ahead and click Connect.

And then it's got the username that works for that virtual machine that I defined, and then I'll specify the password, and I'll click OK. So now what I'm going to do in my virtual machine is open up a command prompt, we'll just do this manually, but there are many ways this could be done. And I'm going to go ahead and paste in that net use command.

[Video description begins] He opens the Administrator Command Prompt window. The command prompt says C:\Users\cirving. [Video description ends]

So it's connecting to my Storage account, stor1989.file.core.windows.net\sharedfiles, that's the name of my share. And then it's got the other details to authenticate to it. So I'm going to go ahead and press Enter to see what happens. It says it completed successfully, really, that easy? Let's see, z: dir.

[Video description begins] He types and executes another command: z:. The command prompt changes to z:. Then he types and executes the following command: dir. The output displays: Volume in drive Z has no label. 1 file and 2 directories display. [Video description ends]
Hey, there's the dog.jpg file. And in the GUI, let's just say, here in my virtual machine in Azure, if I were to go to this PC on the left in Windows Explorer, there's my network location for shared files, and there's the dog file. And indeed, it looks like we've got a picture of a dog.
[Video description begins] He closes the command prompt window and opens the file manager again. He clicks this PC in the navigator and sharedfiles in the network locations. The dog.jpg file displays. [Video description ends]


Azure Key Vault
  - The Azure Key Vault is a secured location in the Azure cloud
    - What does it store and how is it really used?So what we can do is store secrets like cryptographic keys. 
    - You can even import or generate certificates, PKI certificates. You can create your own passwords. Now why would you do this?
  - You would store this in a central, safe location, all of these different types of security mechanisms. Because then you could have applications that your developers might build that will access the key vault to gain access to these items. That might be required to make connections to other application components out on the network, for example. So that's really what this is about.
  - Now when it comes to standards compliance, Azure Key Vault is backed by FIPS 1402-2 Level 2 HSM. What's that? That's a hardware security module. And so an HSM device is a firmware device that is used at certain standards. And this is a US government compliance standard for trustworthiness, to store the secrets. You can also take existing HSM keys that you might already have on-premises or with another provider and bring them in to your Azure Key Vault. So how does this work?

Well, to manage this whole ecosystem of secrets, you start by creating a key vault in Azure, whether you're going to use the portal or command line tools. And from there, you can then create secrets. So you can generate PKI certificates, you can create secret passwords. Or you can upload secrets like certificates, for example. Lastly, you would then configure apps. Now this is more of a developer thing, normally, to retrieve secrets from the key vault.

[Video description begins] A 3-step process infographic displays, outlining steps to create an Azure key vault. The first step is to create a key vault. The second step is to create or upload secrets. The last step is to configure apps to retrieve secrets from the key vault. [Video description ends]

So we're going to see how to do this in a couple of demos.


Implement an Azure Key Vault
In this demonstration, I'm going to create an Azure Key Vault, and I'm going to do it using the Azure portal. Now, why would you create a Key Vault? You create an Azure Key Vault because you want to store some kind of a secret, like passwords, or PKI certificates, or that kind of thing, cryptographic keys. Because your applications need that information, maybe to connect to other application components.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. The address bar contains the URL: https://portal . azure. com /#home. The page is divided into 2 sections. In the left section, is a navigator with menus such as create a resource, home, dashboard, all services and favorites . The right section shows the main Azure services. [Video description ends]

And so to begin the process of building my Azure Key Vault here in the portal, I'll click Create a resource, over on the left.

[Video description begins] He clicks the create a resource menu in the navigator. A page titled New opens on the right. It has a blank search field at the top. Below are two columns titled Azure marketplace and popular. In the azure marketplace column are menus such as get started, recently created, compute, networking and many others. In the popular column are quickstart tutorials for windows server 2016 datacenter, Ubuntu server, and many others. [Video description ends]

And I'll search for the word key, and right away I see Key Vault, perfect.

[Video description begins] He types key in the search field and selects key vault from the search results. [Video description ends]

And I'll click Create, and then I'll fill in the blanks,

[Video description begins] A page titled key vault displays and he scrolls down to reach the create vault button. He clicks it and a new window titled create key vault opens. [Video description ends]

what do you want to call this? How about we call it kv1, for Key Vault 1? Now, when I do that, that name is not unique, so it says, well,

[Video description begins] The window has a number of fields such as name, subscription, resource group, location, pricing tier, access policies, virtual network access, and others. [Video description ends]

that name is already in use. Okay, so let's go ahead and add some characters to it to make it unique, while adhering to organizational naming standards.

[Video description begins] He types kv1989 in the name field. [Video description ends]

So I am going to tie this, or deploy into an existing resource group. I've got my location, I'm not going to change any of the other items. We'll talk about access polices after we create the vault. But notice here, it says all networks can access this vault, potentially. So you can control the source from which a request to connect to the Key Vault comes from.

[Video description begins] He selects Rg1 from the resource group drop-down menu. In all the other fields he doesn't change the default values. The subscription field has pay-as-you-go, the location field has Canada East; the pricing tier is standard; access policies field contains 1 principal selected; and the virtual network access field contains all networks can access. [Video description ends]

But I'm going to leave it on the default for now, and I'll click Create, just to get our Key Vault created.

[Video description begins] He clicks the create button at the bottom of the window. [Video description ends]

And after a moment, it will be created.

[Video description begins] A message displays in the top-right corner of the window. It says: deployment succeeded and has 2 buttons- go to resource and pin to dashboard. [Video description ends]

So of course, I've got the little notification that popped up here. I can get that back by clicking the alarm bell.

[Video description begins] He clicks the bell-shaped icon next to the search field in the home page. It opens a notifications window showing all the events in the activity log. All the activities performed in Azure are listed with their start time. [Video description ends]

However, what I really want to do is just click All resources, over on the left.

[Video description begins] He clicks the all resources menu in the navigator. The detailed page opens on the right. It has buttons- add, edit columns, refresh, assign tags, delete, export to CSV, and try preview. Below the buttons the subscription mode displays. Then, filter options display, namely filter by name, resource groups, types, locations, tags, and grouping. According to the filter options selected, search results display. [Video description ends]

And if I were to look for kv, to filter out the list, there's kv1989, my Key Vault. Okay, I'm going to click on it to open up its properties.

[Video description begins] He types kv in the search by name field and one item-kv1989 displays in the search results. He clicks it. [Video description ends]

So at any point in time, if I decide that I want to delete it, I've got a Delete option. I can also choose to move it to another resource group, or

[Video description begins] The properties page of kv1989 displays. It has a search field at the top; a navigator on the left; and a details page on the right. 2 buttons- delete and move are also present. The move button has 2 options- move to another resource group and move to another subscription. At the bottom of the window is a monitoring section with a field titled show data for last. This is followed by time slots such as 1 hour, 6 hours, 12 hours, 1 day, 7 days, and 30 days. There is also an option to click for additional metrics. [Video description ends]

even a different Azure subscription. But what I really want to do here is scroll down just a little bit, and take a look at Access policies.

[Video description begins] In the navigator, he clicks the access policies menu. The detailed page opens on the right. It has 3 buttons- save, discard, and refresh. There is also an option to look up advanced policies. An add new button with a large plus icon is present below the buttons. A single access policy displays there. [Video description ends]

Here, I can see an existing access policy, but I can click Add new, where I can choose a template, for example. Maybe I only want someone to be able to manage secrets,

[Video description begins] A new window titled add access policy opens. It has an optional field titled configure from template. This is a drop-down field with many options. He selects secret management from the list. The other fields in the window are select principal, key permissions, select permissions, certificate permissions, and authorized application. [Video description ends]

as opposed to PKI certificates stored in this Key Vault. So I could choose that template, and choose a principal. Principal is a user or a group that I want to select that would have access to do that.

[Video description begins] He clicks the select principal field and a window pops up on the far right. It has a button titled invite with a large plus icon. Below that is a select field where you can select principal by name or email address. Some already available principals are listed below. He closes the window and then closes the add access policy window. A window displays with a warning- your unsaved edits will be discarded. He clicks the OK button in the warning box. [Video description ends]

So we can modify our access polices, I'm going to go ahead and close out of that. However, in another demo, we're going to talk about how you can come into Keys, Sequence, and Certificates, to start working with the actual content within the Key Vault.

[Video description begins] He returns to the all resources window. He points to the keys, secrets, and certificates menus in the access policies section of the window. [Video description ends]

Create an Azure Key Vault Secret

[Video description begins] Topic title: Create an Azure Key Vault Secret. The host for this session is Dan Lachance. [Video description ends]

An Azure Key Vault is only useful if it contains some kind of secret. Secrets like PKI certificates or cryptographic keys or passwords. And these would be used by code built by developers. The code would access the vault here. Gain access to some of these secrets, which it might need to authenticate to other services elsewhere.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. [Video description ends]

And so let's start here in the portal by going to the All resources view on the left. Where in the Filter by name field, I'll type kv because I know my key vault starts with that prefix.

[Video description begins] He clicks the All resources menu in the navigator. Its window opens on the right. It has buttons- Add, Edit columns, Refresh, Assign tags, Delete, Export to CSV, and Try preview. Below the buttons the Subscriptions mode displays. Then, filter options display, namely Name, Resource groups, Types, Locations, Tags, and Grouping. According to the filter options selected, search results display. He types kv in the Name field and one item-kv1989 displays in the search results. He clicks it. [Video description ends]

And there it is, kv1989.

[Video description begins] The properties page of kv1989 displays. It has a search field at the top; a navigator on the left; and a details page on the right. 2 buttons- Delete and Move are also present. In the navigator, he scrolls down to the Settings group. Here are menus such as Keys, Secrets, Certificates, Access policies, Firewalls, Properties, Locks, and Automation script. He clicks the Keys menu. It opens on the right. 3 buttons are present on the top, namely Generate/Import, Refresh, and Restore backup. A table with 3 columns- NAME, STATUS, and EXPIRATION DATE, displays below. There is no data available in the table. [Video description ends]

If I click it to open up its properties blade, as I scroll down, under Settings, I see Keys. And when I click it, any keys I've created that are stored in the vault will be listed here. There are none, currently, but I could click Generate or Import. And I could generate key pairs, or I could also import them from here or restore from backup.

[Video description begins] He clicks the Generate button and a new window titled Create a key opens. It has fields- Options, Key type, RSA key size, Set activation date, Set expiration date, and Enabled. He clicks the drop-down button on the Options field. It show 3 options- Generate, Import, and Restore backup. [Video description ends]

Now, I've got options, in this case, related to the generation of keys. So it says Generate, it could be RSA, EC, I've got the Key Size. So for example, let's say I call this Key1.

[Video description begins] He selects Generate. He types Key 1 in Name field. He leaves the default options in all the other fields. They are RSA in Key type; 2048 in RSA key size; and Yes in the Enabled field. He clicks the Create button. [Video description ends]

And I'll leave the defaults and just go ahead and create it. So now we've got a key called Key1 that now exists in this particular key vault.

[Video description begins] He returns to the properties page and now Key 1 displays in the Keys table. He clicks it and a new window titled Key1 opens. 4 buttons display at the top, namely New Version, Refresh, Delete, and Download Backup. Below the CURRENT VERSION of the key is displayed and its status is shown as enabled. [Video description ends]

And I can just click to follow that further down and down to get to the details related to it.

[Video description begins] He clicks the current key vault and its window opens on the right. Its properties display along with its Key Identifier and Settings. A Copy button is present next to the Key Identifier. [Video description ends]

Down below, I can see the Permitted operations. How can this key be used? For encryption, decryption, signatures, verifying signatures, and so on.

[Video description begins] A Permitted operations section is present below the Settings section. It has many check boxes captioned Encrypt, Sign, Wrap key, Decrypt, Verify, and Unwrap key. All boxes are checked. [Video description ends]

However, let's continue on talking about different types of items in the key vault, including secrets.

[Video description begins] He closes all the windows and returns to the key vault. Here he clicks Secrets in the Settings group in the navigator. Its window displays on the right. It is similar to the keys page and says that there are no available secrets now. [Video description ends]

So when I click the Secrets view, I can click Generate/Import. And I'm going to make a manual secret here called, how about, Secret1.

[Video description begins] He clicks Generate and a new window titled Create a secret opens. Its similar to the Create a key window. He types Secret 1 in the Name field and types a secret value in the Secret field. Then he clicks Create. [Video description ends]

And I'll enter in a secret value. Remember, this is what would be used by applications that reach into this vault to grab this stuff. I'll click Create. So I've now got a secret called Secret1 in the vault. And if I click it and just keep clicking on the links to get to the details. We could see, for example, if it's got an activation date of when it's allowed to start being used, when it expires. And I can also choose the Show Secret Value button to actually show my secret value.

[Video description begins] He repeats the steps he followed to create the key. He opens the newly-created secret and its page displays on the far right. Its similar to the keys page. He scrolls down to reach the Show Secret Value button. When he clicks it, the secret value he typed before displays in the Secret field and the button caption changes to Hide Secret Value. [Video description ends]

Finally, we can also work with PKI certificates here, either importing them or generating them.

[Video description begins] He closes all windows and returns to the key vault page. Here, he clicks Certificates in the navigator and its window displays. The page has 5 buttons- Generate, Refresh, Restore backup, Certificate contacts, and Certificate authorities. [Video description ends]

So if I go to Certificates and click the Generate/Import button, we can generate them or import files.

[Video description begins] He clicks the Generate button and a window titled Create a certificate opens. He selects Generate from the Method of Certificate Creation drop-down field. [Video description ends]

Now, we also get to choose things like a Certificate Authority. Certificate authority, or CA, is at the top of the hierarchy and it's the one that issues certificates. Bear in mind that if you generate a self-signed certificate, really, no device will trust it. Because every device, even mobile phones, such as within a web browser or external to the web browser.

Has a list of trusted certificate authorities whose certificates it will trust. And that's why when you connect to online banking, for instance, your web browser or your app on your mobile phone will trust a certificate. Because it trusts the certificate authority that issued it.

[Video description begins] He clicks the Type of Certificate Authority field. It shows a drop-down menu with 3 options- Self-signed certificate, Certificate issued by an integrated CA, and Certificate issued by a non-integrated CA. [Video description ends]

However, I'm not going to go ahead and create this. But now we get a sense of the types of items that we can create within an Azure Key Vault.

Retrieve Secrets from the Azure Key Vault

[Video description begins] Topic title: Retrieve Secrets from the Azure Key Vault. The host for this session is Dan Lachance. [Video description ends]

Once you've created an Azure Key Vault and populated it with secrets, how do you gain access to them? Well let's start by looking at how to do that here in the Azure portal where I'll go to the All resources view on the left.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. The address bar contains the URL: https://portal. azure.com /#home. The page is divided into 2 sections. In the left section, is a navigator with menus such as create a resource, home, dashboard, all services and favorites. The right section shows the main Azure services. He clicks the all resources menu in the navigator. The detailed page opens on the right. It has buttons- add, edit columns, refresh, assign tags, delete, export to CSV, and try preview. Below the buttons the subscription mode displays. Then, filter options display, namely filter by name, resource groups, types, locations, tags, and grouping. According to the filter options selected, search results display. [Video description ends]

And I will find the key vault I'm interested in, which in my case is called kv1989. When I open up the properties blade for that key vault, I can see, for

[Video description begins] He types kv in the filter by Name field and kv1989 displays in the search results. He clicks it and its detailed page opens. [Video description ends]

instance on the left, I've got keys, secrets and certificates. Well, I'm going to go to secrets, because I know I've got one here called Secret1.

[Video description begins] He clicks Secrets in the settings menu group in the navigator. A new window titled secret1 opens. The window has 4 buttons- New Version, Refresh, Delete, and Download Backup. The current version of secret 1 displays and its status is shown as enabled. [Video description ends]

And if I keep clicking on that secret, I'll get to the point where I can click the Show Secret Value button to expose the secret key. So that's how we can gain access to that secret using the portal.

[Video description begins] He clicks the Current Version and reaches a new window that has a button captioned show secret value. He clicks it and the secret value displays in the secret field. [Video description ends]

What about through the command line? Let's start by taking a look at PowerShell. Here in PowerShell I can use the get-az, for Azure, keyvaultsecret cmdlet. Now, I have to give it the name of the vault, so -vaultname in this case is kv1989 as we saw. Then I have to give it the name with a secret within that vault that I'm interested in. We've got one and we know it's called secret mode, we just looked at it in the portal. So -name secret1. The problem is I need to call on a property that will result from this command executing called secret value text. And you separate an object reference from its property using a dot.

[Video description begins] He opens the powershell command window. The command prompt reads as C:\samplefiles. Here, he types and executes the following command: get -azkeyvaultsecret-vaultnamekv1989-name secret1.secretvaluetext. [Video description ends]

However, we've got a problem here because if I press Enter, it's not going to really know what to do. And that's because PowerShell is trying to treat secret1.secretvaluetext as the value of the name parameter. But that's not what I want at all. I want to separate secretvaluetext from everything else. So I'm going to use the Up Arrow key to bring up that command and

[Video description begins] The output displays. It says bad request. [Video description ends]

the solution here, and this is a PowerShell thing. Is simply to enclose what you actually want to treat as a single statement so the PowerShell commandlet and its parameters, enclose it in parentheses. That's better, and so .secretvaluetext is a property reference outside of that, that's going to work. So if I press Enter, it returned the secret value here which is mydoghasfleas.

[Video description begins] He presses the up arrow key and the previous commadn appears on the command prompt. He adds parentheses to the command and now it reads as: ( get -azkeyvaultsecret -vaultname kv1989 -name secret1 ).secretvaluetext. The output displays:my dog has fleas. [Video description ends]

Let's take a look at how to do the same thing but in the Azure CLI. Now just like with PowerShell, in the Azure CLI, I have to have connected and authenticated to my Azure account, which is already done. It was done in Powershell, it's also done here in the CLI. So I'm going to run az keyvault secret show, there's a space between secret and show and keyvault, of course. --name, what is it called? Secret1 is the name of my secret. What's the name of the vault? --vault -name, and it's called kv1989. If we go ahead and press Enter and then after a moment we can see

[Video description begins] He opens the command prompt window of Azure. He tyeps and executes the following command: az keyvault secret show --name secret 1 --vault -name kv1989. [Video description ends]

the value here of that secret, Secret1 is my doghasfleas.                    
                    

                    
Software Defined Networking

[Video description begins] Topic Title: Software Defined Networking. Your host for this session is Dan Lachance. Screen title: Software Defined Networking (SDN). [Video description ends]

If you have previous IT networking experience, then you've probably configured routers or switches or other types of network appliances, some using a command line interface and perhaps other using a GUI tool. Software defined networking, otherwise called SDN, is common in cloud computing in that it hides the underlying technical complexities of configuring network items, and often, that means it's easy for us as cloud users to configure these types of network components using a GUI interface or even command line tools.

So with software defined networking, we've got physical network management that is done through a virtual type of graphical interface. So we have either the GUI or even CLI commands, which could come in the form of the Azure CLI or Azure PowerShell cmdlets, which both of course, are accessible through the Azure portal by going into the Azure cloud shell.

So whether you're using command line or GUI tools in Azure to configure network settings, in the end, it's still considered software defined networking, where it can be making changes to underline physical network equipment like routers, switches, and a variety of different types of gateways.

[Video description begins] Screen title: Azure Network Components. [Video description ends]

Pictured on the screen, you can see here in the Azure portal, we are in the midst of creating a new resource and the networking category has been selected over on the left.

[Video description begins] A screenshot of Azure portal is displayed on the screen. It is titled New. On the left, there is a column titled Azure Marketplace. Some of the options listed here are: Recently created, Compute, Networking, Storage, etc. Networking is currently selected. On the right, there is a column titled Featured. Some of the components here are: Virtual Network, Load Balancer, Application Gateway, etc. [Video description ends]

Take a look at some of the things over on the right. We can define a virtual network. Well, on-premises, that would be like configuring a new VLAN, perhaps in a switch or acquiring a new entire physical switch and connecting it to the network, so we can have devices deployed on that particular network, except, here in the Azure cloud, we're all doing it through a software interface, in this case, a GUI interface in the Azure portal.

The same is true if we were to start configuring a load balancer, as seen here, to distribute incoming traffic to backend nodes or configuring a virtual network gateway for VPN connectivity. So, all of these things in the end have to have some kind of underlying configuration at the network level, within an Azure data center. But those complexities are hidden from us, the cloud users, through software defined networking.

Azure Virtual Networks

[Video description begins] Topic title: Azure Virtual Networks. Your host for this session is Dan Lachance. Screen title: Azure Virtual Networks (VNets). [Video description ends]

Azure Virtual Networks or VNets are network definitions that we create within the Azure cloud. Now we would do this for the same reasons that we would define a new network physically on-premises, because we want to have a separate isolated part of the network where we deploy certain services, whether it's file servers, or DNS servers, or client stations.

So we would do it for the same types of reasons in the cloud, and this falls under the category of software defined networking or SDN, where the actual underlying technical complexities in making this happen at the data center level are hidden from us. Instead, we have easy-to-use command line tools or graphical interfaces such as through the Azure portal, through which we can configure these things.

So the management is varied, using the GUI or command line tools. When you deploy an Azure virtual network, there are some things to consider, one of which is the location or the Azure region where you are creating it. Now that could have an impact because you want to try to place that closest to where the use of resources that you will deploy into that VNet will be accessed from.

So, for instance, if you know that you're going to have some virtual machines accessed by client devices in the American western seaboard area, then you should probably create the VNet that will host those resources in the West US region. We then have to plan out our IPv4 CIDR notation. We've got to think about the IP address range or ranges that we want to use within our virtual network.

Now bear in mind, a virtual network contains subnets as we see here listed in the bottom left, and each subnet takes an IP address range that is derived from the parent IP address range assigned to the virtual network. So there's a hierarchy where subnets fall under virtual networks. We also have to think about whether we're going to be deploying firewall and/or DDoS protection in that VNet or any of its subnets. Firewall protection controls traffic flow either in or out of VNet subnets but distributed denial of service attacks can be subscribed to as an Azure service.

[Video description begins] Four instances for the Azure Virtual Networks are shown on the screen. These are: IPv4 CIDR notation, Firewalls and DDoS protection, VNets contain subnets, and VNet location (region). Screen title: Virtual Network Creation - Portal. [Video description ends]

Here we have a screenshot of the creation of a virtual network in the Azure portal.

[Video description begins] A screenshot for Create virtual network is shown on the screen. It has input boxes for Name, and Address Space, and drop-down menus for Subscription, Resource Group, and Location. The Name is vnet1 and Address space is 10.1.0.0/16. The Subscription is Pay-As-You-Go, Resource group is RG1, and Location is East US. Below it, a section titled Subnet is present. It has input boxes for Name and Address range. The Name is Subnet1 and Address range is 10.1.1.0/24. There are two options with radio buttons for DDoS protection: Basic and Standard. Basic is selected. There are two options for Service Endpoints: Enabled and Disabled. Disabled is selected. There are two options for Firewall: Enabled and Disabled. Disabled is selected. [Video description ends]

We can see at the top, we have to specify a unique name, followed by which we must specify an address space in CIDR notation. Now this is something that needs to be planned ahead of time as it would be if we were creating a brand new network on-premises. We can also see that in the portal, we are also creating a new subnet while we are creating the VNet and that the subnet IP address falls within the parent VNet range.

So we can use Azure virtual networks then to isolate deployed Azure resources. You could say that a VNet, in a loose way, is kind of like a security boundary when it comes to network transmissions. We can also link VNets to other VNets in Azure; this is called peering. And these VNets can even be in a different Azure subscription. VNets can also be used to link to an on-premises network, so you can essentially extend your on-premises network into the Azure cloud.

You can also customize the DNS configuration for VNet. By default, it uses Azure supplied DNS for name resolution. But depending on the services and workloads that you're deploying in the VNet, you might need your own custom DNS name resolution. And so you could opt to configure addresses for your own custom DNS servers instead of using Azure provided DNS.

And for resources that we deploy within Azure, we can determine whether we want them to stick with private IP addresses, that are not directly reachable, for example, from the Internet versus those that should have public IP addresses. So you might have a public IP address assigned to a host in a subnet, so you can get into it from across the Internet. And from there, you might further be able to get access to other internal hosts using their internal IP addresses.

So that's really a definition of a jumpbox that IT administrators would use. We know that Azure virtual subnets are created within an Azure VNet, and you can have more than one subnet within the VNet. Each subnet is assigned a network security group, an NSG, which is used to control in and outbound network traffic. And also, each subnet is assigned a routing table to control network traffic flow.

You might want to modify this, for instance, if you have a firewall appoints, deployed as a virtual machine, that you want all traffic to go through first to be inspected, either on its way in or on its way out of your Azure VNet. The subnet IP address range, remember, must fall within the parent VNet range.

So it's important to have planned the IP addressing that will be used ahead of time. You can also go back into a subnet and change IP address ranges at any time. So for example, if you decide you wanted to find a new subnet or a new range within a subnet, you can go ahead and do that, using either the Azure portal or command line tools.

[Video description begins] Topic title: Azure Virtual Networks. Your host for this session is Dan Lachance. Screen title: Azure Virtual Networks (VNets). [Video description ends]

Azure Virtual Networks or VNets are network definitions that we create within the Azure cloud. Now we would do this for the same reasons that we would define a new network physically on-premises, because we want to have a separate isolated part of the network where we deploy certain services, whether it's file servers, or DNS servers, or client stations.

So we would do it for the same types of reasons in the cloud, and this falls under the category of software defined networking or SDN, where the actual underlying technical complexities in making this happen at the data center level are hidden from us. Instead, we have easy-to-use command line tools or graphical interfaces such as through the Azure portal, through which we can configure these things.

So the management is varied, using the GUI or command line tools. When you deploy an Azure virtual network, there are some things to consider, one of which is the location or the Azure region where you are creating it. Now that could have an impact because you want to try to place that closest to where the use of resources that you will deploy into that VNet will be accessed from.

So, for instance, if you know that you're going to have some virtual machines accessed by client devices in the American western seaboard area, then you should probably create the VNet that will host those resources in the West US region. We then have to plan out our IPv4 CIDR notation. We've got to think about the IP address range or ranges that we want to use within our virtual network.

Now bear in mind, a virtual network contains subnets as we see here listed in the bottom left, and each subnet takes an IP address range that is derived from the parent IP address range assigned to the virtual network. So there's a hierarchy where subnets fall under virtual networks. We also have to think about whether we're going to be deploying firewall and/or DDoS protection in that VNet or any of its subnets. Firewall protection controls traffic flow either in or out of VNet subnets but distributed denial of service attacks can be subscribed to as an Azure service.

[Video description begins] Four instances for the Azure Virtual Networks are shown on the screen. These are: IPv4 CIDR notation, Firewalls and DDoS protection, VNets contain subnets, and VNet location (region). Screen title: Virtual Network Creation - Portal. [Video description ends]

Here we have a screenshot of the creation of a virtual network in the Azure portal.

[Video description begins] A screenshot for Create virtual network is shown on the screen. It has input boxes for Name, and Address Space, and drop-down menus for Subscription, Resource Group, and Location. The Name is vnet1 and Address space is 10.1.0.0/16. The Subscription is Pay-As-You-Go, Resource group is RG1, and Location is East US. Below it, a section titled Subnet is present. It has input boxes for Name and Address range. The Name is Subnet1 and Address range is 10.1.1.0/24. There are two options with radio buttons for DDoS protection: Basic and Standard. Basic is selected. There are two options for Service Endpoints: Enabled and Disabled. Disabled is selected. There are two options for Firewall: Enabled and Disabled. Disabled is selected. [Video description ends]

We can see at the top, we have to specify a unique name, followed by which we must specify an address space in CIDR notation. Now this is something that needs to be planned ahead of time as it would be if we were creating a brand new network on-premises. We can also see that in the portal, we are also creating a new subnet while we are creating the VNet and that the subnet IP address falls within the parent VNet range.

So we can use Azure virtual networks then to isolate deployed Azure resources. You could say that a VNet, in a loose way, is kind of like a security boundary when it comes to network transmissions. We can also link VNets to other VNets in Azure; this is called peering. And these VNets can even be in a different Azure subscription.

VNets can also be used to link to an on-premises network, so you can essentially extend your on-premises network into the Azure cloud. You can also customize the DNS configuration for VNet. By default, it uses Azure supplied DNS for name resolution. But depending on the services and workloads that you're deploying in the VNet, you might need your own custom DNS name resolution.

And so you could opt to configure addresses for your own custom DNS servers instead of using Azure provided DNS. And for resources that we deploy within Azure, we can determine whether we want them to stick with private IP addresses, that are not directly reachable, for example, from the Internet versus those that should have public IP addresses. So you might have a public IP address assigned to a host in a subnet, so you can get into it from across the Internet.

And from there, you might further be able to get access to other internal hosts using their internal IP addresses. So that's really a definition of a jumpbox that IT administrators would use. We know that Azure virtual subnets are created within an Azure VNet, and you can have more than one subnet within the VNet.

Each subnet is assigned a network security group, an NSG, which is used to control in and outbound network traffic. And also, each subnet is assigned a routing table to control network traffic flow. You might want to modify this, for instance, if you have a firewall appoints, deployed as a virtual machine, that you want all traffic to go through first to be inspected, either on its way in or on its way out of your Azure VNet.

The subnet IP address range, remember, must fall within the parent VNet range. So it's important to have planned the IP addressing that will be used ahead of time. You can also go back into a subnet and change IP address ranges at any time. So for example, if you decide you wanted to find a new subnet or a new range within a subnet, you can go ahead and do that, using either the Azure portal or command line tools.


Azure Virtual Network GUI Management
  - A Microsoft Azure webpage opens. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is present on this screen with the following options: Create a resource, Home, Dashboard, All services, and Favorites. The center pane has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]
  - Now, when I create a new virtual network, or VNet, in the Azure cloud, I need to have some upfront planning, much like you would do if you were about to set up a new network on-premises. Now, if you don't have that experience from the past, what we're really talking about doing is first of all determining, do we need another network in the first place?

Normally, you might need that if you're going to, for example, deploy a test web application you want to keep it isolated network-wise from other resources in production. And so, on-premises you might configure a switch with a new VLAN, a virtual local area network, so you'd also have to think about things like IP address ranges. So here in Azure, I'm going to begin the process of creating my new virtual network by clicking Create a resource in the upper-left.

[Video description begins] He clicks the Create a resource option from the navigation pane. A page titled New opens. At the top, a search bar is present. Below it, a column titled Azure Marketplace is present. Some of the options here are: Get started, Recently created, Compute, Networking, Databases, etc. Another column titled Popular is also present on the screen. Some of the items here are: Windows Server 2016 VM, Ubuntu Server 18.04 VM, Web App, etc. [Video description ends]

I could either search for what I want to create, so I might type in virtual network, and I can see virtual network shows up, or I could browse through the presented categories in the GUI.

[Video description begins] In the search bar, he types: virtual network. Two options appear: virtual network and Virtual network gateway. [Video description ends]

So if I click Networking, here's Virtual network over on the right.

[Video description begins] From the Azure Marketplace column, he selects Networking. A Featured column appears on the right side. It has the following options: Virtual network, Load Balancer, Application Gateway, etc. He selects Virtual network. [Video description ends]

So I'm gonna click on it.

[Video description begins] A page titled Create virtual network appears. It has input boxes for Name and Address Space, and drop-down menus for Subscription, Resource group, and Location. Below it, a section titled Subnet is present. It has input boxes for Name and Address range. There are two options with radio buttons for DDoS protection: Basic and Standard. Basic is selected by default. There are two options for Service endpoints: Enabled and Disabled. Disabled is selected by default. There are two options for Firewall: Enabled and Disabled. Disabled is selected by default. At the bottom of the page, there are two buttons: Create and Automation options. [Video description ends]

We need to have a standard naming convention we adhere to when it comes to the naming of Azure resources. So in this case, I'm going to call this EastVnet1.

[Video description begins] In the input box for Name, he types: EastVnet1. [Video description ends]

We mentioned that we should have pre-planned an IP address space that we want to use. So, for example, here I'm going to specify 10.1.0.0/16. So this is CIDR notation, C-I-D-R, where we use the slash and the number of bits in the subnet mask.

[Video description begins] In the input box for Address space, he types: 10.1.0.0/16. [Video description ends]

Here, I'm specifying /16, so that tells us then that the first two octets, or the first two bytes, 10.1, identify the network for this VNet. We can split that up further when we start creating subnets within this VNet. So I'm going to tie this to my subscription. I can either create a new resource group or choose an existing one. I'm going to choose an existing one from the list that I've previously created, and the Location I'm going to leave as Canada East, that's my region.

[Video description begins] For Subscription, he retains the default value: Pay-As-You-Go. For Resource group, he clicks the drop-down menu, which expands to show the following option: Rg1. He selects it. [Video description ends]

[Video description begins] For Location, he goes with the default option: Canada East. [Video description ends]

Down below, it wants to call the Subnet default. I don't want it called that, so I'm gonna call this EastSubnet1. Now, after I've done that, the next thing I want to do is specify the address range for this subnet. Now, if I go off on a tangent and specify, let's say, 12.1.0.0/16, when I tab out of there it gives me an error and that's because this address range does not fall within the VNet address range listed up above.

So what I'm going to do then, is use 10.1, let's say, .1.0, which means this is a network address, not an address for a specific host, and then /24. So I'm using a 24-bit subnet mask here for this subnet within my VNet which tells me that the first three numbers here, the first three octets, are being used to identify my network. When I tab out of there, notice we get the green check mark. You'll see this everywhere in the Azure portal; it's a good thing. It's telling you that what you're doing is acceptable; it's correct, when it comes to a valid name or in this case, a valid IP address range.

[Video description begins] In the Subnet section, the Name is default. The presenter deletes default and types: EastSubnet1. For Address range, he types: 12.1.0.0/16. An error appears. He then clears the input box and types: 10.1.1.0/24. A green tick mark appears next to it. [Video description ends]

For DDoS protection, I'll leave it on Basic. I'm not going to change any of the other settings here for Service endpoints or Firewall. I'm simply going to click Create.

[Video description begins] He clicks the Create button. [Video description ends]

Now, after a moment, it will have created both the virtual network as well as the subnet. So we have the message in the upper-right about the Deployment in progress. And at any point in time, we can just click the little alarm bell icon for notifications in this session.

[Video description begins] The Microsoft Azure home page appears on the screen. A message appears in the top-right corner. It reads: Deployment in progress. He clicks the Notification icon from the menu bar, which expands to show the progress notification. [Video description ends]

I can then click on All resources, over on the left, if I want to start to see the items that we've just created. For example, we can now see that we've got EastVnet1. We can see it's tied to the resource group called Rg1 and it was deployed in the Canada East region.

[Video description begins] He clicks the All resources option from the navigation pane. A new page titled All resources appears on the screen. The following buttons are present below the title: Add, Edit Columns, Refresh, etc. Below the buttons, there is an input box for name, and drop-down menus for resource groups, types, location, etc. A table is present below these input boxes. It has the following columns: Name, Type, Resource Group, Location, etc. A resource named EastVnet1 is present in the table. [Video description ends]

Now, I could click on the link for the name of that VNet to open up its Properties blade.

[Video description begins] He clicks on EastVnet1 from the table. A new page titled EastVnet1 appears. It has a navigation pane with the following options: Overview, Activity log, Tags, Subnets, etc. [Video description ends]

And for example, I might want to add tags to assign it to a department or a project. But interestingly, this is where I will see subnets. So the subnet itself is not a standalone Azure resource like the VNet is, and shows up as such. Instead, we get to the subnets for a VNet, because it's within that in the property sheet. And that's because it's part of the hierarchy, you can't have a subnet without a VNet.

[Video description begins] He clicks on Tags from the navigation pane. A new page titled: EastVnet1 - Tags appears. It has drop-down menus for Name and Value. He clicks on Subnets from the navigation pane. A new page titled EastVnet1- Subnets appears. It has a table with the following columns: Name, Address Range, Available Addresses, and Security Group. A Subnet named EastSubnet1 is shown in the table. [Video description ends]

So we could also select our subnet from here to open up its details.

[Video description begins] He clicks on EastSubnet1 from the table. A new page titled EastSubnet1 appears. It has an input box for Address range (CIDR block) and the following sections: Available addresses, Network security group, Route table, etc. [Video description ends]

So we can see the address range. We can see whether it's assigned with the network security group to control network traffic. And we'll be focusing on that a little bit later.

[Video description begins] He clicks the cross button on the top-right corner of the page. The screen changes back to the page: EastVnet1 - Subnets. [Video description ends]

But suffice it to say that at this point we've now got one virtual network that we've deployed in the Azure Cloud.
[Video description begins] He again clicks the cross button on the top-right corner of the page. The screen changes back to the page: All resources. [Video description ends]



Azure Virtual Network CLI Management
  - Using the Azure CLI to create an Azure virtual network and subnet. 
    - You can use the CLI through the Azure portal or you can use it the way I'm doing it by downloading and installing the CLI on a station. 
      - This needs to be downloaded and installed on an on-premises station running Windows 10.
  - First run the az login command to authenticate to my Azure account. So the first thing I am going to do here then is type az network vnet --help, so I can figure out what the next level commands are related to working with virtual networks.

[Video description begins] In the command line, he types: az network vnet --help and presses Enter. The following sections appear on the screen: Group, Subgroups, and Commands. Each section has a list of items with their definitions. [Video description ends]

The first thing I see here is create. And, of course, we can take that step further and run az network vnet create --help to get the next level commands that we would use in our syntax.

[Video description begins] Under Commands section, he highlights create. He then types: cls and presses Enter. The screen clears. In the command line, he types: az network vnet create --help. He presses Enter and the following list of Arguments appears: Subnet Arguments, Global Arguments, Examples, etc. [Video description ends]

So now that we have a sense of how we can get help on this, let's get to it. I'm going to run az network vnet create as we saw in the help screen. And I'm gonna tie that to a resource group, so -g that I've already created called rg1. The name of this -n, let's say, will be eastVnet2. And I'm gonna use the --address-prefix parameter. And this would have been planned ahead of time, of course, but, let's say, I've planned to use the 14.1.0.0/16 addressing.

So the /16 means we're using CIDR notation that identifies how many bits remain in the subnet mask. So in this case, my network address is 14.1, at least for the Vnet itself, so that's fine. I'm gonna use --subnet-name to also build the subnet within this Vnet. And I want this to be called Subnet1 and I'm gonna use the IP address range for the subnet within that VNet range. So --subnet-prefix, and, in this case, I'm going to use, let's say, 14.1.1.0, it's a network address, /24 bits. And I'll go ahead and press Enter.

[Video description begins] In the command line, he types: az network vnet create -g rg1 -n EastVnet2 --address-prefix 14.1.0.0/16 --subnet-name Subnet1 --subnet-prefix 14.1.1.0/24 and presses Enter. In the result output, details aboutid, Purpose, routeTable, etc. appear. [Video description ends]

And after a moment, we can see the returned JSON which indicates that it successfully provisioned this resource, the Vnet and the subnet. And we can even list it here in the Azure CLI, for example, by running az network vnet list. Now what I might wanna do is pipe that to the find command in Windows and tell I only want to see the names, I don't want to see all of the other properties.

[Video description begins] He types: az network vnet list | find "name" and presses Enter. In the result output, details of names appear. [Video description ends]

And sure enough, we can see our newly created EastVnet2 virtual network along with its subnet, Subnet1.

[Video description begins] He highlights the output line 7. It reads: "name": "EastVnet2", and hovers over line 8. It reads: "name": "Subnet1",. [Video description ends]


Azure Virtual Network PowerShell Management
  - You can use PowerShell cmdlets to manage Azure virtual networks.
Here, in PowerShell, I've already run the Connect-AzAccount cmdlet to authenticate to my Azure account. Nowm I'm running PowerShell here on-premises on my station, where I've downloaded and installed the Azure PowerShell module. So to get started, I'm going to create a variable that I'm going to call $vnet. In PowerShell, variables are always prefixed with the dollar sign.

I'm going to say equals, and what I want to put in that variable is the result of this PowerShell cmdlet, new-azvirtualnetwork. Then I'll use -resourcegroupname, and I'm going to put this or deploy this into a resource group I've already created called rg1. I'm going to set -location to canadaeast.

And -name to EastVnet3 and -addressprefix, which I would have planned ahead of time just like the nomenclature for these things, 15.1.0.0/16. So we've got a 16-bit subnet mask, and what that means here is my network address, of course, is 15.1. So let's go ahead and press Enter to populate the $vnet variable. We're going to use that a little bit later, but we're not finished because we need to also define a subnet.

[Video description begins] In the command line, he types: $vnet=new-azvirtualnetwork -resourcegroupname rg1 -location canadaeast -name EastVnet3 -addressprefix 15.1.0.0/16 and presses Enter. [Video description ends]

So here, I'm going to create a variable called $subnet, into which I will store the result of add-azvirtualnetworksubnetconfig -name. Let's call this Subnet1, -addressprefix needs to fall somewhere under the Vnet range, so in this case how about 15.1.1.0/24?

It's a 24-bit subnet mask, in other words, the network address for the subnet is 15.1.1. Now, we're not finished because we need to tie this to our virtual network. And we can do that with -virtualnetwork, and we can just pass it our variable we defined above, $vnet. So let's go ahead and press Enter.

[Video description begins] In the next command line, he types: $subnet=add-azvirtualnetworksubnetconfig -name Subnet1 -addressprefix 15.1.1.0/24 -virtualnetwork $vnet and presses Enter. [Video description ends]

Finally, what I want to do is use our $vnet variable and simply pipe the result of that to the set-azvirtualnetwork cmdlet, which means we want to make a change to the virtual network. In other words, we want to make sure our subnet that we've just defined above is actually added to that Vnet. So I'm going to go ahead and press Enter.

[Video description begins] In the next line, he types: $vnet | set-azvirtualnetwork and presses Enter. [Video description ends]

Next thing we'll do, it looks good, is we'll just pop over into the Azure portal and take a peek at the result of our efforts.

[Video description begins] In the result output, a list of details appears on the screen. Some of these are DhcpOptions, Subnets, VirtualNetworkPeerings, etc. A Microsoft Azure web page opens. It has a navigation pane with the following options: Create a resource, Home, Dashboard, etc. A page titled Virtual networks is open. Below it, there is a table with the following columns: Name, Resource Group, Location, etc. Three files are shown in the table: EastVnet1, EastVnet2, and EastVnet3. [Video description ends]

And here in the portal, on the left, I've clicked on the Virtual networks view and indeed we can see our newly created virtual network EastVNet3. And if I click on it to pull up its Properties blade, and if we click on Subnets, we'll see, there's Subnet1 with the appropriate IP address range.

[Video description begins] He clicks the EastVnet3 file. A new page titled EastVnet3 appears. It has a navigation pane with the following options: Overview, Subnets, Firewall, etc. He clicks on Subnets. A new page titled EastVnet3 - Subnets appears on the screen. It has a table with the following columns: Name, Address Range, Available Addresses, etc. The table has a file named Subnet1. He points to its Address range, which is 15.1.1.0/24. [Video description ends]


Azure IP Addresses
  - IP addressing is used in the Azure cloud to allow different devices to communicate, such as virtual machines or database server instances. And as such, it's important to have a solid understanding of how IP addressing actually works in Azure. Azure devices, such as virtual machines, can have private addresses or public addresses. A public IP address would be used, for example, to allow access from the public Internet directly into a virtual machine.

[Video description begins] Four instances for Azure IP Addressing are shown on the screen. These are: Public address, Dynamic IP address, Static IP address, and Private address. [Video description ends]

Now at the same time, bear in mind that the public IP addressing is something that is configured in Azure as an Azure resource. It's not something that we configure the way you would normally configure TCP IP within the virtual machine operating system. And that's an important distinction. So if it's a Windows host, and you type IP config at the command line for an Azure virtual machine, you won't see the public IP address. Instead, the public IP address is controlled through Azure, through a resource.

We can also set static or unchanging IP addresses, as well as configuring dynamic or changing IP addressing. Static IP addressing is going to be important when you need the IP address to stay the same. The way it works in Azure is that the IP address will be allocated to the resource until the resource is deleted. So if that resource happens to be a virtual machine in Azure, then the IP address it gets will stay with it until you delete it.

Even if it's shut down, it will still retain the address when you fire up that virtual machine later on. This is definitely useful when you need the IP address to remain the same. Example of this might be if you're defining your own custom DNS server for name resolution. Static IP addresses get assigned by an Azure address pool. So while you can't specifically select the IP that you want to assign, once your resource gets it, it gets it until the resource is removed from Azure.

Dynamic IP addresses are useful when you don't really care if the IP address changes. And so the IP address could change within each invocation of a service such as each time that you stop a virtual machine. When you fire it back up, you might always get a different private IP address in the case of dynamic private IPs or a dynamic public IP. So as long as you don't need to depend on that address remain the same, dynamic IP addresses would be the correct selection.

[Video description begins] Screen title: Azure Private IP Addressing. [Video description ends]

With Azure private IP addressing, you can use both IPv4 and IPv6. Both static allocation of IP addresses, where you can't choose the address you get, but once you get it, you've got it until the resource is deleted, can be used as well as dynamic allocation of IP addresses. And these addresses are allocated or set, if you're doing it manually from the VNet subnet IP range.

So you have to know what that range is for the subnet in order to know what to assign if you're doing it statically. You can also use private IP addressing within a VNet to allow communication between deployed resources like virtual machines, or also you can use private IP addressing if your VNet is connected through a VPN or an ExpressRoute circuit to an on-premises network.

[Video description begins] Screen title: Azure Public IP Addressing. [Video description ends]

You can also assign public IP addresses as we have mentioned, whether they be IPv4 or IPv6. And like private IP addresses they can be assigned statically or dynamically. Now, the public IP address will allow incoming and outgoing Internet connections. Now to be clear, even if a public IP address isn't associated with a virtual machine, let's say, that virtual machine will still be able to get out to the Internet.

So what we are talking about is the inability of a connection to be initiated from the Internet into a virtual machine that has only a private IP address. Public IPv6 addresses currently are useful in Azure only for public-facing load balancers. So IP addressing, whether it's public, private, static, or dynamic, needs to be planned for ahead of time. And we need to think about certain services that might require unchanging addresses that might even need to be reachable from the public Internet.


Azure VPN Gateway
  - Virtual Private Networks, or VPNs, have long been used by business users to allow a secured way to connect over the internet to a private network. And that's what the Azure VPN gateway is also for. It provides an encrypted tunnel between two endpoints. Those endpoints could be one VNet in Azure to another, or more often than not, it would be a link from an on-premises network or an on-premises individual client station to a VNet in the Azure cloud.

In order to deploy the Azure VPN gateway, you need to define a gateway subnet in your Azure virtual network. And the subnet needs to be named GatewaySubnet. But that's not a problem in the portal, for instance, because that name is set and you cannot change it. What happens in the background is two virtual machines get deployed in the Gateway Subnet. However, they are not directly manageable, nor should you deploy anything else into that specific subnet. It should be set aside for this purpose only.

There are two types of Azure VPN gateway configurations: point-to-site and site-to-site. With the point-to-site configuration, it supports SSTP and IPsec protocols. However, you don't need a VPN device on the client's side. So it really provides a single device VPN connection. Now that device could be a laptop used by a traveling user that might travel and need to make a secured connection into Azure to access a line of business application.

Site-to-site VPN configurations use IPsec in Azure. This might be used, for instance, to link our on-premises network to the VNet. And in order for this to work, we need to have some kind of a VPN device on our on-premises network, unlike with a point-to-site configuration. Now that VPN device could come in the form of software through Windows Routing and Remote Access Service, Windows RRAS, or it could be an actual VPN appliance. Either way, we need a public facing IPv4 address to establish the encrypted tunnel from on-premises to our VNet in Microsoft Azure. Now if you're going to be configuring a VNet to VNet connection in Azure, then you don't actually need a VPN device; it's already taken care of.

Configure an Azure Point-to-Site VPN

[Video description begins] Topic Title: Configure an Azure Point-to-Site VPN. Your host for this session is Dan Lachance. [Video description ends]

An Azure point-to-site VPN is essentially a client-to-site VPN.

[Video description begins] A Microsoft Azure webpage opens. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present on this screen. The options here are: Create a resource, Home, Dashboard, All services, and Favorites. The main body of the page has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

We're going to go ahead and implement that here through the portal. So to get started, I'm going to open up an existing virtual network. To do that I'm going to go to my Virtual networks view on the left here in the portal.

[Video description begins] From the Favorites section in the navigation pane, the presenter clicks on Virtual networks. A page titled Virtual networks appears. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons there is an input box for name and drop-down menus for resource group, location, tags, and grouping. Below these fields, there is a table with the following columns: Name, Resource Group, Location, and Subscription. Three rows of data are present in this table. [Video description ends]

And I'm going to click on my first virtual network here, EastVnet1.

[Video description begins] He clicks on EastVnet1 from the table. A page titled EastVnet1 appears. It has a navigation pane with the following options: Overview, Activity log, Tags, etc. The Overview page is currently displayed. The page has the following buttons on the top: Refresh, Move, and Delete. Below the buttons, a few details are present. These include: Resource group, Location, Subscription, Subscription ID, etc. [Video description ends]

When I click on it to pull up its Properties blade, I can then click on Subnets.

[Video description begins] From the navigation pane, he clicks on Subnets. A page for Subnets opens up. It has two buttons on top: + Subnet and + Gateway subnet. Below the buttons there is a table with the following columns: Name, Address Range, Available Addresses, and Security Group. The table has one row of data. [Video description ends]

Now the reason I'm here is because when you want to set up a point-to-site VPN, you have to choose a virtual network where you're going to create what's called a gateway subnet, which is required for this type of point-to-site VPN connectivity. So, notice that we've got a button here called Gateway subnet with a plus sign. So to add one, we're going to go ahead and click on that.

[Video description begins] He clicks the + Gateway subnet button. A page titled Add subnet appears. It has input boxes for Name and Address range. The default value for Address range is 10.1.0.0/24. There is a drop-down menu for Route table. No Route table is selected. Under the heading Service endpoints, there is a drop-down menu for Services. No service is selected. Under the heading Subnet delegation, there is a drop-down menu for Delegate subnet to a service. No subnet is selected. At the bottom there is an OK button. [Video description ends]

And here I'm going to specify, let's say, an address range for this subnet of 10.1.2.0/24.

[Video description begins] In the input box for Address range, he types 10.1.2.0/24. [Video description ends]

Now down below, I'm not going to make any other changes, I'm simply going to click OK. So you need to have this gateway subnet defined in order to move further with your configuration of a point-to-site VPN.

[Video description begins] He clicks the OK button. A page titled EastVnet1-Subnets opens up. It has a navigation pane. The page has a table with the following columns: Name, Address Range, Available Addresses, and Security Group. The table has two rows of data. The first Subnet is EastSubnet1 and the second Subnet is Gateway Subnet. [Video description ends]

Now the next thing I need to do is create what's called a virtual network gateway. I don't do that here in the Properties blade of a virtual network, it's its own separate Azure resource. And so I'm going to click on Create a resource in the upper-left, and what I'm going to do is, let's say, search for virtual network gateway.

[Video description begins] From the navigation pane of the home screen, he clicks on Create a resource. A screen titled New appears. It has a search bar and a column titled Azure Marketplace. Some of the items here are: Get started, Recently created, Compute, Networking, Databases, etc. A column titled Popular is also present on this screen. Some of the items here are: Windows Server 2016 Datacenter, Ubuntu Server 18.04 LTS, Web App, etc. [Video description ends]

So, if I start searching for that virtual network gateway, and we could see it pops up in the list, I'm going to go ahead and click on that and click the Create button on the introductory screen.

[Video description begins] In the search bar, he types virtual network gateway. A result for Virtual network gateway appears. [Video description ends]

[Video description begins] He clicks on Virtual network gateway. A page titled Virtual network gateway appears. It has a drop-down menu for Select a software plan. Virtual network gateway is selected by default. Below it, there is a Create button. He clicks the Create button. A page titled Create virtual network gateway appears. It has the following fields: Name, Gateway type, VPN type, SKU, Virtual network, Public IP address, etc. At the bottom, there is a Create button. [Video description ends]

And I'm going to start by giving it a name. How about we call it vpngw1, for VPN gateway 1?

[Video description begins] In the input box for Name, he types vpngw1. [Video description ends]

It's not for a dedicated express route circuit, which is used if you have a dedicated network link from your network to the Azure cloud without going through the Internet. That's not the case here. This is going to be going over the Internet, hence VPN.

[Video description begins] For Gateway type, there are two options: VPN and ExpressRoute. VPN is selected by default. [Video description ends]

It's going to be a route-based VPN connection.

[Video description begins] For VPN type, there are two options: Route-based and Policy-based. Route-based is selected by default. For SKU, there is a drop-down menu. VpnGw1 is selected by default. [Video description ends]

I'm not gonna change any of the other specific items other than linking this to our virtual network where we've defined our gateway subnet.

[Video description begins] He clicks on the field for Virtual network. A page titled Choose virtual network appears. It has three options: EastVnet1, EastVnet2, and EastVnet3. [Video description ends]

And that was EastVNet1, so I'm going to select that.

[Video description begins] He selects EastVnet1. The Choose virtual network page closes. [Video description ends]

The next thing is I need to have a public IP address defined for this, because if you think about it, we need some way to make a connection over the Internet to some location to get into the Vnet through an encrypted tunnel.

[Video description begins] For Public IP address, there are two options: Create new and Use existing. Create new is selected by default. Below it there is an input box. [Video description ends]

And so I'm gonna let it create a new public IP address, and so we're going to call it vpngw1pubIP.

[Video description begins] In the Public IP address input box , he types vpngw1pubIP. [Video description ends]

And as we go further down, it's going to be a dynamic IP address, we don't have much of a choice here.

[Video description begins] He scrolls down the page. A section titled Configure public IP address appears. It has two options for Assignment: Dynamic and Static. Dynamic is selected by default. A check box for Configure BGP ASN is also present. There is a drop-down menu for Subscription. The default value is Pay-As-You-Go. The Resource group is Rg1. For Location, there is a drop-down menu. Canada East is selected by default. [Video description ends]

And I'm just going to leave it in my Canada East location, and I'm going to click Create. Now, beware that this can take some time. Microsoft states in their documentation it can take up to 45 minutes before this is ready to go.

[Video description begins] Microsoft Azure home page opens up. [Video description ends]

So feel free to put on a pot of coffee and enjoy that as you wait for your virtual network gateway to be fully deployed.

[Video description begins] A Windows Powershell ISE editor opens up. It has a tool bar and a menu bar. A tab titled Generate_Certs_for_VPN.ps1 is open. 15 code lines are displayed. It has a console pane with the following directory name: PS Cert:\CurrentUser\my>. [Video description ends]

Now, in the meantime, we can deal with the whole PKI certificate issue. Because clients that connect to the point-to-site VPN need to authenticate themselves with a PKI certificate. So here in the PowerShell ISE, the first chunk of code I have here is going to create a self-signed root certificate.

[Video description begins] He highlights code lines 3-6. Code line 3 reads: $cert = New-SelfsignedCertificate -Type Custom -KeySpec Signature `. Code line 4 reads: -Subject "CN=RootCert" -KeyExportPolicy Exportable `. Code line 5 reads: -HashAlgorithm sha256 -KeyLength 2048 `. Code line 6 reads: -CertStoreLocation "Cert:\CurrentUser\My" -KeyUsageProperty Sign -KeyUsage CertSign. [Video description ends]

So I'm doing that using the New-SelfSignedCertificate PowerShell cmdlet. And it's going to be a custom self-signed type of specific certificate that I'm going to call RootCert, CN= means common name equals.

And we can see here that the hashing algorithm is sha256 and the key length will be 2048 bits. We can also see it's going to be stored in the certificate store drive here on this Windows machine. So I'm going to go ahead and select that code, and we're going to execute it by clicking the Run Selection button.

[Video description begins] He selects code lines 3-6. He then presses the Run Selection button from the tool bar. All the selected code lines appear in the console pane. [Video description ends]

And when we've done that down below, it looks like it executed without incident. So I'm going to change directory to the cert drive, and we're going to go ahead and go into currentuser.

[Video description begins] In the console pane, he types cd cert : and presses Enter. [Video description ends]

[Video description begins] He types cd currentuser and presses Enter. The result reads: Cannot find path 'Cert:\CurrentUser\my\currentuser' because it does not exist. [Video description ends]

Looks like we're already there, so we're good to go.

[Video description begins] He types cls and presses Enter. The console pane clears. [Video description ends]

Here I can see I'm in Cert:\CurrentUser\my. And if I do a dir for directory listing, we can see that we've got our RootCert here.

[Video description begins] He types dir and presses Enter. A list of files in the directory appears in the result. He highlights the last line of the result. [Video description ends]

The next thing we're going to do is we're going to create a client certificate using the New-SelfSignedCertificate PowerShell cmdlet.

[Video description begins] He highlights New-SelfSignedCertificate in code line 11. The code on line 11 reads: New-SelfSignedCertificate -Type Custom -DnsName ClientCert -KeySpec Signature `. [Video description ends]

Now once we've run that code, we can see that it will be called ClientCert.

[Video description begins] He selects code lines 11-15. Code line 12 reads: -Subject "CN=ClientCert" -KeyExportPolicy Exportable `. Code line 13 reads: -HashAlgorithm sha256 -KeyLength 2048 `. Code line 14 reads: -CertStoreLocation "Cert:\CurrentUser\My" `. Code line 15 reads: -Signer $cert -TextExtension @("2.5.29.37={text}1.3.6.1.5.5.7.3.2"). [Video description ends]

And we can see indeed that that client certificate has been created.

[Video description begins] A new result appears in the console pane. He highlights CN=ClientCert in code line 12, and in the result. [Video description ends]

Now, the machine on which I've run this code is where that client certificate was created. Otherwise, I could go into the MMC tool and then load up the certificates snap-in and export it. If I wanted to use that client certificate on a different machine. But I'm going to leave that on this machine. From the Start menu on my machine, I searched for and launched MMC, Microsoft Management Console, and this is what I get.

[Video description begins] A window titled Console1 [Console Root] opens up. It has a menu bar and a tool bar. It has a navigation pane which has a folder named Console Root. A section titled Actions is also present which contains two options: Console Root and More Actions. [Video description ends]

So I'm going to go into the File menu and choose Add/Remove Snap-in because I want to work with certificates. So I'll add that component, Certificates, Add.

[Video description begins] He clicks the File menu. A list of options appears. He selects Add/Remove Snap-in from the list. A window titled Add or Remove Snap-ins appears. It has two sections. The first one is titled Available snap-ins. It has two columns: Snap-in and Vendor. The second section is titled Selected snap-ins. Between the two sections there is an Add button with a forward arrow. On one side of the window, the following buttons are present: Edit Extensions, Remove, Move Up, Move Down, and Advanced. At the bottom, OK and Cancel buttons are present. From the Snap-in column, he selects Certificates. [Video description ends]

I'll leave it on my user account, and Finish and OK.

[Video description begins] He clicks the Add button. A window titled Certificates snap-in appears. The following statement is present here: This snap-in will always manage certificates for. Below this there are three options with radio buttons: My user account, Service account, and Computer account. My user account is selected by default. At the bottom there are three buttons: Back, Finish, and Cancel. He clicks the Finish button. The window closes. He clicks the OK button on the window titled Add or Remove Snap-ins. The window closes. The screen shifts to the window titled Console1 [Console Root]. A folder titled Certificates-Current User appears in the main body, and in the navigation pane under Console Root folder. [Video description ends]

So then on the left I'm going to drill down under Certificates for current user, Personal Certificates.

[Video description begins] He expands the Certificates-Current User folder in the navigation pane. It has a list of folders. Some of these are: Personal, Enterprise Trust, Trusted Publishers, etc. He expands the Personal folder. It has a folder named Certificates. He clicks on it. In the main body, a table appears with the following columns: Issued To, Issued By, Expiration Date, etc. The table has a list of files. [Video description ends]

Now, you may have to refresh the screen and make sure you're seeing the most up-to-date information. Now we've got one root cert, and we've also got our client cert.

[Video description begins] He clicks on the file named RootCert in the table. He clicks on the file named ClientCert in the table. [Video description ends]

What we need to do now is export the root cert to a file, so that we can take the public key portion and configure that in Azure. So I'm going to go ahead and right-click on the RootCert and choose All Tasks, Export, and in the Wizard I'll click Next.

[Video description begins] He right-clicks on RootCert. A list of options appears. He selects All Tasks from the list. Another list of options appears. He selects Export from the list. A window titled Certificate Export Wizard opens up. It has two buttons at the bottom: Next and Cancel. The presenter clicks the Next button. The following question is present on the next screen: Do you want to export the private key with the certificate? It has two options with radio buttons: Yes, export the private key and No, do not export the private key. The second option is selected by default. At the bottom there are two buttons: Next and Cancel. [Video description ends]

We don't want the private key exported, only the public so I'll leave the default of No, do not export the private key, and I'll click Next.

[Video description begins] He clicks the Next button. On the next screen, three options with radio buttons are present for Select the format you want to use. These options are: DER encoded binary X. 509 (.CER), Base 64 encoded X. 509 (.CER), and Cryptographic Message Syntax Standard - PKCS #7 Certificates (.P7B). The first option is selected by default. At the bottom, there are two buttons: Next and Cancel. [Video description ends]

I want to make this a Base-64 encoded CER files, I'll select that and click Next.

[Video description begins] He selects the second option and clicks the Next button. On the next screen, an input box for File name is present. A Browse button is present next to it. At the bottom there are two buttons: Next and Cancel. [Video description ends]

And then I'll specify a file name, let's say, on the root, and I'm going to call it rootcertpubkey. And then I'll just go ahead and click Next and Finish, and it says the export was successful.

[Video description begins] In the input box he types C:\rootcertpubkey. He clicks the Next button. On the next screen, the following heading appears: Completing the Certificate Export Wizard. The following details are mentioned here: File Name, Export Keys, File Format, etc. At the bottom, there are two buttons: Finish and Cancel. [Video description ends]

[Video description begins] He clicks the Finish button. A pop-up message appears. It reads: The export was successful. It has an OK button. He clicks it. [Video description ends]

Here on the root of drive C, I can see the file here, I'm going to right-click on it, and I'm going to open it with Notepad.

[Video description begins] A File explorer opens up. The C drive is currently open. It has a file named rootcertpubkey.cer. The presenter right-clicks on it. A list of options appears. He selects Notepad from the list. A Notepad opens. It has some text for a certificate. The first line is: BEGIN CERTIFICATE. The last line is END CERTIFICATE. [Video description ends]

Because what I want to do is highlight everything between begin certificate and end certificate. This is the public key portion of the root certificate that we need to paste into a specific place, which we'll see in a moment in Azure.

[Video description begins] He copies the main body of the certificate and moves to the Microsoft Azure home page. [Video description ends]

So here in Azure, I'm going to go to All resources. And what I'm interested in is looking at our virtual network gateway that we create, in this case, vpngw1. I'm going to click on it to open up its Properties blade.

[Video description begins] From the navigation pane, he clicks on All resources. The All resources page opens up. He scrolls down the table and clicks on the resource named vpngw1. A page titled vpngw1 opens up. It has a navigation pane along with some details. [Video description ends]

What I want to do is click Point-to-site configuration, and I'm going to click Configure now.

[Video description begins] From the navigation pane, he clicks on Point-to-site configuration. The page for Point-to-site configuration opens up. It has a link named Configure now. [Video description ends]

[Video description begins] He clicks on the link Configure now. A page for configuration opens up. It has the following buttons at the top: Save, Discard, and Download VPN client. An input box for Address pool is also present. Below it there is a drop-down menu for Tunnel type. OpenVPN (SSL) is selected by default. For Authentication type, there are two options with radio buttons: Azure certificate and RADIUS authentication. Azure certificate is selected by default. There is a section titled Root certificates. It has input boxes for Name and Public Certificate Data. There is another section titled Revoked certificates. It has input boxes for Name and Thumbprint. [Video description ends]

So I need to specify an address pool, essentially that I want to assign to VPN clients. And we want to make sure that that matches whatever they should have access to on a specific network. So, for example, maybe what I would do is set that to 1.1.1.0/24 that has to match what's on the internal part of the network in Azure that I want clients to have an address for. I'm going to leave it here, well actually I'm going to change that from tunnel type OpenVPN (SSL), let's say, to IKEv2 and SSTP, depending on the type of VPN you want to set up.

[Video description begins] In the input box for Address pool, he types 1.1.1.0/24. [Video description ends]

[Video description begins] He clicks the drop-down menu for Tunnel type. A list of options appears. He selects IKEv2 and SSTP (SSL) from the list. [Video description ends]

And for the Azure certificate, I'm going to call it here RootCert, and I'm going to paste in what we just copied into the public certificate data field.

[Video description begins] Under the Root certificates section, he types RootCert in the input box for Name. In the input box for Public Certificate Data, he pastes the certificate copied from the Notepad file. [Video description ends]

So at this point we've got that configuration, so I'm going to go ahead and click Save.

[Video description begins] He clicks the Save button. [Video description ends]

The next thing I'm going to do is click on the Connections part of the blade.

[Video description begins] From the navigation pane, he clicks on Connections. A pop-up message appears. It reads: Your unsaved edits will be discarded. It has two buttons: OK and Cancel. He clicks the OK button. A new screen titled vpngw1 - Connections appears. It has an Add button at the top. Below it, there is a table with the following columns: Name, Status, Connection Type, and Peer. The table is currently empty. [Video description ends]

Notice currently we have no VPN connection. So I'll go back to Point-to-site configuration where I have the option of downloading a VPN client package.

[Video description begins] He clicks on Point-to-site configuration from the navigation pane. The page for Point-to-site configuration opens up. [Video description ends]

I'm going to go ahead and click on that.

[Video description begins] He clicks the Download VPN client button. [Video description ends]

After it's been downloaded, I'm going to go ahead and open it up.

[Video description begins] He opens the downloaded folder. A File explorer opens up. The Downloads page is currently displayed. It has three folders: Generic, WindowsAmd64, and WindowsX86. [Video description ends]

When I open up the zip file, I'm going to choose the appropriate platform, in this case Windows AMD64. And I'm going to go ahead and I'm going to run that executable installer.

[Video description begins] He clicks on WindowsAmd64. It has a file named VpnClientSetupAmd64.exe. He right-clicks on it. A list of options appears. [Video description ends]

And it asks me if I want to install the VPN client for EastVnet1. I'll choose Yes.

[Video description begins] A pop-up box appears with the following question: Do you wish to install a Vpn Client for EastVnet1 ? It has two options: Yes and No. He clicks Yes. [Video description ends]

Now on my machine, if I go down and click on my Network Settings, I'll see I've got a connection for EastVnet1.

[Video description begins] From the task bar, he clicks on the network icon. A list of available networks appears. EastVnet1 is present in the list. He clicks on it. The Settings page of the system opens up. Under the heading VPN, EastVnet1 is present. It has a section titled Advanced Options. In this section, Allow VPN over metered networks is On and Allow VPN while roaming is ON. [Video description ends]

If I select that, I can then choose to make a connection.

[Video description begins] He clicks on EastVnet1. Three options appear: Connect, Advanced options, and Remove. He clicks on Connect. A window titled EastVnet1 appears. It has three buttons: Connect, Cancel, and Properties. [Video description ends]

So I'm going to click Connect and Continue.

[Video description begins] He clicks the Connect button. A set-up window titled EastVnet1 appears. It has two buttons: Continue and Cancel. He clicks the Continue button. [Video description ends]

And after a moment, we can see indeed we are connected through our point-to-site VPN to our EastVnet1 virtual network in the cloud.

[Video description begins] On the Settings page, EastVnet1 is now displayed as a Connected network. [Video description ends]

And on my machine, notice if I go to a command prompt and run ipconfig that we've got an IP address within that specific range for that point-to-site VPN connection.

[Video description begins] A command prompt window appears. It has the prompt name: C:\>. He types ipconfig and presses Enter. A result is displayed. In the result, he highlights the IPv4 Address which is 1.1.1.2. He then highlights EastVnet1: In the following line: PPP adapter EastVnet1: . [Video description ends]

Azure Application Gateway

[Video description begins] Topic Title: Azure Application Gateway. Your host for this session is Dan Lachance. [Video description ends]

In a very general sense, the Azure Application Gateway is a load balancer for web application traffic. But that's where the similarities stop because with a traditional load balancer, traffic gets routed to backend virtual machine instances through the load balancer based on things like the IP address and port number. However, with the Azure Application Gateway, we have many options above and beyond what you can do with a traditional load balancer.

As an example of this, the Azure Application Gateway could load balance and get clients connected to backend virtual machines based on routing rules that might be based on an incoming URL passed to the application from the client. So pictured in the diagram, we've got the Internet listed over on the left. The Azure App Gateway is then connectable from the Internet. It will have a public facing IP address if it's designed to be made publicly visible.

The Azure App Gateway will then have access to backend VMs, listed here as VM1, VM2, and VM3, Although it doesn't have to be three; it could be two, it could be more than three. Also, we can configure options like session affinity. This can be used so that a user that's got an established session on VM1, let's say, the next time that they make a connection which could be moments later, they will still have their session directed to that same backend server.

Remember that when we talk about web applications over HTTP or HTTPS, bear in mind that HTTP and HTTPS are really stateless. In other words, once we contact a web server and ask it to do something and it does it, that's it. So we need to have a way therefore where we can maintain session affinity information on the backend. And this is a configuration option within the Azure Application Gateway among many others.

The application gateway also supports a web application firewall, or a WAF, W-A-F. So when you deploy an Azure Application Gateway, you have a web application firewall that can be configured. This is a specific type of firewall that's designed to look for web application exploits, such as cross-site request forgeries, or directory traversals, where attackers might try to go further back in the file system outside of the location of files that make the website run, which could give them unauthorized access to other files in the operating system.

Cross-site scripting is also another type of attack that can be prevented, and SQL injection which might allow a user to input query statements in fields that get sent to a database. And those fields are validated properly and so might reveal more sensitive information than it was designed to do. Now there are many other types of web application exploits that are protected with a web application firewall.

Configure Azure Application Gateway

[Video description begins] Topic title: Configure Azure Application Gateway. Your host for this session is Dan Lachance. [Video description ends]

The Azure application gateway takes incoming client requests for an application and forwards it off to a backend server that can host that request.

[Video description begins] A Microsoft Azure web page opens up. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is present on this screen with the following options: Create a resource, Home, Dashboard, All services, and Favorites. The center pane has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

Now, that might sound like a load balancer, and it is a load-balancing solution. But what makes the application gateway different than a traditional load balancer is that beyond just looking at IP addresses and port numbers, the application gateway can look at the incoming URL request.

And it can make a routing decision to a backend virtual machine based on that. So if a client requests something in the URL that includes /jpg images, that can be forwarded to a backend host that's been optimized to serve up that kind of content. So let's get started here in the portal by clicking Create a resource.

[Video description begins] He clicks the Create a resource option from the navigation pane. A page titled New opens. At the top, a search bar is displayed. Below it, a list of Azure Marketplace services is present. Some of the options are: Get started, Recently created, Compute, Networking, Databases, etc. Another column with a list of Popular services is also present on the screen. Some of the items here are: Windows Server 2016 Datacenter, Ubuntu Server 18.04 LTS, etc. [Video description ends]

I'm going to start by deploying two virtual machines that are going to be running Windows Server 2016 Data Center.

[Video description begins] From the Azure Marketplace column, he selects Compute. A Featured column appears. It has the following options: Windows Server 2016 Datacenter, Red Hat Enterprise Linux 7.2, Ubuntu Server 18.04 LTS, etc. He selects Windows Server 2016 Datacenter. A page titled Create a virtual machine appears. It has the following tabs: Basics, Disks, Networking, etc. Basics tab is currently open. It has drop-down menus for Subscription and Resource group. The default value for Subscription is Pay-As-You-Go. The default value for Resource group is cloud-shell-storage-eastus. At the bottom there are three buttons: Review + create, Previous, and Next: Disks. [Video description ends]

The key here is I want two virtual machines deployed into their own specific virtual network and subnet.

[Video description begins] He scrolls down the page. A section titled Instance Details is displayed. It has an input box for Virtual machine name. There are drop-down menus for Region, Availability options, and Image. The Region is East US, Availability options is No infrastructure redundancy required, and Image is Windows Server 2016 Datacenter. The Size is Standard DS1 v2. [Video description ends]

And these virtual machines will be used as our backend pool for our application gateway. So I'm going to go through and tie this to a resource group, and I'm gonna call this webapp1vm1.

[Video description begins] He clicks the drop-down menu for Resource group. A list of options appears. He selects Rg1 from the list. [Video description ends]

[Video description begins] In the input box for Virtual machine name, he types webapp1vm1. [Video description ends]

Now, I'm gonna copy that because I'm gonna make a second one afterwards, where the only difference is going to be vm2 instead of vm1. So I'm going to put this in the Canada East location.

[Video description begins] He clicks the drop-down menu for Location. A list of options appears. He selects Canada East from the list. [Video description ends]

And I'm going to scroll down and specify the username and password information.

[Video description begins] He scrolls down the page. A section titled Administrator Account appears. It has input boxes for Username, Password, and Confirm Password. Below it there is a section titled Inbound Port Rules. It has two options with radio buttons for Public inbound ports. These options are: None and Allow selected ports. None is selected by default. It also has a drop-down menu for Select inbound ports. [Video description ends]

And then for inbound port rules, I'm going to allow incoming RDP on port 3389 for management. I don't have to enable port 80 or 443, because these will be running in the backend pool. They don't need to be publicly accessible.

[Video description begins] In the input box for Username, he types cirving. He then types the password and confirms the password. He selects Allow selected ports for Public inbound ports. He clicks the drop-down menu for Select inbound ports. A list of options appears. He selects RDP from the list. [Video description ends]

So I'm going to go ahead and click Next.

[Video description begins] He clicks the Next: Disks button. The screen shifts to the next tab titled Disks. It has a drop-down menu for OS disk type. Premium SSD is selected by default. At the bottom there are three buttons: Review + create, Previous, and Next: Networking. [Video description ends]

I'm okay with Disks but I'm interested in the Networking.

[Video description begins] He clicks the Next: Networking button. The screen shifts to the next tab titled Networking. It has drop-down menus for Virtual network, Subnet, and Public IP. The default value for Virtual network is EastVnet1. Below this, there is a link for Create new. The default value for Subnet is EastSubnet1 (10.1.1.0/24). Below it there is a link for Manage subnet configuration. The default value for Public IP is (new) webapp1vm1-ip. Below it there is link for Create new. For NIC network security group, there are three options with radio buttons: None, Basic, and Advanced. None is selected by default. At the bottom there are three buttons: Review + create, Previous, and Next: Management. [Video description ends]

I'm going to create a new VNet called webapp172Vnet.

[Video description begins] He clicks the Create new link present below Virtual network. A page titled Create virtual network slides onto the screen. It has an input box for Name. There is a section titled Address Space. It has a table with the following columns: Address Range, Addresses, and Overlap. It has one row of data. The Address Range is 10.0.0.0/16, Addresses is 10.0.0.0 - 10.0.255.255 (65536 addresses), and Overlap is None. There is another section titled Subnets. It has a table with the following columns: Subnet Name, Address Range, and Addresses. Subnet Name is default, Address Range is 10.0.0.0/16, and Addresses is 10.0.0.0 - 10.0.255.255 (65536 addresses). At the bottom there are two buttons: OK and Discard. In the input box for Name, he types webapp 172Vnete. [Video description ends]

And I'm going to specify the address range I want to use for that, which would have been planned ahead of time, that's for the VNet. And then I'm going to make a subnet here called Subnet1 and we'll configure a range for the subnet that falls within what is being used here in the VNet.

[Video description begins] In the table for Address Space, he changes the Address Range to 10.1.0.0/16. [Video description ends]

Just make sure we're using CIDR notation here, with the slash for the number of bits in the subnet mask.

[Video description begins] In the table for Subnets, he changes the Subnet Name to Subnet 1, and the Address Range to 10.1.1.0/24. [Video description ends]

And I'm going to go ahead and click OK. So now we've got that configured, and now I'm going to click Review and create.

[Video description begins] He clicks the OK button. The Virtual network changes to (new) webapp 172Vnete. [Video description ends]

Once the validation passes, I'll go ahead and I'll click the Create button.

[Video description begins] He clicks the Review + create button. The screen shifts to the Review + create tab. It has the following sections: Product Details, Terms, and Basics. At the bottom there are three buttons: Create, Previous, and Next. He clicks the Create button. [Video description ends]

And while that's happening, I'm going to go ahead and deploy a second virtual machine. Everything will be the same except the name will end in vm2 instead of vm1.

[Video description begins] A new page opens up. It has a navigation pane with the following options: Overview, Inputs, Outputs, and Template. The Overview page is currently open. It has the following heading: Your deployment is underway. The page has a table with the following columns: Resource, Type, Status, and Operation Details. [Video description ends]

Now I should say, if you've got existing virtual machines hosting your app, you can use those. It just so happens, I'm deploying them from scratch here. And, of course, what you would do is install, in this case, the IIS web server and any other components within each virtual machine that you need to support your web application. Okay, so the next thing I'll do is actually deploy the application gateway. So I'll click Create a resource, and I'll type in application gateway.

[Video description begins] He shifts to the Microsoft Azure home page and clicks on Create a Resource. A page titled New opens. [Video description ends]

And I'll select it from the list, and I'll choose Create.

[Video description begins] In the search bar, he types application gateway. Two options appear: Application Gateway and Azure Application Gateway Analytics. He clicks on Application Gateway. A page titled Application Gateway appears. It has a drop-down menu for Select a software plan. Application Gateway is selected by default. At the bottom there is a Create button. He clicks the Create button. [Video description ends]

I'm going to call this webapp172appgw, for app gateway.

[Video description begins] A page titled Create application gateway opens. It has three steps listed: Basics, Settings, and Summary. A page for Basics is currently displayed. It has an input box for Name. There are drop-down menus for Tier, Instance count, SKU size, Subscription, Resource group, and Location. The default value for Tier is Standard, Instance count is 2, SKU size is Medium, Subscription is Pay-As-You-Go, and Location is Canada East. At the bottom there is an OK button. In the input box for Name, he types webapp172appgw. [Video description ends]

And if I leave it on the Standard tier, I can see the SKU sizes available are Small, Medium, and Large. And these relate to the amount of throughput that can be handled by the application gateway. If I were to choose a Web Application Firewall tier, then all I have are Medium and Large available as sizing.

[Video description begins] He clicks the drop-down menu for Tier. A list of options appears. He selects WAF from the list. [Video description ends]

So I'm going to choose Medium.

[Video description begins] He clicks the drop-down menu for SKU size. Two options appear: Medium and Large. He selects Medium. [Video description ends]

I'm going to leave it at 2 for Instance count, and I'll pop this into an existing resource group.

[Video description begins] He clicks the drop-down menu for Resource group. A list of options appears. He selects Rg1 from the list. [Video description ends]

And the same location where I've deployed my virtual machines in their own VNets, so I'll click OK. And for the virtual network on the next page, I'm going to choose an existing virtual network.

[Video description begins] He clicks the OK button. The Basics page closes and a page for Settings appears. It has a section titled Subnet configuration. It has a field for Virtual network. A link for Choose a virtual network is present here. Below it there is a drop-down menu for Subnet. There is a section titled Frontend IP configuration. Here there are two options with radio buttons for IP address type: Public and Private. Public is selected by default. For Public IP address, there are two options with radio buttons: Create new and Use existing. Create new is selected by default. Below it there is an input box with the following value: webapp172appgw-ip. At the bottom there is an OK button. The presenter clicks on the link for Choose a virtual network. A page titled Choose virtual network opens. It has three options: EastVnet1, EastVnet2, and EastVnet3. A fourth option webapp172Vnete is present but unavailable. Above these, there is a Create new option. [Video description ends]

Now, notice here how the webapp172Vnet that we created is unavailable because we need another empty subnet as indicated here by the information screen.

[Video description begins] He points to the info icon present next to the fourth option. It reads: This virtual network doesn't have an eligible subnet for this deployment. It should contain an empty subnet or a subnet with no other resource types besides application gateways. [Video description ends]

No problem. So I've opened up another web browser window where I've navigated to Virtual networks.

[Video description begins] In a new tab, the Virtual networks page is open in the Microsoft Azure web page. It has the following buttons on the top: Add, Edit columns, Refresh, etc. It has an input box for Name, and drop-down menus for resource groups, locations, tags, and grouping. Below these fields, there is a table with the following columns: Name, Resource Group, Location, and Subscription. Four rows of data are present in the table. [Video description ends]

I'm going to open up that virtual network and I'm going to click Subnets, and I'm going to add a new Subnet.

[Video description begins] From the table, he clicks on webapp172Vnete. A page titled webapp172Vnete opens up. It has a navigation pane and other details. From the navigation pane, he clicks on Subnets. A page for Subnets opens up. It has two buttons on the top: +Subnet and +Gateway subnet. It has a table with the following columns: Name, Address Range, Available Addresses, and Security Group. [Video description ends]

I'm going to call it Subnet2.

[Video description begins] He clicks on + Subnet. A page titled Add subnet opens up. It has an input box for Name and Address range(CIDR block). In the input box for Name, he types Subnet2. There are drop-down menus for Network security group and Route table. None is selected for both. Under the heading Service Endpoints, there is a drop-down menu for Services. No service is selected. Under the heading Subnet delegation, there is a drop-down menu to Delegate subnet to a service. No subnet is selected. At the bottom, there is an OK button. [Video description ends]

And for the address range, I'll use 10.1.2.0/24 for bits in subnet mask. And I'll just go ahead and OK that to add a second subnet.

[Video description begins] In the input box for Address range(CIDR block), he types 10.1.2.0/24. He clicks the OK button. The screen shifts to the Subnets page. In the table, Subnet2 is present. [Video description ends]

So now when I go to select the virtual network, and you might have to close this screen of the wizard and go back one step and come back in, which I've done.

[Video description begins] He shifts to the previous tab. [Video description ends]

I can now select that virtual network and it's got Subnet2, select it.

[Video description begins] From the list of four options in Choose virtual network page, he selects webapp172Vnete, which is now active, as the Virtual network. [Video description ends]

This is going to be a public facing application gateway, so I'll leave the IP address type as Public, as opposed to Private for an internal line of business app, for example. We'll let it create a new public IP address, and I'm going to accept all the defaults here for HTTP port 80, and I'll click OK.

[Video description begins] He scrolls down the Settings page. There is a section titled Configure public IP address. Here SKU is Basic. For Idle timeout (minutes), there is a scale with a pointer. The pointer is at 4. The input box for DNS name label is empty. For Assignment there are two options with radio buttons: Dynamic and Static. Dynamic is selected by default. There is a section titled Listener configuration. For Protocol there are two options with radio buttons: HTTP and HTTPS. HTTP is selected by default. For Port there is an input box. The value here is 80. Under Additional Settings, there are two options for HTTP2: Disabled and Enabled. Disabled is selected by default. Under Web application firewall, there are two options for Firewall status: Disabled and Enabled. Enabled is selected by default. For Firewall mode, there are two options: Detection and Prevention. Detection is selected by default. [Video description ends]

Then I'll click OK on the Summary screen.

[Video description begins] He clicks the OK button. The Settings page closes and the Summary page opens. It has the details of the application gateway. At the bottom there is an OK button. He clicks the OK button. The home page of Microsoft Azure is displayed. [Video description ends]

And we can now see our application gateway is being deployed. But we're not finished configuring it yet. We have to link our backend virtual machines to the backend pool for the gateway. So now if I go to the All resources view, and if I filter it for web, we can see that we've got a number of resources with that prefix such as our web application 172 app gateway.

[Video description begins] From the navigation pane, he clicks on All resources. The All resources page opens. In the input box for name, he types web. He points to the resource named webapp172appgw in the table. [Video description ends]

I'm going to go ahead and click on it to pull up its Properties blade.

[Video description begins] He clicks on webapp172appgw. A page titled webapp172appgw opens up. It has a navigation pane and a few details such as Resource group, Location, Virtual network/subnet, etc. [Video description ends]

And in the Properties blade, if I scroll down to the Backend Pools, I've got my backend pool listed here.

[Video description begins] He clicks on Backend pools in the navigation pane. A page for Backend pools opens. It has two buttons: Add and Refresh. A table with the following columns is also present: Name, Rules Associated, and Targets. It has the following Backend pool listed: appGatewayBackendPool. [Video description ends]

However, from the dropdown list, I can choose virtual machines.

[Video description begins] He clicks on appGatewayBackendPool. A page titled Edit backend pool opens. It has the following buttons: Save, Discard, and Delete. It has a drop-down menu for Targets. IP address or FQDN is selected by default. It also has an input box for Name. [Video description ends]

And when I go to select a virtual machine, I'll see the two virtual machines that I deployed in that virtual network that this application gateway is associated with.

[Video description begins] He clicks the drop-down menu for Targets. A list of options appears. He selects Virtual machine from the list. Drop-down menus for Virtual Machine and Network Interfaces appear. He clicks the drop-down menu for Virtual Machine. Two options appear: webapp1vm1 and webapp1vm2. [Video description ends]

So I'm going to go ahead and choose the appropriate network interface for both of those virtual machines.

[Video description begins] He selects webapp1vm1. He then clicks the drop-down menu for Network Interfaces. One option appears. He selects it. It is webapp1vm198 (10.1.1.4) Another set of drop-down menus for Virtual Machine and Network Interfaces appears. [Video description ends]

Now again, these would be configured with our web application.

[Video description begins] He clicks the drop-down menu for Virtual Machine and selects webapp1vm2. He then clicks the drop-down menu for Network Interfaces. One option appears. He selects it. It is webapp1vm2581 (10.1.1.5) [Video description ends]

And then I'll click Save to save that backend pool configuration.

[Video description begins] He clicks the Save button. The screen goes back to the Backend pools page. [Video description ends]

We can also click on Web application firewall in the Properties blade to ensure that the Web application firewall is enabled. If we go to Rules, we can see the ruleset that's being used.

[Video description begins] From the navigation pane, he clicks on Web application firewall. A page for Web application firewall opens. It has three buttons on top: Save, Discard, and Refresh. The page has two tabs: Configure and Rules. The Configure tab is currently selected. It has two options for Tier: Standard and WAF. WAF is selected by default. The Firewall status is Enabled. For Firewall mode, there are two options: Detection and Prevention. Detection is selected by default. A section titled Exclusions is also present here. It has a table with three columns: Field, Operator, and Selector. All three columns have drop-down menus. [Video description ends]

If you really want to, you can enable Advanced rule configuration to determine exactly which type of web application firewall rules that you want enabled.

[Video description begins] He goes to the Rules tab. It has a drop-down menu for Rule set. The default value is OWASP 3.0. For Advanced rule configuration there are two options: Enabled and Disabled. Disabled is selected by default. He clicks the drop-down menu for Rule set. Two options appear: OWASP 3.0 and OWASP 2.2.9. [Video description ends]

[Video description begins] He clicks Enabled for Advanced rule configuration. A table with the following columns appears: Enabled, Name, and Description. A list of items is present in the table. There are check boxes with tick marks present under the Enabled column for each item. [Video description ends]

However, I'm not worried about making a change there. Also, if we go to Rules, we also have the option of configuring additional path-based rules to look at incoming URLs for routing purposes. That would require creating a front-end listener as well.

[Video description begins] From the navigation pane, he clicks on Rules. A pop-up message with the following text appears on the screen: Your unsaved edits will be discarded. It has two buttons: OK and Cancel. The presenter clicks the OK button. A page for Rules opens. It has a navigation pane and two buttons on top: +Basic and +Path-based. Below it there is a table with the following columns: Name, Type, and Listener. There is one row of data in the table. [Video description ends]

And we can click Health probes to determine the configuration for how often we're going to check backend servers to make sure that they are responsive.

[Video description begins] He clicks on Health probes from the navigation pane. A page for Health probes opens. It has an Add button. It has a table with the following columns: Name, Protocol, Host, Path, and Timeout (Seconds). The table is empty. [Video description ends]


Content Delivery Networks (CDNs)
  - A Content Delivery Network or CDN is a strategy that we can employ in Azure to make sure that content is available to users locally. So the overall goal then is to speed up the user experience when content is delivered to them, whether it's basic standard website files, graphic images, audio-video media, whether it's streaming or not, we wanna make sure that gets to end-users as quickly as possible. And that can be done with a CDN because the Azure content delivery network has geographical point of presence servers in Azure regions all over the world.
  - We can create configurations in Azure to specify details about what should be cached and for how long on these geographical point of presence servers in different parts of the world. The idea is that users that request content in one region should get that content served within the same region instead of having to retrieve it across multiple regions which will slow down the end-user experience.

The Content Delivery Network process begins with the user requesting content via a URL. Now that URL is then sent to a content delivery network point of presence server, and we will have configured data caching, or the client might have sent HTTP headers that have TTLs related to caching content and how long it should stay there. Otherwise, by default, content that gets cached sits on the CDN servers for seven days.

Now, in the event that a user makes a request for content that is not cached already, then the CDN server will make the request to the origin server, which in turn will feed the content back to the user through the content delivery network. There are a number of features to be aware of that you might want to configure while you're configuring your Azure content delivery network settings, one of which is geo-filtering.

Geo-filtering lets you specify the type of content that should be cacheable based on the country of the origin request. Content compression allows us to enable compression for files so that they are more quickly delivered throughout the CDN, and that we could potentially incur lesser bandwidth charges since we're sending less data. Caching rules can be used to specify exactly how data gets cached and for how long.

And there are a couple of different types of caching rules that you can configure, that we'll see when we configure a demo. Whether we're talking about just generic mobile caching rules or query string caching rules based on incoming query strings with HTTP requests. There's also a site acceleration option where you can configure this as you add endpoints to your CDN configuration to speed up access to content. Finally, you can also use HTTPS custom domain names to map more to your organizational presence on the Internet using your fully qualified domain name in your configuration.



Configure the Azure Content Delivery Network
   - Delivery network or CDN is used so that we can take web application content and place in geographically near users that will need it.
  - Content can stem from static web pages on a private website that we host on Azure. We can have files from Azure Blob Storage cached. We can even reference other publicly accessible web applications and have their content cached. Here in the Azure portal I'm going to start by going into my app services view on the left where I've already deployed a web application called webapp172.
  - [Video description begins] In the navigation pane, under Favorites, he clicks the App Services option. The App Services page opens. Three buttons are present at the top: Add, Edit columns, and Refresh. A table is displayed with six columns: Name, Status, App Type, App Service Plan, Location, and Subscription. One item is listed in the table: webapp172. [Video description ends]

If I click on it to open up its Properties blade, we can see the URL.

[Video description begins] He clicks on webapp172. A new page titled webapp172 opens. It has six buttons at the top, including: Browse, Stop, Restart, etc. It has a left pane, which contains various options such as: Overview, Activity Log, Tags, Deployment, Settings, etc. In the center pane, the following details are displayed: Resource group, Status, Location, URL, etc. [Video description ends]

So I'm just going to copy the URL and we're going to pop that into another web browser window to make sure at least that works.

[Video description begins] He copies the URL: https://webapp172.azurewebsites.net. [Video description ends]

And we can see the default page where it states that our App Service application is up and running.

[Video description begins] He pastes the URL in a new tab and presses Enter. A new Microsoft Azure page opens. He highlights the title of the page: Your App Service app is up and running. [Video description ends]

So back in the Azure portal, now what I want to do in the Properties blade for that application is scroll all the way down until we get to the networking section.

[Video description begins] He shifts to the previous tab. In the left pane, he clicks the Networking option. A new page titled webapp172- Networking, opens. In the center pane, four sections are displayed: VNet Integration, Hybrid connections, Azure CDN, and Access Restrictions. [Video description ends]

Then when I select networking over on the right, I can see Azure CDN, content delivery network, and I can choose the link to configure Azure CDN for my app.

[Video description begins] A link for Configure Azure CDN for your app is present below the AZURE CDN option. He clicks the link. A new page titled Azure CDN opens. The page heading is Azure Content Delivery Network. There are two sub-headings: Endpoints and New endpoint. Under Endpoints, a table is displayed with three columns: HOSTNAME, STATUS, and PROTOCOL. The table is empty. At the bottom of the page, there is a Create button. [Video description ends]

So down below, I'm going to go ahead and create a new CDN profile, a new configuration. So I'm going to call this webapp172cdnprofile.

[Video description begins] He scrolls down the page. Under New endpoint, there are two options with radio buttons for CDN profile: Create new and Use existing. Create new is selected by default. Below it there is an input box. Drop-down menu for Pricing tier is also present here. Below it there are input boxes for CDN endpoint name and Origin hostname. The default value for Origin hostname is webapp172.azurewebsites.net. In the input box below CDN profile, he typeswebapp172cdnprofile. [Video description ends]

And then I'm going to go ahead and choose the standard Microsoft pricing tier.

[Video description begins] He clicks the drop-down menu for Pricing tier. A list of options appears, including Standard Microsoft, Standard Verizon, Standard Akamai, and Premium Verizon. He selects Standard Microsoft from the list. [Video description ends]

The pricing tiers that I can select from the drop-down list really determine the feature set, such as, if I want dynamic site acceleration I would have to use the Standard Verizon or the Standard Akamai, or Premium Verizon configuration. Standard Microsoft doesn't support features like dynamic site acceleration. The standard Microsoft pricing for CDN also doesn't support features such as mobile device rules.

However, for this example I'm going to stick with Standard Microsoft. And for the CDN endpoint name I'm going to call it webapp172cdn and it's going to tack on the .azureedge.net DNS suffix, at least by default. Although notice that there's a link up above to migrate custom domains to content delivery network configurations here in Azure.

[Video description begins] In the input box for CDN endpoint name, he types webapp172cdn. Below the input box, the following text appears: .azureedge.net. He points to the link titled Migrate custom domain to CDN. [Video description ends]

So at this point I'm going to go ahead and click Create.

And after a moment we can see that our content delivery network endpoint is now listed with the status of running.
[Video description begins] In the Endpoints table, one row of data is displayed. The HOSTNAME is webapp172cdn.azureedge.net and the STATUS is Running. [Video description ends]

Now even though it may be true, it may not be available for a period of time depending on the pricing tier that you've selected. So the thing to do then is to use that URL to test connectivity. I've already popped that URL here, it includes CDN to make sure that our web application is up and running and indeed it says, our app service app is up and running.
So we now know that we can serve content through our configured Azure content delivery network.

Moving to the Cloud
Organizations looking at moving to the cloud, means that they will have to consider some of the migration options to migrate data that they might currently host on-premises into the cloud, or migrating applications are currently run on-premises in the cloud, and also, any servers that they have running on-premises that might serve up files or that might actually run application workloads can also potentially be migrated into the cloud computing environment.
Now with cloud migration, you can either migrate from your existing on-premises environment. But at the same time if you're already using cloud computing, you might consider migrating from an existing cloud service provider, to a new cloud service provider. Now the benefits of moving to the cloud would include first of all, reduced infrastructure expenses. At least compared to what you might have to do on-premises.

On-premises, you have capital expenditures related to purchasing the hardware to create the supporting IT infrastructure. Things like physical servers, storage arrays, UPS backup systems. However, in the cloud that's done by the cloud service provider. Another benefit of moving to the cloud, is minimizing capacity boundary issues. Cloud providers have the benefit of economies of scale where they have such a vast pool of resources made available to cloud customers. They can offer it at a reduced charge compared to what we would have to do if we were doing this ourselves entirely on-premises.

The other thing is that when you run out of capacity on-premises such as storage, you have to then acquire additional hardware and configure it to have that additional storage available. That takes a lot longer than it would to simply allocate more cloud storage through a public cloud service provider. Another benefit is the reduced total cost of ownership, or TCO over time. Now, that can be gauged by comparing the ongoing operational expense of cloud computing charges against the on-premises capital upfront expenditures required to acquire all of the equipment to support the infrastructure.

Another benefit of moving to the cloud, is the increased global scope and access to redundancy. Public cloud service providers have data centers around the globe, and so the benefit of that, for example, if you're hosting a public facing website, is that you've already got that availability to place that website near users that might access it. You also have access to redundancy by replicating content, whether it's files stored in the cloud, or even replicating virtual machines running out workloads to alternate locations around the planet. Moving to the cloud means standardizing on file formats.

You want to make sure that you don't move to a public cloud service provider that has a proprietary or customized way of dealing with file formats and data exchange, you want to use open standards. That way you have an easy exit strategy, if you need to switch to a different cloud service provider. The other consideration when you move to the cloud is that the service offerings, whether they are new ones that will be introduced or changing existing ones, there are going to be changes with the way things are done over time with a cloud computing provider, and that even includes with the management tools be the command line based or graphically based.

So be aware that there are changes that are made, and we kind of have to go with the flow, don't have a choice because we don't have the underlying control of the infrastructure, the cloud service provider does. The other consideration is privacy and security. Now moving to the cloud, it does not mean you have less security. Instead, we should consider the security accreditations or the compliance that the public cloud service provider has, with various security audits to determine which one we should use.

So your organization might be very concerned with privacy and security, and there's no reason that can't be achieved in the cloud as it would be on-premises. The only distinction being, perhaps less configuration, flexibility and control when it comes to security in the public cloud. The other consideration when moving to the cloud is integration. For instance, you might have on-premises software components that you're currently running, that you want to leave on-premises.

You might want to integrate them with cloud services. For example, developers could make API programmatic calls from on-premises software components to talk to cloud services. The other consideration are the various cloud models available and the offerings within each. First we have software as a service. Whenever we refer to a cloud service offering, it usually ends with as a service.

[Video description begins] Software as a Service is abbreviated as SaaS. [Video description ends]

It means it's delivered and available over a network, hosted on equipment that is the responsibility of the cloud provider. So software as a service or SaaS is normally used by end users, it's prepackaged software. You might think of things like Office 365, or Google Classroom, or Google documents. Platform as a service, or PaaS, is of the most interest to developers. It provides operating system, and application, and database stacks, and programming tools like centralized code repod... repositories that support continuous integration and delivery, the ability to host custom APIs in the cloud and so on.

Infrastructure as a service, or IaaS is of primary interest to IT technicians, administrators. Where we're talking about the underlying virtual machines and the storage that is available in the cloud, and also the virtual network capabilities that we can configure. So we've got software, platform, and infrastructure available as cloud service models. The other thing to consider when moving to the cloud is the cloud provider service-level agreements, or SLAs.

There will always be an SLA for each type of cloud service offering. So if you're looking at storage in the cloud, there might be multiple storage SLAs, if there are multiple different service offerings for different types of storage in the cloud. Just like there would be an SLA for virtual machine instances in the cloud, which guarantees things like uptime on a monthly basis. The other consideration is looking into the security accreditations that the cloud service provider has acquired.

For example, if they're PCI DSS compliant that might be important if you are running an e-commerce site and you have to deal with credit card holder information. The other thing to consider are the management tools available, whether they're command line based, API programming based, or GUI based, and then determining if there are automation and orchestration techniques available with that cloud service provider. One of the benefits of the cloud is for repetitive types of tasks, you can automate a lot of those, which speed things up and makes a resilient against human failure.


Cloud Computing Roles
There are a number of definable roles when it comes to a cloud computing ecosystem. The first role is the cloud service provider, otherwise called as CSP. Where they bear much of the responsibility for making sure that the underlying infrastructure supporting cloud services remains up and running, and that things perform well according to SLAs for cloud services. Also at the CSP level, they have the ultimate configuration flexibility because they control the actual physical hardware, the physical servers, the physical storage arrays, the physical network switches and routers, and so on in their data centers.

Cloud consumers also called cloud customers or cloud tenants, have a multitude of different cloud models they can work with in terms of offerings. So developers, for example, will be interested in platform as a service or PaaS, which would be useful for developing custom apps. So the cloud service provider has offerings that facilitate those tasks. Next, we have common office staff or end users that would be interested primarily in Software as a Service or SaaS. For example, using cloud-based email or office productivity tools like spreadsheets and word processors, all in the cloud. In other words, having that software delivered over a network.

At the IT level, then we have Infrastructure as a Service or IaaS. This would be for cloud administrators or cloud technicians that would be responsible for determining which cloud services need to be deployed, and then deploying and managing those cloud services. Things like virtual machines or applications, custom applications, running in the cloud and allocating storage and controlling access to all of those cloud resources. So that's really part of the IT support team's responsibilities.

Other roles include the Cloud Service Brokerage or the CSB. Think of this kind of as a mortgage broker, an intermediary that has the ability to look at your computing needs as it pertains to the cloud and then going out and negotiating and finding the best cloud service provider that meets those needs. Cloud architects are the technicians that will design your organization-specific use of cloud services to achieve organizational objectives. Cloud auditors are those people that will audit the usage of cloud activities to ensure things like legal and regulatory compliance, and also to ensure peak optimum efficiency.

So having things running smoothly at an efficient cost level. Finally, we've got cloud carriers. Cloud carriers come in a few different forms, the most common of which, when it comes to public cloud service providers are internet service providers. They are the cloud carriers that provide the network link between an on premises network or an individual customer to the cloud provider. Other types of cloud carriers would also include local telco or cable companies. Anyone that can provide a dedicated network circuit were available in different regions around the world, from an on premises network directly to the cloud without traversing the internet. That would be another example of a cloud carrier role.


On-premise vs. Cloud
To further illustrate the benefits of cloud computing, sometimes it's important to compare it against the equivalent on-premises solutions. So we're going to take a look at running IT services on-premises and in the cloud.

[Video description begins] Screen title: On-premise IT Solutions. [Video description ends]

The first thing to consider is that when you run things on-premises. Because it's running on your equipment and everything is your responsibility. That also means by extension, you have more configuration control. There's more flexibility in how that IT solution is configured and how it's maintained over time. But then there is the issue of hardware acquisition. So if you need to support a new line of business app, for example, on-premises. You need to make sure you have the underlying hardware to support it. Whether that includes servers, whether that includes network routing equipment or switches, storage arrays, and so on.

That means it costs money. It costs more money to acquire all of this hardware than it would to simply rent it or use it on an as needed basis in the cloud. It also means waiting for it to arrive. So if you place an order for hardware, it takes time for it to be shipped to your on-premises network or data center. The other consideration is software. You need to acquire software that you're going to use on-premises. Not only that, but you also need to license it. Now the same thing would be true in the cloud, the difference being it's a little easier in the cloud.

Even to the point where you can bring your own existing licenses that you might have already previously acquired, and reuse them in the cloud, when you adopt the cloud. With on-premises IT solutions, you also have the responsibility of ongoing management. That's the responsibility of the organization, that owns that infrastructure. So normal administration, such as making sure that backups occur. Making sure that user accounts are created for newly hired employees, applying updates and so on. That's all the responsibility of the IT team on-premises. Deploying resources on-premises, such as a new application, usually involves the on-premises IT team and the help desk, and maybe even some training staff.

However, in the cloud, often new software that is made available is simply available to use over the network immediately. There's no need to deploy it in most cases. I say most cases because depending on what types of solutions you're using in the cloud. There still might be some software components you need to download and install on user devices. Whether that device is a smartphone, or a laptop or a desktop. Then there is the cost factor. With on-premises, there are ongoing costs related to acquiring hardware such as server hardware. Which is really considered a capital expenditure, otherwise shortened to CAPEX. Then there's the power consumption, for all of the IT infrastructure equipment.

You've got to pay the power bill and the heating and cooling bills as well. Then there's the amount of real estate or the space that you need to accommodate all of this equipment. In a server room or even in your own on-premises data center. In the cloud, you only pay for the resources that you use, kind of like electricity, or water. It's metered based on your consumption, you pay a certain amount. That's an operational expense otherwise shortened to OPEX. So the prices will adjust depending on how much you consume.

That's why it's important in the cloud, to ensure when you're finished with something. Such as a virtual machine or database that was used for testing, that you immediately shut it down, and if you don't need it in the future, delete it. Otherwise leaving things running means incurring unnecessary charges. Then there's the control of things like data and the configuration of your IT solutions. With on-premises you have full control of every aspect of the data life cycle. From its creation, its storage, it's sharing. You also have full configuration control of your IT solutions. In the cloud, in some cases, data ownership could be questionable. Especially where you start replicating cloud stored data to alternate regions around the world.

Where that data could be subject to the laws within the jurisdiction that the data center falls within, and of course in the cloud we have limited configuration control. Because some of the responsibility for the underlying IT infrastructure falls upon the cloud service provider. Certainly at the hardware level all of the responsibility falls on the cloud service provider. When comparing on-premises computing to cloud computing, security always comes up. Now with on-premises environments, you might have sensitive data or systems that are highly classified, that require a high level of privacy.

Now that could be related to government agencies, including military and law enforcement, or banking. However, in the cloud, there is a potential for a security breach, just as there is on-premises. Now one of the arguments that you'll hear is that, well, public cloud service providers are more of a target. They're centralized target where there are multiple customers or tenants storing potentially sensitive data. Which you could also liken to saying, you shouldn't store your money in a bank.

Because the bank stores money for a lot of customers, it's a larger target. Remember, public cloud service providers are in the business of earning a profit. It's bad for business if there are security breaches. So chances are, public cloud providers probably have much more security in place than most private sector organizations would be able to afford. So there could be public records, intellectual property, whether it's on-premises or in the cloud, that needs to be protected. But we want to move away from a statement as simple as saying, that security is not as strong in the cloud for data as it would be on-premises.

Because that's definitely not the case. Then there's compliance, we have to think about on-premises compliance with regulations and laws, especially as it applies to sensitive data. In the cloud the same thing is really true. So what to look for with cloud service providers is what is relevant to your organization in the type of data that it will be dealing with. So you might look at legislative acts such as HIPAA for the protection of medical information, or GDPR for the protection of European Union citizen data, or PCI DSS for the protection of credit card holder information.


IaaS
Infrastructure as a Service or IaaS is a cloud computing service model that allows for self service, and that is actually a cloud computing characteristic, self service or self provisioning of cloud based resources. This also includes not only the provisioning, but the monitoring of deployed resources, and also having access to them, such as being able to use SSH to remotely administer a Linux deployed virtual machine in the cloud. So compute would include things like virtual machines.

Networking would include things like virtual network definitions in the cloud into which virtual machines are deployed, and also the configuring of cloud-based storage. All of these items are configured compute infrastructure. Of course, at the end of the day in the data center, these are all based on underlying physical hardware. But the underlying physical hardware is the responsibility of the cloud service provider.

The software deployment of those items as we see here, is the responsibility in terms of management and patching of the cloud service customer. Some characteristics of infrastructure as a service include the fact that the resources, the virtual machines, the storage, it can be provisioned as a service, and as a service means that there's an easy to use interface, whether it's command line based or graphically based.

Costs are based on consumption. So for instance, for every minute that a virtual machine runs, you incur a charge. When you don't need that virtual machine running therefore, you should shut it down to save on costs, and many cloud providers will give you a way to automate the... or schedule the shut down of virtual machine instances. The other thing about infrastructure as a service in the cloud is that it's highly scalable.

Because there are so many pooled underlying resources made available by the cloud service provider, it's very quick and easy to all of a sudden, ask for a more powerful virtual machine. In other words, to resize it, or to group virtual machines together to support a busy application or to increase the amount of storage that's available. So we have control of the infrastructure at the software level as cloud customers with infrastructure as a service.

[Video description begins] Screen title: IaaS. [Video description ends]

So virtualization technology then would apply to servers and operating systems. So in a matter of seconds, potentially you could deploy a Linux or a Windows based virtual machine, once you select the appropriate operating system image version. You can also virtualize networks. You can define a virtual network with one or more subnets and you can specify the IPv4 or the IPv6 address ranges that you want to use. Networking also includes things like network ACLs, access control lists, essentially firewalls where you can control inbound and outbound network flow.

Then there's the storage side, such as provisioning additional storage space that will be used for users to upload content to the cloud. Infrastructure as a service has many different possible use cases for many different types of organizations such as companies that want to avoid high hardware and software costs. Because you weren't paying the upfront cost for the entire hardware infrastructure with cloud computing, you're only paying for what you are using. Also for companies that are experiencing rapid growth. Because of rapid elasticity in the cloud in just a matter of seconds, we can spin up new virtual machines or new storage space that's available or configure a new virtual network into which we deploy virtual machines. All of this can happen very quickly. So for companies experiencing rapid growth, this lends itself to it nicely.


SaaS
Software as a service, or SaaS, otherwise called SaaS, is another form of cloud computing. It's another cloud service model that's often referred to as cloud application services. Arguably, it's the most common way that cloud computing gets used by a vast number of users, such as those using cloud-based email or even personal cloud storage and of course, at the enterprise level as well. So what happens with software as a service is we have prepackaged software that's ready to use that's made available over a network, such as the Internet.

[Video description begins] Screen title: SaaS: Delivery. [Video description ends]

The vendor, in this context, the cloud service provider, is responsible for managing the underlying infrastructure that supports the SaaS solution. So the underlying data storage, the underlying servers that run the software. One of the great advantages about software as a service is rapid elasticity. So in the example of cloud-based email, if your organization hires ten new employees, you can very quickly provision new cloud-based email accounts, and not have to worry about licensing, and so on, in the cloud. Now, they do have to be licensed, but it's already available immediately and conveniently with the cloud provider solution. Scalability is another advantage.

As things get busy, scaling adds more underlying compute horsepower to handle the increased workload. That, in this context, with software as a service would be the responsibility of the cloud service provider. There would be a service level agreement, or an SLA for the specific service such as cloud-based email, a guaranteed level of performance and uptime. Another advantage of software as a service is integration. For example, you might be able to integrate previous used software like email on premises and import messages or archives into the cloud, but it really depends on the specific SaaS solution.

Upgrades are not the responsibility of the cloud customer when it comes to upgrading the underlying software that supports the specific solution such as cloud-based email. That's the responsibility of the cloud service provider, and so from the cloud customer's perspective, that definitely works out to be an advantage. Cloud service providers also strive to make these solutions very very easy to use for the average user. So some characteristics of software as a service. It is centrally managed by the cloud service provider. It's accessible over a network such as the Internet when it comes to public cloud computing.

Vendors are responsible for managing updates to the underlying software, and it's hosted remotely on cloud service provider equipment. So organizations that use software as a service will benefit in many ways. For example, startup companies. It's a very inexpensive way to provision cloud resources at the software level very quickly and easily. It can be used for short-term projects because you're only paying for what you're using and when you remove access to that application, you no longer are charged. Also, it can be used for web and mobile applications.

[Video description begins] Screen title: SaaS: Considerations. [Video description ends]

Now there are some limitations, with software as a service, one being potential vendor lock-in. If you're using a specific cloud service provider's software as a service solution, it might be specific to that provider, and so it could be difficult for you to get your data out of it or to integrate it with other components. But it really depends on the specific solution question, at least it's a consideration.

So integration support falls under that, it might only be limited abilities. You might have very limited customization capabilities, since you don't control the actual underlying servers, that house that software. Then there's the issue of data security. Now, data security isn't solely the responsibility of the cloud service provider, especially in this context. So users might opt, for example, to encrypt documents they create with a cloud-based word processor. S

o some of that responsibility then for data security will certainly fall on users and also cloud users determining, which physical geographical location data is stored in, which means that the data could be subject to laws of that area. Now remember that software as a service runs centrally on cloud provider equipment.

So it's controlled by that third party, the cloud service provider. Because we don't control as customers, the underlying network and storage and servers that run software as a service solutions, performance could be an issue but also at the same time on the other side of the coin. Remember that performance details are specified in the service level agreement and if the cloud service provider does not abide by those terms, then the consequence would be service credits for you the cloud customer against your next cloud computing bill.


PaaS
Platform-as-a-Service, or PaaS, is yet another cloud service model. It's also called cloud platform services. This one serves as a great framework for software developers and testers, which we'll explore in further detail soon. So the infrastructure that supports platform as a service is managed by a third party. Of course, in this context, that third party is the cloud service provider.

[Video description begins] Screen title: PaaS: Delivery. [Video description ends]

So developers then can leverage, platform as a service solutions in the cloud to create and test software and also deliver it to users of that software. A lot of this can be automated. For example, when a developer checks in a new code change that can trigger a series of tests to automatically be run against that for quality assurance, and upon successful testing, then the software could be packaged up and through a push notification sent out to mobile devices or automatically published on a website for download.

A lot of that can be automated. Some advantages of platform as a service, it's scalable because it's running on cloud provider equipment, and cloud providers pool resources together for use by cloud customers. It's highly available, that's especially true when you start configuring replication of your cloud based data to alternate locations. It's highly customizable, and that comes at many different levels. Such as customizing the code that you actually host in the cloud, customizing testing and Automation and customizing the packaging and delivery of the software. So automation is an important part of that.

We even have the option of migrating some of your existing software development data from on-premises into the cloud. That would even include things like databases used by custom software. So characteristics of platform as a Service, it is a virtualization type of technology in a broad sense. It uses a number of underlying virtualization Technologies such as virtual machines and even application containerization, where application files and settings are stored within their own logical boundary. There are variety of services available. That's definitely true. Where you could host custom functions or collections of functions API's in the cloud.

Also, you have different types of databases that can be deployed automatically, kind of as a stack where you'll have certain operating system, certain developer tools and a certain type of database that can be deployed really with just a few clicks. Database integration, is always very important with Platform as a Service. Databases whether they be SQL based or no SQL based where no SQL doesn't really have a rigid storage blueprint as SQL does. These can be used depending on the type of application being constructed. Also accessibility. Platform as a Service, is a service model in the cloud, and one characteristic of the cloud is, self provisioned resources.

So it doesn't take very much for developers to begin provisioning additional items in the cloud. You might say what kinds of items, it could be a code repository that supports code check-in. It could be an automated code pipeline. That includes automated testing that's triggered as we've mentioned, when code is checked-in by developer to a code repository that's cloud based. So who will use platform as a service? Well, organizations that are looking at making customized software applications even for internal use, such as line of business apps, will benefit from platform as a service.

So also the deployment of the app will benefit from platform as a service in the cloud. That would be continuous integration and continuous delivery, such as automated testing, automated packaging and pushing out of software changes. Of course, we We always have to consider the security of data that results from the use of platform as a service offerings. That could mean enabling encryption, for example at the database level. So this would fall upon the responsibility of the cloud customer, in this case, a software developer, to make sure security is implemented correctly.

The other thing is integration such as with existing services, we have to consider any potential runtime issues that might cause Flaws in the software, so it stops functioning. Now again if we have rigid and automated testing in place, then that type of issue should be minimized. Then there are operational issues. Remember that when you use cloud computing, you are essentially outsourcing the responsibility. It's a risk to a third party, and the third party is the cloud service provider. Even though they need to abide by service level agreements, still a risk that at least needs to be considered.


Private Cloud
There's a common misconception that if you run virtualization on premises. So if you're running virtual machines, you have a private cloud. This is not the case. In order to have a cloud, you not only have to use virtualization technologies, but self-provisioning of resources needs to be in place. You need to have a large number of resources pooled together. You need to track and charge based on resource consumption. It needs to be made available over the network. So virtualization is only about one component of cloud computing. So you might wonder then, well, what does constitute a private cloud?

First of all, we're talking about private IT infrastructure that resides behind a firewall. So for example, it could be equipment owned and managed by a single organization on their own network, that adheres to cloud computing principles. Such as rapid elasticity, and self-provisioning, and metered usage. So it's used by one organization and that's where the private comes from. There is a fee per unit time model. In other words, just like with public cloud computing, you are charged based on what you consume, what you use. Now you might say, how can an organization charge itself? This is often used in a private cloud within an organization for departmental charge back.

So different department managers might have access to a web based GUI where they can provision licensing, for example for email users, with just a click of a button, or they can provision virtual machines for testing purposes and that is tracked and at the end of each month, each department is billed accordingly from IT or from headquarters. So what are some advantages of a private cloud? There's no question that you have entire and full control of everything, including security control, not to mention predictable performance.

You can predict what happens in terms of network bandwidth performance and individual virtual machine performance in a private Cloud. Because you control all aspects of it, in the same way you have full configuration flexibility. Again, because you have full control of every component all the way down to the hardware level. Now one important private cloud consideration is the cost of it. Because a private cloud means a single organization uses all of its own infrastructure, all of that infrastructure needs to be paid for somehow up front, and so that's a capital type of expenditure and so that's a cost that needs to be considered.

Then there's the ongoing maintenance, making sure things run smoothly, working through help desk tickets, making sure things are patched, adding updates as they occur and so on. So when should an organization use private cloud computing then? Well, one reason would be because they require a virtualized environment with cloud computing flexibility. Remember, virtualization unto itself does not constitute a cloud. Also, organizations that have privacy or compliance concerns about running their services in the public cloud, could opt to have full control. So that they are compliant, by running it in their own private cloud.


Public Cloud
A public cloud, is accessible over a network such as the Public Internet, or even through a Dedicated Circuit from an organization's on-premises network to the cloud without going over the Internet. But either way, public cloud computing makes shared resources available to subscribers. This would include things like virtual machine servers, storage in the cloud, network configurations, even VPN solutions going to the cloud. All of this can be provisioned through cloud computing in a public sense, as well as the use of software applications.

Things like Office 365 or Google Documents or Google Classroom. All of these things allow end-user productivity software to be made available over a network. In the case of public cloud computing, it's available to anybody that wants to subscribe. So when should organizations use public cloud computing services? Well, the first reason to use it is for rapid provisioning of IT services. So if you need to provision 100 new email accounts, you can do it very, very rapidly in the public cloud. Including taking care of the licensing that goes along with that, compared to what you might need to do on-premises.

Where you might all of a sudden realize you don't have enough hardware to handle that capacity. So first you have to acquire the hardware before you can configure it to be used to support your ten new email users. If you need IT system and data storage scalability. For example, we realize that for a project that we're working on, we need an additional amount of storage space. Well on-premises, you have to physically have that space available in your storage arrays. Now the same thing is true in the public cloud, but the public cloud has enormous capacity, and so you're more likely to be able to have that available immediately in the public cloud, than you would be on-premises.

Organizations that have no desire or don't have the budget to implement a private cloud. Might also be likely candidates for using public cloud computing. Scalability in the public cloud, is based on large hardware installations. That's the vast amounts of pooled hardware resources that are made available to cloud customers by the cloud service provider. So it allows for scalability. For example, with just a few clicks, I could resize an existing cloud based virtual machine, to add more CPUs, more virtual processors to increase its compute power or add more RAM.

This can be done very, very quickly with a minimal effort. Also, scalability means that we can respond to demand for services in real time. For example, you might deploy a load balancer in the cloud in front of your application, maybe a custom application, and as requests for the app increase.

You can have it automatically scale by adding more virtual machine instances to handle the increase in the workload. You can also have it automatically remove those virtual machines when they're not needed to save on costs. Because when you have virtual machines running, you're paying for them. The other thing to think about, is that you're saving in many ways with public cloud computing to what you might alternatively do on-premises.

[Video description begins] Screen title: Costs Savings. [Video description ends]

First thing is that you only pay for the resources that you are using in the public cloud. So for example, if you need a virtual machine to test out a new configuration. You can do that in the cloud, very quickly by spinning up the virtual machine, and then when you're finished, shut it down. You aren't paying for it. Now on-premises, if you have enough people doing that. You might need to actually acquire additional hardware to support that increased demand for testing purposes, let's say with virtual machines. In the cloud, licencing is very convenient and easy to use.

So if you provision a Windows operating system in a virtual machine in the cloud. The price permitted, for example, while the VM is running will also include the licensing costs. That's not quite the case on-premises, you'd have to acquire the licensing and make sure you are compliant with the license terms. Also, you will require less IT staff on-premises. If you are using public cloud computing, than if you exclusively used on-premises IT services. Because there's no hardware to acquire and maintain, and depending on the specific services being used in the public cloud, you might not even require servers on-premises.


Hybrid Cloud
A Hybrid Cloud computing model, combines both private and public clouds. Where a private cloud refers to private infrastructure owned and used by a single organization, that follows cloud computing characteristics, such as metered usage, self-provisioning and so on, as well as using public cloud provider solutions. But a hybrid cloud can also mean that you are linking your on-premises IT infrastructure with the public cloud. Examples of this would include, using a site-to-site VPN, between your on-premises network and the cloud.

Essentially, extending your on-premises network environment into the cloud environment or even linking your on-premises identity store like Microsoft Active Directory with Active Directory in the cloud, to allow users to sign-in once with their on-premises credentials, yet still be authorized to use cloud apps. So there are a number of variations then on what a hybrid cloud is. Now in the public cloud, you might use this, so you could work with services, that don't deal with sensitive data, and also you want the benefits of scalability in the public cloud. Whereby, you might use the private cloud to store more sensitive data. However, that's not to say in any way that storing anything in the cloud is less secure than storing it on-premises.

So we can use a hybrid cloud environment for big data operations. Big data refers to the vast amounts of data, even from streaming over the network, over the Internet, such as data coming in from news feeds, data coming in from IoT devices, it could be coming from anywhere. But when we have vast amounts of data, it makes sense that we have a scalable environment to analyze that data, and an easy and cheap way to do that is in the public cloud, but that's public cloud.

What's the take on hybrid? Well, the hybrid kicks in, because you might have some of those data feeds sourced from your on-premises network, or perhaps your analysis tools are on-premises, but you want big data stored in the cloud. Another use case would be, cloud backup and replication. For instance, you might install an agent on your on-premises servers or even devices, doesn't have to be a server that periodically on a schedule backs data up to the cloud environment, the public cloud. So you've got a link between your on-premises environment and the cloud in terms of backup, even replication.

So not only backups, but you might have live replica data, replicated from an on-premises file server into the cloud, and whether content is changed in the cloud or on-premises, it synchronizes to the other location. Then of course, you might use a hybrid solution for the short term because you are adopting cloud computing. You want to migrate some of your on-premises components into the cloud, such as data, or applications, or virtual machines, that type of thing. The other thing to think about with the hybrid cloud is that, at least on the public cloud computing side, you're only paying for resources that are used.
So you should therefore always avoid idle cloud resources, especially things like databases that you deploy in the cloud as a managed service, meaning you don't have to worry with the underlying servers to get that up and running. Don't leave those things running because you will incur charges. Only leave them running, if they need to be left running.


Community Cloud
A community cloud, is used amongst organizations that have similar IT needs. Such as similar underlying compute requirements, perhaps for graphics processing. Similar storage requirements, such as within national boundaries. Similar security requirements, such as the protection of sensitive data, using very specific tools and methods, and also scalability. So in essence, a community cloud is cloud computing, but it's kind of a subset of it where it's a little bit more specialized and caters to more specific needs. So community cloud characteristics include a shared infrastructure. Well, this is true with all cloud computing models except for private.

Also, understand that the organizations or entities that might have similar computing needs, could be both in the private sector and/or at the government level. So some public cloud service providers, offer government cloud solutions. So when should an organization use the community cloud solution? Well, you probably have to, if for example, it's a government agency that must meet very strict security requirements. So for regulatory compliance related to processing, storing, and collecting things like health information, financial records, legal documents. So it's common then to see in the healthcare industry, for example, community clouds being used that meet the specific security and operational requirements, of that type of industry.


Cloud Migration Risks and Benefits
Organizations that assess moving to the cloud, need to weigh the benefits of cloud computing along with the risks to determine which action should be taken. One of the benefits of migrating to the cloud is reduced capital costs. Now, in the public cloud computing environment, we are using the cloud service provider's underlying infrastructure. Their physical servers, their storage arrays, their network equipment. Which means that we as the customer, do not have to put up the money upfront to acquire that hardware infrastructure, hence, reduced capital costs.

On-demand scalability is a benefit of the cloud. If we determine that we need more power in a virtual machine, we can resize it with a click of a button, and add more RAM or virtual CPUs. If we need more storage space, we can do that quickly. If we need to have more virtual machines running in a cluster to support an app, to improve performance, we can do that very quickly and easily without any underlying technical knowledge. So on demand scalability, is a very important benefit related to cloud computing.

Disaster recovery, many organizations actually use the public cloud as an alternate recovery site. Now this takes proactive planning ahead of time, meaning that you might replicate virtual machines which run applications and data to alternate geographical locations, essentially, to other data centers owned by the cloud service provider. So that in the event of a regional disaster, for example, you've already got your systems and your data running elsewhere. So that can minimize business disruptions. Remote access to applications. Well, when you're running things in the cloud, then you can access them from anywhere.

Now, of course, we have security rules that are in place to limit traffic flow, but the potential is there to allow that to happen, and depending on the specific type of migration scenario you're talking about, you could result with less administrative responsibility. So for example, imagine that you are moving from an on-premises mail server that your IT team must maintain, where all the user mailboxes are stored. Let's say you're moving from that, to a cloud hosted email solution. You don't have to worry about the server anymore.

You can just add users and licenses with a click of a button, and so that means then in that particular example that you don't have to worry about updating the mail server software or the underlying operating system running the mail server. That would then become the responsibility, of the cloud service provider. So that's definitely a perceived benefit. But there's no gain without some kind of undertaken risk. One is proprietary technologies. If a cloud service provider is offering their services or data exchange formats over the network and with files in a very specific format, that could make it difficult to get your data out of that cloud, back on premises or to a different cloud provider.

Then there's network latency and downtime of services, which are potential risks. However, remember that public cloud service providers have a service level agreement that guarantees uptime on a monthly basis, and so usually the risk is more prevalent on the customer side, meaning that if we only have a single Internet connection, linking an on premises office to the cloud and we depend on the cloud, then we should probably consider having a secondary Internet connection to the cloud from a different Internet service provider to increase resiliency against failure.

The other thing to think about is data sensitivity. So, you might have certain laws or regulations that require data to be collected, processed, stored, shared, and archived in a very specific way. So in order to comply with these laws and regulations, it would be upon you, the cloud customer, to configure settings appropriately, to meet those data sensitivity requirements.


Common Cloud Vulnerabilities
One important aspect of properly using cloud computing is thinking about common cloud vulnerabilities. Many of which are no different than what you would experience on-premises. So it all boils down to how you configure and use these services. Let's start by talking about data assets, such as databases or files containing sensitive information. One problem is not encrypting that information. Often, encryption is automatically put in place over the network such as through HTTPS communications, very common.

But what's less common is enforcing encryption for everything that gets stored, at least everything that is considered sensitive. Now, many public cloud providers will automatically encrypt content stored in the cloud. But otherwise, it's always an option for the cloud customer if it's not turned on automatically, and also, customers will always have the ability to use their own custom encryption keys that are in their control for their cloud data that's encrypted. The other possible issue related to data assets is more on the administrative side. Where a data asset is important, also cloud resources are important such as cloud virtual machines running a mission critical app.

So the principle of least privilege, or PoLP, states that only the permissions required to perform a job task should be granted and nothing more, and so principle at least privilege abuse could be a problem where we might simply grant too many permissions to cloud resources, such as to other administrators, and therefore they might mistakenly delete virtual machines that are critical, or deploy too many of them and not shut them down, which means the organization is paying for those unnecessarily, and so what can be done then is to use role-based access control or RBAC.

In other words, if you need someone to be able to manage your virtual machine in the cloud, let's say, but not actually getting to the data within it, we could use a role, that would allow them to manage the virtual machine, and then that would take care of that problem. They wouldn't have any additional permission. So RBAC is an important consideration when it comes to security in cloud computing. Then there's users and devices. For example, instead of going with just username and password, which constitutes single factor authentication, because it's both something you know, you might use multi-factor authentication for all cloud user accounts.
Now, multi-factor authentication uses another authentication factor, such as requiring the possession of a smartphone, where a six digit PIN might be sent. That must be used in addition to a username and password to authenticate. So something you know, plus something you have. The other thing is to harden all user devices. All it takes is a single compromised smartphone that has access to cloud resources to start a security breach or some kind of a malware infection in the cloud.

So always remember that every endpoint device, whether it be a smartphone, a tablet, an industry specific device connected to the cloud. All of these items need to be secured to reduce their attack surface. Then there's the insider abuse. There is the potential for staff or cloud administrators to damage or exfiltrate information. One of the things that we can apply in a cloud computing environment is data loss prevention policies, otherwise called DLP policies.

Data loss prevention, has rules that looks at the type of information or data being worked with, and if it, for example, determines that maybe there's credit card numbers in it, it can automatically encrypt and prevent forwarding of that information through email, as just one example.Then, of course, auditing. Auditing allows for accountability. We can track not only user activity, but also device activity that might be abnormal, such as devices authenticating to a VPN in the middle of the night when that normally does not happen, and many public cloud service providers have mechanisms in place to automatically detect things like this, suspicious login activity.


Azure Virtual Machines
One of the great things about deploying virtual machines in the Azure cloud is how easy and rapidly those virtual machines can be provisioned.
Whether using command line tools or the Azure portal, you can deploy Windows and Linux virtual machines in the Azure cloud. The usage fees that we are charged for that is based on a couple of items, such as the virtual machine size, which really determines the horsepower that virtual machine has when it's running.
And speaking of when a virtual machine is running, you are also charged for the amount of time virtual machines are left running. So when you don't need them to be running, perhaps if you're testing something, make sure to shut down virtual machines, and you might even delete the virtual machine if you no longer need it. There are a lot of factors to consider when you deploy and manage virtual machines in Azure.
We've mentioned the VM size, which consists of things like the number of virtual CPUs, the amount of RAM, and the disk IOPS, the input/output operations per second. So more of these items is better for performance but, of course, you're going to be paying more. But you might need more of RAM or more vCPUs to support the workload running within the VM.

When you deploy a VM, you deploy it into an Azure region or location. And so you should consider this because you might want to deploy it in a region that is geographically close to the user base that will require access to that virtual machine. Azure Virtual Machines have an operating system disk. But you can create separate independent managed disks that you can then attach to virtual machines or detach as needed, and they show up as data disks within the virtual machine operating system.

So in the virtual machine operating system, you still have to treat it as a new disk and initialize a partition and format it. Virtual machines can also have extensions. These are like little software agents that run within the VM operating system. And you might do this for the purposes of things like security. You might want some kind of anti-malware scanner running as an extension within your VM, or a backup agent, or even script support agents, such as for PowerShell desired state configuration.

When you deploy your Azure Virtual Machine, be it Windows or Linux, you also have to consider the Azure virtual network and subnet into which you are deploying it. Which also means that we have to think about the IP addressing that will be assumed from a subnet, or whether or not you need a public IP address for a virtual machine if you need to access it from the outside, such as from an on-premises network.

The thing to consider is, let's say that you're going to deploy five virtual machines into the same Azure virtual subnet. Well, instead of assigning five public IP addresses to each of them, you might consider assigning only one, which gives you a way in, kind of as a jump box. And once you're in, then you connect to the private IP addresses of the other four virtual machines. With Azure Windows Virtual Machines, we need to specify the logon credentials.

In other words, the username and the password that we'll use when we authenticate to it using Remote Desktop Protocol, or RDP. You need to make sure that any firewalls between a client device trying to connect to your Azure Windows Virtual Machine and it allows RDP traffic over port 3389. You can also, when you are deploying or creating a new virtual machine, add it to an availability set. Availability sets group virtual machines together for high availability.

However, the virtual machines in the set don't have to be exactly the same. But you can only do that when you are creating the virtual machine added to an availability set. You should also consider your backup strategy for your Azure virtual machine. Whether you're going to have extensions in the VM that support backup, or whether you're going to be using some kind of a backup vault, and we'll talk about that later.

Azure Linux Virtual Machines can use either username and password authentication or public key authentication, where you don't have to use the password. However, you have to have a public and a private key pair, where the public key is defined with the Azure Linux Virtual Machine, and you would keep the private key, for example, with your on-premises station. We can connect using Secure Shell, or SSH, over port 22, and so your firewalls have to allow SSH traffic for this to work.

Just like when working with Windows Azure Virtual Machines, when we deploy a Linux virtual machine at that time, we can also add it to an availability set a virtual machine availability set for high availability. And we should also consider our backup strategy, whether it's an extension, or whether we have a script running within the virtual machine, or whether we're going to use some kind of a recovery services vault backup solution. When you deploy a manual virtual machine in Azure, meaning it's Infrastructure as a Service, or IaaS,

[Video description begins] Screen title: Azure Virtual Machine Control. [Video description ends]

it means that you have full configuration control of that virtual machine and the operating system and software running within it. Which means that you are responsible for updating those things. However, there's also the notion of managed VMs. This means that virtual machines in some cases can be deployed automatically for you depending on the service you choose, like when you deploy a higher level service like Azure SQL Database. So as such, you have limited configuration control for managed virtual machines. To work with virtual machines in Azure, we can use the Azure Portal.

[Video description begins] Screen title: Azure Virtual Machine Management. [Video description ends]

There's also Azure PowerShell commandlets, the Azure CLI. An ARM template can be used, where you define one or more virtual machines, even other types of resources, that can be deployed and managed through the ARM template. And the ARM template can be itself deployed through the Portal or through PowerShell or the CLI. And developers can also use client SDKs and REST APIs to programatically talk to Azure resources like virtual machines.


Windows Azure Virtual Machine Deployment
There are a few ways that you can end up having a virtual machine running in the Azure Cloud. One way would be to migrate an on-premises server into the cloud.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. The address bar contains the URL: https://portal . azure. com /#home. The page is divided into 2 sections. In the left section, is a menu bar with menus such as Create a resource, Home, Dashboard, All services and Favorites . The right section shows the page linked to the menu item clicked on the left. He clicks Virtual machines in the navigator. Its window displays on the right. It has tabs named Basics, Disks, Networking, Management, Guest config, Tags, and Review+create. The Basics tab is active now. There is a section titled PROJECT DETAILS. It has fields captioned Subscription and Resource group. Another section called INSTANCE DETAILS is present. It has fields such as Virtual machine name and Region. On the left side of the window are 2 buttons- Add and Reservations. No virtual machines display there. He closes this window and clicks Create a resource in the navigator. A page titled New opens on the right. It has a blank search field at the top. Below are two columns titled Azure Marketplace and Popular. In the Azure marketplace column are menus such as Get started, Recently created, Compute, Networking and others. The Popular column has quickstart tutorials for different operating systems with their logos. [Video description ends]

Or you might use a managed service in Azure. In other words, you might configure a service offering that takes care of setting up the virtual machines for you. And of course, you could then manually deploy virtual machines,

[Video description begins] He clicks Compute in the Azure Marketplace column, and then clicks the See all link . A window titled Compute opens. The top of the window has a blank Search field. Below this are various filter options such Pricing, Operating System, and Publisher. Below is a section titled Recommended with large logos of various quickstart tutorials such as Windows Server and Red Hat Enterprise Linux. The next section is titled Operating Systems. [Video description ends]

in this case using the Azure portal. So one way to do that here in the Azure portal is to click Virtual machines when you're looking at the Azure home page.

[Video description begins] He clicks the drop down arrow in the Operating System field. The menu has Select all option at the top and it is checked now. Below are check boxes grouped by operating systems such as Windows and Linux. He unchecks Select all. [Video description ends]

That puts you in the Virtual machines view where you could click Add to add a virtual machine.

[Video description begins] He checks the Windows 2016 Server check box in the Windows group. The search results show a list of tutorials. [Video description ends]

But there are other ways. We could also click Create a resource over on the left. And under the Compute section, we can see some featured virtual machine images like Windows Server 2016 Datacenter. But we can also click See all, where we can even filter this list of virtual machine images. So for Operating System, for example, I can uncheck Select all and maybe I'm only interested in Windows Server 2016. So I can turn that on and the list gets filtered to show me only that.

[Video description begins] He clicks Create a resource in the navigator. A window titled New opens. In the search field, he types template and selects Template deployment from search results. A new window titled Template deployment opens. It has brief explanation about template deployment. A button captioned Create is at the bottom of the window. [Video description ends]

Notice that we are getting not only Windows Server 2016 but also apps installed within it like SQL server.

[Video description begins] A new window titled Custom deployment opens. There are 3 sections here- Learn about template deployment, Common templates, and Load a GitHub quickstart template. The first section has 2 links- Read the docs and Build your own template in the editor. The next section has 4 links- Create a Linux virtual machine, Create a Windows virtual machine, Create a web app, and Create a SQL database. In the last section is a field captioned Select a template. [Video description ends]

BYOL, as seen here, stands for Bring Your Own License. And so it would let you reuse any SQL Server 2016 Enterprise licenses you might already have here in the cloud. Another option for deploying a virtual machine here in the portal would be to click Create a resource. And if I search for template, I could choose Template deployment, then I can click Create. We're talking about ARM templates here, Azure Resource Manager. And what we could do is build our own template and

[Video description begins] He closes the window without saving any changes. [Video description ends]

manually specify that we want to create one or more virtual machines. We could even import any existing template files, you might have to do that.

[Video description begins] He returns to the Azure home page and clicks Virtual machines again. Then he clicks the Add button. [Video description ends]

There's also templates here to create a Linux virtual machine, Windows.

[Video description begins] The Create a virtual machine window opens on the right. [Video description ends]

We can ever refer to some templates available on the GitHub community that deal with the creation of the virtual machines.

[Video description begins] In the PROJECT DETAILS section, he leaves the default value of Pay-As-You-Go in the Subscription field, and selects Rg1 in the Resource group field. [Video description ends]

So there are a lot of ways to do it and this is just in the portal. We haven't even talked yet about how to do that in the command line tools, but we'll do that on the demos. So I'm going to go ahead and close out of this. And I'm going to go back to the Virtual machines view on the left and I'll click the Add button here, we're going to do it this way. So the first thing we have to do is tie this to a subscription and then deploy it into a resource group. So I'm going to deploy this into an existing resource group I have called Rg1, then the virtual machine name. It's very important that we're aware of what types of characters are allowed.

[Video description begins] He types a name in the Virtual machine name field. Since the name does not fulfil naming convention rules in Azure, the field gets highlighted in red and rules for naming appear below the field. There are 3 rules in all, and as he types any name, the rule which is violated gets a red cross mark in front of it. [Video description ends]

So here, I've got a bunch of capital letters and weird symbols of my virtual machine name. And it tells me that the virtual machine name can't contain non-ASCII or special characters.

[Video description begins] He leaves the default value of No infrastructure redundancy required in the Availability options field. [Video description ends]

Well, that's fine. Now like all Azure resource deployments, we have to have first considered a naming standard. I'm going to call this eastwindowsvm1. So that's the name of my virtual machine. Then I have to deploy it in a specific Azure region. So I'm going to go ahead and choose here Canada East. I'm not going to configure any availability options, but I'm certainly interested in the image. Here, it's got Ubuntu server, well, that's Linux. If I open this drop down list, I can see I can choose from other items including Windows Server 2016 Datacenter. Now you always have to consider what kind of workload will run, because that's going to determine which operating system you need to support that workload. So in this case, if I've already thought about that,

[Video description begins] A new window titled Select a VM size opens. It has a Search field on top and various filter options, namely Size, Generation, Family, and Premium disk. There is an Add filter button. A table with 12 of 165 VM sizes display. The table has columns VM SIZE, OFFERING, FAMILY, VCPUS, RAM, DATA, MAX IOPS, TEMPORARY STORAGE, PREMIUM DISK STORAGE, and COST/MONTH. [Video description ends]

I'll choose Windows Server 2016 Datacenter. Now at the same time, I've got a link to browse all images and disks if I want to see more, but that's the selection I need. So I'm good with that. The sizing here determines how much horsepower is available. So here, we've got one virtual CPU and 3.5 gigabytes of memory.

[Video description begins] The default size is Standard DS 1 v2. [Video description ends]

Again, if we consider the workload that this virtual machine will be

[Video description begins] The next section is titled ADMINISTRATOR ACCOUNT. It has 3 fields- Username, Password, and Confirm password. [Video description ends]

supporting, we'll be able to determine if that makes sense or not. And if it doesn't, I can click Change size. Naturally, the more vCPUs and RAM and the faster disk speed for Max IOPs that you select, the more cost you will incur. And we can see that over here in the cost per month estimation over on the right hand column.

[Video description begins] Naming rules for Username field appear. Rule 1 is that Username cannot contain special characters or end with period. Rule 2 is that Username must not include reserved words. Rule 3 is that the value is in between 1 and 32 characters long. [Video description ends]

However, if I'm happy with the default sizing that was selected, I can leave it.

[Video description begins] The next section is INBOUND PORT RULES. It has one compulsory field- Public inbound ports with 2 radio options - None and Allow selected ports. The default value is None. The next field is Select inbound ports. [Video description ends]

The next thing is credentials for our new virtual machine. So I'm going to fill in a username and a password and I'll confirm that same password.

[Video description begins] The last section is SAVE MONEY. There is just one field -Already have a Windows license? And is has two radio options- Yes and No. No is the deafult value. [Video description ends]

Now bear in mind, you won't be able to use things like Administrator because that's considered a reserved word. So I'm just going to use a user here, cirving, I've specified and

[Video description begins] The next tab, Disks, gets activated now. Its first section is titled DISK OPTIONS. It has one drop-down field- OS disk type, with a default value of Premium SSD. An additional field is Enable Ultra SSD compatibility (Preview) with 2 radio options- Yes and No. No is the default value. This field is disabled now. [Video description ends]

confirmed a password. I can also at this point in time determine what type of inbound network traffic I want to allow. I'm going to leave the default selections because we'll be talking about firewalls and inbound and outbound allowed traffic in other demos. And down below it says, do you already have a Windows license?

[Video description begins] The next section is titled DATA DISKS. No data disks are available now. There are links to create and attach a new disk, and to attach an existing disk. [Video description ends]

Well, we do not, so I'm going to leave it on the default of No. We don't have a license that we can reuse. I'm going to click Next to go to the disks configuration. Here we can determine if we want to use Premium SSDs for

[Video description begins] The Networking tab gets activated now. Its first section is NETWORK INTERFACE. It shows no available network interfaces. The next section is titled CONFIGURE VIRTUAL NETWORKS. It has fields-Virtual network, Subnet, Public IP, NIC network security group, Public inbound ports, and Accelerated networking. [Video description ends]

the utmost in performance, or Standard magnetic hard disk drives, HDD's. Now that would incur less cost, but of course, that comes with less performance. I'm going to leave it on Premium SSD. I can also attach data disks, whether they already exist or they want to Create a new one. Because what we're going to be creating here is essentially the operating system disk for the virtual machine. I'm okay with the defaults here of not having an additional data disk. So I'll click Next to move on to the Networking section. You need to deploy the virtual machine into an Azure Virtual Network, a VNet. Now, we can create a new Virtual network. Or I can choose from the drop down list if I've already created any.

[Video description begins] The value in Subnet is EastSubnet 1 with an IP address. [Video description ends]

And I have, I've got one called Eastvnet that I've deployed into a resource group called Rg1 which we also see listed here. So I'm going to leave that selection.

[Video description begins] The value in Public IP is ( new ) eastwindowsvm 1 - IP. [Video description ends]

A VNet is organized into one or more subnets. And down below, I can choose the appropriate subnet within that VNET that I actually want to deploy the virtual machine in. And always take note of the IP addressing because that reflects what addressing will be used, at least within that subnet for your Azure virtual machine.

[Video description begins] The default value in NIC network security group is Basic, in Public inbound ports is None and in Accelerated networking is Off. [Video description ends]

I can determine whether I want a public IP address available here.

[Video description begins] The last section is titled LOAD BALANCING. It has one field- Place this virtual machine behind an existing load balancing solution? It has 2 radio options -Yes and No. No is the default value. [Video description ends]

It's going to make a new one automatically

[Video description begins] The next tab- Management- gets activated. Its first section is titled MONITORING. It has 3 fields- Boot diagnostics, OS guest diagnostics, and Diagnostics storage account. [Video description ends]

that uses a name of the virtual machine with -ip at the end of it. Now, I want the public IP because I want to be able to connect to this virtual machine from outside of Azure from across the Internet.

[Video description begins] The default value in OS guest diagnostics is Off and the value in Diagnostics storage account field is eaststorageaccount 1. [Video description ends]

So we're not going to worry about changing any of the security settings or inbound ports because we'll be focusing on that in another demonstration. Much like we'll be talking about load balancing later on as well.

[Video description begins] The next section is titled IDENTITY and it has just 1 field, System assigned managed identity. Its default value is Off. [Video description ends]

So we will leave all the default selections for those. Then I'll click Next.

[Video description begins] The next section is titled AUTO-SHUTDOWN and it has just 1 field, Enable auto-shutdown. Its default value is Off. [Video description ends]

Boot diagnostics, which is used to capture things like boot up screens, is on by default and we've got a diagnostic storage account where that will be stored. I can also turn on operating system guest diagnostics if I want

[Video description begins] The last section is titled BACKUP, and it has 1 field, Enable backup with a default value of Off. [Video description ends]

metrics about the performance of that virtual machine gathered periodically.

[Video description begins] The tab Guest config gets activated. It has 2 sections- EXTENSIONS and CLOUD INIT. [Video description ends]

We can also assign a system assigned managed identity. You would use that if, for example, you had an app within this virtual machine that needed to talk to an Azure Key Vault to get credentials of some kind. We can also enable auto shutdown so that if we forget to turn off virtual machines at the end of the day, they'll turn off based on our configuration so we don't keep incurring costs.

[Video description begins] When he clicks the link Select an extension to install in the EXTENSIONS section, a new window titled New resource appears in the far-right side. It lists extensions with their logos. He closes this window. [Video description ends]

And we can determine whether we want to enable backup so I'm going to leave all of these default selections as they are. I'll click Next. I can also add extensions within the virtual machine.

[Video description begins] The tab Tags gets activated now. It has 3 drop-down fields- NAME, VALUE, and RESOURCE. He selects Project in the NAME field and Project A in the VALUE field. The value in RESOURCE field is 7 selected. When he has populated these fields, a new row with blank fields appears for adding new tags. [Video description ends]

If I choose Select an extension to install, we've got essentially agents that run within the virtual machine operating system for things like backup. Or for additional cloud security or script extensions if we want to run custom scripts, PowerShell Desired State, to maintain a baseline configuration, and so on. But I'm not going to do that, I'm going to click Next for tagging.

[Video description begins] The Review+create tab gets activated now. A progress bar at the top shows the review progress is going on. When it completes, a message says:Validation passed. PRODUCT DETAILS and TERMS shows the values he added in all the previous steps. [Video description ends]

And I will assign this to the ProjectA project,

[Video description begins] A window appears in the top-right corner showing the progress of the deployment process. The window has the text: Initializing deployment. [Video description ends]

I've already got that tag and value, otherwise I could add new ones. And then I'm going to click Review and create.

[Video description begins] After the window text changes to Submitting deployment, a screen titled Your deployment is underway appears. It has Cancel and Refresh buttons enabled on the top. [Video description ends]

So at this point, it's going to run a little validation based on my selections. And it now says validation passed and this is very important.

[Video description begins] The All resources window opens. [Video description ends]

We can see here what the US dollar cost per hour is approximated at here, so this is going to be important for determining the pricing for this. I'm okay with all of these settings. So I'm going to go ahead and click Create to build our Windows virtual machine. That pops us into this Your deployment is underway screen. And I could even click on All resources on the left, which I will do,

[Video description begins] Under the NAME column, 5 items for eastwindowsvm 1 are present. In the TYPE column, the item types are Virtual machine, Disk, Network interface, Public IP address, and Network security group. [Video description ends]

to see what's happening. Now, because a virtual machine really consists of a number of moving parts like an IP address, a network security group, a network interface, you'll notice that you could end up with more than just the virtual machine resource listed here when you're looking at the All resources view. And as I refresh the All resources view, notice I'm seeing more and more. I'm seeing the operating system disk for that virtual machine. And of course, I can also see the virtual machine itself. And as is the case with all Azure resources, if I were to click on the link for the name of that virtual machine, it opens up the properties blade where I could see all the items that I could configure about this virtual machine.

Linux Azure Virtual Machine Deployment

[Video description begins] Topic title: Linux Azure Virtual Machine Deployment. The host for this session is Dan Lachance. [Video description ends]

In this demonstration I will use the Azure portal to create a new Linux virtual machine. To get started, in the upper left, I'm going to click Create a resource.

[Video description begins] The Microsoft Azure portal home page opens in a browser window. He clicks Create a resource in the navigator pane. [Video description ends]

Now I can see the most popular virtual machine images here, including Ubuntu Server, which I'm going to use. Now I can see more options by clicking the Compute category on the left. And then on the right, I can click the See all link. Here I can filter, for example, by operating systems. So instead of selecting all operating systems, I could choose only the Linux variants shown here.

[Video description begins] In the Compute window, he clicks the drop-down arrow of Operating System field. He unchecks Select all and checks all the 6 check boxes in the Linux group. [Video description ends]

Now when I do that and then close the drop down list, the filter is effective. So in this case for example, I'm going to choose Ubuntu Server 18.04 LTS. When I click on it, it gives me a little brief synopsis about that.

[Video description begins] A new window title Ubuntu Server 18.04 LTS. It has a brief explanation about the server and a section titled Legal Terms. Its publisher and documentation links are also displayed. A Create button is placed at the window bottom. [Video description ends]

And I'm going to go ahead and click Create. Then I get details that need to be filled in.

[Video description begins] A Create a virtual machine window opens. The Basics tab is active now. [Video description ends]

So I've got the Subscription already filled in. I'm going to put this into an existing Resource group.

[Video description begins] He selects Rg1 in the Resource group field. [Video description ends]

And I'm going to call this, eastlinuxvm1. For the region, in this case I'll chose Canada East, because that's the closest proximity where I am working from. And I'm going to make sure that the Ubuntu image here is what I want, it is.

[Video description begins] The value in the Image field is Ubuntu Server 18.04 LTS. [Video description ends]

I'm going to leave the default virtual machine sizing. Otherwise, if I need to accommodate a busier workload, I might need more than 2 vcpus and 8 GB of memory. Notice that when I change size, it's not only increasing or scaling up vertically. But I can also scale down, that means choosing less horse power. So for example, maybe I'll choose a standard general purpose type of sizing. When I click Select, it now reflects the change, only 1 vcpu and 2 GB of memory.

[Video description begins] He selects Standard B1ms in the Select a VM size window. [Video description ends]

With Linux you can either use SSH public key authentication or standard password authentication, which I'll do here.

[Video description begins] He selects the Password radio option in the Authentication type field. [Video description ends]

With password authentication you've got to specify a username and confirm a password. But with SSH public key, you need to paste in the SSH public key for the specific username that you specify. And of course, you need to have the related private key in your possession on your station.

[Video description begins] When he selects the SSH public key radio option, the Password and Confirm password fields disappear, and are replaced by a field captioned SSH public key. [Video description ends]

So I'm going to go ahead and configure password authentication here. Once I've done that, as we scroll down further, we can control things like inbound port rules for network traffic.

[Video description begins] He leaves the default value of Off in the Login with Azure Active Directory field. [Video description ends]

However, I'm going to leave the defaults, I'm going to click Next.

[Video description begins] The Disks tab gets activated now. [Video description ends]

So here we have the option, just like with the Windows virtual machine, as to whether we want the better performing SSD, or the slower performing HDD, hard disk drive type of disk system. So I'm going to leave it on Premium SSD. I'm not going to attach any additional data disks. I'll just stick with the operating system disk here. When I go to Next, I can then place this within a virtual network in subnet, which I can either create newly or I can choose from the drop-down list.

[Video description begins] The Networking tab gets activated now. [Video description ends]

I'm going to leave this in my existing Vnet and Subnet. I wanted to create a Public IP, so I can reach into that virtual machine from across the Internet. I'm not going to change any of the other settings here related to inbound ports,

[Video description begins] The value in Virtual network field is EastVnet 1 and the value in Subnet field is EastSubnet 1 and an IP address. [Video description ends]

public configuration, or NIC security group options. I'm not going to change load balancing options. So in other words, I'm just going to click Next.

[Video description begins] The Management tab gets activated now. [Video description ends]

I'm going to leave the defaults for boot and OS guest diagnostics and auto-shutdown, I'll click Next.

[Video description begins] The Guest config tab gets activated now. [Video description ends]

Now, on the Guest config, I could click Select an extension to install, which is an agent that exist in the VM, just like it does for Windows. So for virus scanning, or for backup purposes, and so on.

[Video description begins] The New resource window pops up. [Video description ends]

But I'm not going to do that. I'll click Next for tagging.

[Video description begins] The Tags tab gets activated now. [Video description ends]

And here I could tie it to a project. Now I can tie it to an existing project, in this case ProjectA. That's a value, that's already been filled in, or I'm going to define something new here, Project B.

[Video description begins] He selects Project A in the VALUE field and changes A to B. [Video description ends]

Then I'm going to click Review + create. I'm going to check that all my options passed the final validation.

[Video description begins] A message- Validation passed- displays on the top of the window. [Video description ends]

Here we can see it has, listed here at the top. So I'm okay with this. I can see the pricing per hour on a US dollar basis, then I'll click Create. And that's going to give us a little deployment screen so we can see how far along the deployment is.

[Video description begins] The Initializing deployment window pops up in the top-right corner of the window. [Video description ends]

And of course, I can go to the All resources view on the left. And as I refresh it here, we'll see it has started to create the various resources that are required to run my Linux virtual machine.

[Video description begins] He clicks the All resources menu in the navigator and its window opens . He keeps clicking the Refresh button to update the list of resources displayed below. [Video description ends]

That would include things like an IP address, a network security group, and other items like the network interface, that it's going to create as we keep going. Here we can see the network interface, and even the virtual machine itself. So when I click on that virtual machine link to open up its properties blade, we can see from here we have all management options available in the portal. Including the ability to start, stop, and restart the virtual machine.

[Video description begins] He clicks eastlinuxvm 1 link under the NAME column and its window opens. [Video description ends]

Just like we have the option to do for a Windows virtual machine.

Connect to Azure Virtual Machines

[Video description begins] Topic title: Connect to Azure Virtual Machines. The host for this session is Dan Lachance. [Video description ends]

Once you've deployed a virtual machine into the Azure cloud, how do you connect to it?

[Video description begins] The Microsoft Azure portal displays in a browser window. The Virtual machines page is open. [Video description ends]

Well, there are a few ways to do it, and our perspective in this demo will be how to do it from outside of Azure. In other words, from over the Internet from our on-premises network. So here in the Azure portal, I've already clicked on the Virtual machines view on the left. And we've got two virtual machines here, one running Linux, one running Windows. We can see that one is in the midst of being created and one is running.

[Video description begins] The 2 items display in the Virtual machines window. They are eastlinuxvm 1 and eastwindowsvm 1. The status of the first is shown as Creating and the second as Running. [Video description ends]

So our Windows virtual machine is currently running. So we're going to talk first about how to connect to a Windows virtual machine deployed in the Azure cloud. So I'll click on the link for the name of that Windows virtual machine.

[Video description begins] The eastwindowsvm 1 window opens. Properties of this VM display here. [Video description ends]

What I'm interested in here is its public IP address. I've configured it with a public IP so I can reach into it from over the Internet. So when I hover over it, I get the little two pieces of paper icon over on the right, which implies copying, like the tip tells me. So I'm going to click to copy that to my Windows clipboard.

[Video description begins] A tip saying Click to copy appears when he hovers over the Public IP address. The tip text changes to Copied when he clicks the copy icon. [Video description ends]

Next, I'm going to fire up the Remote Desktop Protocol, or RDP client, here on my Windows 10 station.

[Video description begins] A window titled Remote Desktop Connection displays. He pastes the copied IP address in the Computer field and None specified in the User name field. 2 buttons- Connect and Help display in the window. [Video description ends]

Now I'm going to paste that public IP address assigned to my Azure Windows virtual machine, and then I'm going to click Connect.

[Video description begins] A warning message displays in a window. He clicks the check box captioned Don't ask me again for connections to this computer, and clicks the Connect button in the window. [Video description ends]

I'm going to tell it, Don't ask me again for connections to this computer, about trusting it, and I'll click Connect again, Now, notice I'm getting a message that says, Remote Desktop can't connect to it. Well, we know it's running, and we know that that is a valid IP address, and obviously we are connected to the Internet to see this screen in the first place. So it's probably related to some kind of blockage, not allowing port 3389 traffic, which is what is used by Remote Desktop Connections. So I'm going to go ahead and click OK, and let's go back into Azure and take a look at this.

[Video description begins] A window showing the progress of the connection displays. The text: Initializing remote connection- displays there. [Video description ends]

[Video description begins] He closes all windows and returns to the Azure page. [Video description ends]

So I'm still in the portal, I'm still looking at the Properties blade for my Windows virtual machine. I'm interested in clicking on Network in the Properties blade.

[Video description begins] He clicks Networking in the Settings group in the navigator. [Video description ends]

On the right I can see that VNet, so virtual network inbound traffic, is allowed. It says allowed over on the right, so is load balancer traffic, but everything else is denied. Well, no wonder we can't make a connection. So I'm going to go ahead and click Add inbound port.

[Video description begins] The Networking window opens on the right. The Inbound port rules tab is active now and it shows a table with all the active ports. The table has columns titled PRIORITY, NAME, PORT, PROTOCOL, SOURCE, DESTINATION, and ACTION. There are 3 ports listed in the table. 2 ports have Allow in the ACTION column, and 1 port has Deny. [Video description ends]

[Video description begins] A new window titled Add inbound security rule displays. [Video description ends]

The source here can be configured as a specific IP address, or an Application security group, or I'll leave it here on Any. Then I can specify the source port.

[Video description begins] The first field is Source and it has 4 options in the drop-down menu. They are Any, IP Addresses, Service Tag, and Any. The default value is Any. [Video description ends]

Well that's fine, but the destination here, I can specify as being any or a specific IP address. I'm going to leave it here on any, but the destination port range is important.

[Video description begins] He leaves the default value of * in the Source port ranges field. [Video description ends]

[Video description begins] There are 4 options in the Destination field drop-down menu. They are Any, IP Addresses, VirtualNetwork, and Application security group. Any is the default value. [Video description ends]

Here I want to allow traffic to 3389.

[Video description begins] He clears the Destination port ranges field and types 3389. [Video description ends]

And that's going to be TCP based, or I could specify UDP, or just leave it on Any, and in this case I want to allow not deny it.

[Video description begins] He selects Any in the Protocol field and Allow in the Action field. [Video description ends]

So I have to also specify the priority. Notice the default priority here is 100. Let's also change the name here to reflect the new port number for Remote Desktop Protocol.

[Video description begins] He types Port_ 3389 in the Name field. [Video description ends]

Then I'm going to go ahead and click Add. Now, that's going to add it to the list of inbound rules that we see listed in the background.

[Video description begins] A window with the text- Creating security rule- pops up in the top-right corner of the window. [Video description ends]

It's important to note that the rule is at the top of the list, because these rules are checked from top down. And so we don't want this Port_3389 rule underneath the DenyAllInBound, because it would never get used. So let's go ahead and try to Remote Desktop into this virtual machine again. Well, this is much better.

[Video description begins] The newly-added rule is at the top of the list. [Video description ends]

[Video description begins] A window titled Windows Security displays. It has the text - Enter your credentials- and 2 fields. The first field has cirving and the second field has an encrypted password. [Video description ends]

I've specified my username and password that I defined when I deployed that virtual machine, and I'm going to go ahead and click OK. We can see here we're being asked to trust the identity of the computers. I'll say, Don't ask me again, I trust it, and I'll choose Yes.

[Video description begins] A window shows the progress of the remote desktop connection. Then another window titled Remote Desktop Connection displays. He clicks the check box in the window, and the Yes button. [Video description ends]

And after a moment, we can see that we are actually now being sent into a Remote Desktop session of that Windows Server 2016 virtual machine, which is running in the cloud.

[Video description begins] The 2 windows close and a new desktop screen appears. [Video description ends]

And before you know it, we're in. So it's just another Windows virtual machine. In this case, it happens to be running in the cloud.

[Video description begins] A panel titled Networks display on the right. It is asking for access permissions. He clicks the Yes button. [Video description ends]

Much quicker and easier to set up than we might do if we were trying to set this up ourselves manually on-premises. And if I go into the Start menu here, and let's say we go to a command prompt. So I'm going to run cmd. You can see in the background it's automatically launching the Server Manager GUI tool, which is normal for new installations of the Windows Server operating system.

[Video description begins] He clicks Run from the Start menu and types cmd. Then he clicks cmd from the best-matched results. A new window titled Select Administrator C:\Windows\System32\cmd.exe displays. [Video description ends]

But what I want to do here is simply type ipconfig. And notice here that we don't see a reference to the public IP address we connected to, because that's not configured within the virtual machine operating system, it's a separate Azure resource.

[Video description begins] At the command prompt, he types and executes the following command: ipconfig. The output displays. It is the Windows IP Configuration of the remote machine. He highlights the IP address 10.1.1.4. [Video description ends]

However, what we do see is an IP address that's been assigned based on the subnet address range that we deployed the virtual machine into. So that's it, we are now able to get into our Windows virtual machine. Well, that's fine for Windows, but what about Linux? Back here in the portal, I've gone back to my Virtual machines view and we can see our Linux virtual machine now has a status of Running.

[Video description begins] He closes the command prompt window and returns to the Azure portal. The Virtual machines window displays here. [Video description ends]

So I'm going to click on it so that we can see its public IP address.

[Video description begins] He clicks eastlinuxvm 1 from the list and its window opens. He points to the Public IP address 52.235.38.158. [Video description ends]

Now, what you want to do is use an SSH client of some kind. So if you're using a Linux machine already, you can use the SSH command line to connect to your Azure Linux virtual machine. Or, I'm using Windows, I could also use the free PuTTY tool. I've downloaded and installed the free PuTTY tool. And when I fire it up, I can paste in the public IP address from my Linux VM running in Azure, along with Port 22, which is used by SSH.

[Video description begins] He opens the PuTTY Configuration tool. It has a navigation pane on the left and Basic options for your PuTTY session on the right. The Linux IP address displays in the Host Name for IP address field, and the number 22 displays in the Port field. Connection type field has the SSH radio option clicked. [Video description ends]

I've already gone, made some other changes, like the window appearance to increase the font, and I've saved it into a setting called Azure Linux VM.

[Video description begins] In the navigation pane, he clicks Appearance in the Window menu group. New settings display on the right. [Video description ends]

So I can load that up at any point in time.

[Video description begins] Then he clicks Session in the navigation pane. Azure Linux VM displays in the Saved Sessions field. 3 buttons- Load, Save, and Delete are also present here. [Video description ends]

Now, to make the SSH connection, I would click Open.

[Video description begins] He clicks the Open button in the window and a new window with the IP address in the title bar opens. The window is blank. [Video description ends]

And it's trying to make the connection, but remember with the Windows virtual machine there was no default inbound port enabled? That's the problem here. Let's go back and let's explore that here in the Linux virtual machine in Azure.

[Video description begins] He closes the window and returns to Azure. The Networking window displays here. [Video description ends]

So I'm going to go to networking and again, we can see our inbound ports. There's no allowance here for port 22, so I'm going to click Add inbound port, and I'm going to specify a destination port of 22, so TCP 22 for SSH allow.

[Video description begins] The Add inbound security rule window opens and he types 22 in the Destination port ranges field, selects TCP in Protocol, and Allow in Action. He types Port_22 in the Name field. [Video description ends]

And I'm going to change the name here to reflect the port number, and I will go ahead and click Add. And we can now see the rules at the top. It's allow rule, so it should allow our traffic in.

[Video description begins] Port_22 displays at the top of the inbound ports list. [Video description ends]

Let's go back and test it out. So back here in PuTTY, let's try again.

[Video description begins] He again opens the PoTTY configuration window and clicks the Open button. [Video description ends]

I'm going to click Open. This time we get something immediately.

[Video description begins] The IP address window opens again and a security alert message displays in a window. He clicks Yes in the window. [Video description ends]

So it's asking me, do we trust the unique fingerprint for the server, because it's the first time we've connected. I'll choose Yes, and it wants me to log in. Well, I've specified credentials when I deployed this. So we're using username and password authentication as opposed to public key authentication, which is a choice when you deploy a Linux virtual machine.

[Video description begins] He returns to the IP address window and the text- login as- displays there. He types cirving and presses Enter. A line of text appears. It reads: cirving @52.235.38.158's password. [Video description ends]

So it now wants the password for this account. So I'll go ahead and supply that. And after I've done that, if the credentials are correct, we will be logged into the virtual machine remotely over the Internet. And we can see in fact, that's been done, and if I do an ifconfig to show the interface, we can see not the public IP, just like with Windows, but rather the private IP, which is derived from the address range assigned to the subnet that this Azure virtual machine was deployed into.

[Video description begins] The command prompt changes to cirving@eastlinuxvm1. He types and executes the following command: ifconfig. The output displays. It shows the configuration details of the remote machine. He highlights the public IP address 10.1.1.5. [Video description ends]

Azure Virtual Machine PowerShell Management

[Video description begins] Topic title: Azure Virtual Machine PowerShell Management. The host for this session is Dan Lachance. [Video description ends]

In this demonstration, I'll be using PowerShell to create a new Azure virtual machine. Here in the PowerShell ISE, I've already got a script ready to go. In the first line of the script, it's actually lines 1 and 2 but I've got the back tick symbol here as the line continuation character. I've got a statement using a PowerShell cmdlet called Get-AzVMImage.

So this is important because we can specify the image name that we want to build the new virtual machine from. And so, let's go ahead and highlight that first set of code for Get-AzVMImage. And I'm going to go ahead and run that selection.

[Video description begins] A Windows PowerShell ISE window displays. There is a menu bar and a tool bar at the top. A tab titled it_clazfd_ enus _06.jps1 is active. The screen below is divided horizontally into 2 scrollable sections. The top section has lines numbered from 1. Code is written in lines 1 through 19. In lines 1 and 2, the following command is written and highlighted: Get -AzVMImage -Location "Central US" -PublisherName "MicrosoftwindowsServer" -Offer "windowsserver" -Skus "2012-R2-Datacenter". He clicks the Run button denoted by a page and a right-facing arrow. The highlighted command displays in the bottom section of the window. [Video description ends]

And down below, we can see some of the images that are available here based on Microsoft Windows Server.

[Video description begins] The command output displays in the section below. It is a table with all the images and their Version, FilterExpression Skus, Offer, PublisherName, Location, and Id. [Video description ends]

So we can see here that the SKU names are listed in the list. However, I'm going to go ahead and comment those back out in my script. And I'm going to clear the screen down at the bottom.

[Video description begins] He types a # in the beginning of lines 1 and 2. In the bottom section, he types the command cls at the command prompt. [Video description ends]

Now to actually work with a virtual machine. To build it through PowerShell, the first thing I'm doing is building a variable here called $creds for credentials. And we're using the PowerShell Get-Credential cmdlet, which will pop up a graphical dialog box where I can specify both a username and a password. And so that's going to be stored in the $creds variable that I will refer to later.

[Video description begins] He highlights the following command in line 6: $creds = Get -Credential -Message "New VM username and password?". [Video description ends]

Then I'm creating a variable called vmconfig. And I'm setting the resource group that I want to deploy this virtual machine into. I'm setting the name of the virtual machine, the location, the image I want to create the virtual machine from, in this case Win2016Datacenter. I'm also giving a name for the public IP address resource. Here's the $creds I'm passing for the credential. And then I'm opening port 3389. So what these all are in the vmconfig section here, ResourceGroupName, Name,

[Video description begins] He highlights the following code written in lines 8 through 17, line by line: $vmconfig = @ { ResourceGroupName = 'rg1' Name = 'vm33452' Location = 'Canadaeast' ImageName = 'win2016Datacenter' PublicIPAddressName = 'eastwindowsvm2_ pubIP' Credential = $creds OpenPorts =3389 }. [Video description ends]

Location, ImageName, these are parameters. And I could just as well use dash in front of each of these parameter names, and then pass the values. All I'm doing here is organizing it into a single resource or a single variable rather called $vmconfig that I simply refer to here. And I pass it to the appropriate cmdlet. The appropriate cmdlet here is New-AzVM to build a virtual machine based on the configuration defined above, the parameters, and their values.

[Video description begins] He highlights the following command in line 19: New - AzVM @vmconfig. [Video description ends]

So let's go ahead and run this entire script by clicking the Run Script button.

[Video description begins] He clicks the run script button denoted by a right-facing arrow. A new window titled Windows PowerShell credential request displays. It has a line of text, New VM username and password?, and 2 fields- User name and Password. [Video description ends]

And sure enough, it pops-up and it says, new VM username and password, that comes from -Message up above. So after I've specified those credentials, I'll go ahead and click OK. And it's going to go ahead and create my virtual machine based on the settings defined here in PowerShell.

[Video description begins] The bottom section shows a progress bar with the text : Creating Azure resources. [Video description ends]

Once the script completes, we're going to go ahead and switch over to the Azure portal to check for our new virtual machine, vm33452.

[Video description begins] Once the process completes, configuration of the VM resource displays. [Video description ends]

And sure enough, here in the portal, if I go to the Virtual machines view, which I've done. We can see our new virtual machine listed, and it's running. So by default, when you deploy a virtual machine, even through PowerShell, its state is set to Running. So it's started up, and ready to go.

[Video description begins] He opens the Microsoft Azure portal in a browser window. The Virtual machines window is open now and vm33452 displays in the list of VM there. Its Status is shown as Running. [Video description ends]

Azure Virtual Machine Scale Sets

[Video description begins] Topic title: Azure Virtual Machine Scale Sets. The host for this session is Dan Lachance. [Video description ends]

Microsoft Azure virtual machine scale sets are used for load balancing, where we have a series of identical virtual machines working together to serve up some kind of an application. It also supports auto-scaling. So for example, depending on the demand, we can increase the number of backend virtual machines supporting the application through the scale set.

So we can control this through the instance count property. This is the number of instances that are running in the scale set, and we can even set that to a minimum value. Pictured on the screen, we have a diagram where, on the left, we've got a client that is trying to access a web application over port 80.

[Video description begins] Screen title: Azure Virtual Machine Scale Sets. On the left is a man's icon labelled Client (Port 80). On the right, are three rectangular boxes, one inside the other. There are 3 boxes inside the smallest rectangle. All the 3 boxes have the text VM (port 80) written inside them. The smallest rectangle depicts Subnet . The next rectangle depicts VNET. [Video description ends]

So that connection goes to the load balancer. So if the client is typing in www.app.com, that is resolving to the public IP address of our load balancer. And so that's how the request gets from the client to the load balancer.

[Video description begins] An arrow points from the client to a Load Balancer, depicted by a load balanced on a circle. [Video description ends]

Now, the load balancer periodically checks that the backend virtual machines, of which we have three here, listed on the far right. It periodically checks to make sure that they are responsive. Because if we have a virtual machine that is not responsive, then client requests are not forwarded to it. Otherwise, we have three virtual machines in the backend in our scale set, in this diagram, that can be used to service client request. And so it increases performance while providing high availability. Because if we have virtual machines in the backend that aren't running, then client requests are simply directed to other ones that are still responsive. We manage our scale sets using the Azure portal.

[Video description begins] 3 arrows emerge from the load balancer and go towards the 3 rectangles on the right. [Video description ends]

[Video description begins] Screen title: Scale Set Management. [Video description ends]

We can use the Azure CLI. For example, you can use the az vmss virtual machine scale set create command to create one. In PowerShell, the equivalent to create a new virtual machine scale set would be New-AzVmss. And then finally, we can also use an ARM template, where we can specify our resource type of Microsoft.Compute/VirtualMachineScalesets.

Deploy an Azure Virtual Machine Scale Set

[Video description begins] Topic title: Deploy an Azure Virtual Machine Scale Set. The host for this session is Dan Lachance. [Video description ends]

In this demonstration, I will use the Azure portal to deploy a new Azure Virtual Machine Scale Set. To get started, I'm going to click Create a resource over on the left, and

[Video description begins] The Microsoft Azure portal homepage displays in a browser window. He clicks Create a resource in the navigation pane and a window titled New opens. [Video description ends]

I'm going to search for the word scale. And here it is, Virtual machine scale set. I'm going to go ahead and choose that, and then I'll click Create.

[Video description begins] A Virtual machine scale set window opens. It has a brief description of scale sets and a Save for later button. The publisher name and documentation links are also present. [Video description ends]

The purpose of creating this virtual machine scale set is to make sure that we have a number of identical backend virtual machines supporting an application. So, basically, we're going to have a frontend load balancer that supports this capability.

[Video description begins] A new window titled Create virtual machine scale set displays. It has a section titled BASICS with many fields. [Video description ends]

So I need a name for my virtual machine scale set. I'm going to call it webapp3 and vmss, virtual machine scale set. So because the backend virtual machines all need to be identical, when you define the scale set, which we're doing, you need to choose the Operating system disk image, okay?

[Video description begins] He types webapp3vmss in the Virtual machine scale set name field. [Video description ends]

So, let's say it's going to be Windows Server 2016 Datacenter. Of course, you could also have some kind of a custom image that has an application loaded within it. Next thing I'm going do here is deploy it to a resource group, and specify the location, and down below I need to specify credentials. Username and password, in this case, for the Windows operating system since that's the image I selected for my scale set. Notice this is different than if you create an Azure load balancer, which we'll see in another demo.

[Video description begins] He clicks the drop-down arrow in the Operating system disk image field. A list of OS display, grouped under Windows and Linux. [Video description ends]

[Video description begins] He leaves the default value of Pay-As-You-Go in the Subscription field, and selects Rg1 in the Resource group field, and Canada East in the Location field. [Video description ends]

[Video description begins] He types cirving in the Username field and the password in the Password and Confirm Password fields. [Video description ends]

Because with an Azure load balancer, as opposed to specifying the operating system image and the credentials here, the load balancer can reference existing virtual machines that are already out there. And they don't even all have to be identical. So that's a little bit different than what we're doing here with the virtual machine scale set.

Here's the Instance count property, where it defaults to having 2, but I can change that. I can also set the instant size, which determines things like the amount of CPU power and the amount of memory. I'm going to click Change size, I'll just choose something very basic, let's say 1 VCPU and 1 GB of RAM.

[Video description begins] He selects 81s VM SIZE in the Select a VM size window. [Video description ends]

And I'll go ahead and select that. And as we scroll further down, I'm going to let it use managed disks, which is by default. Under advanced settings, I can determine whether I want to allow scaling beyond 100 instances. I shouldn't need that, so I'm not going to turn that on.

[Video description begins] He clicks Show advanced settings link below the Use managed disks field. Enable scaling beyond 100 instances field shows up and he leaves its default value of No unchanged. [Video description ends]

And I can also enable autoscaling. Autoscaling changes the number of backend instances automatically based on things like CPU busyness or threshold.

[Video description begins] He selects Enabled in the Autoscale field. [Video description ends]

So here, we can see that if we've got a CPU threshold above 75%, then we can increase by a virtual machine. One VM based on the image that we specified when we were creating this.

[Video description begins] In the Scale Out section, he points to the value in the CPU threshold field. It is 75. Then, he points to the value in the next field, Number of VMs to increase by. It is 1. [Video description ends]

That's for scaling out, adding virtual machines to support a busy workload. The opposite is scaling in, so both of them are horizontal scaling, but scaling it reduces the virtual machines based on a CPU threshold. And this is a good setting. It's important because we don't want to have virtual machines running we don't need, because we're paying for that. And, as I go further down,

[Video description begins] In the Scale in section, he points to the value in the CPU threshold field. It is 25. Then, he points to the value in the next field, Number of VMs to decrease by. It is 1. [Video description ends]

I'm going to decide whether I want to use an application gateway for load balancing, although I don't have any already defined. I could also choose load balancing as a solution, while I am defining the scale sets, I'm really doing two things at once.

[Video description begins] He scrolls down and reaches the field Choose Load balancing options. He selects the radio option Load balancer. [Video description ends]

So I can give a public IP address name for the load balancer IP address. So, if we scroll back up at the top here, the name of this scale set is webapp3vmss. I'll copy that, and I'm just going to go ahead and use that as part of the name here, I'll call it pubIP at the end.

[Video description begins] He pastes the Virtual machine scale set name in the Public IP address name field and adds IP after it. [Video description ends]

And then I can use a domain name label to which the following suffix listed down here, .canadaeast, that's my region, .cloudapp.azure.com will be added.

[Video description begins] He pastes the Virtual machine scale set name in the Domain name label field. [Video description ends]

Of course, that can be customized, but I'll accept that default. And then finally, I have to choose a virtual network. So I'm going to choose EastVNet1, and I've got 1 subnet, that's important because that's where we will be deploying these virtual machines. They're going to assume IP addresses from that subnet address range.

[Video description begins] He selects EastSubnet 1 (10.1.1.0/24) in the Subnet field. [Video description ends]

So it's important to make the correct selection. Do we need a public IP address for each and every instance, it's set to off? I'm going to say, no, because these are running in the backend to support an app. And you might wonder, how do I gain access to them if I need to manage them? Well, you might have another virtual machine outside of the scales set running in that subnet that does have a public IP address.

And, so you can connect to it, for example, from on-premises, and once you're connected to it, you would be on the private network. And you could then manage these additional virtual machines from this scale set. So it means having less public IP addresses, which saves on cost. Okay, so the next thing we're going to do is just click Create. So now let's go to the All resources view, and let's take a look at our newly created scale set.

[Video description begins] He clicks All resources in the navigation pane and its window opens on the right. [Video description ends]

So I'm going to filter this view for vmss, and here we can see we've got our webapp3vmss virtual machine scale set. We can also see the load balancer and the public IP address resources.

[Video description begins] He types vmss in the Name field. 3 items display. They are the VM scale set he just created , the load balancer, and the Public IP address. [Video description ends]

I'm going to go ahead and click on the virtual machine scale set to open up its Properties blade. And in the Overview section on the right, we can see the public IP address here, that's actually for the load balancer component.

[Video description begins] He highlights the Public IP address of the webapp3vmss virtual machine. It is 40.80.249.17. [Video description ends]

And if I click on Instances on the left, we can see the virtual machine instances here in their current state.

[Video description begins] He clicks Instances in the Settings group. 4 instances display on the right. [Video description ends]

And if I were to click, for example, on Scaling, this is where during the creation we had the option of configuring autoscaling. So for scaling out and also for scaling in.

[Video description begins] He clicks Scaling in the Settings group and points to the Scale mode field on the right. [Video description ends]

If I were to click Operating system, we can see here that it's the Windows Operating System, based on the image we selected. Same with the sizing, we can see the size of the virtual machine, which determines the underlying horse power, like the number of VCPUs and the amount of RAM.

[Video description begins] He clicks Operating system and then Size. The VM size he selected before is highlighted [Video description ends]

I'm going to close out of that, and I'm going to click on our load balancer that was created for the scale set.

[Video description begins] He returns to the All resources window and clicks the second item in the list. [Video description ends]

And notice, again, that we've got the public IP address here, that's the frontend for client connectivity to the backend configuration.

[Video description begins] The load balancer window opens on the right, and he highlights the Public IP address field value. It is 40.80.249.17. [Video description ends]

And notice that if I were to click the Backend pools here, we can see that we've got a backend pool that was created for us automatically, and here are the virtual machine instances. And, of course, we can see the private IP addresses that they've been assigned.

[Video description begins] He clicks Backend pools in the Setting group. A list of 4 instances displays on the right. Their names, NETWORK INTERFACE, and PRIVATE IP ADDRESS properties display. [Video description ends]

Now while we've got virtual machines instances listed here, if I click on the Virtual machines view over on the left, I don't see virtual machines here that result from the use of a scale set.

[Video description begins] He clicks Virtual machines in the navigation pane of the Azure home page. [Video description ends]

Azure Load Balancing

[Video description begins] Topic title: Azure Load Balancing. The host for this session is Dan Lachance. [Video description ends]

The Azure Load Balancer is used to take incoming client requests and spread them out amongst backend virtual machines that support an application. This means we have a result of increased performance because we've got more virtual machines to service client requests. It also supports high availability. So client requests bypass unresponsive VMs.

What this means is that the load balancer is configured to periodically probe backend virtual machines to make sure they respond. And for those that do not respond, client requests will not rerouted to those specific instances. We can configure a public load balancer. That means that the load balancer is Internet-facing and it will be assigned a public IP address.

And so when clients enter the URL for a web app, it needs to resolve to that load balancer public IP address. So that's for inbound Internet traffic. But we can also define an internal load balancer that would be used not over the Internet, but instead within an Azure VNet, maybe for some kind of internal line of business application running in the cloud.

It can also be used for on-premises traffic that's coming into Azure, for example, through a VPN in a hybrid cloud configuration scenario. With the Azure Public Load Balancer, we have health probes that verify the backend virtual machine responsiveness. And that actually gets configured within what's called a load balancer rule. You'll see that when you open up a load balancer in Azure and take a look at its properties blade. So in the diagram, we've got clients on the Internet that make a connection to the load balancer, which in turn will send a request to backend hosts.

[Video description begins] A diagram displays progressively. At the top is a cloud icon. An arrow emerges from the icon bottom and leads to a load balancer icon. 3 arrows emerge from the bottom of the load balancer icon and lead to 3 computer icons depicting 3 clients. [Video description ends]

Load balancers in Azure can be managed like most resources in a number of ways, such as through the Azure Portal, the web GUI, or the Azure CLI.

[Video description begins] Screen title: Azure Load Balancer Management. [Video description ends]

So for example, to create a load balancer in the CLI, we could issue the az network lb, for load balancer, create. In PowerShell, the equivalent would be the New-AzLoadBalancer cmdlet. And if you're using an ARM template to deploy load balancer resources, then you would refer to the Microsoft.Network/LoadBalancers resource type.

Configure Azure Load Balancing

[Video description begins] Topic title: Configure Azure Load Balancing. The host for this session is Dan Lachance. [Video description ends]

In this exercise, you're going to start by using the Azure portal, so the web graphical interface, to create a storage account. Then, after the account is created, upload a file to it using the portal. Then you will create an Azure file share, which is essentially a cloud-based shared folder. Next, you will create a key vault and then store a secret within the vault. Think about how you might approach each of these items by pausing the video.

And then after you've thought about it, come back to view the solutions. Here in the portal, I can create a storage account by going to the Create a resource link over in the upper left. Then I can choose the Storage category, and choose Storage account.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. He clicks the Create a resource menu from the navigation page and then Storage category in the Azure Marketplace column displayed in the New window. Then he clicks Storage accounts in the Featured column. [Video description ends]

So I have to specify things like a resource group into which to deploy this new Storage account.

[Video description begins] Create storage account window displays. He selects Rg1 in the Resource group field. [Video description ends]

Storage account name, not using uppercase letters. So let's say we call this stor1990. Then I have to specify the Azure location to deploy this to.

[Video description begins] He selects Canada east in the Location field. [Video description ends]

And I have to determine whether I want it to be Standard or Premium, and the account kind. So if I want BlobStorage, I would choose that.

[Video description begins] He leaves the default value of Standard in the Performance field and selects Blob Storage in the Account kind field. [Video description ends]

Let's say I want the Cool access tier. And assuming that's all I want to do, I would just review my settings, let the validation succeed, and then create the storage account.

[Video description begins] A window with a progress bar and text- Submitting deployment- displays in the top-right corner of the screen. [Video description ends]

Once that's done, I can go to the Storage accounts view on the left, and I will see my newly created storage account. I may have to refresh. And here I'll see my newly created storage account, stor1990. If I click it, from within here, I can upload content.

[Video description begins] He clicks Storage accounts in the main navigation panel and stor1990 displays in the list of items on the right. When he clicks its name, its properties window displays. [Video description ends]

For example, by going to Blobs, where I could create a container, which I will call pics.

[Video description begins] He clicks Blobs in the Blob service group in the navigation pane. A New container window opens on the right. [Video description ends]

I'll leave it as Private, no anonymous access to the content.

[Video description begins] He types pics in the Name field and leaves the default value of Private in the Public access level field. [Video description ends]

And within pics, I can then select to upload content.

[Video description begins] He clicks the OK button and pics blob displays in the content list. He clicks its name and pics window opens. He clicks the Upload button on the top and an Upload blob window appears on the far-right. [Video description ends]

From here, I can then click the Select a file icon over on the far right.

[Video description begins] He clicks the folder icon next to the Files field. [Video description ends]

And once I've specified a file, I can click Upload to upload that file.

[Video description begins] He selects the file CustomerTransactions.xlsx and clicks the Upload button. The file name displays in the Current uploads section of the Upload a blob window. A window with the text : upload completed for CustomerTransactions.xlsx appears in the top-right corner of the screen. [Video description ends]

Now, the next thing I need to do is create an Azure file share. Now, what we can do is within the Properties blade for a storage account, we can work with files. Now, notice here as I look through the Properties blade of this, we're looking at the Blobs within the storage account. So if I back up one level, let's go back into that, as you scroll down through, sometimes in a storage account, depending on how it was created, you'll see the Files option. Other times, as in this one, you will not. That's because of the way that this was created for Blob storage.

[Video description begins] He closes the cross on all the 3 open windows and reaches the Storage accounts window. He clicks stor1990 in the list and scrolls through its navigation pane, looking for the Files menu. [Video description ends]

So if I were to open up a different storage account, like stor1989, and scroll down. Notice here that the Files service is available.

[Video description begins] He closes this window and goes back to the Storage account window. He clicks stor1989 and its properties page displays. He locates the Files menu in the File service group in the navigation pane. [Video description ends]

So I'm going to go ahead and click Files. I'll click File share and call it something.

[Video description begins] He clicks File and its window opens on the right. He clicks the File share button with a large plus icon and a File share window opens on the far right. There are 2 fields -Name and Quota, and 2 buttons- Create and Discard. [Video description ends]

So for example, if this is going to be for budgets, then I would call it budgets. And for the Quota, maybe I'll set a size of 4 gigabytes, and I'll click Create.

[Video description begins] A window with the text - Successfully created storage file share- appears in the top-right corner of the screen. Budgets file share displays in the properties window now. [Video description ends]

Now, when I go into budgets, I then have to bear in mind that if I click Connect, here I can see the commands that could be used to connect to it from either an on-premises machine or even a virtual machine deployed in the Azure cloud.

[Video description begins] A budgets window opens. It has buttons- Connect, Upload, Add directory, Refresh, Delete share, and Quota. Location is budgets and no files are listed below. [Video description ends]

[Video description begins] A Connect window opens in the far right. It has 3 tabs- Windows, Linux, and MacOS. Windows tab is active now. Drive Letter is Z and 2 commands displays with a copy icon beside them. [Video description ends]

For instance, using the net use command on a Windows host to map drive letter Z to this specific shared folder. The last thing I need to do here is create a key vault and create a secret within it. I'm going to choose Create a resource, and I'm going to type in key vault, and I'm going to click Create.

[Video description begins] He clicks Create a resource in the main navigation pane and types key vault in the Name field. Then, he selects Key vault from the drop-down results and a Key Vault window opens. [Video description ends]

So I have to give it a name, I'm going to call this kv1991. And I'm going to deploy this into an existing resource group, and I'll accept all of the other defaults, and I'll click Create.

[Video description begins] In the Create key vault window, he types kv1991 in the Name field and selects Rg1 in the Resource group field. [Video description ends]

Now, a key vault needs to have secrets in it that are accessed by code. Which the code might need in turn to authenticate to other services elsewhere. So if I go to All resources, my view, and I filter, let's say by kv, we'll see our new vault, kv1991.

[Video description begins] When the key vault kv1991 is created, he closes the window and clicks All resources in the main navigation pane. He types kv in the Name field to filter by name. kv1991 displays in the results below. He clicks kv1991. [Video description ends]

Within it, I can click Secrets if all I want to do is to find, for example, a secret password as opposed to security keys, cryptographic keys, or PKI certificates.

[Video description begins] He clicks Secrets in the Setting group in the kv1991 navigation pane. No secrets display on the right. [Video description ends]

So I'm going to choose Generate/Import, and I'm going to manually create a secret here called secret2. And I'll put in a secret value here, and then I'll click Create.

[Video description begins] A window with the text - Deployment succeeded- displays in the top-right corner of the window. He closes it and clicks the Generate/Import button at the top of the window. [Video description ends]

[Video description begins] A Create a secret window opens. The Upload options contains Manual. He types secret2 in the Name field and types a value in the Value field. A window with the text- Creating the secret 'secret2' - appears at the top of the screen. Secret2 displays in the list of secrets in the kv1991 storage vault. [Video description ends]

Now, here within the portal, I can actually click on secret2 and follow down through that to the point where I can click the Show Secret Value button to actually expose that key vault secret item.

[Video description begins] When he clicks on secret2, its properties window displays. It shows 1 item in the CURRENT VERSION section with a status of Enabled. [Video description ends]

[Video description begins] When he clicks the item, its window opens. He scrolls down to the Secret section and clicks the Show Secret Value button. The field below displays the text testing, and this is the value he typed while creating secret2. [Video description ends]

Azure Serverless Computing

[Video description begins] Topic title: Azure Serverless Computing. The host for this session is Dan Lachance. [Video description ends]

Microsoft Azure has a number of service offerings that are under the classification of serverless computing, but what does this mean? Because in the end, there's always an underlying server that's used, for example, to support a database application and code that's running. However, we're talking here about automated server deployment and management, what this means is a managed service. So that we don't have to worry about actually deploying a virtual machine and the operating system and the tools within it that will run our code.

So, really we're talking about focusing more on code and applications that result from that. So, really this is of primary interest to developers. An example of this would be working with what are called Azure functions, which we'll talk about in more detail later. Azure functions allow you to create and run code on-demand in the cloud without having to worry about provisioning a server that has the appropriate engine that can run that code. It's taken care of for you.

Now we can implement Azure functions in a number of different ways. It could be used for a web application, it could be a mobile device app that we're developing, that is configured to talk to Azure resources through our functions. We could look at Internet of Things, or IoT, received data, such as through the Azure IoT Hub. In Azure, that could trigger a function that we've created as an Azure function.

And so the key is here, we've got a container, so to speak, in which we can run our code without having to define the underlying server operating system details to support the running of that code. You might even have an Azure function through serverless computing that takes a look at files that people might upload to an Azure storage account. And when that file is uploaded, that is a trigger that fires off the Azure function that maybe categorizes or adds metadata to that file or does something specific with it.

Deploy an HTML Azure App Service

[Video description begins] Topic title: Deploy an HTML Azure App Service. The host for this session is Dan Lachance. [Video description ends]

In this demonstration, I'm going to use the Azure portal to deploy an HTML Azure app service, in other words, an HTML website.

[Video description begins] The Microsoft Azure portal home page displays in a browser window. [Video description ends]

So here in the Azure portal, I'm going to start in the upper left by clicking Create a resource. And then under the Web category, I'm going to choose Web App.

[Video description begins] In the navigation pane, he clicks Create a resource and the New window displays. He clicks Web in the Azure Marketplace column, and a list of apps with their logos display in the Featured column. He clicks Web App from here. [Video description ends]

I'm going to call this web app webapptest172. And notice it that's going to be part of the url, because it's going to add .azurewebsites.net as a DNS domain name suffix. Although I can configure custom DNS domain names if I wish.

[Video description begins] The Web App window displays. He types webapptest172 in the App name field. The same text gets displayed in the Resource Group below too. [Video description ends]

I'm going to stick with that one, and I'm going to put this in an existing resource group. Although you could build a brand new resource group into which you deploy all of the items that will be related to this web application.

[Video description begins] He clicks Use existing in the Resource group field, and selects Rg1 from the drop-down menu. [Video description ends]

I can choose either Windows or Linux for the backend operating system hosting my application, my web app. I'm going to leave it as just code, as opposed to using a darker image to run the app.

[Video description begins] He leaves the default value of Windows in the OS field and Code in the Publish field. [Video description ends]

And then I have to deal with the service plan. And I'm going to click on Service plan and we're going to create a new one.

[Video description begins] He clicks the arrow in the App Service plan/Location field. The App Service plan window appears on the right. He clicks the Create new button there. [Video description ends]

Going to call this testwebapp172_ or dash rather, serviceplan.

[Video description begins] A New App Service Plan window appears on the far-right side. He types testwebapp172-serviceplan in the App Service plan field. [Video description ends]

The next thing I'm going to do is specify the location, which in this case will be Canada East. And notice that in this service plan for the app, this is where I can specify the pricing tier or the sizing for the underlying virtual machine or machines that will support my app.

[Video description begins] He clicks the arrow in the Pricing tier field. A new window with Recommended pricing tiers displays. There are 3 tabs in the window, namely Dev/Test, Production, and Isolated. He clicks the first tab. [Video description ends]

So I'm going to go ahead and choose the Dev / Test category. And I'm going to choose this F1 pricing tier, where I've got 1 gigabyte of memory and I'm going to go ahead and click Apply, and then I'll click OK.

[Video description begins] 3 Recommended pricing tiers display. He selects the first one named F1, and clicks the Apply button. F1 Free displays in the Pricing tier field now. testwebapp172-serviceplan displays in the App Service plan field now. [Video description ends]

So we can now see that that app service plan is now tied to this web application. And then I'm going to go ahead and click Create to build the web app. After a moment, over on the left, if I go to App Services, I will see that my application now exists and that its status is listed as Running.

[Video description begins] He clicks App Services in the main navigation pane and all the available app services are listed on the right. webapptest172 displays there. [Video description ends]

Otherwise I can keep clicking Refresh up at the top until I see it. Of course, I can always look up my alerts until I see that the deployment succeeded for this specific resource.

[Video description begins] He clicks the bell icon located next to the Search field in the Azure window. All the notifications display. Deployment succeeded displays there. [Video description ends]

So I'm going to go ahead and click on my web app, and in the overview panel, what I'm interested in to start with is the URL.

[Video description begins] He closes the notifications window and clicks webapptest172. Its properties window displays. [Video description ends]

So notice the URL here is comprised of the name of the resource with .azurewebsites.net which we saw while we were creating it. I'm going to go ahead and copy that.

[Video description begins] The URL is https: //webapptest172.azurewebsites.net. A copy button is present next to it. When he clicks the button, the text Copied displays as a tip. [Video description ends]

And we're going to open up that website in a new web browser window. And this is what I can expect to see by default, an Azure page that says, Your App Service app is up and running.

[Video description begins] He pastes the copied URL in a new browser window and a Microsoft Azure page displays. [Video description ends]

And if I go back to the Azure portal, indeed, we can see that is the URL, and indeed everything is working. Now, if I scroll down, we also have a lot of configuration settings for our web applications. So if I go to Application settings, we can determine the language support in the back end. For example, the version of PHP, which can matter, depending on what kind of functionality you're writing into your PHP scripts.

[Video description begins] He clicks Application settings in the Settings group in the navigation pane. Its window displays on the right. v4.7 displays in the .NET Framework version field. He clicks the drop-down arrow in the PHP version field. 5 options display, namely Off, 5.6, 7.0, 7.1, and 7.2. [Video description ends]

Also, we can see the .NET Framework version, Python and Java, if we're going to be using those. So we have a number of options here that we can configure for our specific application. As I go further down on the application settings page, I can also see the default documents. So these are the documents that will be pulled up when the URL is connected to.

Such as Default.htm or, what we're going to be interested in in a moment, index.php. As I scroll further and further down, we can also specify custom domain names. Now, in this particular case, we'd have to upgrade the app service plan type in order to do that, but we can do it.

[Video description begins] He clicks the Custom domains menu in the navigation pane and a page opens on the right. It is titled Custom Hostnames and it is used to configure and manage custom hostnames assigned to your app. There is a button with a caption- Click here to upgrade your App service plan to assign custom hostnames to your app. [Video description ends]

So what I'm going to do then is I'm going to take an existing on-premises PHP file I've created. And we're going to upload it here to our web app and make sure that it takes effect. So here's my sample PHP file on-premises. It really just comes back and says, sample PHP page hosted in Azure. And sets the title in the browser to My Azure Web App.

[Video description begins] He opens a document in MS-Word. It has HTML code for the main page of his web app. Between the title tags is the text - My Azure Web App. [Video description ends]

What I want to do is save this file locally on-premises and then upload it to the site, and I'm going to do that through FTP. So back here in the portal, I'm still looking at the properties blade for my web application. I'm going to scroll back up and choose Overview. And then from here, I can see I've got the FTP hostname, which is important, but what I want to do is get the publishing profile.

[Video description begins] He goes back to the web app window and clicks Overview in the navigation page. He clicks the Get publish profile button denoted by a download symbol. [Video description ends]

This is going to provide me with the credentials, not just the FTP username, but also the FTP password. So I'm going to go ahead and download the publishing profile. Once that's been downloaded, I'm going to go ahead and click to open it up.

[Video description begins] The downloaded publish profile displays in the start bar of Windows and he clicks it. A Notepad file displays. [Video description ends]

What I'm interested in primarily is the username here listed and also the user password for FTP.

[Video description begins] He highlights userName and userPWD in the file. [Video description ends]

I've downloaded and installed the free FileZilla FTP GUI tool. So the first thing you need here is the host.

[Video description begins] He opens FileZilla. It has a menu bar and a tool bar at the top. Next, are 4 fields, namely Host, Username, Password, and Port. Then there is a Quickconnect button. All the files and folders in the network display below in a hierarchial format. [Video description ends]

So back here in the portal, I'm on the Overview part of the Properties blade. So I'm going to go ahead and copy the FTP hostname and paste that into FileZilla.

[Video description begins] He goes back to the Azure window. He clicks the copy button next to FTP hostname and pastes it in the Host field in FileZilla. [Video description ends]

Next, I'm going to go to the publishing profile I downloaded and copy the FTP username and password and then paste them into the appropriate fields here in FileZilla. And once I've done that, I'll then click, Quickconnect. And after a moment, we can see on the right, under the Remote site section, we have access to our web application, but in the underlying file system through FTP. So if I go to wwwroot, the root of the website, we've got the default Azure placed hostingstart.html file.

[Video description begins] Below the fields and Quickconnect button, the screen is divided into left and right sides. The left side shows files and folders in the Local site, and the right side shows the Remote side. In the Remote side section, he clicks site located in the root. [Video description ends]

[Video description begins] 3 folders display under site. One of them is wwwroot. When he clicks it, hostingstart.html file displays below, on the right side. [Video description ends]

But what I want to put there is my index.php. So that is available on my local machine under samplefiles, which I'll choose on the left.

[Video description begins] He goes to the Local site section in the left, and clicks samplefiles folder there. [Video description ends]

There's index.php, so I'm just going to drag that over and drop it so that it shows up into the wwwroot folder for my site.

[Video description begins] index.php file appears on the left side below. [Video description ends]

And here in a browser, I've still got the URL for my site, but if I refresh, I'm now going to see it's picking up my Sample PHP page that I've uploaded.

[Video description begins] He closes FileZilla and goes to the new Azure window there. A line of text displays there. It says: Sample PHP page hosted in Azure. [Video description ends]

So you can use other tools to manage the content and the code for your website, such as Visual Studio. You might run that on-premises, so that you can work with your code and then push it up into the cloud into your Azure web application.

Azure Functions

[Video description begins] Topic title: Azure Functions. The host for this session is Dan Lachance. [Video description ends]

Azure Functions fall under the classification of serverless computing. These allow developers in the cloud to create and run code. And so the fees that are charged are based only on when that code is actually running. With Azure Functions, developers don't have to worry about deploying virtual machines and virtual networks, and taking care of all of that underlying infrastructure. Because this is a managed service, developers can focus more on the code and the applications that they need to think about and work on, instead of the supporting infrastructure.

So this is really for software developers. And as a software developer, you would be interested in knowing whether or not you can use the language of your choosing, that you're familiar with, with Azure Functions. There are a wide variety of languages that can be used, including PHP, Java, Node.js, C#, and F#. Now, what happens is we have to think about what will trigger the functions to execute.

[Video description begins] Screen title: Azure Function Usage. [Video description ends]

There are plenty of different types of triggers that can be defined for an Azure Function, such as a CosmosDBTrigger. This means that when data is either modified or placed into a Cosmos DB database, then the code can be triggered at that point in time. If users upload content to a storage account container, then the BlobTrigger would kick in, and we could have it execute an Azure Function of our choosing.

You might do that to further organize uploaded files, or to do something specific to them. Such as maybe adding a watermark to a video image that's uploaded or to a graphic file image. The HTTPTrigger, as the name implies, gets triggered based on a specific type of HTTP request. And so when that is triggered, we can define which Azure Function runs. There's also a QueueTrigger, which is based on messages coming into an Azure storage queue that developers could query. And then when that occurs, an Azure Function could run.

Azure Functions, because we're talking about development here, can be defined in a number of different places, such as through the Azure portal. Or you might use a tool that you're familiar with, such as Visual Studio. You might use the Azure CLI to work with functions. And of course, you might use specific language tools related to languages such as Java and Python.

[Video description begins] An infographic displays. It has a cloud with a hammer and screw driver in the center. 4 branches emerge from the symbol. Each ends in a caption.- Azure Portal, Visual Studio, Java and Python, and Azure CLI, respectively. [Video description ends]


Azure App Event Grid
  - The purpose of Event Grid is it lets developers configure certain triggers by events such as making a change to an Azure resource. That can then connect to some kind of endpoint or hook into some other aspect of an application for notifications. And in our particular case, we're simply going to set it up such that when a change is written to an Azure virtual machine, we want to be notified via email.
  - The first thing we'll do here, to get started is we will create a Logic App. Here in the Azure portal, I'm going to click Create a resource over on the left, and I'm going to type in the word logic and then from the results, I'll choose Logic App.
[Video description begins] He clicks Create a resource in the navigation pane, and types logic in the Search field. He selects Logic App from the drop-down results. A Logic App window displays. It has a brief explanation about logic apps and a Create button. [Video description ends]

Then I'm going to go ahead and click on Create so we can get to the point where we start configuring this resource. So after specifying a name, here I'm going to call it vmchange_logicapp, and in this case, I'm going to put it into an existing resource group and I've specified the location. After having done that I'm simply going to click on Create.

[Video description begins] The Logic App window displays. He types vmchange_ logicapp in the Name field. He leaves the default value of Pay-As-You-Go in the Subscription field. He leaves the default option- Use existing- in the Resource group field, and selects Rg1 in the field below. He selects Canada east in the Location field, and leaves the default value Off in the Log Analytics field. [Video description ends]

And after a moment, if I go to my All Resources view and if I type in logic, then we could see our Logic App listed.

[Video description begins] He clicks All resources in the navigation pane and types logic in the Name field on the right. vmchange_ logicappdisplays in the list below. He clicks it and its properties page displays. [Video description ends]

If I click on it, it starts the Logic App's designer where we can get some help on how to work with this and we can also choose from some basic templates.

[Video description begins] The Logic Apps Designer window opens. Basic templates are listed there. [Video description ends]

So like when a message is received in a queue, or when an http request is received, and so on. And if I scroll down a little bit beyond all that, I can choose to build a blank Logic App which I'm going to do here.

[Video description begins] He scrolls down and clicks the tile with a large plus symbol and caption Blank Logic App. A new page opens It has buttons, Save, Discard, Run, Designer, Code View, Templates, Connections, and Help. A Search field is also present to search connections and triggers. Below are 6 tabs- For You, All, Built-ins, Connections, Enterprise, and Custom. The For You tab is active now and there are no recent connections to show. [Video description ends]

And I'm going to search for event grid.

[Video description begins] He types event grid in the Search field and clicks the All tab. Many event grids with their logos display below. [Video description ends]

So I'm going to choose Azure Event Grid. And then when a resource event occurs for Azure Event Grid.

[Video description begins] He clicks the Azure Event Grid and a new tile appears. It has a field, Tenant, with the text Default Directory written in it. There is a Sign in button below the field. [Video description ends]

And then I'm going to click Sign in to authenticate to my Azure subscription And then I'm asked to confirm that I want to allow the provisioning to provide access to Azure Event Grid.

[Video description begins] A confirmation dialog box appears. He clicks Allow access. [Video description ends]

And I'm going to choose Allow Access. And then I have to fill in this detail related to the subscription and also the resource type that I'm interested in in this particular case. So I'm going to choose Microsoft.Resources.ResourceGroups for the resource type and I'm going to set the resource name to a resource group that I already have Rg1 that I know virtual machines have been deployed into. And then I'm going to go ahead and save this Logic App.

[Video description begins] A new tile appears titled When a resource event occurs. He selects Pay-As-You-Go in the Subscription field. [Video description ends]

[Video description begins] He clicks the Save button in the Logic Apps Designer window. [Video description ends]

Now, I'm going to go back into the Logic app designer here in my Logic app.

[Video description begins] In the vmchange_ logicapp window, he clicks Logic app designer in the Development Tools group in the navigation pane. [Video description ends]

And underneath, when a resource event occurs, I'm going to click New step, and then I'm going to choose Built-in and I need some kind of conditional way to determine what's going to happen next. But to do that I'm going to scroll down and choose Condition. That's a control.

[Video description begins] A Choose an action window opens. He selects the Built-ins tab. [Video description ends]

[Video description begins] He scrolls down to the section with 2 tabs- Triggers and Actions. All the actions are listed in the Action tab and he selects Condition. [Video description ends]

And I'm going to specify data.operationName is equal to and what we're looking for is any right activity for our Azure virtual machines related to the resource group.

[Video description begins] A tile titled Condition opens. It has boxes with text and drop-down arrows. At the top is a box with text And. It branches down into 2- one a check box with 3 boxes captioned data.operationName, is equal to, and Microsoft Compute. The second branch has text +Add and a drop-down arrow. [Video description ends]

So that's my condition. Now, down below, for true, and also, of course, if that turns out to be true versus false, we can add an action. So if it's true, if a change has been made to write to a virtual machine, I'm going to click Add an action.

[Video description begins] Below the tile, are 2 more tiles titled if true and if false. He clicks Add an action in the if true tile, and a Choose an action box window appears again. [Video description ends]

And from here I can choose what it is exactly that I want to do. So for example I could search for email if I want to send off an email notification. And lets say I choose Gmail.

[Video description begins] He types email in the search field and clicks Gmail icon in the search results. A new window with actions related to Gmail pops up. [Video description ends]

And then what do you want to do in Gmail? Well what I want to do is send an email message. And from here what I would have to specify are the details related to working with Gmail. If it's the first time I've ever done this, I'm going to have to sign into my Gmail account. Because I've already done that I can specify who I want to send the message to. So a list of email addresses, and I can also add other additional items such as the subject and body here of the message.

[Video description begins] He clicks the action Send email and a new window pops up. It is titled Send email and has fields such as To, Body, and Subject. He checks the elements he wants in his email. [Video description ends]

So maybe in the body, what I want to do is add, let's say, the specific type of event and if I scroll over maybe for the subject, I want to list the subject of the event. And again up here, I can specify some email addresses. So I'm going to go ahead and do that. Email addresses should receive this notification and then I'll click the save button.

[Video description begins] He clicks the Body field and a panel pops up in the right side. It has 2 tabs- Dynamic content and Expression. There is a Search field on the top and various events listed below. Some of them are Event Time, Event Type, and ID. He clicks all the events he wants. [Video description ends]

[Video description begins] He types an email address in the To field. [Video description ends]

After that's done, if I were to go for example to a virtual machine and open up its properties blade and make a change to it such as let's say go to sizing and just choose a different size and click on resize.

[Video description begins] He goes back to the Virtual machines page and clicks Size in the Settings group in the navigation pane. [Video description ends]

I'm writing to that virtual machine, and so our Logic app should capture that event.

[Video description begins] He clicks 81s in the VM SIZE column. A window with the text- Resizing virtual machine- pops up at the top of the machine. [Video description ends]

And so if I go back, let's say to all resources, the view filter for logic, and there's our Logic app. Under the overview part of that if I scroll down I can see for example the status is succeeded down under the run history for our current configuration.


SQL Overview
  - Structured Query Language, or SQL, is the language that's used to access relational database objects and their data. So with a SQL-compliant type of database system, data tables are related via common fields. This is called normalization, and it's a technique that's used to reduce the amount of repeated data. We'll see that in a moment when we see an example of how we might link tables together.

SQL objects include the server that hosts one or more databases. Within a database, we can have one or more tables that actually store the data. Within the table, we have it broken down by fields or columns. So, for example, we might have a table called Customers, and one of the fields might be Customer ID. When we actually populate a table with data, we end up with a record otherwise called a row.

In our example with the Customers table, the record or row would include everything about a customer. So a customer ID, the first and last name, mailing information, and so on. Databases can also contain stored procedures, essentially which are scripts that can be run against items within the database.

We can also create views within a SQL-compliant database that can bring together columns from different tables so we can view it all in one place. And, of course, we can construct a multitude of different types of queries, essentially asking questions about the data stored in tables, such as show me all customers that have spent more than $10,000 in the last quarter.

[Video description begins] Screen title: SQL Table Relationship. [Video description ends]

Pictured on the screen, we've got two tables, and this is used to demonstrate the relationship between tables.

[Video description begins] Two tables are displayed on the screen. The first table is titled Customers table. It has the following three columns: CustID, Lname, and Fname. It contains two rows of data for customer IDs 001 and 002, respectively. The second table is titled Purchases table. It has the following three columns: CustID, Date, and Amount. It has two rows of data for customer ID 001. [Video description ends]

At the top, we've got a Customers table, where we have three columns: Customer ID, Lname for last name, and Fname for first name. Then, we have a second table called Purchases table. It's got three columns, but notice what it has in common with the Customers table, the Customer ID. So Customer ID 001 exists only once in the Customers table.

However, that customer, hopefully, will have more than one purchase with us, and so we can expect to have repeating entries for that Customer ID in the Purchases table. But we don't want to repeat the last name and the first name and everything else about a customer. All we need is one unique item, in this case, the Customer ID to be repeated to link all the purchases in the Purchases table to the customer in the Customers table.

Common SQL-compliant database products would include Microsoft SQL Server, MySQL, Oracle Database, and Sybase to name just a few. In other demonstrations, we're going to take a look at how we would deploy Microsoft Azure SQL Database in the cloud, which is a managed service where we don't have to worry about the underlying virtual machine deployment and the SQL software; it's already built in.


Azure SQL Database
  - One characteristic of cloud computing is rapid provisioning of resources and rapid elasticity, and that's definitely true with Microsoft Azure SQL Database. With SQL Database, we're talking about database as a service, called DBaaS, which is also platform as a service in the cloud.

[Video description begins] Platform as a Service is abbreviated to PaaS. [Video description ends]

It's a managed service, and that's where the rapid elasticity comes in because we don't have to worry about deploying virtual machines and then installing the Microsoft SQL Server software. All of that is taken care of for us when we deploy Azure SQL Database. So, it's very quick to get up and running. We can also bring our own license. BYOL, bring your own license, will let you reuse any existing SQL Server additional licenses that you want to reuse in the cloud when you deploy Azure SQL Database.

You also have the option of migrating your on-premises SQL data into Azure, so you can reuse your data instead of having to recreate it in the cloud. Azure SQL Database supports scaling in the form of horizontal scaling. This means scaling out, by adding database replicas and also database sharding, which allows us to have more information split up horizontally. What this really means is taking large datasets and breaking them into smaller pieces to improve performance, that's where sharding comes from.

But also, Azure SQL Database allows us to scale vertically, increasing or decreasing the underlying horsepower for each SQL Server instance. And we can do that by configuring virtual machine instance sizing. We can manage Azure SQL Database using the GUI, through the Azure portal, or through the Azure CLI. For example, we could use the az sql db create command to create a database. The equivalent in PowerShell would be New-AzSqlDatabase.

And if you're using ARM templates to deploy and manage Azure resources, you would be looking at a resource type of Microsoft.Sql/Servers. With Azure SQL Database, there is a specific database server firewall enabled, and that's on by default for SQL. So if you want to make a connection into Azure SQL Database from externally, you are going to have make sure you create a firewall rule to allow inbound port 1433 traffic.

Port 1433 is what's used by SQL Server by default. There is even an option where you can add your client IP. So when you are using the portal and you are viewing the firewall information for this, for SQL Database, then what you'll notice is that it'll show your current client IP address that you are connected from, your public IP address if you are behind a NAT router.

And so you can conveniently simply add that as the IP you want to allow through the firewall. And then I would allow you, for example, to use tools like SQL Server Management Studio on-premises to reach into the Azure cloud to your SQL Database instance to manage it.

[Video description begins] Screen title: Azure SQL Database Details. [Video description ends]

When you deploy Azure SQL Database, whether it's through the GUI or through command line tools, there are a number of things you have to take into account, one of which is whether you want to deploy a new SQL Server instance or use an existing one that you might have already deployed. SQL Server instances have the DNS domain suffix of .database.windows.net by default.

You need to specify a unique server and a database name when you are deploying Azure SQL. You have to determine which location, or Azure region, into which you want to deploy Azure SQL Database. From a performance standpoint, you also have an option of selecting database transaction units, or DTUs.

This is a culmination of factors that control the performance when it comes to reading and writing to and from databases. It includes things like the amount of virtual CPU, the amount of memory, and how fast disk I/O is.

The last consideration is that if you're deploying Azure SQL Database for testing purposes or any other temporary reason, make sure that you remove any unused databases and server instances as soon as you are finished. You don't want to leave these things running in the background because you are charged for all of the time that it's left running. So make sure to delete it when you are finished with it.


Azure SQL Database GUI Deployment
  - Azure SQL database is a managed service, and in the cloud, what this really means is that we have an easy way to quickly provision something, in this case, an Azure SQL database, without worrying about the underlying complexities, like virtual machines, and the operating systems, and installing the database software, in this case, Microsoft SQL Server.

[Video description begins] A Microsoft Azure webpage is displayed on the screen. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present with the following options: Create a resource, Home, Dashboard, All services, and Favorites. The main body of the page has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

So here in the portal, let's see how this works by starting with clicking on Create a resource in the upper left.

[Video description begins] He clicks on Create a resource from the navigation pane. A screen titled New appears. It has a search bar and a column titled Azure Marketplace. Some of the items here are: Get started, Recently created, Compute, Networking, Databases, etc. A column titled Featured is also present on this screen. Some of the items here are: Azure SQL Managed Instance, SQL Database, SQL Data Warehouse, etc. [Video description ends]

And in the Databases category, on the right, I will then choose SQL database.

[Video description begins] From the Azure Marketplace column, he selects Databases. From the Featured column, he selects SQL Database. A page titled Create SQL Database appears. It has four tabs: Basics, Additional settings, Tags, and Review +Create. The Basics tab is currently open. It has drop-down menus for Subscription and Resource Group. The default value for Subscription is Pay-As-You-Go. The default value for Resource Group is cloud-shell-storage-eastus. [Video description ends]

Now the first thing I have to do is tie this to a resource group. I've already got one, so I'm going to put it in that resource group, and I have to give this a Database name.

[Video description begins] He clicks the drop-down menu for Resource Group. A list of options appears. He selects Rg1 from the list. He then scrolls down the page. A section titled Database Details appears. It has an input box for Database name and a drop-down menu for Server. There is a question that reads: Want to use SQL elastic pool? It has two options with radio buttons: Yes and No. No is currently selected. For Compute+storage, there is a link for Configure database. At the bottom, there are two buttons: Review+Create and Next: Additional settings. [Video description ends]

So I'm going to start by calling this sqldb172. Now, this name needs to be checked for uniqueness. And once it is okay, and it's been typed in correctly, and there are no invalid characters, we'll get this little green check mark over on the right.

[Video description begins] In the input box for Database name, he types sqldb172. [Video description ends]

Now, down below, I can either tie this to an existing SQL server instance hosted in Azure or I can click Create new, which I'm going to do here.

[Video description begins] There is a link titled Create new below the drop-down menu for Server. He clicks the link. A screen titled New server slides onto the screen. It has input boxes for Server name, Server admin login, Password, and Confirm password. A drop-down menu for Location is also present. The default location is Canada East. Below it, there is a check box for Allow Azure services to access server, which is currently checked. At the bottom there is a Select button. [Video description ends]

And I'm going to call this sqlsvr, for SQL Server, 172. Again, it has to wait for the name to be checked, and it looks good. Then I'm going to specify some server admin login info, so user name, and I will confirm the password.

[Video description begins] In the input box for Server name, he types sqlsvr172. [Video description ends]

[Video description begins] In the input box for Server admin login, he types cirving. He types the password and confirms the password. [Video description ends]

And after that, I'm going to go ahead and click on Select.

[Video description begins] He clicks the Select button. The New Server screen disappears. The value for Server is (new)sqlsvr172 (Canada East). [Video description ends]

So we're creating a new SQL server instance, which is good. I'm just going to scroll down here, I'm going to leave it on the default Compute and storage configuration.

[Video description begins] The value for Compute+storage is Standard S0 10DTUs, 250 GB. [Video description ends]

So 10 DTUs, that's database transaction units, and 250 gigabytes. Although we could click on Configure database and depending on our workload, we could choose the amount of data that we want to be able to accommodate and the database transaction units using these two sliders. So it's always dependent upon your specific workload.

[Video description begins] He clicks the Configure database link. A page titled Configure appears. It has three options: Basic, Standard, and Premium. Basic is currently selected. It has two sliders for DTUs and Data max size. The current DTU is 0 and Data max size is 250 GB. At the bottom, there is an Apply button. He clicks it and the screen shifts to the previous page. [Video description ends]

In this case, I'm going to click Next: Additional settings.

[Video description begins] He clicks the Next: Additional settings button. The screen shifts to the next tab: Additional settings. It has three options for Use existing data: None, Backup, and Sample. None is currently selected. For Collation, there is an input box with the following default value: SQL_Latin1_General_CP1_ CI_AS. At the bottom, there are three buttons: Review + Create, Previous, and Next: Tags. [Video description ends]

Then, I can determine whether I want to have a blank database or use some kind of existing data from a sample data set or a backup. I'm going to leave it blank by leaving it on None. Then I'll click Next.

[Video description begins] He clicks the Next: Tags button. The screen shifts to the next tab, Tags. It has drop-down menus for Name, Value, and Resource. The Resource is Database. At the bottom, there are three buttons: Review + Create, Previous, and Next: Review + Create. [Video description ends]

I can tag this, perhaps to tie it to a project or department, but I'm going to leave that as it is. And finally, on the Review page, I can see the estimated cost per month.

[Video description begins] He click the Next: Review + Create button. The screen shifts to the next tab, Review + Create . It contains Product Details, Terms, Basics, etc. At the bottom, there are two buttons: Create and Previous. [Video description ends]

So we wana be careful with this. This is one of those types of resources in Azure you wanna make sure you shut down or even delete the moment you no longer need it, so you don't incur charges.

[Video description begins] He highlights the estimated cost per month, which is 16.50 USD, listed under Product Details. [Video description ends]

So I'm going to go ahead and click Create.

[Video description begins] He clicks the Create button. An overview page appears. It reads: Your deployment is complete. It has a button labelled Go to resource. It has a navigation pane with the following options: Overview, Inputs, Outputs, and Template. The Overview page is currently open. There is a table on this page. It has following columns: Resource, Type, Status, and, Operation Details. The table has three rows of data. [Video description ends]

And after a moment, we have a message that says our deployment is complete. See it's created a firewall rule here to allow inbound port 1433 traffic to SQL. Then we've got the database and the server.

[Video description begins] The presenter points to the data in the table. He then closes the Overview page and shifts to the home screen of Microsoft Azure. [Video description ends]

Of course, we're going to see all those items here if we go to the All resources view and start to filter the view.

[Video description begins] From the navigation pane, he clicks on All resources present under Favorites. A page titled All resources appears. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. A few rows of data are present in this table. [Video description ends]

So if I just type in sql, here we can see our SQL server deployed in the cloud.

[Video description begins] He types sql in the input box for Name. Two rows of data can now be seen in the table. [Video description ends]

But we didn't have to worry about all the complexities that would normally be involved with that if we had deployed a SQL server on premises ourselves. So let's click on the SQL server here in Azure to pop up its Properties blade.

[Video description begins] He clicks on sqlsvr172 present in the table. A screen titled sqlsvr172 appears. It has a navigation pane. The main body contains details about the server. At the bottom, there are two tabs: Notifications and Features. The Features tab is currently selected. It has four tabs: All, Security, Performance, and Recovery. [Video description ends]

And from within here, for example, if I go to the SQL databases view, I can see it is hosting one of our SQL databases, sqldb172, which currently has a status of Online.

[Video description begins] From the navigation pane, he selects SQL databases. A page titled sqlsvr172-SQL databases appears. It has a table with the following three columns: Database, Status, and Pricing Tier. It has one row of data. The Database is sqldb172, Status is Online, and Pricing Tier is Standard S0: 10DTUs. [Video description ends]

And I'll just close out of this.

[Video description begins] He closes the current screen. [Video description ends]

If we go into our SQL database instance, so I'll click on it to pull up its Properties blade, then we have options we can configure, such as Geo-Replication, if we want it replicated to other locations in different Azure regions.

[Video description begins] On the All resources page, from the list of resources present in the table, he clicks sqldb172(sqlsvr172/sqldb172). A page titled sqldb172(sqlsvr172/sqldb172) opens. It has a navigation pane and the following buttons: Copy, Restore, Export, Set server firewall, etc. A list of information about the server is also displayed here. [Video description ends]

[Video description begins] He selects Geo-Replication under Settings from the navigation pane. A world map is displayed on the screen. [Video description ends]

And as we go further down, we'll see that we have a number of options related to things like security. So we've got some Advanced Data Security options available for the database, so vulnerability assessments, also, Dynamic Data Masking to mask some kind of important information, such as the entering of credit card numbers, and so on. And this is configured by configuring what are called masking rules.

[Video description begins] In the navigation pane, there is a section titled Security. It has the following options: Advanced Data Security, Auditing, Dynamic Data Masking, and Transparent data encryption. He clicks on Advanced Data Security. A page for Advanced Data Security opens up. It has a button labelled Enable Advanced Data Security on the server. [Video description ends]

[Video description begins] He clicks on Dynamic Data Masking, and the page for Dynamic Data Masking opens. It has a section titled Masking rules, where there is a table with two columns: Mask Name and Mask Function. The table is currently empty. Below it, there is a section titled Recommended fields to mask, where there is a table with three columns: Schema, Table, and Column. The table is currently empty. [Video description ends]

And if I go back to the Overview here for our database, I can see the SQL server name. This is what you need if you want to make a connection to this, for example, from on-premises. Now, at the same time, even from here within the database Properties blade, I could click the Set server firewall button, and, I can see my current Client IP address as seen on the Internet.

[Video description begins] He shifts to the page titled sqldb172(sqlsvr172/sqldb172). From the list of information, he points to the Server name, which is sqlsvr172.database.windows.net. [Video description ends]

[Video description begins] He clicks the Set server firewall button. A page titled Firewall settings appears. It has three buttons: Save, Discard, and Add client IP. For Allow access to Azure service, there are two buttons: On and OFF. On is currently selected. Client IP address is 71.7.176.108. There is a table with input boxes for Rule Name, Start IP, and End IP. [Video description ends]

[Video description begins] He highlights the Client IP address. [Video description ends]

And so from here, we have the option of making sure that we add a rule that could, for example, contain that IP address or other address ranges that we want to allow access from. Notice we've got an Add client IP button at the top that fills all that stuff in for me to allow connectivity.

So I'm going to go ahead and save that firewall rule because the machine I'm sitting at right now that does have this public IP address I do want to allow in through the firewall for SQL purposes.

[Video description begins] He clicks the Add client IP button. A new row gets added in the table. The Rule Name is ClientIPAddress_2019-3-13. Start IP is 71.7.176.108 and End IP is 71.7.176.108. He clicks the Save button. [Video description ends]

[Video description begins] A pop-up message appears. It reads: Successfully updated server firewall rules. The presenter clicks the OK button. The pop-up message closes. He then closes the Firewall settings page. [Video description ends]


Azure SQL Database CLI Deployment
The first thing I'll do is run az sql --help. This is a great way to get a sense of what the syntax will be as you begin working with this.

[Video description begins] In the command prompt window, he types az sql -- help. The group name and its function appear. This is followed by a list of subgroups and their definitions and a list of commands and their definitions. [Video description ends]

So notice, I can work with Azure SQL databases as well as servers, and so on.

[Video description begins] From the list of subgroups, he highlights db and server. The definition of db is Manage databases. The definition of server is Manage SQL servers. [Video description ends]

So I'm going to clear this screen, and I'm going to start by running az sql server create --name. Let's say, I call it sqlsvr456. And then, I'm going to put that in a --resource-group that I've already got called rg1. And --location. I'll put canadaeast, and then --admin-user for the SQL server, specify a value for that.

And then --admin-password. Now make sure you have the two dashes in front of these parameters, otherwise you get some kind of an error related to that. And I'm gonna go ahead and specify the password here that I want to use for that deployment. I'm going to go ahead and press Enter to build our Azure SQL Server instance.

[Video description begins] He types cls and presses Enter. The screen is now clear. He then types az sql server create -- name sqlsvr456 -- resource-group rg1 -- location canadaeast -- admin - user cirving -- admin - password Pa$$w0rdABC123. He presses Enter. A result is being generated. [Video description ends]

Now that that's successfully completed, I'm going to go ahead and build a SQL database tied to that server.

[Video description begins] A list of information is generated in the result. It includes details of administrator login, administrator login password, fully qualified domain name, id, identity, kind, location, name, resource group, state, tags, type, and version. [Video description ends]

So az sql db create, so I've got to deploy this into a resource group. So --resource-group rg1 in this case and --server. I've got to tie it to a server, so in this case, sqlsvr456. And I want to call this database --name, let's say, db456.

[Video description begins] He types cls and presses Enter. The screen is now clear. He then types az sql db create --resource-group rg1 -- server sqlsvr456 -- name db456. He presses Enter. A list of information is generated in the result. Some of these are: longTermRetentionBackupResourceID, maxLogSizeBytes, recoverableDatabaseID, sampleName, etc. [Video description ends]

Now that, that's done, the next consideration is that if you're gotta be using any kind of code or tools on-premises to reach into Azure to work with that SQL database, then you're going to need to have a firewall exception created in Azure. So let's go ahead and deal with that under that assumption. So I'm going to clear the screen with CLS, and I'm going to run az sql server firewall-rule create.

We're creating a firewall rule for SQL server, --resource-group rg1, and the server, --server sqlsvr456, and -n. What do you want to call this rule? How about AllowInboundSQL? And then --start-ip-address. Now because I'm behind a NAT firewall, I need to specify the public IP address as known out on the Internet for my connection here for this to work properly. So I'm going to go ahead and specify that address.

And after I've done that, I can then begin to specify the ending IP address. In this case, it's going to be the same thing because it's one IP. So once I've verified that that is correct, and it looks correct, I'm going to use --end-ip-address. And in this case, I'm going to use the exact same thing because it's only one IP I want to allow in, and that's my public IP address. So I'm going to make sure I don't have any typos here. And I'm going to press Enter to create that, and it looks like it's created. Let's go ahead and check our work in the Azure portal.

[Video description begins] He types cls and presses Enter. The screen is now clear. He then types az sql server firewall -rule create --resource-group rg1 -- server sqlsvr456 - n AllowInboundSQL --start -ip-address 71.7.176.108 --end -ip-address 71.7.176.108. He presses Enter. The following details are generated in the result: endIpAddress, id, kind, location, name, resourceGroup, startIpAddress, and type. [Video description ends]

[Video description begins] A Microsoft Azure webpage opens. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present on this screen. The options here are: Create a resource, Home, Dashboard, All services, and Favorites. The main body of the page has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

Here in the portal in the left-hand navigator, I'm going to click SQL databases. Here's db456. We can see it's tied to our server.

[Video description begins] He clicks on SQL databases from the navigation pane. A page titled SQL databases appears. It has the following buttons on the top: Add, Reservations, Edit columns, Refresh, etc. It has a table with the following columns: Name, Status, Replication, Server, Pricing Tier, Location, and Subscription. The table has one row of data. The SQL database name is db456 (sqlsvr456/db456). He clicks on this name. A page titled db456 (sqlsvr456/db456)appears. It has a navigation pane. The main body of the page has details about the following options: Resource Group, Status, Location, Server name, Elastic pool, etc. [Video description ends]

So if I go take a look at it, it look like it's online and ready to go.

[Video description begins] He points to the Status. It reads Online. [Video description ends]

I'm going to go to All resources, and I'll filter the list of Azure resources with things that start with SQL.

[Video description begins] From the navigation pane, he clicks on All resources present under Favorites. A page titled All resources appears. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. A few rows of data are present in this table. [Video description ends]

[Video description begins] He types sql in the input box for name. Two rows of data are now present in the table. [Video description ends]

There's our SQL server, sqlsvr456, and in the Properties blade, I'm going to scroll down under the Security section until I see firewalls and virtual networks, and notice here on the right, sure enough, we've got our AllowInboundSQL rule for our public IP address.

[Video description begins] He clicks on sqlsvr456 in the table. A screen titled sqlsvr456 appears. It has a navigation pane. The main body has details about the server. Some of these are: Status, Location, Subscription, etc. At the bottom, there are two tabs: Notifications and Features. The Features tab is currently selected. It has four tabs: All, Security, Performance, and Recovery. [Video description ends]

[Video description begins] In the navigation pane, there is a section titled Security. It has the following options: Advanced Data Security, Auditing, Firewalls and virtual networks, and Transparent data encryption. He clicks on Firewalls and virtual networks. A page for Firewalls and virtual networks opens up. For Allow access to Azure services, there are two buttons: On and OFF. OFF is currently selected. Client IP address is 71.7.176.108. There is a table with input boxes for Rule Name, Start IP, and End IP. One row of data is present in this table. The Rule Name is AllowInboundSQL, Start IP is 71.7.176.108, End IP is 71.7.176.108. [Video description ends]

Azure SQL Database PowerShell Deployment

[Video description begins] Topic Title: Azure SQL Database PowerShell Deployment. Your host for this session is Dan Lachance. [Video description ends]

In this demonstration, I'm going to use PowerShell to deploy an Azure SQL database. Here in this PowerShell ISE, I've got this in a script. I've commented out the first line, that's what the hashtag or pound symbol means because I've already connected to my Azure account and authenticated it.

[Video description begins] A window titled Windows Powershell ISE opens up. It has a tool bar and a menu bar. A tab titled Create_SQL_Server_DB.ps1 is open. It has 8 code lines. A Console pane is also present on this window. [Video description ends]

[Video description begins] He highlights code line 1. It reads: # Connect-AzAccount. [Video description ends]

So the first thing we're doing here is building a new Azure SQL server using that cmdlet. We are tying it or deploying it into a resource group. I am specifying a SQL server name. We are specifying the Azure location or region, and then we are specifying -SqlAdministratorCredentials. Now I've got the back tick symbol here that's not just a single quote, it's a back tick, and that allows me to continue the expression on the next line here in PowerShell.

[Video description begins] He points to code line 3. It reads: New-AzSqlServer -ResourceGroupName rg1 -ServerName sqlsrv3362 -Location canadaeast -SqlAdministratorCredentials `. [Video description ends]

And what I'm doing is then running new object of type System.Management.Automation.PowerShell or PSCredential. And the argument list is going to have the username, in this case cirving. And then I'm going to convert to a secure string, a password that I'm specifying here, within double quotes.

[Video description begins] He points to code line 4. It reads: $ (New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList "cirving" , $ (ConvertTo-SecureString - String "Pa$$w0rdABC123" -AsPlainText -Force)). [Video description ends]

Then what's happening is we're building our new Azure SQL database and tying it to our SQL server instance that we've created above. And I'm calling this database db112.

[Video description begins] He points to code line 6. It reads: New-AzSqldatabase -ResourceGroupName rg1 -ServerName sqlsrv3362 -DatabaseName db112. [Video description ends]

And then I'm adding a new Azure SQL Server firewall rule to allow incoming SQL traffic from the appropriate IP address, which happens to be my public IP address for my on-premises environment.

[Video description begins] He points to code line 8. It reads: New-AzSqlServer FirewallRule -ResourceGroupName rg1 -ServerName sqlsrv3362 -FirewallRuleName "AllowIncoming SQL" - StartIpAddress 71.7.176.108 -EndIpAddress 71.7.176.108. [Video description ends]

So I'm going to go ahead and run this script by clicking the Run Script button up at the top.

[Video description begins] He clicks the Run Script button present in the tool bar. A list of details is displayed in the Console pane. [Video description ends]

And after a moment or two, we can see it looks like the script has completed running. So let's go check our work in the portal. Let's take a look for sqlsrv3362 and db112.

[Video description begins] He highlights sqlsrv3362 in code line 3, and db112 in code line 6. [Video description ends]

Here in the portal, I've gone to the All resources view and filtered for anything that starts with SQL, S-Q-L, and we can see indeed, we've got sqlsrv3362.

[Video description begins] A Microsoft Azure webpage opens up. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present on this screen. It has the following options: Create a resource, Home, Dashboard, All services, and Favorites. The All resources page is currently open. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. In the name input box, sql is entered. A list of sql resources is displayed in the table. [Video description ends]

And, if I open that Properties blade up, and go down under Firewalls and virtual networks, we can see our Allow incoming SQL firewall rule that was created.

[Video description begins] He clicks the 1st sql resource listed in the table: sqlsrv3362. A page titled sqlsrv3362 appears. It has a navigation pane. The main body has details about the server. Some of these are: Status, Location, Subscription, etc. At the bottom, there are two tabs: Notifications and Features. The Features tab is currently selected. It has four tabs: All, Security, Performance, and Recovery. [Video description ends]

[Video description begins] In the navigation pane, there is a section titled Security. It has the following options: Advanced Data Security, Auditing, Firewalls and virtual networks, and Transparent data encryption. He clicks on Firewalls and virtual networks. A page for Firewalls and virtual networks opens. For Allow access to Azure services, there are two buttons: On and OFF. OFF is currently selected. Client IP address is 71.7.176.108. There is a table with input boxes for Rule Name, Start IP, and End IP. One row of data is present in this table. The Rule Name is AllowIncoming SQL, Start IP is 71.7.176.108, and End IP is 71.7.176.108. The presenter closes this page and shifts to the All resources page. [Video description ends]

And we can also see that we've got DB or database 112 that was created as the result of our PowerShell script.

[Video description begins] He points to the 2nd sql resource listed in the table: db112 (sqlsrv3362/db112). [Video description ends]

Now the only other thing to bear in mind is don't leave these database resources running in Azure if you're not using them. Because you will pay for using them even if they're running, and you're not actually using them. So remove these resources when you no longer need them immediately.

Connect to Azure SQL Database

[Video description begins] Topic Title: Connect to Azure SQL Database. Your host for this session is Dan Lachance. [Video description ends]

Once you've deployed Azure SQL database in the Azure cloud, how do you connect to it? That's going to be the focus of this demonstration.

[Video description begins] A Microsoft Azure webpage opens. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present on this screen. The options here are: Create a resource, Home, Dashboard, All services, and Favorites. The All resources page is currently open. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. In the input box for name, sql is entered. A list of sql resources is displayed in the table. [Video description ends]

Here in the Azure portal, I've already deployed Azure SQL database. So I've got a SQL server instance and a database already up and running.

[Video description begins] He points to the two sql resources listed in the table: sqlsrv3362and db112 (sqlsrv3362/db112). [Video description ends]

So I'm going to go ahead and click on the link to open up the Properties blade for my SQL server instance.

[Video description begins] He clicks on sqlsrv3362. A page titled sqlsrv3362 appears. It has a navigation pane. The main body contains details about the server. Some of these are: Status, Location, Subscription, etc. At the bottom, there are two tabs: Notifications and Features. The Features tab is currently selected, which has four tabs: All, Security, Performance, and Recovery. [Video description ends]

And the first thing I'll do is scroll all the way down under Security and look at Firewalls and virtual networks.

[Video description begins] In the navigation pane, there is a section titled Security. It has the following options: Advanced Data Security, Auditing, Firewalls and virtual networks, and Transparent data encryption. He clicks on Firewalls and virtual networks. A page for Firewalls and virtual networks opens up. For Allow access to Azure services, there are two buttons: ON and OFF. OFF is currently selected. The Client IP address is 71.7.176.108. There is a table with input boxes for Rule Name, Start IP, and End IP. One row of data is present in this table. The Rule Name is AllowIncoming SQL, Start IP is 71.7.176.108, and End IP is 71.7.176.108. [Video description ends]

I've already added a firewall exception to allow my current client IP address, my public IP.

[Video description begins] He highlights the client IP address. [Video description ends]

I've made a firewall rule to allow traffic from this address. This is my on-premises public IP as it's known out on the Internet.

[Video description begins] He highlights the Start IP and End IP in the table. [Video description ends]

The other thing that we can do here, let me just close this out, is open up the Properties blade for our deployed SQL database in the cloud.

[Video description begins] He closes the current page and shifts to the All resources page. [Video description ends]

And from here, we can see the server name that we can simply copy.

[Video description begins] He clicks on db112 (sqlsrv3362/db112). A page titled db112 (sqlsrv3362/db112)appears. It has a navigation pane. The main body has details about the server. Some of these are: Status, Location, Subscription, Server name, etc. He copies the Server name. The Server name is: sqlsrv3362.database.windows.net. [Video description ends]

So what I'm going to do now is go to my on-premises environment and launch the SQL Server Management Studio tool.

[Video description begins] A window titled Microsoft SQL Server Management Studio appears. It has a menu bar and a tool bar. It has a section titled Object Explorer. It has a Connect button with a drop-down arrow. A few more buttons are present here. [Video description ends]

Specifically, this is the Microsoft SQL Server Management Studio tool for SQL Server 2014. What I'm going to do here is click Connect over on the left.

[Video description begins] He clicks the Connect button. A list of options appears. These are: Database Engine, Analysis Services, Integration Services, Reporting Services, and Azure Storage. [Video description ends]

What I want to do is connect to a database engine.

[Video description begins] He selects Database Engine. A window titled Microsoft SQL Server 2014 appears. It has drop-down menus for Server type, Server name, Authentication, and Login. An input box for Password is also present. The default value for Server type is Database Engine. The default value for Server name is sqlsrv3362.database.windows.net. The default value for Authentication is SQL Server Authentication. The default value for Login is cirving. At the bottom, there are four buttons: Connect, Cancel, Help, and Options. [Video description ends]

And I want to make sure that I've got the SQL Server name that I copied from Azure listed here, and I do.

[Video description begins] He highlights the Server name. [Video description ends]

Now when I deployed that SQL Server, I specified an admin name of cirving, so I've got that there. Now, I just have to supply the password that I specified when I deployed that SQL server instance. Once I've done that, I can go ahead and click on the Connect button.

[Video description begins] He enters the password. He clicks the Connect button. In the Object Explorer section, a server named sqlsrv3362.database.windows.net opens. It has two folders: Databases and Security. [Video description ends]

Because the firewall allows connectivity from this host behind a NAT firewall, we can see now that we are indeed connected to our Azure SQL database instance. And if I start going down under Databases to take a peek, here's db112 or database 112, where if we flip back to the portal, we can see indeed that is the name of our Azure deployed SQL database.

[Video description begins] He expands the Databases folder. It has two folders: System Databases and db112. He then expands the db112 folder. It has a list of folders. Some of these are: Tables, Views, Synonyms, etc. He shifts to the Microsoft Azure webpage. The page titled db112 (sqlsrv3362/db112) is currently open. [Video description ends]

[Video description begins] He highlights the title of the page. [Video description ends]

Azure Database Migration Service

[Video description begins] Topic title: Azure Database Migration Service. Your host for this session is Dan Lachance. [Video description ends]

The Azure Database Migration Service allows you to keep your existing data and simply move it into the cloud. So we're talking about moving database workloads from an on-premises IT environment into Microsoft Azure. Now, the movement of that data can happen through a site-to-site VPN tunnel that you would've first defined between your on-premises network and an Azure virtual network or you might do that movement of data through an ExpressRoute circuit.

ExpressRoute does not go through the Internet. Instead, it is a dedicated network circuit from your on-premises network directly into the Azure cloud. And depending on where you are in the world, this may not be an option. But generally, it is conceptually a choice that we at least have to examine when we're going to be moving or migrating data from on-premises into Azure.

The Azure database migration process begins with discovery. What we're talking about discovering are database items available on-premises. The next thing is assessing the workloads that use those databases to determine whether or not they can be migrated into Azure.

[Video description begins] Screen title: Azure Database Migration Process. [Video description ends]

The convert part of the process means that we want to take a look at the database schema on-premises. The schema is the blueprint of what type of data is allowed to be stored, and we want to make sure that, that schema will function correctly in the Azure environment. This is normally not an issue unless, on-premises, you've customized your database schema to support non-standard data types, for example.

Now, that's all considered pre-migration in terms of tasks. The next thing that we have is to actually migrate the schema and data objects. Depending on the amount of data you're talking about and the speed of your network link to the Azure cloud, we'll determine how long it will take to bring across very large data sets.

Next, we've got data synchronization, so the data that's migrated into Azure is kept in sync with on-premises data during this transitory process. Finally, at the cutover stage, we actually cut ties with the on-premises data source. And so there is no longer synchronization between on-premises and Azure cloud hosted data.

[Video description begins] An illustration appears. There are two boxes titled: Pre-migration and Migration. The Pre-migration box has Discover, Assess, and Convert. The Migration box has Migrate schema & data object, Data sync, and Cutover . Discover is connected to Assess which is then connected to Convert. Convert is connected to Migrate schema & data object, which is then connected to Data sync. Data sync is connected to Cutover. [Video description ends]

As we'll see in a different demonstration, we start the process of working with Azure Database Migration by actually creating a database migration instance. And we can do that, for example, through the Azure portal. From there, it will take us through all of these steps in the database migration process.

SQL Server Migration Assessment

[Video description begins] Topic Title: SQL Server Migration Assessment. Your host for this session is Dan Lachance. [Video description ends]

The SQL Server Migration Assessment tool allows you to run this on-premises, so you can assess what you currently have running and which are likely candidates for being migrated into the Azure cloud.

[Video description begins] The Microsoft webpage is open on the screen. The Download Center page is currently open. It has a list of options at the top. Some of these are: Windows, Office, Web browsers, etc. The page has a section titled Microsoft Data Migration Assistant v4.2. A Download button is present in this section. [Video description ends]

So here, I've gone to the Microsoft.com website, and I've searched the downloads for the Migration Assistant. So we can see here, Data Migration Assistant v4.2, at least at the time of this recording. So I have to go ahead and download that tool.

[Video description begins] He clicks the Download button. A File explorer opens up. The Downloads folder is currently open. It has a file named DataMigrationAssistant.msi. [Video description ends]

Once it's downloaded, I'm going to go ahead and run the installer, so it's called the DataMigrationAssistant.msi. So I'm just going to right-click on that and choose Install.

[Video description begins] He right-clicks on the file. A list of options appears. He selects Install from the list. A window titled Microsoft Data Migration Assistant Setup is launched. It has three buttons at the bottom: Back, Next, and Cancel. [Video description ends]

I'll choose Next, I will accept the terms of the license agreement, I'll click Next again, and it'll just go ahead and run the installation.

[Video description begins] He clicks the Next button. The End-User License Agreement appears on the next screen. It has a check box for accepting the terms of the License Agreement. He checks the box. At the bottom there are four buttons: Print, Back, Next, and Cancel. He clicks the Next button. A Privacy Statement appears on the next screen. It has three buttons at the bottom: Back, Install, and Cancel. He clicks the Install button. A progress bar displaying the installation status appears on the next screen. At the bottom, there are three buttons: Back, Next, and Cancel. Once the installation is complete, the screen reads: Completed the Microsoft Data Migration Assistant Setup Wizard. This screen has a check box for Launch Microsoft Data Migration Assistant. At the bottom, there is a Finish button. [Video description ends]

Before you know it, it's done. So, there's a check box here on the installation screen to launch the Microsoft Data Migration Assistant. Of course, I could launch it after through my Start menu, but I'm going to go ahead and turn that check mark on, and I'm going to click Finish.

[Video description begins] He checks the box for Launch Microsoft Data Migration Assistant and clicks the Finish button. [Video description ends]

Now it's loading the Microsoft Data Migration Assistant.

[Video description begins] A window titled Data Migration Assistant opens up. On one side of the window, there is a toolbar. [Video description ends]

So the first thing I'll do here is click the new button, the plus sign, to create a new migration project.

[Video description begins] He clicks the + sign in the toolbar. A window titled New appears. It has two options for Project type: Assessment and Migration. Assessment is selected by default. There is an input box for Project name. Drop-down menus for Source server type and Target server type are also present. The default value for Source server type is SQL Server. The default value for Target server type is Azure SQL Database. At the bottom, there is a Create button. [Video description ends]

Notice, we can build in assessment project, which is what we're going to do, to assess our on-premises SQL databases to test their suitability to be migrated to Azure. However, we can also actually perform a migration. However, we're not going to build a migration project here, just assessment. So the project name here is going to be HfxProj1 because my city, where this is happening on-premises, is Halifax.

[Video description begins] In the input box for Project name, he types HfxProj1. [Video description ends]

And the source server will be SQL, the target will be Azure SQL database. I'll click create, then I'm going to click Next.

[Video description begins] He clicks the Create button. A page titled HfxProj1 appears. It has three steps of creation. The first step called Options is currently displayed. Three options for report type are present here. These are: Check database compatibility, Check feature parity, and Benefit from new features. The first two are selected by default. At the bottom, there is a Next button. [Video description ends]

I'm going to give it some details, such as the name of the on-premises server that I want to use.

[Video description begins] He clicks the Next button. The screen shifts to the next step, which is Select sources. It has two buttons: Add sources and Remove sources. A window titled Connect to a server slides onto the screen. It has drop-down menus for Server name and Authentication type. The default value for Authentication type is Windows Authentication. For Connection properties, there are two options with check boxes. These are: Encrypt connection and Trust server certificate. Both the options are checked by default. At the bottom, there is a Connect button. In the drop-down menu for Server name, he selects srv2016-1. He retains the default value for Authentication type. [Video description ends]

So I'll fill that in, that's my on-premises SQL server. It uses Windows Authentication, but I could choose the appropriate authentication type. If you're not sure what to choose here, talk to your on-prem SQL people and I'm going to click Connect. We're not going to change anything else here.

[Video description begins] He clicks the Connect button. The window titled Connect to a server disappears. A new window titled Add sources appears. It has a check box for srv2016-1. Below it, there are four options with check boxes for sources. These are: CM_S01, ReportServer, ReportServerTempDB, and XTrans. At the bottom, there is an Add button. [Video description ends]

So I know it's made a good connection because I have a list of valid databases that are being hosted on that SQL server instance. So I'm just going to choose one of the databases in question that I'm thinking about migrating to Azure, and I'm going to click Add.

[Video description begins] He selects CM_S01. srv2016-1 gets automatically selected. He clicks the Add button. The window titled Add sources disappears. On the screen for the second step, which is Select sources, CM_S01 is added. At the bottom of this screen, there are two buttons: Back and Start Assessment. [Video description ends]

So we can see it's been added here. And we can add and remove sources at will here to determine what we want our assessment to be run against. So I'm going to go ahead and click Start Assessment in the bottom right.

[Video description begins] He clicks the Start Assessment button. The screen shifts to the third step, which is Review results. On one side of this screen, there are two options with radio buttons. These are SQL Server feature parity and Compatibility issues. SQL Server feature parity is selected by default. Below these options, there is a search box and below this box, srv2016-1 is present. In the main body of the screen, a tab titled Feature parity appears. It has a list of Unsupported features, and a section titled Cross-database references not supported in Azure SQL Database. This section has two sub-parts: Details and Databases. At the bottom, there is an Export report button. [Video description ends]

Once the assessment is complete, we can see that we are in step 3, where we're reviewing the results. And so we can see our SQL server on-premises listed over here on the left. And then we can see our listed items of unsupported features.

So the service broker feature not being supported in the Azure cloud and when we select that unsupported feature, we get some details listed over here on the right.

[Video description begins] From the list of Unsupported features, the presenter selects Service Broker feature is not supported. Its details appear in the Details section of the page. He scrolls down the Details section. A section titled Recommendation appears. [Video description ends]

Then we also get some recommendations about what we might be able to do to resolve this issue once the database has actually been migrated into the Azure Cloud.

[Video description begins] He highlights the following lines from the Recommendation section: Once the database has been migrated to Azure, you can look into Azure Service Bus functionality to implement a generic, cloud-based messaging system instead of Service Broker. [Video description ends]

Now, also remember that once you're happy with this, you can actually add an actual migration project,

[Video description begins] He clicks the + sign in the toolbar. The window titled New appears. He selects Migration for Project type. [Video description ends]

where you can actually start moving data into the cloud. So this migration assistant is a great tool then for you to evaluate your on-premises SQL databases and how likely they are as candidates for running in the Azure cloud.

[Video description begins] He closes the window titled New. [Video description ends]

Azure SQL Geo-Replication

[Video description begins] Topic Title: Azure SQL Geo-Replication. Your host for this session is Dan Lachance. [Video description ends]

To increase fault tolerance and availability for Azure SQL, we have the option of enabling Geo-Replication.

[Video description begins] A Microsoft Azure webpage displays on the screen. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present here with the following options: Create a resource, Home, Dashboard, All services, and Favorites. The main body of the page has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

Here in the portal, I've already got Azure SQL deployed. So if I go to the All resources view, and if I filter that view for anything that has a prefix of SQL, we can see both.

[Video description begins] From the navigation pane, he clicks on All resources present under Favorites. A page titled All resources appears. It has the following buttons on the top: Add, Edit columns, Refresh, etc. Below the buttons, there is an input box for name and drop-down menus for resource groups, types, location, tags, and grouping. Below these, there is a table with the following columns: Name, Type, Resource Group, Location, Subscription, and Tags. A few rows of data are present in this table. [Video description ends]

We've got a SQL Server and a single SQL database instance hosted on that server.

[Video description begins] He types sql in the input box for name. Two rows of data can be seen in the table. [Video description ends]

If I click on the server to open up its Properties blade, you'll notice that we don't have any options related to Geo-Replication, at least not at the server level.

[Video description begins] He clicks on sqlsvr172 in the table. A screen titled sqlsvr172 appears. It has a navigation pane. The main body contains details about the server. At the bottom, there are two tabs: Notifications and Features. The Features tab is currently selected. It has four tabs: All, Security, Performance, and Recovery. [Video description ends]

However, if I get back out of that, if I go into my database property sheet, notice that Geo-Replication is an option.

[Video description begins] He closes the sqlsvr172 page and shifts to the All resources page. He clicks on the 2nd sql resource listed in the table. A page titled sqldb172(sqlsvr172 /sqldb172) opens up. It has a navigation pane. The main body contains details about the server. Some of these are: Status, Location, Subscription, Server name, etc. He selects Geo-Replication from the navigation pane. A world map is displayed on the screen. [Video description ends]

Now currently, we can see that we've got an area on the map here in Eastern Canada where we've currently got our current SQL database deployed. That's the Azure region or location.

[Video description begins] The East Canada region has a blue tick mark on the map. [Video description ends]

Now if you're not so great with your geography, don't worry if you don't know what you're looking at on the map. Because when I scroll down a little bit, I can see indeed Canada East is that current region.

[Video description begins] He scrolls down the page. Below the map, there is a table with three columns: Server/Database, Failover Policy, and Status. In the table, there are two sections: Primary and Secondaries. Under Primary, Canada East is listed. Its Server/Database is sqlsvr172 /sqldb172, Failover Policy is None and Status is Online. [Video description ends]

And I can see the status of that replica is that it's online. Down below, it says for secondaries, Geo-Replication is not configured, and we can see here the list of target regions.

[Video description begins] He scrolls down the page. A section titled Target Regions appears. Some of the regions listed here are: West US, Canada Central, Brazil South, North Europe, etc. [Video description ends]

So let's say, for example, I want this to be replicated to Canada Central as a different region.

[Video description begins] He clicks on Canada Central from the list. A page titled Create secondary appears. It has the following criteria: Region, Database name, Secondary type, Target server, Elastic pool, and Pricing tier. The Region is Canada Central, Database name is sqldb172, Secondary type is Readable, Target server is Configure required settings, Elastic pool is None, and Pricing tier is Configure required settings. Lock icons are present next to Region, Secondary type, Elastic pool, and Pricing tier. At the bottom, there is an OK button. [Video description ends]

Now the secondary type is by default set to a readable replica of our Azure SQL database. Then for the target server, I have to configure settings. Now, what that means is I need another Azure SQL server instance.

[Video description begins] He clicks on Target server. A page titled Server appears. It has a button titled Create a new Server. No servers are listed on this page. Next to it, another page opens up. It is titled New Server. It has input boxes for Server name, Server admin login, Password, Confirm password, and a drop-down menu for Location. Below these fields, there is a check box that reads: Allow Azure services to access server. This check box as a tick mark. At the bottom, there is a Select button. [Video description ends]

Now if I don't have one, I have to create one here. So I'm going to call this sqlsvr172_central. You'll notice that it's going to tell me over here if it likes underscores, upper case letters, lower case letters. So notice here, it doesn't like a lot of the items that are specified here in the name.

[Video description begins] In the input box for Server name, he types sqlsvr172 _central. An error message pops up. It reads: Your server name can contain only lowercase letters, numbers, and '-', but can't start or end with '-' or have more than 63 characters. He then types sqlsvr172 central. [Video description ends]

So I'm just going to call it sqlsvr172central. And I'm going to specify the credentials and password here which do not have to be the same as they are for the primary server holding the master writable replica.

[Video description begins] The credentials for Server admin login, Password, and Confirm password appear. The login id is cirving. [Video description ends]

Once that's been filled in, I'm just going to go ahead and click Select.

[Video description begins] He clicks the Select button. The pages titled Server and New Server close. [Video description ends]

So really we're creating a new SQL Server instance to accommodate our Geo-Replication to a different Azure region. I'm going to leave the standard pricing tier as it is, and I'm going to click OK.

[Video description begins] In the page titled Create secondary, Target server changes to sqlsvr172 central (Canada Central) and Pricing tier changes to Standard S0: 10 DTUs, 250 GB. He clicks the OK button. The Create secondary page closes. [Video description ends]

Now currently, we have a message about the deployment being in progress up here in the upper right in the Azure portal.

[Video description begins] He points to the pop-up box titled Deployment in progress. [Video description ends]

And if I kind of scroll up here, and take a look here, after a moment, we'll see that it will reflect that we've got Geo-Replication from the Canada East region to the Canada Central region.

[Video description begins] On the map, a green dot with a check mark appears in the Canada Central region. [Video description ends]

And before you know it, you'll have this little check mark in these regions that are filled in with the solid color. You can see the other regions that are not filled in, and they do not have a check mark. So therefore, we don't have a replica of this SQL database in those locations.

And if we scroll down, we can see that represented in textual form. So, not only do we have our original online master replica in Canada East listed here at the top, but we can also see we've got a secondary now in the Canada Central region, and it's currently listed as being readable.

[Video description begins] He scrolls down to the table. Under Secondaries, Canada Central is listed. Its Server/Database is sqlsvr172 central/sqldb172. The Status is Readable.... [Video description ends]

Now if you click the ellipsis button, the three dots with the context menu next to the word readable, you'll have the option to force a failover which essentially promotes this to be the primary replica, and the other current primary would then become a secondary. It does say that this can cause some data loss while you're doing this.

[Video description begins] The presenter clicks the three dots next to Readable. Three options appear: Pin to dashboard, Forced Failover, and Stop Replication. He clicks on Forced Failover. A pop-up box titled Failover appears. It has two buttons: Yes and No. [Video description ends]

Also notice that we do have the option also of stopping replication, so, for instance, if there's a failure or a disaster in our primary region.

[Video description begins] He again clicks on the three dots next to Readable. He then points to Stop Replication from the list of options. [Video description ends]

NoSQL Overview

[Video description begins] Topic title: NoSQL Overview. Your host for this session is Dan Lachance. Screen title: NoSQL Databases. [Video description ends]

In the Microsoft Azure Environment, you can choose to deploy a SQL compliant type of database or a NoSQL database, so it's important to know the difference between the two. With NoSQL databases, we have a less rigid schema than with a traditional, relational database, such as MySQL or Microsoft SQL Server.

The schema, remember, is the blueprint of what type of data is allowed to be stored. And, so, with NoSQL, it's really designed to be much less structured to allow or accommodate for the storage of many different types of data. NoSQL is also designed for high scalability because it's really what is often used to work with very large data sets.

[Video description begins] Screen title : NoSQL Database Characteristics. [Video description ends]

So high performance and availability are a big part of NoSQL. Essentially, the manipulation and analysis of big data. With NoSQL, each stored row can actually store different types of data. That's unlike a relational database structure that has a blueprint or schema that defines exactly what can be stored in each row within a table.

We don't have that kind of structured limitation with a NoSQL database. There are a number of different types of storage configurations for NoSQL databases, such as key and value pairs, or NoSQL document stores, or graph database stores, but in the end, a NoSQL database is not relational.

[Video description begins] Screen title: NoSQL Horizontal Scaling. [Video description ends]

NoSQL uses horizontal scaling extensively as a traditional relational database system can as well.

[Video description begins] A diagram appears on the screen. It has a box with four blocks placed side by side. Below the box, there is a forward arrow. [Video description ends]

What this means is scaling out, as we see pictured in the diagram by adding database servers to handle the workload. Now this can be done for clustering purposes, for load balancing, and for replication of data.

[Video description begins] Screen title: Common NoSQL Database Products. [Video description ends]

Common NoSQL products include Azure CosmosDB, Azure Redis memory caching, which allows us to take data and cache it in memory. Data that is accessed frequently, so that subsequent requests are a service from the cache, which is much quicker than reading it from disk.

There are also numerous database options, including for NoSQL available to the Azure marketplace. So you can choose to deploy a new Virtual Machine instance that has a variety of different NoSQL products installed and configured for you already.

CosmosDB

[Video description begins] Topic title: CosmosDB. Your host for this session is Dan Lachance. [Video description ends]

Azure CosmosDB is a NoSQL database option available in Microsoft Azure. So it's a NoSQL solution that is globally distributed across Azure regions. This global distribution means that users can contact the nearest replica of CosmosDB to work with the data. And that way, there's a better user experience instead of accessing it across multiple Azure regions.

Azure CosmosDB supports default encryption of data at rest, and it's used by a lot of popular services that you've probably heard of, like Xbox, Office 365, and Skype. When you start to deploy Azure CosmosDB, you begin by creating an Azure CosmosDB account, as we'll see in another demonstration. You also get to select the appropriate API for the account type.

Now, we might choose, for example, a certain type of account type like Gremlin if we want to use graph databases, or MongoDB if we're using a document type of database, and so on. So we'll see that as well when we configure Azure CosmosDB in a demonstration.

We can import data into CosmosDB from a number of different sources, including SQL databases. Now, even though CosmosDB is generally considered NoSQL, we still have the option of bringing in SQL data to store it in here. We also can specify CSV or comma separated value files as a data source or JSON files, and even standard NoSQL compliant databases like MongoDB.

Deploy CosmosDB

[Video description begins] Topic Title: Deploy CosmosDB. Your host for this session is Dan Lachance. [Video description ends]

Microsoft Azure CosmosDB is a great choice when you have vast amounts of unstructured data that you want to store and manage in the cloud. I'm going to start here in the left-hand navigator in the Azure Portal by clicking Create a resource, and I'll search for cosmos.

[Video description begins] A Microsoft Azure webpage displays on the screen. It has a menu bar with a search bar and the following options: Filter, Notifications, Settings, etc. A navigation pane is also present here with the following options: Create a resource, Home, Dashboard, All services, and Favorites. The main body of the page has a section titled Azure services. Some of the options here are: Virtual machines, Storage accounts, App Services, etc. [Video description ends]

[Video description begins] He clicks on Create a resource from the navigation pane. A screen titled New appears. It has a search bar and a column titled Azure Marketplace. Some of the items here are: Get started, Recently created, Compute, Networking, Databases, etc. A column titled Popular is also present on this screen. Some of the items here are: Windows Server 2016 Datacenter, Ubuntu Server 18.04 LTS, Web App, etc. [Video description ends]

[Video description begins] In the search bar, he types cosmos. A list of options appears. [Video description ends]

And from here, I'll choose Azure Cosmos DB, and then I'll click Create.

[Video description begins] He selects Azure Cosmos DB from the list of options. Some information about Azure Cosmos DB is displayed on the screen. Below it there is a Save for later button. A drop-down menu for Select a software plan is present on the screen, in which Azure Cosmos DB is selected by default. At the bottom, there is a Create button. He clicks the Create button. A page titled Create Azure Cosmos DB Account opens up. It has four tabs: Basics, Network, Tags, and Review + create. The Basics tab is currently open. It has two sections: Project details and Instance details. The Project details section has drop-down menus for Subscription and Resource Group. The Instance Details section has an input box for Account Name and drop-down menu for API. The default value for Subscription is Pay-As-You-Go. The default value for Resource Group is cloud-shell-storage-eastus. The default value for API is Core (SQL). At the bottom, there are three buttons: Review + create, Previous, and Next: Network. [Video description ends]

The first thing I'll do is place this into a resource group, and then, down below I need to create a Cosmos DB account name.

[Video description begins] He clicks the drop-down menu for Resource Group. A list of options appears. He selects Rg1 from the list. [Video description ends]

[Video description begins] He scrolls down the page. A drop-down menu for Location is also present on this page. Its default value is Australia East. For Geo-Redundancy, there are two options: Enable and Disable. Enable is selected by default. For Multi-region Writes, there are two options: Enable and Disable. Disable is selected by default. [Video description ends]

So I'm going to call this cosmosdb-acct172. Now, be careful because in some cases in Azure if you start to use weird symbols like underscores, it'll tell you. So luckily we have this kind of easy notification that there's something wrong with the name, so, just be aware of that.

[Video description begins] In the input box for Account Name, he types cosmosdb_acct172. An error message pops up. It reads: The name can contain only lowercase letters, numbers, and the '-' character, and must be between 3 and 31 characters. Name is invalid. He then types cosmosdb-acct172. [Video description ends]

Now for the API, I can determine exactly what it is I want to configure Cosmos DB as because really it's kind of like a multi-model type of solution. So, do we want to treat it as a core SQL solution?

Or do we want it to adhere to the MongoDB API standard, or Cassandra, or is it a table type of data store or a graph type of NoSQL data store? So in this example, I'll choose Azure Cosmos DB for Mongo DB API.

[Video description begins] He clicks the drop-down menu for API. A list of options appears. He selects Azure Cosmos DB for MongoDB API. [Video description ends]

Now, I would do that if I knew that I had perhaps an application or some code that was already written that needs to talk to the MongoDB API to access data. I'm going to specify an appropriate location.

[Video description begins] He clicks the drop-down menu for Location. A list of options appears. He selects Canada East from the list. [Video description ends]

I'm going to disable geo-redundancy. Notice, that was enabled by default for Cosmos DB. I also, of course, want to leave multi-region writes disabled since I've disabled geo-redundancy. When I click Next, I then have to place this into an Azure Vnet. So I'll choose a Vnet and a subnet.

[Video description begins] He clicks the Next: Network button. The screen shifts to the next tab titled Network. It has drop-down menus for Virtual Network and Subnet. He clicks the drop-down menu for Virtual Network. A list of options appears. He selects EastVnet1 from the list. A section titled Configure Firewall appears. For Allow access from Azure Portal, there are two options: Allow and Deny. Allow is selected by default. For Allow access from my IP (71.7.176.108), there are two options: Allow and Deny. Deny is selected by default. He clicks the drop-down menu for Subnet. A list of options appears. He selects EastSubnet1 from the list. At the bottom, there are three buttons: Review + create, Previous, and Next: Tags. [Video description ends]

And right now it's set to allow access from the Azure Portal, which is great. So I can use this portal GUI interface to make a connection to my Cosmos DB and also to connect to it and look at performance metrics and things of that nature.

And conveniently, it also has my current public IP address listed here, and I can click Allow to add, essentially, a firewall exception for CosmosDB, so that if I need to get in from on-premises, maybe I'm using a MongoDB GUI management tool, for example, that I will be able to get in, or maybe I've got some code segments running on-premises on a server that need to talk in Azure to my Cosmos DB to work with that. So I'm going to turn on Allow for that, and I'm going to click Next for tagging.

[Video description begins] He clicks on the Allow button for Allow access from my IP (71.7.176.108). [Video description ends]

Well, there's no tags in here to assign here so I'll just go to Review and create, and once the validation says it succeeded, I will create my Cosmos DB deployment.

[Video description begins] He clicks the Next: Tags button. The screen shifts to the next tab titled Tags. It has input boxes for Key, Value, and Resource Type. The default value for Resource Type is Azure cosmos DB account. At the bottom, there are three buttons: Review + create, Previous, and Next: Review + create. [Video description ends]

[Video description begins] He clicks the Next: Review + create button. The screen shifts to the next tab titled Review + create. A list of information is displayed on the screen. It has three sections: Basics, Virtual Network, and Firewall. At the bottom, there are two buttons: Create and Previous. [Video description ends]

[Video description begins] A pop-up message appears at the top of the screen. It reads: Validation Success. The presenter clicks the Create button. A page titled Microsoft.Azure.CosmosDB-20190313130002-Overview appears. It has a navigation pane with the following options: Overview, Inputs, Outputs, and Template. The Overview tab is currently selected. The main body of the screen has the following heading: Your deployment is complete. Above the heading, the following buttons are present: Delete, Cancel, Redeploy, and Refresh. It has a Go to resource button. At the bottom there is a table with the following four columns: Resource, Type, Status, and Operation Details. The table has one row of data. [Video description ends]

And after a moment we can see our deployment is complete, and we've even got a view over on the left here called Azure Cosmos DB, and I can see my deployed instance listed here.

[Video description begins] From the navigation pane of the home page, the presenter clicks on Azure Cosmos DB. A page titled Azure Cosmos DB appears. It has the following buttons: Add, Reservations, Edit columns, and Refresh. It has a table with the following columns: Name, Status, Location, and Subscription. One row of data is present in the table where the Name is cosmosdb-acct172, Status is Online, Location is Canada East, and Subscription is Pay-As-You-Go. [Video description ends]

I'm going to click it, and here we can see a number of interesting items.

[Video description begins] He clicks on cosmosdb-acct172. A page titled cosmosdb-acct172 appears. It has a navigation pane. The following buttons are present on this page: Add Collection, Refresh, Move, Delete Account, etc. Below the buttons, there is a list of details. These include: Status, Resource group, Read Location, Write Location, etc. [Video description ends]

For example, as I scroll down in the Overview part of the Properties blade, I can see the region into which it was deployed. This looks like Eastern Canada.

[Video description begins] He scrolls down the page. A section titled Regions appears. It has a world map. The East Canada region has a blue tick mark. [Video description ends]

And as I scroll down, I've also got this Data Explorer option, where I have buttons to create a new database or a new collection to begin working with data.

[Video description begins] From the navigation pane, he clicks on Data Explorer. A Data explorer page opens up. The following buttons are present here: New Database, New Collection, and Open Full Screen. [Video description ends]

Of course, you can do this programatically or using command line tools or even GUI tools that you might even run on-premises. You would just need to make sure you have a way to access Cosmos DB, and we're talking really here about adding a firewall exception, so here in the Properties blade, if I go to Firewall and virtual networks, notice here that my client IP, my public IP on the Internet, has been added here as being allowed in.

[Video description begins] He clicks on Firewall and virtual networks from the navigation pane. A page for Firewall and virtual networks opens up. For the field, Allow access from, there are two options with radio buttons: All networks and Selected networks. The Selected networks option is selected by default. A section titled Virtual networks is also present. It has a table with the following columns: Virtual Network, Subnet, Address Range, Endpoint Status, Resource Group, and Subscription. One row of data is present here. Virtual Network is eastvnet1, Subnet is 1, Address Range is 10.1.0.0/16, Resource Group is rg1, and Subscription is Pay-As-You-Go. Below it, there is a section titled Firewall. The following IP address is listed here. 71.7.176.108. [Video description ends]

[Video description begins] He highlights the following IP address: 71.7.176.108. [Video description ends]

But you would also need to go to Connection String because you would have to have the correct Cosmos DB host name, the port number to connect to, as well as the Cosmos DB user name, and either the primary or secondary password.

[Video description begins] From the navigation pane, he clicks on Connection String. A page for Connection String opens up. It has two tabs: Read-write Keys and Read-only Keys. Read-write Keys is currently open. It has the following criteria listed: Host, Port, Username, Primary Password, Secondary Password, Primary Connection String , Secondary Connection String, etc. The presenter highlights the values for Host, Port, and Username. The Host is cosmosdb-acct172.documents.azure.com. Port is 10255, and Username is cosmosdb-acct172. [Video description ends]

So you would do that, for example, if you were using some kind of MongoDB type of GUI tool on-premises that you wanted to reach into the cloud to this instance to make changes to.

[Video description begins] He highlights the Primary Password. [Video description ends]
